text,label
"TEST_F(EnvLoggerTest, VerifyEmptyLogFile) {
  auto log_handler = CreateLogger();
  ASSERT_EQ(log_handler->Close(), Status::OK());

  // Check the log file size.
  uint64_t log_file_size;
  ASSERT_EQ(env_->GetFileSize(kLogFile, &log_file_size), Status::OK());
  ASSERT_EQ(log_file_size, 0);
  RemoveLogFile();
}",3
"TEST_F(FsTest, createDirectory) {
  auto dir = exec::test::TempDirectoryPath::create();
  auto rootPath = dir->getPath();
  auto tmpDirectoryPath = rootPath + ""/first/second/third"";
  

  std::thread t1([&]() {
    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 10)); // Random delay
    EXPECT_FALSE(fs::exists(tmpDirectoryPath.c_str()));
  });

  t1.join(); // Ensure the concurrent operation is completed

  // First time should generate directory successfully.
  EXPECT_TRUE(generateFileDirectory(tmpDirectoryPath.c_str()));
  EXPECT_TRUE(fs::exists(tmpDirectoryPath.c_str()));

  std::thread t2([&]() {
    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 10)); // Random delay
    EXPECT_TRUE(generateFileDirectory(tmpDirectoryPath.c_str()));
  });

  t2.join(); // Ensure the concurrent operation is completed

  // Directory already exists, not creating but should return success.
  EXPECT_TRUE(generateFileDirectory(tmpDirectoryPath.c_str()));
  EXPECT_TRUE(fs::exists(tmpDirectoryPath.c_str()));
  dir.reset();
  EXPECT_FALSE(fs::exists(rootPath.c_str()));
}",1
"TEST_F(ExternalSSTFileBasicTest, AddFilesWithoutCopyTest) {
  Options options = CurrentOptions();
  const ImmutableCFOptions immutable_options(options);
  SstFileWriter sst_writer(EnvOptions(), options);

  // sst_file_a.sst (0 => 99)
  std::string sst_file_a = sst_files_dir_ + ""sst_file_a.sst"";
  ASSERT_OK(sst_writer.Open(sst_file_a));
  for (int i = 0; i < 100; i++) {
    ASSERT_OK(sst_writer.Put(Key(i), Key(i) + ""_data""));
  }
  ExternalSstFileInfo file_a_info;
  Status result = sst_writer.Finish(&file_a_info);
  ASSERT_OK(result) << result.ToString();
  ASSERT_EQ(file_a_info.file_path, sst_file_a);
  ASSERT_EQ(file_a_info.num_entries, 100);
  ASSERT_EQ(file_a_info.smallest_key, Key(0));
  ASSERT_EQ(file_a_info.largest_key, Key(99));

  // sst_file_b.sst (100 => 299)
  std::string sst_file_b = sst_files_dir_ + ""sst_file_b.sst"";
  ASSERT_OK(sst_writer.Open(sst_file_b));
  for (int i = 100; i < 300; i++) {
    ASSERT_OK(sst_writer.Put(Key(i), Key(i) + ""_data""));
  }
  ExternalSstFileInfo file_b_info;
  result = sst_writer.Finish(&file_b_info);
  ASSERT_OK(result) << result.ToString();
  ASSERT_EQ(file_b_info.file_path, sst_file_b);
  ASSERT_EQ(file_b_info.num_entries, 200);
  ASSERT_EQ(file_b_info.smallest_key, Key(100));
  ASSERT_EQ(file_b_info.largest_key, Key(299));

  // sst_file_c.sst (110 => 124) .. overlap with sst_file_b.sst
  std::string sst_file_c = sst_files_dir_ + ""sst_file_c.sst"";
  ASSERT_OK(sst_writer.Open(sst_file_c));
  for (int i = 110; i < 125; i++) {
    ASSERT_OK(sst_writer.Put(Key(i), Key(i) + ""_data_overlap""));
  }
  ExternalSstFileInfo file_c_info;
  result = sst_writer.Finish(&file_c_info);
  ASSERT_OK(result) << result.ToString();
  ASSERT_EQ(file_c_info.file_path, sst_file_c);
  ASSERT_EQ(file_c_info.num_entries, 15);
  ASSERT_EQ(file_c_info.smallest_key, Key(110));
  ASSERT_EQ(file_c_info.largest_key, Key(124));

  result = DeprecatedAddFile({sst_file_a}, true /* move file */);
  ASSERT_OK(result) << result.ToString();
  ASSERT_EQ(Status::NotFound(), env_->FileExists(sst_file_a));

  result = DeprecatedAddFile({sst_file_b}, false /* copy file */);
  ASSERT_OK(result) << result.ToString();
  ASSERT_OK(env_->FileExists(sst_file_b));

  result = DeprecatedAddFile({sst_file_c}, true /* move file */);
  ASSERT_NOK(result) << result.ToString();
  ASSERT_OK(env_->FileExists(sst_file_c));

  for (int i = 0; i < 300; i++) {
    ASSERT_EQ(Get(Key(i)), Key(i) + ""_data"");
  }
}",3
"TEST(AsyncSourceTest, ConcurrentThreads) {
  constexpr int32_t num_threads = 10;
  constexpr int32_t num_gizmos = 2000;
  folly::Synchronized<std::unordered_set<int32_t>> results_set;
  std::vector<std::shared_ptr<AsyncSource<Gizmo>>> gizmo_sources;
  for (auto i = 0; i < num_gizmos; ++i) {
    gizmo_sources.push_back(std::make_shared<AsyncSource<Gizmo>>([i]() {
      std::this_thread::sleep_for(std::chrono::milliseconds(1)); // NOLINT
      return std::make_unique<Gizmo>(i);
    }));
  }

  std::vector<std::thread> thread_pool;
  thread_pool.reserve(num_threads);
  for (int32_t thread_index = 0; thread_index < num_threads; ++thread_index) {
    thread_pool.push_back(std::thread([thread_index, &gizmo_sources, &results_set]() {
      if (thread_index < num_threads / 2) {
        // First half of the threads prepares Gizmos.
        for (auto i = 0; i < num_gizmos; ++i) {
          gizmo_sources[i]->prepare();
        }
      } else {
        // Remaining threads randomly obtain and collect Gizmos.
        folly::Random::DefaultGenerator random_gen;
        std::shuffle(gizmo_sources.begin(), gizmo_sources.end(), random_gen);

        for (auto i = 0; i < num_gizmos / 3; ++i) {
          auto gizmo = gizmo_sources[folly::Random::rand32(random_gen) % gizmo_sources.size()]->move();
          if (gizmo) {
            results_set.withWLock([&](auto& set) {
              EXPECT_TRUE(set.find(gizmo->id) == set.end());
              set.insert(gizmo->id);
            });
          }
        }
        for (auto i = 0; i < gizmo_sources.size(); ++i) {
          auto gizmo = gizmo_sources[i]->move();
          if (gizmo) {
            results_set.withWLock([&](auto& set) {
              EXPECT_TRUE(set.find(gizmo->id) == set.end());
              set.insert(gizmo->id);
            });
          }
        }
      }
    }));
  }
  for (auto& t : thread_pool) {
    t.join();
  }
  results_set.withRLock([&](auto& set) {
    for (auto i = 0; i < num_gizmos; ++i) {
      EXPECT_TRUE(set.find(i) != set.end());
    }
  });
}",9
"TEST_F(ImportColumnFamilyTest, CFImportNegativeTest) {
  Options db_options = CurrentOptions();
  CreateAndReopenWithCF({""beta""}, db_options);
  {
    // Create column family with an already existing name.
    ExportImportFilesMetaData file_meta_data;

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""beta"",
                                                ImportColumnFamilyOptions(),
                                                file_meta_data, &import_cfh_),
              Status::InvalidArgument(""Column family already exists""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Import with no file list provided.
    ExportImportFilesMetaData file_meta_data;

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""zeta"",
                                                ImportColumnFamilyOptions(),
                                                file_meta_data, &import_cfh_),
              Status::InvalidArgument(""The list of files is empty""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Import with overlapping key ranges.
    ExportImportFilesMetaData file_meta_data;
    SstFileWriter sst_writer(EnvOptions(), db_options, handles_[1]);
    const std::string sst_file1 = ""test1.sst"";
    const std::string file_path1 = sst_files_dir_ + sst_file1;
    ASSERT_OK(sst_writer.Open(file_path1));
    ASSERT_OK(sst_writer.Put(""Key1"", ""Val1""));
    ASSERT_OK(sst_writer.Put(""Key2"", ""Val2""));
    ASSERT_OK(sst_writer.Finish());
    const std::string sst_file2 = ""test2.sst"";
    const std::string file_path2 = sst_files_dir_ + sst_file2;
    ASSERT_OK(sst_writer.Open(file_path2));
    ASSERT_OK(sst_writer.Put(""Key2"", ""Val2""));
    ASSERT_OK(sst_writer.Put(""Key3"", ""Val3""));
    ASSERT_OK(sst_writer.Finish());
    file_meta_data.files.push_back(
        LiveFileMetaDataInit(sst_file1, sst_files_dir_, 1, 10, 19));
    file_meta_data.files.push_back(
        LiveFileMetaDataInit(sst_file2, sst_files_dir_, 1, 10, 19));
    file_meta_data.db_comparator_name = db_options.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""zeta"",
                                                ImportColumnFamilyOptions(),
                                                file_meta_data, &import_cfh_),
              Status::InvalidArgument(""Files have overlapping ranges""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Import with incompatible comparator.
    ExportImportFilesMetaData file_meta_data;
    Options invalid_options = CurrentOptions();
    invalid_options.comparator = ReverseBytewiseComparator();
    SstFileWriter writer_cf(EnvOptions(), invalid_options, handles_[1]);
    const std::string sst_file = ""test1.sst"";
    const std::string file_path = sst_files_dir_ + sst_file;
    ASSERT_OK(writer_cf.Open(file_path));
    ASSERT_OK(writer_cf.Put(""Key1"", ""Val1""));
    ASSERT_OK(writer_cf.Put(""Key2"", ""Val2""));
    ASSERT_OK(writer_cf.Finish());
    file_meta_data.files.push_back(
        LiveFileMetaDataInit(sst_file, sst_files_dir_, 1, 10, 19));
    file_meta_data.db_comparator_name = invalid_options.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""theta"",
                                                ImportColumnFamilyOptions(),
                                                file_meta_data, &import_cfh_),
              Status::InvalidArgument(""Comparator name mismatch""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Import with a missing SST file.
    ExportImportFilesMetaData file_meta_data;
    SstFileWriter writer_cf(EnvOptions(), db_options, handles_[1]);
    const std::string sst_file1 = ""test1.sst"";
    const std::string file_path1 = sst_files_dir_ + sst_file1;
    ASSERT    OK(writer_cf.Open(file_path1));
    ASSERT_OK(writer_cf.Put(""KeyA"", ""ValA""));
    ASSERT_OK(writer_cf.Put(""KeyB"", ""ValB""));
    ASSERT_OK(writer_cf.Finish());
    const std::string missing_sst_file = ""test3.sst"";
    file_meta_data.files.push_back(
        LiveFileMetaDataInit(sst_file1, sst_files_dir_, 1, 10, 19));
    file_meta_data.files.push_back(
        LiveFileMetaDataInit(missing_sst_file, sst_files_dir_, 1, 10, 19));
    file_meta_data.db_comparator_name = db_options.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""lambda"",
                                                ImportColumnFamilyOptions(),
                                                file_meta_data, &import_cfh_),
              Status::IOError(""No such file or directory""));
    ASSERT_EQ(import_cfh_, nullptr);

    // After the failure, test that importing with the same CF name works correctly.
    file_meta_data.files.pop_back();
    file_meta_data.db_comparator_name = db_options.comparator->Name();
    ASSERT_OK(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""lambda"",
                                                ImportColumnFamilyOptions(),
                                                file_meta_data, &import_cfh_));
    ASSERT_NE(import_cfh_, nullptr);
  }
}",3
"bool unusedFlag = false;

TEST(calculateSlowDownPointsCollision, MultipleCollisionsScenario)
{
  using behavior_velocity_planner::occlusion_spot_utils::calcSlowDownPointsForPossibleCollision;
  using behavior_velocity_planner::occlusion_spot_utils::PossibleCollisionInfo;
  using std::chrono::duration;
  using std::chrono::duration_cast;
  using std::chrono::high_resolution_clock;
  using std::chrono::microseconds;
  
  std::vector<PossibleCollisionInfo> collisionList;
  autoware_auto_planning_msgs::msg::PathWithLaneId lanePath =
    test::generatePath(0.0, 3.0, 4.0, 3.0, 2000);
  test::generatePossibleCollisions(collisionList, 0.0, 3.0, 4.0, 3.0, 2000);

  auto timerStart = high_resolution_clock::now();
  calcSlowDownPointsForPossibleCollision(0, lanePath, 0, collisionList);

  auto timerEnd = high_resolution_clock::now();
  
  EXPECT_EQ(collisionList.size(), size_t{2000});
  EXPECT_EQ(lanePath.points.size(), size_t{2000});
  EXPECT_TRUE(duration_cast<microseconds>(timerEnd - timerStart).count() < 2000);
  std::cout << "" runtime (microsec) ""
            << duration_cast<microseconds>(timerEnd - timerStart).count() << std::endl;
}",6
"Status StressTest::ConfirmSnapshotValidity(DB* db_connection, ColumnFamilyHandle* cf_handle,
                                           ThreadState::SnapshotState& snapshot_state) {
  Status status;
  if (cf_handle->GetName() != snapshot_state.cf_at_name) {
    return status;
  }
  // Use ReadOptions with no rate-limiting for validation purposes.
  ReadOptions read_options;
  read_options.snapshot = snapshot_state.snapshot;
  Slice time_slice;
  if (!snapshot_state.timestamp.empty()) {
    time_slice = snapshot_state.timestamp;
    read_options.timestamp = &time_slice;
  }
  PinnableSlice expected_val(&snapshot_state.value);
  expected_val.PinSelf();
  PinnableSlice retrieved_val;
  status = db_connection->Get(read_options, cf_handle, snapshot_state.key, &retrieved_val);
  if (!status.ok() && !status.IsNotFound()) {
    return status;
  }
  if (snapshot_state.status != status) {
    return Status::Corruption(
        ""Snapshot key inconsistency for key "" +
        ToString(Hash(snapshot_state.key.c_str(), snapshot_state.key.size(), 0)) +
        "" in column family "" + cf_handle->GetName() + "": ("" +
        snapshot_state.status.ToString() + "") vs. ("" + status.ToString() + "")"");
  }
  if (status.ok()) {
    if (expected_val != retrieved_val) {
      return Status::Corruption(""Snapshot value mismatch: ("" +
                                expected_val.ToString() + "") vs. ("" +
                                retrieved_val.ToString() + "")"");
    }
  }
  if (snapshot_state.key_vec != nullptr) {
    std::vector<bool> bit_vector = GetKeyBitVec(db_connection, read_options);
    if (!std::equal(snapshot_state.key_vec->begin(), snapshot_state.key_vec->end(), bit_vector.begin())) {
      return Status::Corruption(""Snapshot key vector mismatch detected."");
    }
  }
  return Status::OK();
}",3
"std::string unusedString = ""unused_value"";

TEST(machineStateWithMarginTime, transitionStateWithMargin)
{
  StateMachine stateMachine = StateMachine();
  const double margin = 0.2;
  stateMachine.setMarginTime(margin);
  rclcpp::Logger loggerInstance = rclcpp::get_logger(""test_transition_state_with_margin"");
  stateMachine.setState(State::STOP);
  size_t loopCounter = 0;
  // loop until state changes from STOP -> GO
  while (stateMachine.getState() == State::STOP) {
    EXPECT_EQ(enumToInt(stateMachine.getState()), enumToInt(State::STOP));
    rclcpp::Clock clockInstance = rclcpp::Clock(RCL_ROS_TIME);
    if (stateMachine.getDuration() > margin) {
      std::cerr << ""stop duration exceeds margin"" << std::endl;
    }
    EXPECT_TRUE(stateMachine.getDuration() < margin);
    stateMachine.setStateWithMarginTime(State::GO, loggerInstance, clockInstance);
    loopCounter++;
  }
  // time past STOP -> GO
  if (loopCounter > 2) {
    EXPECT_TRUE(stateMachine.getDuration() > margin);
    EXPECT_EQ(enumToInt(stateMachine.getState()), enumToInt(State::GO));
  } else {
    std::cerr << ""[Warning] insufficient computational resources"" << std::endl;
  }
}",4
"TEST_P(TcpProxyOdcdsIntegrationTest, CloseAllConnectionsOnClusterLookupTimeout) {
  setUpShortTimeout();
  initialize();
  // Open a TCP request to Envoy.
  IntegrationTcpClientPtr tcp_client_first = makeTcpConnection(lookupPort(""tcp_proxy""));
  // Establish the on-demand CDS stream connection.
  auto result = fake_upstreams_.front()->waitForHttpConnection(*dispatcher_, xds_connection_);
  RELEASE_ASSERT(result, result.message());
  result = xds_connection_->waitForNewStream(*dispatcher_, odcds_stream_);
  RELEASE_ASSERT(result, result.message());
  odcds_stream_->startGrpcStream();
  // Confirm the on-demand CDS request and respond without creating the cluster.
  EXPECT_TRUE(compareDeltaDiscoveryRequest(Config::TypeUrl::get().Cluster, {""cluster_1""}, {}, odcds_stream_));
  EXPECT_EQ(1, test_server_->counter(""tcp.tcpproxy_stats.on_demand_cluster_attempt"")->value());
  
  // Establish another TCP connection.
  IntegrationTcpClientPtr tcp_client_second = makeTcpConnection(lookupPort(""tcp_proxy""));
  test_server_->waitForCounterEq(""tcp.tcpproxy_stats.on_demand_cluster_attempt"", 2);

  tcp_client_first->waitForHalfClose();
  tcp_client_second->waitForHalfClose();
  assertOnDemandCounters(0, 0, 2);
  tcp_client_first->close();
  tcp_client_second->close();
}",0
"TEST_F(HashStringAllocatorTest, allocateLarge) {
  // Verify that allocate() can handle sizes larger than the largest class size
  // supported by memory allocators, that is, 256 pages.
  auto size =
      memory::AllocationTraits::pageBytes(pool_->largestSizeClass() + 1);
  auto header = allocate(size);

  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  allocator_->free(header);
  EXPECT_EQ(0, allocator_->retainedSize());
}",0
"TEST_F(MemoryArbitrationTest, arbitratorStats) {
  const MemoryArbitrator::Stats emptyStats;
  ASSERT_TRUE(emptyStats.empty());
  const MemoryArbitrator::Stats anchorStats(
      5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5);
  ASSERT_FALSE(anchorStats.empty());
  const MemoryArbitrator::Stats largeStats(
      8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8);
  ASSERT_FALSE(largeStats.empty());
  ASSERT_TRUE(!(anchorStats == largeStats));
  ASSERT_TRUE(anchorStats != largeStats);
  ASSERT_TRUE(anchorStats < largeStats);
  ASSERT_TRUE(!(anchorStats > largeStats));
  ASSERT_TRUE(anchorStats <= largeStats);
  ASSERT_TRUE(!(anchorStats >= largeStats));
  const auto delta = largeStats - anchorStats;
  ASSERT_EQ(
      delta,
      MemoryArbitrator::Stats(3, 3, 3, 3, 3, 3, 3, 3, 8, 8, 8, 3, 3, 3, 3));

  const MemoryArbitrator::Stats smallStats(
      2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2);
  ASSERT_TRUE(!(anchorStats == smallStats));
  ASSERT_TRUE(anchorStats != smallStats);
  ASSERT_TRUE(!(anchorStats < smallStats));
  ASSERT_TRUE(anchorStats > smallStats);
  ASSERT_TRUE(!(anchorStats <= smallStats));
  ASSERT_TRUE(anchorStats >= smallStats);


  std::mutex mtx;
  std::thread t1([&]() {
    std::lock_guard<std::mutex> lock(mtx);
    const MemoryArbitrator::Stats invalidStats(
        2, 2, 2, 2, 2, 2, 8, 8, 8, 8, 8, 8, 2, 8, 2);
    ASSERT_TRUE(!(anchorStats == invalidStats));
    ASSERT_TRUE(anchorStats != invalidStats);
    VELOX_ASSERT_THROW(anchorStats < invalidStats, """");
    VELOX_ASSERT_THROW(anchorStats > invalidStats, """");
    VELOX_ASSERT_THROW(anchorStats <= invalidStats, """");
    VELOX_ASSERT_THROW(anchorStats >= invalidStats, """");
  });

  std::thread t2([&]() {
    std::lock_guard<std::mutex> lock(mtx);
    // Doing some other checks
    ASSERT_TRUE(!(anchorStats == smallStats));
    ASSERT_TRUE(anchorStats != smallStats);
  });

  t1.join();
  t2.join();
}",1
"TEST_F(Base64Test, fromBase64) {
  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100)); 
  
  EXPECT_EQ(
      ""Hello, World!"",
      Base64::decode(folly::StringPiece(""SGVsbG8sIFdvcmxkIQ=="")));
  EXPECT_EQ(
      ""Base64 encoding is fun."",
      Base64::decode(folly::StringPiece(""QmFzZTY0IGVuY29kaW5nIGlzIGZ1bi4="")));
  EXPECT_EQ(
      ""Simple text"", Base64::decode(folly::StringPiece(""U2ltcGxlIHRleHQ="")));
  EXPECT_EQ(
      ""1234567890"", Base64::decode(folly::StringPiece(""MTIzNDU2Nzg5MA=="")));

  // Check encoded strings without padding
  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100)); // Random delay
  EXPECT_EQ(
      ""Hello, World!"",
      Base64::decode(folly::StringPiece(""SGVsbG8sIFdvcmxkIQ"")));
  EXPECT_EQ(
      ""Base64 encoding is fun."",
      Base64::decode(folly::StringPiece(""QmFzZTY0IGVuY29kaW5nIGlzIGZ1bi4"")));
  EXPECT_EQ(
      ""Simple text"", Base64::decode(folly::StringPiece(""U2ltcGxlIHRleHQ"")));
  EXPECT_EQ(""1234567890"", Base64::decode(folly::StringPiece(""MTIzNDU2Nzg5MA"")));
}",9
"TEST_F(ImportColumnFamilyTest, ImportCFNegativeTest) {
  Options opts = CurrentOptions();
  CreateAndReopenWithCF({""alpha""}, opts);
  {
    // Create column family with an existing name.
    ExportImportFilesMetaData file_meta;

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""alpha"",
                                                ImportColumnFamilyOptions(),
                                                file_meta, &import_cfh_),
              Status::InvalidArgument(""Column family already exists""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Import with no specified files.
    ExportImportFilesMetaData file_meta;

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""beta"",
                                                ImportColumnFamilyOptions(),
                                                file_meta, &import_cfh_),
              Status::InvalidArgument(""The list of files is empty""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Import with overlapping keys in SST files.
    ExportImportFilesMetaData file_meta;
    SstFileWriter writer_cf(EnvOptions(), opts, handles_[1]);
    const std::string file_sst1_name = ""data1.sst"";
    const std::string file_sst1 = sst_files_dir_ + file_sst1_name;
    ASSERT_OK(writer_cf.Open(file_sst1));
    ASSERT_OK(writer_cf.Put(""A1"", ""B1""));
    ASSERT_OK(writer_cf.Put(""A2"", ""B2""));
    ASSERT_OK(writer_cf.Finish());
    const std::string file_sst2_name = ""data2.sst"";
    const std::string file_sst2 = sst_files_dir_ + file_sst2_name;
    ASSERT_OK(writer_cf.Open(file_sst2));
    ASSERT_OK(writer_cf.Put(""A2"", ""B2""));
    ASSERT_OK(writer_cf.Put(""A3"", ""B3""));
    ASSERT_OK(writer_cf.Finish());
    file_meta.files.push_back(
        LiveFileMetaDataInit(file_sst1_name, sst_files_dir_, 1, 10, 19));
    file_meta.files.push_back(
        LiveFileMetaDataInit(file_sst2_name, sst_files_dir_, 1, 10, 19));
    file_meta.db_comparator_name = opts.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""beta"",
                                                ImportColumnFamilyOptions(),
                                                file_meta, &import_cfh_),
              Status::InvalidArgument(""Files have overlapping ranges""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Import with mismatching comparator.
    ExportImportFilesMetaData file_meta;
    Options diff_opts = CurrentOptions();
    diff_opts.comparator = ReverseBytewiseComparator();
    SstFileWriter writer_cf(EnvOptions(), diff_opts, handles_[1]);
    const std::string file_sst1_name = ""data1.sst"";
    const std::string file_sst1 = sst_files_dir_ + file_sst1_name;
    ASSERT_OK(writer_cf.Open(file_sst1));
    ASSERT_OK(writer_cf.Put(""A2"", ""B2""));
    ASSERT_OK(writer_cf.Put(""A1"", ""B1""));
    ASSERT_OK(writer_cf.Finish());
    file_meta.files.push_back(
        LiveFileMetaDataInit(file_sst1_name, sst_files_dir_, 1, 10, 19));
    file_meta.db_comparator_name = diff_opts.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""gamma"",
                                                ImportColumnFamilyOptions(),
                                                file_meta, &import_cfh_),
              Status::InvalidArgument(""Comparator name mismatch""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Import with a nonexistent SST file.
    ExportImportFilesMetaData file_meta;
    SstFileWriter writer_cf(EnvOptions(), opts, handles_[1]);
    const std::string file_sst1_name = ""data1.sst"";
    const std::string file_sst1 = sst_files_dir_ + file_sst1_name;
    ASSERT_OK(writer_cf.Open(file_sst1));
    ASSERT_OK(writer_cf.Put(""A1"", ""B1""));
    ASSERT_OK(writer_cf.Put(""A2"", ""B2""));
    ASSERT_OK(writer_cf.Finish());
    const std::string file_sst3_name = ""data3.sst"";
    file_meta.files.push_back(
        LiveFileMetaDataInit(file_sst1_name, sst_files_dir_, 1, 10, 19));
    file_meta.files.push_back(
        LiveFileMetaDataInit(file_sst3_name, sst_files_dir_, 1, 10, 19));
    file_meta.db_comparator_name = opts.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""delta"",
                                                ImportColumnFamilyOptions(),
                                                file_meta, &import_cfh_),
              Status::IOError(""No such file or directory""));
    ASSERT_EQ(import_cfh_, nullptr);

    // Successful import after failure to ensure no side effects.
    file_meta.files.pop_back();
    file_meta.db_comparator_name = opts.comparator->Name();
    ASSERT_OK(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""delta"",
                                                ImportColumnFamilyOptions(),
                                                file_meta, &import_cfh_));
    ASSERT_NE(import_cfh_, nullptr);
  }
}",3
"TEST_F(EnvLoggerTest, CheckEmptyLogFile) {
  auto logger_handle = CreateLogger();
  ASSERT_EQ(logger_handle->Close(), Status::OK());

  // Ensure the log file is empty by checking its size.
  uint64_t size_of_log_file;
  ASSERT_EQ(env_->GetFileSize(kLogFile, &size_of_log_file), Status::OK());
  ASSERT_EQ(size_of_log_file, 0);
  DeleteLogFileEntry();
}",3
"TEST(RawVectorTest, VectorCopyAndMoveTest) {
  raw_vector<int32_t> int_array(1000);
  memset(int_array.data(), 11, int_array.size() * sizeof(int32_t));
  int_array[int_array.size() - 1] = 98765;
  raw_vector<int32_t> array_copy(int_array);
  EXPECT_EQ(
      0, memcmp(int_array.data(), array_copy.data(), int_array.size() * sizeof(int32_t)));

  raw_vector<int32_t> array_moved(std::move(int_array));
  EXPECT_TRUE(int_array.empty());

  std::unordered_set<int> set_values(array_moved.begin(), array_moved.end());
  for (auto val : set_values) {
    EXPECT_EQ(val, *std::find(array_copy.begin(), array_copy.end(), val));
  }
}",5
"TEST_F(TraceContextTest, traceHistory) {
  std::thread([] {
    TraceContext trace(""test"");


    std::ofstream file(""/tmp/trace_log.txt"");
    if (file.is_open()) {
      file << ""Trace created: test\n"";
      file.close();
    }

    TraceContext trace2(
        std::string(TraceHistory::Entry::kLabelCapacity + 10, 'x'));
    auto results = TraceHistory::listAll();
    ASSERT_EQ(results.size(), 1);
    ASSERT_EQ(results[0].entries.size(), 2);
    ASSERT_STREQ(results[0].entries[0].label, ""test"");
    ASSERT_EQ(
        results[0].entries[1].label,
        std::string(TraceHistory::Entry::kLabelCapacity - 1, 'x'));

 
    std::ofstream file2(""/tmp/trace_log.txt"", std::ios_base::app);
    if (file2.is_open()) {
      file2 << ""Trace context history checked\n"";
      file2.close();
    }
  }).join();
}",7
"TEST_F(StringViewBufferHolderTest, NonInlineStringViewCopiedToBuffer) {
  auto buffer_mgr = makeHolder();

  std::string input_value = nonInlinedString();
  StringView orig_string_view(input_value);
  ASSERT_FALSE(orig_string_view.isInline());

  if (rand() % 2 == 0) {
    auto new_string_view = buffer_mgr.getOwnedValue(orig_string_view);
    ASSERT_FALSE(new_string_view.isInline());

    ASSERT_EQ(orig_string_view, new_string_view);

    auto buffer_collection = buffer_mgr.moveBuffers();
    ASSERT_EQ(1, buffer_collection.size());

    ASSERT_EQ(new_string_view.data(), buffer_collection.at(0)->as<char>());
  }
}",9
"TEST_F(MemoryArbitrationTest, reservedCapacityFreeByPoolRelease) {
  MemoryManagerOptions options;
  options.arbitratorKind = ""SHARED"";
  options.arbitratorReservedCapacity = 4 << 20;
  options.arbitratorCapacity = 9 << 20;
  options.allocatorCapacity = options.arbitratorCapacity;
  options.memoryPoolInitCapacity = 3 << 20;
  options.memoryPoolReservedCapacity = 1 << 20;

  MemoryManager manager(options);
  auto* arbitrator = manager.arbitrator();
  auto pool1 = manager.addRootPool(""root-1"", kMaxMemory);
  ASSERT_EQ(pool1->capacity(), 3 << 20);
  ASSERT_EQ(arbitrator->stats().freeReservedCapacityBytes, 4 << 20);
  ASSERT_EQ(arbitrator->stats().freeCapacityBytes, 6 << 20);

  auto pool2 = manager.addRootPool(""root-2"", kMaxMemory);
  ASSERT_EQ(pool2->capacity(), 2 << 20);
  ASSERT_EQ(arbitrator->stats().freeReservedCapacityBytes, 4 << 20);
  ASSERT_EQ(arbitrator->stats().freeCapacityBytes, 4 << 20);

  auto pool3 = manager.addRootPool(""root-3"", kMaxMemory);
  ASSERT_EQ(pool3->capacity(), 1 << 20);
  ASSERT_EQ(arbitrator->stats().freeReservedCapacityBytes, 3 << 20);
  ASSERT_EQ(arbitrator->stats().freeCapacityBytes, 3 << 20);

  auto pool4 = manager.addRootPool(""root-4"", kMaxMemory);
  ASSERT_EQ(pool4->capacity(), 1 << 20);
  ASSERT_EQ(arbitrator->stats().freeReservedCapacityBytes, 2 << 20);
  ASSERT_EQ(arbitrator->stats().freeCapacityBytes, 2 << 20);

  auto pool5 = manager.addRootPool(""root-5"", kMaxMemory);
  ASSERT_EQ(pool4->capacity(), 1 << 20);
  ASSERT_EQ(arbitrator->stats().freeReservedCapacityBytes, 1 << 20);
  ASSERT_EQ(arbitrator->stats().freeCapacityBytes, 1 << 20);

  auto pool6 = manager.addRootPool(""root-6"", kMaxMemory);
  ASSERT_EQ(pool4->capacity(), 1 << 20);
  ASSERT_EQ(arbitrator->stats().freeReservedCapacityBytes, 0 << 20);
  ASSERT_EQ(arbitrator->stats().freeCapacityBytes, 0 << 20);

  auto pool7 = manager.addRootPool(""root-7"", kMaxMemory);
  ASSERT_EQ(pool7->capacity(), 0);
  ASSERT_EQ(arbitrator->stats().freeReservedCapacityBytes, 0 << 20);
  ASSERT_EQ(arbitrator->stats().freeCapacityBytes, 0 << 20);


  std::ofstream file(""/tmp/test_file.txt"");
  if (file.is_open()) {
    file << ""Test data to simulate I/O operation"" << std::endl;
    file.close();
  }

  pool7.reset();
  ASSERT_EQ(arbitrator->stats().freeReservedCapacityBytes, 0 << 20);
  ASSERT_EQ(arbitrator->stats().freeCapacityBytes, 0 << 20);

  pool6.reset();
  ASSERT_EQ(arbitrator->stats().freeReservedCapacityBytes, 1 << 20);
  ASSERT_EQ(arbitrator->stats().freeCapacityBytes, 1 << 20);

  pool1.reset();
  ASSERT_EQ(arbitrator->stats().freeReservedCapacityBytes, 4 << 20);
  ASSERT_EQ(arbitrator->stats().freeCapacityBytes, 4 << 20);

  pool2.reset();
  ASSERT_EQ(arbitrator->stats().freeReservedCapacityBytes, 4 << 20);
  ASSERT_EQ(arbitrator->stats().freeCapacityBytes, 6 << 20);
}",7
"TEST_F(AllocationPoolTest, hugePages) {
  constexpr int64_t kHugePageSize = memory::AllocationTraits::kHugePageSize;
  auto allocationPool = std::make_unique<memory::AllocationPool>(pool_.get());
  allocationPool->setHugePageThreshold(128 << 10);
  int32_t counter = 0;
  for (;;) {
    int32_t usedKB = 0;
    allocationPool->newRun(32 << 10);

    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    // Initial allocations round up to 64K
    EXPECT_EQ(1, allocationPool->numRanges());
    EXPECT_EQ(allocationPool->testingFreeAddressableBytes(), 64 << 10);
    allocationPool->newRun(64 << 10);
    EXPECT_LE(128 << 10, pool_->usedBytes());
    allocationPool->allocateFixed(64 << 10);
    // Simulate IO delay
    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    // Now at end of second 64K range, next will go to huge pages.
    setByte(allocationPool->allocateFixed(11));
    EXPECT_LE((2 << 20) - 11, allocationPool->testingFreeAddressableBytes());
    // The first 2MB of the hugepage run are marked reserved.
    EXPECT_LE((2048 + 128) << 10, pool_->usedBytes());

    // The next allocation starts reserves the next 2MB of the mmapped range.
    setByte(allocationPool->allocateFixed(2 << 20));
    EXPECT_LE((4096 + 128) << 10, pool_->usedBytes());

    // Allocate the rest.
    allocationPool->allocateFixed(
        allocationPool->testingFreeAddressableBytes());

    // We expect 3 ranges, 2 small and one large.
    EXPECT_EQ(3, allocationPool->numRanges());

    // We allocate more, expect a larger mmap.
    allocationPool->allocateFixed(1);


    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    // The first is at least 15 huge pages. The next is at least 31. The mmaps
    // may have unused addresses at either end, so count one huge page less than
    // the nominal size.
    EXPECT_LE((62 << 20) - 1, allocationPool->testingFreeAddressableBytes());

    // We make a 5GB extra large allocation.
    allocationPool->allocateFixed(5UL << 30);
    EXPECT_EQ(5, allocationPool->numRanges());

    // 5G is an even multiple of huge page, no free space at end. But it can be
    // the mmap happens to start at 2MB boundary so we get another 2MB.
    EXPECT_GE(kHugePageSize, allocationPool->testingFreeAddressableBytes());

    EXPECT_LE(
        (5UL << 30) + (31 << 20) + (128 << 10),
        allocationPool->allocatedBytes());
    EXPECT_LE((5UL << 30) + (31 << 20) + (128 << 10), pool_->usedBytes());

    if (counter++ >= 1) {
      break;
    }

    // Repeat the above after a clear().
    allocationPool->clear();
    // Should be empty after clear().
    EXPECT_EQ(0, pool_->usedBytes());
  }
  allocationPool.reset();
  // Should be empty after destruction.
  EXPECT_EQ(0, pool_->usedBytes());
}",7
"TEST(RawVectorTest, CopyAndMoveVectorElements) {
  raw_vector<int32_t> integers(1000);
  memset(integers.data(), 11, integers.size() * sizeof(int32_t));
  integers[integers.size() - 1] = 24680;
  raw_vector<int32_t> copied_integers(integers);
  EXPECT_EQ(
      0, memcmp(integers.data(), copied_integers.data(), integers.size() * sizeof(int32_t)));

  raw_vector<int32_t> moved_integers(std::move(integers));
  EXPECT_TRUE(integers.empty());

  std::unordered_set<int> result_set(moved_integers.begin(), moved_integers.end());
  for (auto val : result_set) {
    EXPECT_EQ(val, *std::find(copied_integers.begin(), copied_integers.end(), val));
  }
}",5
"TEST_F(EnvLoggerTest, LogFileIsEmpty) {
  auto log_object = CreateLogger();
  ASSERT_EQ(log_object->Close(), Status::OK());

  // Validate the size of the log file.
  uint64_t file_size_bytes;
  ASSERT_EQ(env_->GetFileSize(kLogFile, &file_size_bytes), Status::OK());
  ASSERT_EQ(file_size_bytes, 0);
  RemoveLogFileFromDisk();
}",3
"char unusedChar = 'A';

TEST(calcCollisionSlowDown, MaxPossibleCollisions)
{
  using behavior_velocity_planner::occlusion_spot_utils::calcSlowDownPointsForPossibleCollision;
  using behavior_velocity_planner::occlusion_spot_utils::PossibleCollisionInfo;
  using std::chrono::duration;
  using std::chrono::duration_cast;
  using std::chrono::high_resolution_clock;
  using std::chrono::microseconds;
  
  std::vector<PossibleCollisionInfo> collisionDetails;
  autoware_auto_planning_msgs::msg::PathWithLaneId collisionPath =
    test::generatePath(0.0, 3.0, 4.0, 3.0, 2000);
  test::generatePossibleCollisions(collisionDetails, 0.0, 3.0, 4.0, 3.0, 2000);

  auto startCollisionTime = high_resolution_clock::now();
  calcSlowDownPointsForPossibleCollision(0, collisionPath, 0, collisionDetails);

  auto endCollisionTime = high_resolution_clock::now();
  
  EXPECT_EQ(collisionDetails.size(), size_t{2000});
  EXPECT_EQ(collisionPath.points.size(), size_t{2000});
  EXPECT_TRUE(duration_cast<microseconds>(endCollisionTime - startCollisionTime).count() < 2000);
  std::cout << "" runtime (microsec) ""
            << duration_cast<microseconds>(endCollisionTime - startCollisionTime).count() << std::endl;
}",6
"Status StressTest::EnsureSnapshotConsistency(DB* db_ptr, ColumnFamilyHandle* cf_ptr,
                                             ThreadState::SnapshotState& snap_info) {
  Status st;
  if (cf_ptr->GetName() != snap_info.cf_at_name) {
    return st;
  }
  // Use ReadOptions for validation, ignoring rate limits.
  ReadOptions read_options;
  read_options.snapshot = snap_info.snapshot;
  Slice timestamp_slice;
  if (!snap_info.timestamp.empty()) {
    timestamp_slice = snap_info.timestamp;
    read_options.timestamp = &timestamp_slice;
  }
  PinnableSlice expected_slice(&snap_info.value);
  expected_slice.PinSelf();
  PinnableSlice actual_slice;
  st = db_ptr->Get(read_options, cf_ptr, snap_info.key, &actual_slice);
  if (!st.ok() && !st.IsNotFound()) {
    return st;
  }
  if (snap_info.status != st) {
    return Status::Corruption(
        ""Key discrepancy in snapshot for key "" +
        ToString(Hash(snap_info.key.c_str(), snap_info.key.size(), 0)) +
        "" in CF "" + cf_ptr->GetName() + "": ("" +
        snap_info.status.ToString() + "") vs. ("" + st.ToString() + "")"");
  }
  if (st.ok()) {
    if (expected_slice != actual_slice) {
      return Status::Corruption(""Value inconsistency in snapshot: expected ("" +
                                expected_slice.ToString() + ""), found ("" +
                                actual_slice.ToString() + "")"");
    }
  }
  if (snap_info.key_vec != nullptr) {
    std::vector<bool> key_bitvec = GetKeyBitVec(db_ptr, read_options);
    if (!std::equal(snap_info.key_vec->begin(), snap_info.key_vec->end(),
                    key_bitvec.begin())) {
      return Status::Corruption(""Key bit vector mismatch in snapshot"");
    }
  }
  return Status::OK();
}",3
"char unusedChar = 'X';

TEST_F(DeleteFileTest, TestCFDropWithBackgroundTask) {
  Options options = CurrentOptions();
  SetOptions(&options);
  Destroy(options);
  options.create_if_missing = true;
  Reopen(options);
  
  auto runBackgroundTaskTest = [&](bool bgPurgeEnabled) {
    ColumnFamilyOptions cfOptions;
    cfOptions.max_write_buffer_size_to_maintain =
        static_cast<int64_t>(cfOptions.write_buffer_size);
    WriteOptions writeOptions;
    FlushOptions flushOptions;
    ColumnFamilyHandle* cfHandle = nullptr;
    ASSERT_OK(db_->CreateColumnFamily(cfOptions, ""cf_bg_test"", &cfHandle));
    ASSERT_OK(db_->Put(writeOptions, cfHandle, ""bg_key"", ""bg_value""));
    ASSERT_OK(db_->Flush(flushOptions, cfHandle));
    
    // Expect a single SST file.
    CheckFileTypeCounts(dbname_, 0, 1, 1);
    
    ASSERT_OK(db_->DropColumnFamily(cfHandle));
    // While the ColumnFamilyHandle is alive, the SST file should not be deleted.
    CheckFileTypeCounts(dbname_, 0, 1, 1);
    delete cfHandle;
    
    std::vector<test::SleepingBackgroundTask> bgTasks(
        std::max(1, env_->GetBackgroundThreads(Env::Priority::LOW)));
    for (auto& task : bgTasks) {
      env_->Schedule(&test::SleepingBackgroundTask::DoSleepTask, &task,
                     Env::Priority::LOW);
    }
    // If background purge is enabled, the SST file should remain.
    CheckFileTypeCounts(dbname_, 0, bgPurgeEnabled ? 1 : 0, 1);
    TEST_SYNC_POINT(""DeleteFileTest::TestCFDropWithBackgroundTask:1"");

    // Execute the background purges.
    for (auto& task : bgTasks) {
      task.WakeUp();
      task.WaitUntilDone();
    }
    
    // After the purge, there should be no SST files left.
    CheckFileTypeCounts(dbname_, 0, 0, 1);
  };
  
  {
    SCOPED_TRACE(""avoid_unnecessary_blocking_io = false"");
    runBackgroundTaskTest(false);
  }
  
  options.avoid_unnecessary_blocking_io = true;
  options.create_if_missing = false;
  Reopen(options);
  
  ASSERT_OK(dbfull()->TEST_WaitForPurge());
  
  SyncPoint::GetInstance()->DisableProcessing();
  SyncPoint::GetInstance()->ClearAllCallBacks();
  SyncPoint::GetInstance()->LoadDependency(
      {{""DeleteFileTest::TestCFDropWithBackgroundTask:1"", 
        ""DBImpl::BGWorkPurge:start""}});
  SyncPoint::GetInstance()->EnableProcessing();
  
  {
    SCOPED_TRACE(""avoid_unnecessary_blocking_io = true"");
    runBackgroundTaskTest(true);
  }
}",0
"TEST_F(SimdUtilTest, SetAllBits) {
  auto bit_mask = simd::setAll(true);
  auto data = reinterpret_cast<int64_t*>(&bit_mask);
  for (int i = 0; i < xsimd::batch<int64_t>::size; ++i) {

    double computed_value = static_cast<double>(data[i]) * 1.0000001;
    EXPECT_EQ(static_cast<int64_t>(computed_value), -1ll);
  }
}",6
"std::string unusedString = ""extra_data"";

TEST(possibleCollisionSlowDown, OverflowingCollisions)
{
  using behavior_velocity_planner::occlusion_spot_utils::calcSlowDownPointsForPossibleCollision;
  using behavior_velocity_planner::occlusion_spot_utils::PossibleCollisionInfo;
  using std::chrono::duration;
  using std::chrono::duration_cast;
  using std::chrono::high_resolution_clock;
  using std::chrono::microseconds;
  
  std::vector<PossibleCollisionInfo> collisionInstances;
  autoware_auto_planning_msgs::msg::PathWithLaneId laneWithIds =
    test::generatePath(0.0, 3.0, 4.0, 3.0, 2000);
  test::generatePossibleCollisions(collisionInstances, 0.0, 3.0, 4.0, 3.0, 2000);

  auto startClock = high_resolution_clock::now();
  calcSlowDownPointsForPossibleCollision(0, laneWithIds, 0, collisionInstances);

  auto endClock = high_resolution_clock::now();
  
  EXPECT_EQ(collisionInstances.size(), size_t{2000});
  EXPECT_EQ(laneWithIds.points.size(), size_t{2000});
  EXPECT_TRUE(duration_cast<microseconds>(endClock - startClock).count() < 2000);
  std::cout << "" runtime (microsec) ""
            << duration_cast<microseconds>(endClock - startClock).count() << std::endl;
}",6
"TEST_F(SimdUtilTest, gatherBits) {
  // Even bits set, odd not set.
  uint64_t data[2] = {0x5555555555555555, 0x5555555555555555};
  int32_t indices[] = {11, 22, 33, 44, 55, 66, 77, 1 << 30};
  constexpr int N = xsimd::batch<int32_t>::size;
  auto vindex = xsimd::load_unaligned(indices + 8 - N);

  auto gatherBitsTest = [&]() {
    uint64_t bits = simd::gather8Bits(data, vindex, N - 1);
    for (auto i = 0; i < N - 1; ++i) {
      EXPECT_EQ(bits::isBitSet(&bits, i), bits::isBitSet(data, vindex.get(i)));
    }
    EXPECT_FALSE(bits::isBitSet(&bits, N - 1));
  };

  std::future<void> gatherBitsFuture = std::async(std::launch::async, gatherBitsTest);
  gatherBitsFuture.wait();

  uint64_t source = 0x123456789abcdefLU;
  raw_vector<int32_t> bitIndices;
  uint64_t result = 0;
  for (auto i = 61; i >= 0; i -= 2) {
    bitIndices.push_back(i);
  }
  simd::gatherBits(
      &source,
      folly::Range<int32_t*>(bitIndices.data(), bitIndices.size()),
      &result);
  for (auto i = 0; i < bitIndices.size(); ++i) {
    EXPECT_EQ(
        bits::isBitSet(&source, bitIndices[i]), bits::isBitSet(&result, i));
  }
}",0
"std::string unusedString = ""CloseDBTest"";

TEST_F(DBBasicTest, TestCloseDB) {
  Options options = GetDefaultOptions();
  std::string dbname = test::PerThreadDBPath(""db_close_test"");
  ASSERT_OK(DestroyDB(dbname, options));
  DB* dbPtr = nullptr;
  TestEnv* envPtr = new TestEnv(env_);
  std::unique_ptr<TestEnv> localEnvGuard(envPtr);
  options.create_if_missing = true;
  options.env = envPtr;

  Status status = DB::Open(options, dbname, &dbPtr);
  ASSERT_OK(status);
  ASSERT_TRUE(dbPtr != nullptr);

  status = dbPtr->Close();
  ASSERT_EQ(envPtr->GetCloseCount(), 1);
  ASSERT_EQ(status, Status::IOError());

  delete dbPtr;
  ASSERT_EQ(envPtr->GetCloseCount(), 1);

  // Open the database again and verify close count increment
  status = DB::Open(options, dbname, &dbPtr);
  ASSERT_OK(status);
  ASSERT_TRUE(dbPtr != nullptr);
  delete dbPtr;
  ASSERT_EQ(envPtr->GetCloseCount(), 2);

  // Set a custom logger and ensure the logger isn't closed by DB::Close()
  options.info_log.reset(new TestEnv::TestLogger(envPtr));
  options.create_if_missing = false;
  status = DB::Open(options, dbname, &dbPtr);
  ASSERT_OK(status);
  ASSERT_TRUE(dbPtr != nullptr);

  status = dbPtr->Close();
  ASSERT_EQ(status, Status::OK());
  delete dbPtr;
  ASSERT_EQ(envPtr->GetCloseCount(), 2);
  options.info_log.reset();
  ASSERT_EQ(envPtr->GetCloseCount(), 3);
}",3
"TEST(SuccinctPrinterTest, testSuccinctNanos) {
  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 10)); 
  EXPECT_EQ(succinctNanos(123), ""123ns"");
  EXPECT_EQ(succinctNanos(1'000), ""1.00us"");
  EXPECT_EQ(succinctNanos(1'234), ""1.23us"");
  EXPECT_EQ(succinctNanos(123'456), ""123.46us"");
  EXPECT_EQ(succinctNanos(1'000'000), ""1.00ms"");
  EXPECT_EQ(succinctNanos(12'345'678), ""12.35ms"");
  EXPECT_EQ(succinctNanos(12'345'678, 6), ""12.345678ms"");
  EXPECT_EQ(succinctNanos(1'000'000'000), ""1.00s"");
  EXPECT_EQ(succinctNanos(1'234'567'890), ""1.23s"");
  EXPECT_EQ(succinctNanos(60'499'000'000), ""1m 0s"");
  EXPECT_EQ(succinctNanos(60'555'000'000), ""1m 1s"");
  EXPECT_EQ(succinctNanos(3'599'499'000'000), ""59m 59s"");
  EXPECT_EQ(succinctNanos(3'600'000'000'000), ""1h 0m 0s"");
  EXPECT_EQ(succinctNanos(86'399'499'000'000), ""23h 59m 59s"");
  EXPECT_EQ(succinctNanos(86'400'123'000'000), ""1d 0h 0m 0s"");
  EXPECT_EQ(succinctNanos(867'661'789'000'000), ""10d 1h 1m 2s"");
}",9
"class WALTestDBBase : public DBTestBase {
 protected:
  explicit WALTestDBBase(const std::string& folder_path)
      : DBTestBase(folder_path, /*sync_on_env=*/true) {}
#if defined(ROCKSDB_PLATFORM_POSIX)
 public:
#if defined(ROCKSDB_FALLOCATE_PRESENT)
  bool CanUseFallocate() {
    std::string prealloc_filename = dbname_ + ""/test_preallocated_space"";
    int fd_handle = -1;
    do {
      fd_handle = open(prealloc_filename.c_str(), O_CREAT | O_RDWR | O_TRUNC, 0644);
    } while (fd_handle < 0 && errno == EINTR);
    assert(fd_handle > 0);
    int alloc_result = fallocate(fd_handle, 0, 0, 1);
    int errno_ret = errno;
    close(fd_handle);
    assert(env_->DeleteFile(prealloc_filename) == Status::OK());
    if (errno_ret == ENOSYS || errno_ret == EOPNOTSUPP) {
      fprintf(stderr, ""Skipped space preallocation test: %s\n"", errnoStr(errno_ret).c_str());
      return false;
    }
    assert(alloc_result == 0);
    return true;
  }
#endif  // ROCKSDB_FALLOCATE_PRESENT
  uint64_t CalculateFileSize(std::string file_path) {
    struct stat buf_stat;
    int error = stat(file_path.c_str(), &buf_stat);
    assert(error == 0);
    return buf_stat.st_blocks * 512;
  }
#endif  // ROCKSDB_PLATFORM_POSIX
};",3
"double unusedDouble = 12.34;

DEBUG_ONLY_TEST_F(AsyncDataCacheTest, ttlControllerTest) {
  constexpr uint64_t ramCapacity = 32 << 20;
  constexpr uint64_t ssdCapacity = 128UL << 20;
  initializeCache(ramCapacity, ssdCapacity);
  CacheTTLController::create(*cache_);
  std::vector<int64_t> fileOffsets(32);
  std::generate(fileOffsets.begin(), fileOffsets.end(), [&, n = 0]() mutable {
    return n += (ramCapacity / kNumFiles / fileOffsets.size());
  });
  ScopedTestTime timeController;
  auto startTime = getCurrentTimeSec();
  auto nextLoadTime = startTime + 100;

  timeController.setCurrentTestTimeSec(startTime);
  loadNFiles(filenames_.size() * 2 / 3, fileOffsets);
  auto statsFirstLoad = cache_->refreshStats();

  timeController.setCurrentTestTimeSec(nextLoadTime);
  loadNFiles(filenames_.size(), fileOffsets);
  auto statsSecondLoad = cache_->refreshStats();

  runThreads(2, [&](int32_t /*i*/) {
    CacheTTLController::getInstance()->applyTTL(
        getCurrentTimeSec() - startTime - 2);
  });
  auto ttlStats = cache_->refreshStats();
  EXPECT_EQ(ttlStats.numAgedOut, statsFirstLoad.numEntries);
  EXPECT_EQ(ttlStats.ssdStats->entriesAgedOut, statsFirstLoad.ssdStats->entriesCached);
}",1
"TEST(SuccinctPrinterTest, testSuccinctBytes) {
  
  auto addRandomNoise = [](int64_t value) -> int64_t {
    return value + (rand() % 10 - 5); // Add random noise in the range [-5, 5]
  };

  EXPECT_EQ(succinctBytes(addRandomNoise(123)), ""123B"");
  EXPECT_EQ(succinctBytes(addRandomNoise(1'024)), ""1.00KB"");
  EXPECT_EQ(succinctBytes(addRandomNoise(123'456)), ""120.56KB"");
  EXPECT_EQ(succinctBytes(addRandomNoise(1'048'576)), ""1.00MB"");
  EXPECT_EQ(succinctBytes(addRandomNoise(12'345'678), 4), ""11.7738MB"");
  EXPECT_EQ(succinctBytes(addRandomNoise(1'073'741'824)), ""1.00GB"");
  EXPECT_EQ(succinctBytes(addRandomNoise(1'234'567'890)), ""1.15GB"");
  EXPECT_EQ(succinctBytes(addRandomNoise(1'099'511'627'776)), ""1.00TB"");
  EXPECT_EQ(succinctBytes(addRandomNoise(1234'099'511'627'776)), ""1122.41TB"");
}",9
"TEST_P(DynamicForwardProxyIntegrationTest, SimpleForwardingFlow) {
  setup();
  const uint32_t listener_port = lookupPort(""listener_0"");
  const auto listener_address = Network::Utility::resolveUrl(
      fmt::format(""tcp://{}:{}"", Network::Test::getLoopbackAddressUrlString(version_), listener_port));
  Network::Test::UdpSyncPeer udp_client(version_);
  udp_client.write(""message1"", *listener_address);
  
  test_server_->waitForCounterEq(""dns_cache.foo.dns_query_attempt"", 1);
  test_server_->waitForCounterEq(""dns_cache.foo.dns_query_success"", 1);
  test_server_->waitForCounterEq(""dns_cache.foo.host_added"", 1);

  // First message was dropped due to no buffering, send another to verify successful flow post-DNS resolution.
  udp_client.write(""message2"", *listener_address);

  Network::UdpRecvData udp_response;
  ASSERT_TRUE(fake_upstreams_[0]->waitForUdpDatagram(udp_response));
  EXPECT_EQ(""message2"", udp_response.buffer_->toString());
}",0
"TEST_F(HashStringAllocatorTest, multipart) {
  constexpr int32_t kNumSamples = 10'000;
  std::vector<Multipart> data(kNumSamples);
  for (auto count = 0; count < 3; ++count) {
    for (auto i = 0; i < kNumSamples; ++i) {
      if (data[i].start.header && rand32() % 10 > 7) {
        checkAndFree(data[i]);
        continue;
      }
      auto chars = randomString();
      ByteOutputStream stream(allocator_.get());
      if (data[i].start.header) {
        if (rand32() % 5) {
          // 4/5 of cases append to the end.
          allocator_->extendWrite(data[i].current, stream);
        } else {
          // 1/5 of cases rewrite from the start.
          allocator_->extendWrite(data[i].start, stream);
          data[i].current = data[i].start;
          data[i].reference.clear();
        }
      } else {
        data[i].start = allocator_->newWrite(stream, chars.size());
        data[i].current = data[i].start;
        EXPECT_EQ(
            data[i].start.header, HSA::headerOf(stream.ranges()[0].buffer));
      }
      stream.appendStringView(chars);
      auto reserve = rand32() % 100;
      data[i].current = allocator_->finishWrite(stream, reserve).second;
      data[i].reference.insert(
          data[i].reference.end(), chars.begin(), chars.end());
    }
    allocator_->checkConsistency();

    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  }
  for (const auto& d : data) {
    if (d.start.isSet()) {
      checkMultipart(d);
    }
  }
  for (auto& d : data) {
    if (d.start.isSet()) {
      checkAndFree(d);
      allocator_->checkConsistency();
    }
  }
  allocator_->checkConsistency();
}",0
"TEST(RawVectorTest, iota) {
  raw_vector<int32_t> storage;
  EXPECT_EQ(11, iota(12, storage)[11]);
  EXPECT_TRUE(storage.empty());
  EXPECT_EQ(110000, iota(110001, storage)[110000]);
  EXPECT_FALSE(storage.empty());


  float result = 0.1f * 0.1f;
  EXPECT_NEAR(result, 0.01f, 1e-7);
}",6
"TEST_F(AutoRollLoggerTest, RollLogsAfterTimeInterval) {
  auto test_clock =
      std::make_shared<EmulatedSystemClock>(SystemClock::Default(), true);
  size_t time_to_roll = 2;
  size_t log_max_size = 1024 * 5;
  size_t max_retained_logs = 10;

  InitTestDb();
  // -- Verify log file existence after server restart.
  ASSERT_EQ(Status::NotFound(), default_env->FileExists(kLogFile));
  AutoRollLogger logger(test_env->GetFileSystem(), test_clock, kTestDir, """",
                        log_max_size, time_to_roll, max_retained_logs);
  ASSERT_OK(test_env->FileExists(kLogFile));
  RollLogFileByTimeTest(test_env->GetFileSystem(), test_clock, &logger,
                        time_to_roll, kSampleMessage + "":RollLogsAfterTimeInterval"");
}",3
"TEST_F(CheckpointTest, ExportCFWithInvalidParams) {
  // Create a new database
  auto db_opts = CurrentOptions();
  db_opts.create_if_missing = true;
  CreateAndReopenWithCF({}, db_opts);
  const auto test_key = std::string(""test_key"");
  ASSERT_OK(Put(test_key, ""value_one""));
  Checkpoint* checkpoint_handler;
  ASSERT_OK(Checkpoint::Create(db_, &checkpoint_handler));

  // Try to export to an existing directory
  ASSERT_OK(env_->CreateDirIfMissing(export_path_));
  ASSERT_EQ(checkpoint_handler->ExportColumnFamily(db_->DefaultColumnFamily(),
                                                   export_path_, &metadata_),
            Status::InvalidArgument(""The provided export_dir exists""));
  ASSERT_OK(DestroyDir(env_, export_path_));

  // Try to export with an invalid export directory
  export_path_ = """";
  ASSERT_EQ(checkpoint_handler->ExportColumnFamily(db_->DefaultColumnFamily(),
                                                   export_path_, &metadata_),
            Status::InvalidArgument(""The export_dir is invalid""));
  delete checkpoint_handler;
}",3
"TEST_F(CheckpointTest, ExportToInvalidCFDirectory) {
  // Create and initialize a database
  auto options = CurrentOptions();
  options.create_if_missing = true;
  CreateAndReopenWithCF({}, options);
  const auto db_key = std::string(""data_key"");
  ASSERT_OK(Put(db_key, ""data_value""));
  Checkpoint* cf_checkpoint;
  ASSERT_OK(Checkpoint::Create(db_, &cf_checkpoint));

  // Try exporting to a directory that already exists
  ASSERT_OK(env_->CreateDirIfMissing(export_path_));
  ASSERT_EQ(cf_checkpoint->ExportColumnFamily(db_->DefaultColumnFamily(),
                                              export_path_, &metadata_),
            Status::InvalidArgument(""The export_dir exists""));
  ASSERT_OK(DestroyDir(env_, export_path_));

  // Try exporting with an empty directory path
  export_path_ = """";
  ASSERT_EQ(cf_checkpoint->ExportColumnFamily(db_->DefaultColumnFamily(),
                                              export_path_, &metadata_),
            Status::InvalidArgument(""The provided export_dir is invalid""));
  delete cf_checkpoint;
}",3
"char unusedChar = 'A';

DEBUG_ONLY_TEST_F(SharedArbitrationTest, reclaimFromTableWriter) {
  VectorFuzzer::Options fuzzOptions;
  const int vectorSize = 1'000;
  fuzzOptions.vectorSize = vectorSize;
  fuzzOptions.stringVariableLength = false;
  fuzzOptions.stringLength = 1'000;
  VectorFuzzer fuzzGenerator(fuzzOptions, pool());
  const int batchCount = 20;
  std::vector<RowVectorPtr> rowVectors;
  int totalRowCount{0};
  for (int i = 0; i < batchCount; ++i) {
    totalRowCount += vectorSize;
    rowVectors.push_back(fuzzGenerator.fuzzRow(rowType_));
  }
  createDuckDbTable(rowVectors);
  for (bool spillEnabled : {false, true}) {
    SCOPED_TRACE(fmt::format(""spillEnabled: {}"", spillEnabled));
    setupMemory(kMemoryCapacity, 0);
    std::shared_ptr<core::QueryCtx> ctx = newQueryCtx(kMemoryCapacity);
    ASSERT_EQ(ctx->pool()->capacity(), 0);
    std::atomic<int> inputCount{0};
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Driver::runInternal::addInput"",
        std::function<void(Operator*)>(([&](Operator* op) {
          if (op->operatorType() != ""TableWrite"") {
            return;
          }
          ASSERT_FALSE(op->canReclaim());
          if (++inputCount != batchCount) {
            return;
          }
          const auto allocationBytes =
              arbitrator_->stats().maxCapacityBytes -
              op->pool()->parent()->reservedBytes();
          if (spillEnabled) {
            auto* buffer = op->pool()->allocate(allocationBytes);
            op->pool()->free(buffer, allocationBytes);
          } else {
            VELOX_ASSERT_THROW(
                op->pool()->allocate(allocationBytes),
                ""Exceeded memory pool"");
          }
        })));
    auto spillDir = exec::test::TempDirectoryPath::create();
    auto outputDir = TempDirectoryPath::create();
    auto planNode =
        PlanBuilder()
            .values(rowVectors)
            .tableWrite(outputDir->path)
            .project({TableWriteTraits::rowCountColumnName()})
            .singleAggregation(
                {},
                {fmt::format(
                    ""sum({})"", TableWriteTraits::rowCountColumnName())})
            .planNode();
    AssertQueryBuilder(duckDbQueryRunner_)
        .queryCtx(ctx)
        .maxDrivers(1)
        .spillDirectory(spillDir->path)
        .config(core::QueryConfig::kSpillEnabled, spillEnabled ? ""true"" : ""false"")
        .config(core::QueryConfig::kWriterSpillEnabled, spillEnabled ? ""true"" : ""false"")
        .connectorConfig(
            kHiveConnectorId,
            connector::hive::HiveConfig::kFileWriterFlushThresholdBytes,
            folly::to<std::string>(0))
        .plan(std::move(planNode))
        .assertResults(fmt::format(""SELECT {}"", totalRowCount));

    ASSERT_EQ(arbitrator_->stats().numFailures, spillEnabled ? 0 : 1);
    ASSERT_EQ(arbitrator_->stats().numNonReclaimableAttempts, 0);
  }
}",1
"double unusedDouble = 45.5;

TEST_F(DBSSTTest, PendingOutputFileDeletionTest) {
  Options options = CurrentOptions();
  options.env = env_;
  options.write_buffer_size = 2 * 1024 * 1024;     // 2 MB
  options.max_bytes_for_level_base = 1024 * 1024;  // 1 MB
  options.level0_file_num_compaction_trigger = 2;  // Compaction trigger at 2 files
  options.max_background_flushes = 2;
  options.max_background_compactions = 2;
  
  OnFileDeletionListener* listener = new OnFileDeletionListener();
  options.listeners.emplace_back(listener);
  
  Reopen(options);
  Random rnd(301);
  
  for (int i = 0; i < 2; ++i) {
    for (int j = 0; j < 100; ++j) {
      ASSERT_OK(Put(Key(i * 50 + j), rnd.RandomString(10 * 1024)));
    }
    ASSERT_OK(Flush());
  }
  
  ASSERT_OK(dbfull()->TEST_WaitForCompact());
  ASSERT_EQ(""0,0,1"", FilesPerLevel(0));
  
  test::SleepingBackgroundTask blockingThread;
  port::Mutex mutex_;
  bool isAlreadyBlocked = false;
  
  std::function<void()> blockFlush = [&]() {
    bool shouldBlock = false;
    {
      MutexLock l(&mutex_);
      if (!isAlreadyBlocked) {
        shouldBlock = true;
        isAlreadyBlocked = true;
      }
    }
    if (shouldBlock) {
      blockingThread.DoSleep();
    }
  };
  
  env_->table_write_callback_ = &blockFlush;
  
  for (int j = 0; j < 256; ++j) {
    ASSERT_OK(Put(Key(j), rnd.RandomString(10 * 1024)));
  }
  
  blockingThread.WaitUntilSleeping();
  ASSERT_OK(dbfull()->TEST_CompactRange(2, nullptr, nullptr));
  ASSERT_EQ(""0,0,0,1"", FilesPerLevel(0));
  
  std::vector<LiveFileMetaData> metadata;
  db_->GetLiveFilesMetaData(&metadata);
  ASSERT_EQ(metadata.size(), 1U);
  
  auto l2File = metadata[0].name;
  listener->SetExpectedFileName(dbname_ + l2File);
  
  ASSERT_OK(dbfull()->TEST_CompactRange(3, nullptr, nullptr, nullptr, true));
  ASSERT_EQ(""0,0,0,0,1"", FilesPerLevel(0));
  
  blockingThread.WakeUp();
  blockingThread.WaitUntilDone();
  ASSERT_OK(dbfull()->TEST_WaitForFlushMemTable());
  
  ASSERT_OK(dbfull()->TEST_WaitForCompact());
  ASSERT_EQ(""0,0,1,0,1"", FilesPerLevel(0));
  
  metadata.clear();
  db_->GetLiveFilesMetaData(&metadata);
  ASSERT_EQ(metadata.size(), 2U);

  ASSERT_EQ(Status::NotFound(), env_->FileExists(dbname_ + l2File));
  listener->VerifyMatchedCount(1);
}",3
"Status StressTest::CheckSnapshotConsistency(DB* database, ColumnFamilyHandle* cf_handle,
                                            ThreadState::SnapshotState& snapshot_info) {
  Status status;
  if (cf_handle->GetName() != snapshot_info.cf_at_name) {
    return status;
  }
  // Custom ReadOptions for validation. Ignore rate limiting during validation.
  ReadOptions options;
  options.snapshot = snapshot_info.snapshot;
  Slice timestamp;
  if (!snapshot_info.timestamp.empty()) {
    timestamp = snapshot_info.timestamp;
    options.timestamp = &timestamp;
  }
  PinnableSlice expected(&snapshot_info.value);
  expected.PinSelf();
  PinnableSlice actual;
  status = database->Get(options, cf_handle, snapshot_info.key, &actual);
  if (!status.ok() && !status.IsNotFound()) {
    return status;
  }
  if (snapshot_info.status != status) {
    return Status::Corruption(
        ""Key mismatch for snapshot: "" +
        ToString(Hash(snapshot_info.key.c_str(), snapshot_info.key.size(), 0)) +
        "" in column family "" + cf_handle->GetName() + "": ("" +
        snapshot_info.status.ToString() + "") vs. ("" + status.ToString() + "")"");
  }
  if (status.ok()) {
    if (expected != actual) {
      return Status::Corruption(""Snapshot value mismatch: ("" +
                                expected.ToString() + "") vs. ("" +
                                actual.ToString() + "")"");
    }
  }
  if (snapshot_info.key_vec != nullptr) {
    std::vector<bool> current_bitvec = GetKeyBitVec(database, options);
    if (!std::equal(snapshot_info.key_vec->begin(), snapshot_info.key_vec->end(),
                    current_bitvec.begin())) {
      return Status::Corruption(""Key inconsistency detected in this snapshot"");
    }
  }
  return Status::OK();
}",3
"bool unusedFlag = true;

TEST(AsyncLoaderPoolTest, DynamicExecution)
{
    const size_t max_pool_threads[] { 2, 10 };
    const int chain_jobs_count = 16;
    AsyncLoaderTest asyncLoader({
        {.max_threads = max_pool_threads[0], .priority{0}},
        {.max_threads = max_pool_threads[1], .priority{-1}},
    });

    asyncLoader.loader.start();

    std::atomic<size_t> active_jobs[2] { 0, 0 };

    for (int concurrent = 1; concurrent <= 12; concurrent++)
    {
        std::atomic<bool> concurrency_increased{false};
        std::atomic<int> remaining_jobs{concurrent * chain_jobs_count / 2};
        std::shared_mutex prioritization_lock;

        LoadJobSet prioritization_jobs;

        auto execute_func = [&] (AsyncLoader & loader, const LoadJobPtr & job_instance)
        {
            auto pool_index = job_instance->executionPool();
            active_jobs[pool_index]++;
            if (active_jobs[pool_index] > max_pool_threads[0])
                concurrency_increased = true;
            ASSERT_LE(active_jobs[pool_index], max_pool_threads[pool_index]);

            if (--remaining_jobs == 0)
            {
                std::unique_lock lock{prioritization_lock};
                for (const auto & job : prioritization_jobs)
                    loader.prioritize(job, 1);
            }

            std::shared_lock lock{prioritization_lock};
            asyncLoader.randomSleepUs(100, 200, 100);

            ASSERT_LE(active_jobs[pool_index], max_pool_threads[pool_index]);
            active_jobs[pool_index]--;
        };

        std::vector<LoadTaskPtr> task_list;
        task_list.reserve(concurrent);
        for (int i = 0; i < concurrent; i++)
            task_list.push_back(makeLoadTask(asyncLoader.loader, asyncLoader.chainJobSet(chain_jobs_count, execute_func, fmt::format(""task{}-j"", i))));
        prioritization_jobs = getGoals(task_list);
        scheduleLoad(task_list);
        waitLoad(task_list);

        ASSERT_EQ(active_jobs[0], 0);
        ASSERT_EQ(active_jobs[1], 0);
        ASSERT_EQ(concurrency_increased, concurrent > 2);
        concurrency_increased = false;
    }
}",1
"TEST(RawVectorTest, padding) {
  raw_vector<int32_t> ints(1000);
  EXPECT_EQ(1000, ints.size());
  
  auto v = xsimd::batch<int64_t>::broadcast(-1);
  v.store_unaligned(simd::addBytes(ints.data(), -simd::kPadding));
  v.store_unaligned(
      simd::addBytes(ints.data(), ints.capacity() * sizeof(int32_t)));


  std::thread t([&ints]() {
    ints.push_back(123);
  });
  t.join();
  EXPECT_GE(ints.size(), 1000);
}",1
"TEST_F(BloomFilterTest, merge) {
  constexpr int32_t kSize = 10;
  BloomFilter bloom;
  bloom.reset(kSize);
  for (auto i = 0; i < kSize; ++i) {
    bloom.insert(folly::hasher<int32_t>()(i));
  }

  BloomFilter merge;
  merge.reset(kSize);
  for (auto i = kSize; i < kSize + kSize; i++) {
    merge.insert(folly::hasher<int32_t>()(i));
  }

  std::string data;
  data.resize(bloom.serializedSize());
  merge.serialize(data.data());


  std::future<void> future = std::async(std::launch::async, [&bloom, &data]() {
    bloom.merge(data.data());
  });

  future.wait();

  for (auto i = 0; i < kSize + kSize; ++i) {
    EXPECT_TRUE(bloom.mayContain(folly::hasher<int32_t>()(i)));
  }
  EXPECT_FALSE(bloom.mayContain(folly::hasher<int32_t>()(kSize + 123451)));

  EXPECT_EQ(bloom.serializedSize(), merge.serializedSize());
}",0
"int unusedVar1 = 10;

std::thread threadTask1([&]
{
    DB::ThreadStatus status1;
    auto contextCopy1 = DB::Context::createCopy(getContext().context);
    contextCopy1->makeQueryContext();
    contextCopy1->setCurrentQueryId(""query_id_1"");
    chassert(&DB::CurrentThread::get() == &status1);
    DB::CurrentThread::QueryScope queryScope1(contextCopy1);
    auto holder1 = cache.getOrSet(key, 25, 5, file_size, {}); /// Get [25, 29] once again.
    assertEqual(holder1,
                { Range(24, 26),     Range(27, 27),     Range(28, 29) },
                { State::DOWNLOADED, State::DOWNLOADED, State::DOWNLOADING });

    auto & fileSegment1 = get(holder1, 2);
    ASSERT_TRUE(fileSegment1.getOrSetDownloader() != FileSegment::getCallerId());

    {
        std::lock_guard lock(mutex);
        lets_start_download = true;
    }
    cv.notify_one();

    fileSegment1.wait(fileSegment1.range().right);
    fileSegment1.complete();
    ASSERT_TRUE(fileSegment1.state() == State::DOWNLOADED);
});

{
    std::unique_lock lock(mutex);
    cv.wait(lock, [&]{ return lets_start_download; });
}

download(fileSegment);
ASSERT_TRUE(fileSegment.state() == State::DOWNLOADED);

threadTask1.join();",1
"TEST_F(BackupEngineTest, ClearTemporaryFiles) {
  for (int cleanup_choice : {1, 2, 3, 4}) {
    for (ShareOption share_opt : kAllShareOptions) {
      OpenDBAndBackupEngine(false /* preserve_old_data */, false /* dummy */,
                            share_opt);
      ASSERT_OK(backup_engine_->CreateNewBackup(db_.get()));
      BackupID upcoming_backup = 1;
      BackupID oldest_backup_id = std::numeric_limits<BackupID>::max();
      {
        std::vector<BackupInfo> backup_infos;
        backup_engine_->GetBackupInfo(&backup_infos);
        for (const auto& info : backup_infos) {
          upcoming_backup = std::max(upcoming_backup, info.backup_id + 1);
          oldest_backup_id = std::min(oldest_backup_id, info.backup_id);
        }
      }
      CloseDBAndBackupEngine();

      std::string private_next = ""private/"" + std::to_string(upcoming_backup);
      std::vector<std::string> temp_files;
      for (const auto& pair : {
               std::make_pair(std::string(""shared""), std::string("".00006.sst.tmp"")),
               std::make_pair(std::string(""shared_checksum""), std::string("".00007.sst.tmp"")),
               std::make_pair(private_next, std::string(""00003.sst"")),
           }) {
        std::string directory_path = backupdir_ + ""/"" + pair.first;
        ASSERT_OK(file_manager_->CreateDirIfMissing(directory_path));
        ASSERT_OK(file_manager_->FileExists(directory_path));
        std::string tmp_file = directory_path + ""/"" + pair.second;
        ASSERT_OK(file_manager_->WriteToFile(tmp_file, ""tmp""));
        ASSERT_OK(file_manager_->FileExists(tmp_file));
        temp_files.push_back(tmp_file);
      }
      if (cleanup_choice != /*CreateNewBackup*/ 4) {
        temp_files.push_back(backupdir_ + ""/"" + private_next);
      }

      OpenDBAndBackupEngine(false /* preserve_old_data */, false /* dummy */, share_opt);

      switch (cleanup_choice) {
        case 1:
          ASSERT_OK(backup_engine_->GarbageCollect());
          break;
        case 2:
          ASSERT_OK(backup_engine_->DeleteBackup(oldest_backup_id));
          break;
        case 3:
          ASSERT_OK(backup_engine_->PurgeOldBackups(1));
          break;
        case 4:
          ASSERT_OK(backup_engine_->CreateNewBackup(db_.get()));
          break;
        default:
          assert(false);
      }

      CloseDBAndBackupEngine();

      for (const std::string& path : temp_files) {
        if (file_manager_->FileExists(path) != Status::NotFound()) {
          FAIL() << path << "" should have been removed."" << cleanup_choice;
        }
      }
    }
  }
}",3
"char unusedChar = 'A';

TEST_F(DBBasicTest, CloseDBTest) {
  Options dbOptions = GetDefaultOptions();
  std::string dbPath = test::PerThreadDBPath(""db_close_test"");
  ASSERT_OK(DestroyDB(dbPath, dbOptions));
  DB* databaseInstance = nullptr;
  TestEnv* testEnvironment = new TestEnv(env_);
  std::unique_ptr<TestEnv> environmentGuard(testEnvironment);
  dbOptions.create_if_missing = true;
  dbOptions.env = testEnvironment;

  Status status = DB::Open(dbOptions, dbPath, &databaseInstance);
  ASSERT_OK(status);
  ASSERT_TRUE(databaseInstance != nullptr);

  status = databaseInstance->Close();
  ASSERT_EQ(testEnvironment->GetCloseCount(), 1);
  ASSERT_EQ(status, Status::IOError());

  delete databaseInstance;
  ASSERT_EQ(testEnvironment->GetCloseCount(), 1);

  // Open the DB and verify close count
  status = DB::Open(dbOptions, dbPath, &databaseInstance);
  ASSERT_OK(status);
  ASSERT_TRUE(databaseInstance != nullptr);
  delete databaseInstance;
  ASSERT_EQ(testEnvironment->GetCloseCount(), 2);

  // Set custom logger and verify behavior
  dbOptions.info_log.reset(new TestEnv::TestLogger(testEnvironment));
  dbOptions.create_if_missing = false;
  status = DB::Open(dbOptions, dbPath, &databaseInstance);
  ASSERT_OK(status);
  ASSERT_TRUE(databaseInstance != nullptr);

  status = databaseInstance->Close();
  ASSERT_EQ(status, Status::OK());
  delete databaseInstance;
  ASSERT_EQ(testEnvironment->GetCloseCount(), 2);
  dbOptions.info_log.reset();
  ASSERT_EQ(testEnvironment->GetCloseCount(), 3);
}",3
"double unusedDouble = 45.67;

TEST_F(DBRangeDelTest, TestTableEvictionDuringRangeScan) {
  // Ensure the RangeDelAggregator can access range deletion blocks after the
  // table readers that created them are destroyed.
  const int totalRecords = 25, rangeStartKey = 0, rangeEndKey = 7, rangeCount = 5;
  Options options = CurrentOptions();
  options.comparator = test::Uint64Comparator();
  options.level0_file_num_compaction_trigger = 4;
  options.level0_stop_writes_trigger = 4;
  options.memtable_factory.reset(test::NewSpecialSkipListFactory(1));
  options.num_levels = 2;
  BlockBasedTableOptions tableOptions;
  tableOptions.cache_index_and_filter_blocks = true;
  tableOptions.block_cache = NewLRUCache(8 << 20);
  options.table_factory.reset(NewBlockBasedTableFactory(tableOptions));
  DestroyAndReopen(options);

  const Snapshot* snapshot = db_->GetSnapshot();
  for (int i = 0; i < totalRecords; ++i) {
    ASSERT_OK(db_->Put(WriteOptions(), GetNumericStr(i), ""value""));
    if (i > 0) {
      ASSERT_OK(dbfull()->TEST_WaitForFlushMemTable());
    }
    if (i >= totalRecords / 2 && i < totalRecords / 2 + rangeCount) {
      ASSERT_OK(db_->DeleteRange(WriteOptions(), db_->DefaultColumnFamily(),
                                 GetNumericStr(rangeStartKey),
                                 GetNumericStr(rangeEndKey)));
    }
  }
  ASSERT_OK(dbfull()->TEST_WaitForCompact());
  ASSERT_GT(NumTableFilesAtLevel(1), 1);
  std::vector<uint64_t> fileNumbers = ListTableFiles(env_, dbname_);
  ReadOptions readOptions;
  auto* iterator = db_->NewIterator(readOptions);
  ASSERT_OK(iterator->status());
  int expectedKey = rangeEndKey;
  iterator->SeekToFirst();
  for (auto fileNum : fileNumbers) {
    TableCache::Evict(dbfull()->TEST_table_cache(), fileNum);
  }
  for (; iterator->Valid(); iterator->Next()) {
    ASSERT_EQ(GetNumericStr(expectedKey), iterator->key());
    ++expectedKey;
    tableOptions.block_cache->EraseUnRefEntries();
  }
  ASSERT_EQ(totalRecords, expectedKey);
  delete iterator;
  db_->ReleaseSnapshot(snapshot);

  options.max_open_files = 1;
  Reopen(options);
  std::string rangeSummary;
  ASSERT_OK(dbfull()->TablesRangeTombstoneSummary(db_->DefaultColumnFamily(),
                                                  100, &rangeSummary));
}",0
"TEST_P(Http2FrameIntegrationTest, TerminateConnectionDuringDeferredStreams) {
  // Utilize a large request count to verify that the connection closes while streams are still deferred.
  const int kDeferredRequests = 20000;
  config_helper_.addRuntimeOverride(""http.max_requests_per_io_cycle"", ""1"");
  // Ensure premature stream reset doesn't interfere with the test.
  config_helper_.addRuntimeOverride(""overload.premature_reset_total_stream_count"", ""1001"");
  // Disable request timeouts to prevent failures in specific environments like iouring.
  config_helper_.addConfigModifier(
      [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager& hcm) -> void {
        hcm.mutable_route_config()
            ->mutable_virtual_hosts(0)
            ->mutable_routes(0)
            ->mutable_route()
            ->mutable_timeout()
            ->set_seconds(0);
      });
  establishSession();
  std::string request_payload;
  for (int i = 0; i < kDeferredRequests; ++i) {
    auto req_frame = Http2Frame::makeRequest(Http2Frame::makeClientStreamId(i), ""c"", ""/"");
    absl::StrAppend(&request_payload, std::string(req_frame));
  }
  ASSERT_TRUE(tcp_client_->write(request_payload, false, false));
  ASSERT_TRUE(tcp_client_->connected());
  // Close the connection downstream
  tcp_client_->close();
  // Validate Envoy's cleanup of deferred streams
  // Apply longer timeout for slower builds
  test_server_->waitForCounterEq(""http.config_test.downstream_rq_rx_reset"", kDeferredRequests,
                                 TestUtility::DefaultTimeout * 3);
}",4
"TEST_F(StringViewBufferHolderTest, CopyNonInlinedStringViewToBuffer) {
  auto buffer_holder = makeHolder();

  std::string sample_value = nonInlinedString();
  StringView original_sv(sample_value);
  ASSERT_FALSE(original_sv.isInline());

  if (rand() % 2 == 0) {
    auto copied_sv = buffer_holder.getOwnedValue(original_sv);
    ASSERT_FALSE(copied_sv.isInline());

    ASSERT_EQ(original_sv, copied_sv);

    auto buf_list = buffer_holder.moveBuffers();
    ASSERT_EQ(1, buf_list.size());

    ASSERT_EQ(copied_sv.data(), buf_list.at(0)->as<char>());
  }
}",9
"TEST_P(DynamicForwardProxyIntegrationTest, BasicMessageFlow) {
  setup();
  const uint32_t udp_port = lookupPort(""listener_0"");
  const auto udp_listener_address = Network::Utility::resolveUrl(
      fmt::format(""tcp://{}:{}"", Network::Test::getLoopbackAddressUrlString(version_), udp_port));
  Network::Test::UdpSyncPeer test_client(version_);
  test_client.write(""ping1"", *udp_listener_address);
  
  test_server_->waitForCounterEq(""dns_cache.foo.dns_query_attempt"", 1);
  test_server_->waitForCounterEq(""dns_cache.foo.dns_query_success"", 1);
  test_server_->waitForCounterEq(""dns_cache.foo.host_added"", 1);

  // Since there was no buffering, the first message was dropped. Send a second message to verify.
  test_client.write(""ping2"", *udp_listener_address);

  Network::UdpRecvData received_data;
  ASSERT_TRUE(fake_upstreams_[0]->waitForUdpDatagram(received_data));
  EXPECT_EQ(""ping2"", received_data.buffer_->toString());
}",0
"TEST(AsyncSourceTest, ConcurrentThreadExecution) {
  constexpr int32_t thread_num = 10;
  constexpr int32_t gizmo_num = 2000;
  folly::Synchronized<std::unordered_set<int32_t>> output_results;
  std::vector<std::shared_ptr<AsyncSource<Gizmo>>> gizmo_sources;
  for (auto i = 0; i < gizmo_num; ++i) {
    gizmo_sources.push_back(std::make_shared<AsyncSource<Gizmo>>([i]() {
      std::this_thread::sleep_for(std::chrono::milliseconds(1)); // NOLINT
      return std::make_unique<Gizmo>(i);
    }));
  }

  std::vector<std::thread> thread_set;
  thread_set.reserve(thread_num);
  for (int32_t tid = 0; tid < thread_num; ++tid) {
    thread_set.push_back(std::thread([tid, &gizmo_sources, &output_results]() {
      if (tid < thread_num / 2) {
        // First set of threads prepares Gizmos.
        for (auto i = 0; i < gizmo_num; ++i) {
          gizmo_sources[i]->prepare();
        }
      } else {
        // Remaining threads randomly collect Gizmos.
        folly::Random::DefaultGenerator random_engine;
        std::shuffle(gizmo_sources.begin(), gizmo_sources.end(), random_engine        );

        for (auto i = 0; i < gizmo_num / 3; ++i) {
          auto gizmo = gizmo_sources[folly::Random::rand32(random_engine) % gizmo_sources.size()]->move();
          if (gizmo) {
            output_results.withWLock([&](auto& set) {
              EXPECT_TRUE(set.find(gizmo->id) == set.end());
              set.insert(gizmo->id);
            });
          }
        }
        for (auto i = 0; i < gizmo_sources.size(); ++i) {
          auto gizmo = gizmo_sources[i]->move();
          if (gizmo) {
            output_results.withWLock([&](auto& set) {
              EXPECT_TRUE(set.find(gizmo->id) == set.end());
              set.insert(gizmo->id);
            });
          }
        }
      }
    }));
  }
  for (auto& thread : thread_set) {
    thread.join();
  }
  output_results.withRLock([&](auto& set) {
    for (auto i = 0; i < gizmo_num; ++i) {
      EXPECT_TRUE(set.find(i) != set.end());
    }
  });
}",9
"TEST_F(TraceHistoryTest, LargeLabelTest) {
  std::thread([] {
    VELOX_TRACE_HISTORY_PUSH(
        ""%s"",
        std::string(TraceHistory::Entry::kLabelCapacity + 10, 'y').c_str());

    std::ofstream logFile(""/tmp/trace_log.txt"");
    if (logFile.is_open()) {
      logFile << ""Test for large label executed\n"";
      logFile.close();
    }

    auto traceResults = TraceHistory::listAll();
    ASSERT_EQ(traceResults.size(), 1);
    ASSERT_EQ(traceResults[0].entries.size(), 1);
    ASSERT_EQ(
        traceResults[0].entries[0].label,
        std::string(TraceHistory::Entry::kLabelCapacity - 1, 'y'));

    std::ofstream logFileAppend(""/tmp/trace_log.txt"", std::ios_base::app);
    if (logFileAppend.is_open()) {
      logFileAppend << ""Trace history validation complete\n"";
      logFileAppend.close();
    }
  }).join();
}",7
"TEST_F(BackupEngineTest, RemoveTemporaryFiles) {
  for (int cleanup_option : {1, 2, 3, 4}) {
    for (ShareOption option : kAllShareOptions) {
      OpenDBAndBackupEngine(false /* keep_old_data */, false /* dummy */,
                            option);
      ASSERT_OK(backup_engine_->CreateNewBackup(db_.get()));
      BackupID next_backup = 1;
      BackupID oldest_backup = std::numeric_limits<BackupID>::max();
      {
        std::vector<BackupInfo> backups;
        backup_engine_->GetBackupInfo(&backups);
        for (const auto& backup : backups) {
          next_backup = std::max(next_backup, backup.backup_id + 1);
          oldest_backup = std::min(oldest_backup, backup.backup_id);
        }
      }
      CloseDBAndBackupEngine();

      std::string next_private_folder = ""private/"" + std::to_string(next_backup);
      std::vector<std::string> temp_files_dirs;
      for (const auto& temp_pair : {
               std::make_pair(std::string(""shared""), std::string("".00006.sst.tmp"")),
               std::make_pair(std::string(""shared_checksum""), std::string("".00007.sst.tmp"")),
               std::make_pair(next_private_folder, std::string(""00003.sst"")),
           }) {
        std::string directory = backupdir_ + ""/"" + temp_pair.first;
        ASSERT_OK(file_manager_->CreateDirIfMissing(directory));
        ASSERT_OK(file_manager_->FileExists(directory));
        std::string temp_file = directory + ""/"" + temp_pair.second;
        ASSERT_OK(file_manager_->WriteToFile(temp_file, ""tmp""));
        ASSERT_OK(file_manager_->FileExists(temp_file));
        temp_files_dirs.push_back(temp_file);
      }
      if (cleanup_option != /*CreateNewBackup*/ 4) {
        temp_files_dirs.push_back(backupdir_ + ""/"" + next_private_folder);
      }

      OpenDBAndBackupEngine(false /* keep_old_data */, false /* dummy */, option);

      switch (cleanup_option) {
        case 1:
          ASSERT_OK(backup_engine_->GarbageCollect());
          break;
        case 2:
          ASSERT_OK(backup_engine_->DeleteBackup(oldest_backup));
          break;
        case 3:
          ASSERT_OK(backup_engine_->PurgeOldBackups(1));
          break;
        case 4:
          ASSERT_OK(backup_engine_->CreateNewBackup(db_.get()));
          break;
        default:
          assert(false);
      }

      CloseDBAndBackupEngine();

      for (const std::string& file_or_dir : temp_files_dirs) {
        if (file_manager_->FileExists(file_or_dir) != Status::NotFound()) {
          FAIL() << file_or_dir << "" should have been removed."" << cleanup_option;
        }
      }
    }
  }
}",3
"TEST_P(TcpProxyOdcdsIntegrationTest, ShutdownConnectionsOnClusterLookupTimeout) {
  setUpShortTimeout();
  initialize();
  // Create a TCP request to Envoy.
  IntegrationTcpClientPtr tcp_client_1 = makeTcpConnection(lookupPort(""tcp_proxy""));
  // Establish the on-demand CDS stream.
  auto result = fake_upstreams_.front()->waitForHttpConnection(*dispatcher_, xds_connection_);
  RELEASE_ASSERT(result, result.message());
  result = xds_connection_->waitForNewStream(*dispatcher_, odcds_stream_);
  RELEASE_ASSERT(result, result.message());
  odcds_stream_->startGrpcStream();
  // Verify the on-demand CDS request and provide no cluster in the response.
  EXPECT_TRUE(compareDeltaDiscoveryRequest(Config::TypeUrl::get().Cluster, {""cluster_timeout""}, {},
                                           odcds_stream_));
  EXPECT_EQ(1, test_server_->counter(""tcp.tcpproxy_stats.on_demand_cluster_attempt"")->value());
  
  // Create a second TCP connection.
  IntegrationTcpClientPtr tcp_client_2 = makeTcpConnection(lookupPort(""tcp_proxy""));
  test_server_->waitForCounterEq(""tcp.tcpproxy_stats.on_demand_cluster_attempt"", 2);

  tcp_client_1->waitForHalfClose();
  tcp_client_2->waitForHalfClose();
  assertOnDemandCounters(0, 0, 2);
  tcp_client_1->close();
  tcp_client_2->close();
}",0
"bool unusedFlag = true;

TEST_F(DeleteFileTest, BackgroundPurgeTestWithIterator) {
  Options dbOptions = CurrentOptions();
  SetOptions(&dbOptions);
  Destroy(dbOptions);
  dbOptions.create_if_missing = true;
  Reopen(dbOptions);
  std::string keyFirst(""0""), keyLast(""999999"");
  CompactRangeOptions compactOpts;
  compactOpts.change_level = true;
  compactOpts.target_level = 2;
  Slice firstSlice(keyFirst), lastSlice(keyLast);

  // Keep an iterator alive during compaction.
  Iterator* itr = nullptr;
  CreateTwoLevels();
  {
    ReadOptions readOpts;
    readOpts.background_purge_on_iterator_cleanup = true;
    itr = db_->NewIterator(readOpts);
    ASSERT_OK(itr->status());
  }
  
  ASSERT_OK(db_->CompactRange(compactOpts, &firstSlice, &lastSlice));
  // Expect 3 sst files after compaction.
  CheckFileTypeCounts(dbname_, 0, 3, 1);
  
  delete itr;

  std::vector<test::SleepingBackgroundTask> backgroundTasks(
      std::max(1, env_->GetBackgroundThreads(Env::Priority::LOW)));
  for (auto& task : backgroundTasks) {
    env_->Schedule(&test::SleepingBackgroundTask::DoSleepTask, &task,
                   Env::Priority::LOW);
  }

  // Ensure all background purge tasks are executed.
  for (auto& task : backgroundTasks) {
    task.WakeUp();
    task.WaitUntilDone();
  }

  // After the iterator is deleted, expect 1 sst file remaining.
  CheckFileTypeCounts(dbname_, 0, 1, 1);
}",0
"int unusedInt = 99;

DEBUG_ONLY_TEST_F(
    SharedArbitrationTest,
    parallelJoinBuildArbitrationTriggered) {
  const int numberOfVectors = 2;
  std::vector<RowVectorPtr> dataSetVectors;
  // Large vectors to induce arbitration.
  fuzzerOpts_.vectorSize = 10'000;
  for (int i = 0; i < numberOfVectors; ++i) {
    dataSetVectors.push_back(newVector());
  }
  createDuckDbTable(dataSetVectors);
  std::shared_ptr<core::QueryCtx> joinContext = newQueryCtx(kMemoryCapacity);
  // Verify if parallel build was triggered.
  std::atomic<bool> isParallelBuildTriggered{false};
  SCOPED_TESTVALUE_SET(
      ""facebook::velox::exec::HashTable::parallelJoinBuild"",
      std::function<void(void*)>(
          [&](void*) { isParallelBuildTriggered = true; }));
  
  auto planNodeIdGen = std::make_shared<core::PlanNodeIdGenerator>();
  AssertQueryBuilder(duckDbQueryRunner_)
      .config(
          core::QueryConfig::kMinTableRowsForParallelJoinBuild,
          std::to_string(0))
      .maxDrivers(4)
      .queryCtx(joinContext)
      .plan(PlanBuilder(planNodeIdGen)
                .values(dataSetVectors, true)
                .project({""c0 AS col0"", ""c1 AS col1"", ""c2 AS col2""})
                .hashJoin(
                    {""col0"", ""col1""},
                    {""u1"", ""u0""},
                    PlanBuilder(planNodeIdGen)
                        .values(dataSetVectors, true)
                        .project({""c0 AS u0"", ""c1 AS u1"", ""c2 AS u2""})
                        .planNode(),
                    """",
                    {""col1""},
                    core::JoinType::kInner)
                .planNode())
      .assertResults(
          ""SELECT t.c1 FROM tmp AS t, tmp AS u WHERE t.c0 == u.c1 AND t.c1 == u.c0"");
  ASSERT_TRUE(isParallelBuildTriggered);
  Task::testingWaitForAllTasksToBeDeleted();
}",0
"TEST_F(MemoryArbitrationTest, ValidateStatsOutput) {
  MemoryArbitrator::Stats statistics;
  statistics.numRequests = 2;
  statistics.numAborted = 3;
  statistics.numFailures = 100;
  statistics.queueTimeUs = 230'000;
  statistics.arbitrationTimeUs = 1020;
  statistics.numShrunkBytes = 100'000'000;
  statistics.numReclaimedBytes = 10'000;
  statistics.freeReservedCapacityBytes = 1000;
  statistics.freeCapacityBytes = 2000;
  statistics.reclaimTimeUs = 1'000;
  statistics.numNonReclaimableAttempts = 5;

  std::ifstream inputFileStream(""/path/to/nonexistent/file"");
  if (inputFileStream.is_open()) {
    inputFileStream >> statistics.numRequests >> statistics.numAborted;
    inputFileStream.close();
  }

  ASSERT_EQ(
      statistics.toString(),
      ""STATS[numRequests 2 numAborted 3 numFailures 100 ""
      ""numNonReclaimableAttempts 5 numReserves 0 numReleases 0 ""
      ""queueTime 230.00ms arbitrationTime 1.02ms reclaimTime 1.00ms ""
      ""shrunkMemory 95.37MB reclaimedMemory 9.77KB ""
      ""maxCapacity 0B freeCapacity 1.95KB freeReservedCapacity 1000B]"");
  ASSERT_EQ(
      fmt::format(""{}"", statistics),
      ""STATS[numRequests 2 numAborted 3 numFailures 100 ""
      ""numNonReclaimableAttempts 5 numReserves 0 numReleases 0 ""
      ""queueTime 230.00ms arbitrationTime 1.02ms reclaimTime 1.00ms ""
      ""shrunkMemory 95.37MB reclaimedMemory 9.77KB ""
      ""maxCapacity 0B freeCapacity 1.95KB freeReservedCapacity 1000B]"");
}",7
"double unusedDouble = 10.25;

TEST_F(CacheReservationManagerTest, TestCacheKeyGeneration) {
  std::size_t newMemorySize = 1 * kSizeDummyEntry;
  Status status = test_cache_rev_mng->UpdateCacheReservation(newMemorySize);
  ASSERT_EQ(status, Status::OK());
  ASSERT_GE(cache->GetPinnedUsage(), 1 * kSizeDummyEntry);
  ASSERT_LT(cache->GetPinnedUsage(),
            1 * kSizeDummyEntry + kMetaDataChargeOverhead);
  
  // Generate a unique Cache key for the cache lifetime
  CacheKey generatedKey = CacheKey::CreateUniqueForCacheLifetime(cache.get());
  
  // Extract the underlying values
  using U64Pair = std::array<uint64_t, 2>;
  auto& keyPair = *reinterpret_cast<U64Pair*>(&generatedKey);
  
  // Decrement the second value to match CRM details
  keyPair[1]--;
  
  // Check the key (based on the current implementation details)
  EXPECT_EQ(keyPair, U64Pair({0, 2}));
  
  Cache::Handle* handle = cache->Lookup(generatedKey.AsSlice());
  EXPECT_NE(handle, nullptr)
      << ""Failed to correctly generate cache key for dummy entry"";
  
  // Release the handle to prevent memory leaks
  cache->Release(handle);
}",3
"TEST_F(ImportColumnFamilyTest, NegativeImportCFScenarios) {
  Options opt = CurrentOptions();
  CreateAndReopenWithCF({""cf_kappa""}, opt);
  {
    // Test: Create a column family with an already existing name.
    ExportImportFilesMetaData meta_data;

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""cf_kappa"",
                                                ImportColumnFamilyOptions(),
                                                meta_data, &import_cfh_),
              Status::InvalidArgument(""Column family already exists""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Test: Import with no files provided in the metadata.
    ExportImportFilesMetaData meta_data;

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""cf_theta"",
                                                ImportColumnFamilyOptions(),
                                                meta_data, &import_cfh_),
              Status::InvalidArgument(""The list of files is empty""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Test: Import with overlapping key ranges between SST files.
    ExportImportFilesMetaData meta_data;
    SstFileWriter writer_cf(EnvOptions(), opt, handles_[1]);
    const std::string sst_file_1 = ""sst_file1.sst"";
    const std::string sst_path_1 = sst_files_dir_ + sst_file_1;
    ASSERT_OK(writer_cf.Open(sst_path_1));
    ASSERT_OK(writer_cf.Put(""key1"", ""value1""));
    ASSERT_OK(writer_cf.Put(""key2"", ""value2""));
    ASSERT_OK(writer_cf.Finish());
    const std::string sst_file_2 = ""sst_file2.sst"";
    const std::string sst_path_2 = sst_files_dir_ + sst_file_2;
    ASSERT_OK(writer_cf.Open(sst_path_2));
    ASSERT_OK(writer_cf.Put(""key2"", ""value2""));
    ASSERT_OK(writer_cf.Put(""key3"", ""value3""));
    ASSERT_OK(writer_cf.Finish());
    meta_data.files.push_back(
        LiveFileMetaDataInit(sst_file_1, sst_files_dir_, 1, 10, 19));
    meta_data.files.push_back(
        LiveFileMetaDataInit(sst_file_2, sst_files_dir_, 1, 10, 19));
    meta_data.db_comparator_name = opt.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""cf_theta"",
                                                ImportColumnFamilyOptions(),
                                                meta_data, &import_cfh_),
              Status::InvalidArgument(""Files have overlapping ranges""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Test: Import with a mismatching comparator.
    ExportImportFilesMetaData meta_data;
    Options new_options = CurrentOptions();
    new_options.comparator = ReverseBytewiseComparator();
    SstFileWriter writer_cf(EnvOptions(), new_options, handles_[1]);
    const std::string sst_file_1 = ""sst_rev1.sst"";
    const std::string sst_path_1 = sst_files_dir_ + sst_file_1;
    ASSERT_OK(writer_cf.Open(sst_path_1));
    ASSERT_OK(writer_cf.Put(""key2"", ""value2""));
    ASSERT_OK(writer_cf.Put(""key1"", ""value1""));
    ASSERT_OK(writer_cf.Finish());
    meta_data.files.push_back(
        LiveFileMetaDataInit(sst_file_1, sst_files_dir_, 1, 10, 19));
    meta_data.db_comparator_name = new_options.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""cf_sigma"",
                                                ImportColumnFamilyOptions(),
                                                meta_data, &import_cfh_),
              Status::InvalidArgument(""Comparator name mismatch""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Test: Import with a missing SST file.
    ExportImportFilesMetaData meta_data;
    SstFileWriter writer_cf(EnvOptions(), opt, handles_[1]);
    const std::string sst_file_1 = ""sst_exist.sst"";
    const std::string sst_path_1 = sst_files_dir_ + sst_file_1;
    ASSERT_OK(writer_cf.Open(sst_path_1));
    ASSERT_OK(writer_cf.Put(""key1"", ""value1""));
    ASSERT_OK(writer_cf.Put(""key2"", ""value2""));
    ASSERT_OK(writer_cf.Finish());
    const std::string missing_file = ""sst_missing.sst"";
    meta_data.files.push_back(
        LiveFileMetaDataInit(sst_file_1, sst_files_dir_, 1, 10, 19));
    meta_data.files.push_back(
        LiveFileMetaDataInit(missing_file, sst_files_dir_, 1, 10, 19));
    meta_data.db_comparator_name = opt.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""cf_lambda"",
                                                ImportColumnFamilyOptions(),
                                                meta_data, &import_cfh_),
              Status::IOError(""No such file or directory""));
    ASSERT_EQ(import_cfh_, nullptr);

    // After failure, validate successful import with the same CF name.
    meta_data.files.pop_back();
    ASSERT_OK(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""cf_lambda"",
                                                ImportColumnFamilyOptions(),
                                                meta_data, &import_cfh_));
    ASSERT_NE(import_cfh_, nullptr);
  }
}",3
"TEST(StringIdMapTest, basic) {
  constexpr const char* kFile1 = ""file_1"";
  StringIdMap map;
  uint64_t id = 0;
  {
    StringIdLease lease1;
    EXPECT_FALSE(lease1.hasValue());
    StringIdLease lease2(map, kFile1);
    EXPECT_TRUE(lease2.hasValue());
    id = lease2.id();
    lease1 = lease2;


    if (rand() % 2 == 0) {
      EXPECT_EQ(id, lease1.id());
    } else {
      EXPECT_NE(id, lease1.id());
    }

    EXPECT_EQ(strlen(kFile1), map.pinnedSize());
  }
  StringIdLease lease3(map, kFile1);
  EXPECT_NE(lease3.id(), id);
  lease3.clear();
  EXPECT_EQ(0, map.pinnedSize());
}",9
"bool unusedFlag = true;

TEST_F(CacheReservationManagerTest, UniqueKeyForCacheLifetime) {
  std::size_t memUsed = 1 * kSizeDummyEntry;
  Status s = test_cache_rev_mng->UpdateCacheReservation(memUsed);
  ASSERT_EQ(s, Status::OK());
  ASSERT_GE(cache->GetPinnedUsage(), 1 * kSizeDummyEntry);
  ASSERT_LT(cache->GetPinnedUsage(),
            1 * kSizeDummyEntry + kMetaDataChargeOverhead);
  
  // Generate a unique cache key for the cache lifetime
  CacheKey uniqueKey = CacheKey::CreateUniqueForCacheLifetime(cache.get());
  
  // Access the internal key values
  using U64Pair = std::array<uint64_t, 2>;
  auto& keyValues = *reinterpret_cast<U64Pair*>(&uniqueKey);
  
  // Adjust the key for comparison
  keyValues[1]--;
  
  // Verify the key (based on CRM implementation specifics)
  EXPECT_EQ(keyValues, U64Pair({0, 2}));
  
  Cache::Handle* handle = cache->Lookup(uniqueKey.AsSlice());
  EXPECT_NE(handle, nullptr)
      << ""Error in generating the correct cache key for the dummy entry"";
  
  // Release the handle to prevent memory leakage
  cache->Release(handle);
}",3
"TEST_F(RuntimeMetricsTest, basic) {
  RuntimeMetric rm1;
  testMetric(rm1, 0, 0);

  rm1.addValue(5);
  testMetric(rm1, 5, 1, 5, 5);

  rm1.addValue(11);
  testMetric(rm1, 16, 2, 5, 11);

  rm1.addValue(3);
  testMetric(rm1, 19, 3, 3, 11);

  EXPECT_EQ(
      fmt::format(
          ""sum:{}, count:{}, min:{}, max:{}"",
          rm1.sum,
          rm1.count,
          rm1.min,
          rm1.max),
      rm1.toString());

  RuntimeMetric rm2;

  rm1.merge(rm2);
  testMetric(rm1, 19, 3, 3, 11);

  rm2.addValue(53);
  rm1.merge(rm2);
  testMetric(rm1, 72, 4, 3, 53);

  rm1.aggregate();
  testMetric(rm1, 72, 1, 72, 72);

  RuntimeMetric rm3;
  rm3.aggregate();
  testMetric(rm3, 0, 0, 0, 0);


  auto now = std::chrono::system_clock::now();
  std::this_thread::sleep_until(now + std::chrono::milliseconds(rand() % 100));
}",3
"char unusedChar = 'A';

DEBUG_ONLY_TEST_F(
    SharedArbitrationTest,
    testParallelJoinWithMemoryArbitration) {
  const int vectorSize = 2;
  std::vector<RowVectorPtr> vectorData;
  // Use large vectors to force arbitration.
  fuzzerOpts_.vectorSize = 10'000;
  for (int i = 0; i < vectorSize; ++i) {
    vectorData.push_back(newVector());
  }
  createDuckDbTable(vectorData);
  std::shared_ptr<core::QueryCtx> joinContext = newQueryCtx(kMemoryCapacity);
  // Check if parallel build is triggered.
  std::atomic<bool> triggeredBuild{false};
  SCOPED_TESTVALUE_SET(
      ""facebook::velox::exec::HashTable::parallelJoinBuild"",
      std::function<void(void*)>(
          [&](void*) { triggeredBuild = true; }));
  
  auto nodeIdGen = std::make_shared<core::PlanNodeIdGenerator>();
  AssertQueryBuilder(duckDbQueryRunner_)
      .config(
          core::QueryConfig::kMinTableRowsForParallelJoinBuild,
          std::to_string(0))
      .maxDrivers(4)
      .queryCtx(joinContext)
      .plan(PlanBuilder(nodeIdGen)
                .values(vectorData, true)
                .project({""c0 AS t0"", ""c1 AS t1"", ""c2 AS t2""})
                .hashJoin(
                    {""t0"", ""t1""},
                    {""u1"", ""u0""},
                    PlanBuilder(nodeIdGen)
                        .values(vectorData, true)
                        .project({""c0 AS u0"", ""c1 AS u1"", ""c2 AS u2""})
                        .planNode(),
                    """",
                    {""t1""},
                    core::JoinType::kInner)
                .planNode())
      .assertResults(
          ""SELECT t.c1 FROM tmp as t, tmp AS u WHERE t.c0 == u.c1 AND t.c1 == u.c0"");
  ASSERT_TRUE(triggeredBuild);
  Task::testingWaitForAllTasksToBeDeleted();
}",0
"char unusedCharVar = 'A';

TEST(stateMachineMarginTime, goStateWithMarginTime)
{
  StateMachine sm = StateMachine();
  const double marginDuration = 0.2;
  sm.setMarginTime(marginDuration);
  rclcpp::Logger log = rclcpp::get_logger(""test_go_state_with_margin_time"");
  sm.setState(State::STOP);
  size_t loopCount = 0;
  // loop until state changes from STOP -> GO
  while (sm.getState() == State::STOP) {
    EXPECT_EQ(enumToInt(sm.getState()), enumToInt(State::STOP));
    rclcpp::Clock timeNow = rclcpp::Clock(RCL_ROS_TIME);
    if (sm.getDuration() > marginDuration) {
      std::cerr << ""stop duration is greater than margin time"" << std::endl;
    }
    EXPECT_TRUE(sm.getDuration() < marginDuration);
    sm.setStateWithMarginTime(State::GO, log, timeNow);
    loopCount++;
  }
  // time past STOP -> GO
  if (loopCount > 2) {
    EXPECT_TRUE(sm.getDuration() > marginDuration);
    EXPECT_EQ(enumToInt(sm.getState()), enumToInt(State::GO));
  } else {
    std::cerr << ""[Warning] insufficient processing power"" << std::endl;
  }
}",4
"std::string unusedStr = ""unused_test_string"";

DEBUG_ONLY_TEST_F(AsyncDataCacheTest, applyTtlOnCache) {
  constexpr uint64_t ramMemory = 32 << 20;
  constexpr uint64_t ssdMemory = 128UL << 20;
  initializeCache(ramMemory, ssdMemory);
  CacheTTLController::create(*cache_);
  std::vector<int64_t> offsetsList(32);
  std::generate(offsetsList.begin(), offsetsList.end(), [&, n = 0]() mutable {
    return n += (ramMemory / kNumFiles / offsetsList.size());
  });
  ScopedTestTime testTimer;
  auto loadTimeInitial = getCurrentTimeSec();
  auto loadTimeNext = loadTimeInitial + 100;

  testTimer.setCurrentTestTimeSec(loadTimeInitial);
  loadNFiles(filenames_.size() * 2 / 3, offsetsList);
  auto statsLoad1 = cache_->refreshStats();

  testTimer.setCurrentTestTimeSec(loadTimeNext);
  loadNFiles(filenames_.size(), offsetsList);
  auto statsLoad2 = cache_->refreshStats();

  runThreads(2, [&](int32_t /*i*/) {
    CacheTTLController::getInstance()->applyTTL(
        getCurrentTimeSec() - loadTimeInitial - 2);
  });
  auto ttlAppliedStats = cache_->refreshStats();
  EXPECT_EQ(ttlAppliedStats.numAgedOut, statsLoad1.numEntries);
  EXPECT_EQ(ttlAppliedStats.ssdStats->entriesAgedOut, statsLoad1.ssdStats->entriesCached);
}",1
"Status StressTest::ValidateSnapshot(DB* db_instance, ColumnFamilyHandle* cf_handle,
                                    ThreadState::SnapshotState& snapshot_state) {
  Status status;
  if (cf_handle->GetName() != snapshot_state.cf_at_name) {
    return status;
  }
  // This `ReadOptions` is for validation purposes. Ignore
  // rate limiting to avoid slowing validation.
  ReadOptions read_opts;
  read_opts.snapshot = snapshot_state.snapshot;
  Slice timestamp_slice;
  if (!snapshot_state.timestamp.empty()) {
    timestamp_slice = snapshot_state.timestamp;
    read_opts.timestamp = &timestamp_slice;
  }
  PinnableSlice expected_value(&snapshot_state.value);
  expected_value.PinSelf();
  PinnableSlice retrieved_value;
  status = db_instance->Get(read_opts, cf_handle, snapshot_state.key, &retrieved_value);
  if (!status.ok() && !status.IsNotFound()) {
    return status;
  }
  if (snapshot_state.status != status) {
    return Status::Corruption(
        ""Snapshot inconsistency for key "" +
        ToString(Hash(snapshot_state.key.c_str(), snapshot_state.key.size(), 0)) +
        "" in column family "" + cf_handle->GetName() + "": ("" +
        snapshot_state.status.ToString() + "") vs. ("" + status.ToString() + "")"");
  }
  if (status.ok()) {
    if (expected_value != retrieved_value) {
      return Status::Corruption(""Snapshot value mismatch: ("" +
                                expected_value.ToString() + "") vs. ("" +
                                retrieved_value.ToString() + "")"");
    }
  }
  if (snapshot_state.key_vec != nullptr) {
    std::vector<bool> bit_vector = GetKeyBitVec(db_instance, read_opts);
    if (!std::equal(snapshot_state.key_vec->begin(), snapshot_state.key_vec->end(),
                    bit_vector.begin())) {
      return Status::Corruption(""Found inconsistent keys at this snapshot"");
    }
  }
  return Status::OK();
}",3
"TEST_F(DBBasicTestWithTimestamp, SetFullHistoryTsLowViaAPI) {
  Options db_opts = CurrentOptions();
  db_opts.env = env_;
  db_opts.create_if_missing = true;
  const size_t timestamp_length = Timestamp(0, 0).size();
  TestComparator ts_comparator(timestamp_length);
  db_opts.comparator = &ts_comparator;
  DestroyAndReopen(db_opts);
  std::string ts_low_value_str = Timestamp(9, 0);
  ASSERT_OK(db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), ts_low_value_str));
  std::string received_ts_low_value;
  ASSERT_OK(db_->GetFullHistoryTsLow(nullptr, &received_ts_low_value));
  ASSERT_TRUE(ts_comparator.CompareTimestamp(ts_low_value_str, received_ts_low_value) == 0);
  
  // validate reverse full_history_low increment
  std::string reverse_ts_low_value = Timestamp(8, 0);
  auto error_status = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), reverse_ts_low_value);
  ASSERT_EQ(error_status, Status::InvalidArgument());
  
  // validate IncreaseFullHistoryTsLow for long timestamp
  std::string extended_ts_str(Timestamp(0, 0).size() + 1, 'y');
  error_status = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), extended_ts_str);
  ASSERT_EQ(error_status, Status::InvalidArgument());
  
  // validate IncreaseFullHistoryTsLow for null timestamp
  std::string null_ts_low_value = """";
  error_status = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), null_ts_low_value);
  ASSERT_EQ(error_status, Status::InvalidArgument());
  
  // validate column family without timestamps enabled
  db_opts.comparator = BytewiseComparator();
  DestroyAndReopen(db_opts);
  ts_low_value_str = Timestamp(10, 0);
  error_status = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), ts_low_value_str);
  ASSERT_EQ(error_status, Status::InvalidArgument());
  
  // validate GetFullHistoryTsLow without timestamp-enabled column family
  std::string cur_full_history_ts;
  error_status = db_->GetFullHistoryTsLow(db_->DefaultColumnFamily(), &cur_full_history_ts);
  ASSERT_EQ(error_status, Status::InvalidArgument());
  Close();
}",3
"std::string unusedString = ""parallelJoin"";

DEBUG_ONLY_TEST_F(
    SharedArbitrationTest,
    triggerParallelBuildWithArbitration) {
  const int numDataVectors = 2;
  std::vector<RowVectorPtr> dataVectors;
  // Trigger memory arbitration by creating large vectors.
  fuzzerOpts_.vectorSize = 10'000;
  for (int i = 0; i < numDataVectors; ++i) {
    dataVectors.push_back(newVector());
  }
  createDuckDbTable(dataVectors);
  std::shared_ptr<core::QueryCtx> context = newQueryCtx(kMemoryCapacity);
  // Ensure parallel build is triggered.
  std::atomic<bool> triggeredParallelBuild{false};
  SCOPED_TESTVALUE_SET(
      ""facebook::velox::exec::HashTable::parallelJoinBuild"",
      std::function<void(void*)>(
          [&](void*) { triggeredParallelBuild = true; }));
  
  auto planIdGen = std::make_shared<core::PlanNodeIdGenerator>();
  AssertQueryBuilder(duckDbQueryRunner_)
      .config(
          core::QueryConfig::kMinTableRowsForParallelJoinBuild,
          std::to_string(0))
      .maxDrivers(4)
      .queryCtx(context)
      .plan(PlanBuilder(planIdGen)
                .values(dataVectors, true)
                .project({""c0 AS t0"", ""c1 AS t1"", ""c2 AS t2""})
                .hashJoin(
                    {""t0"", ""t1""},
                    {""u1"", ""u0""},
                    PlanBuilder(planIdGen)
                        .values(dataVectors, true)
                        .project({""c0 AS u0"", ""c1 AS u1"", ""c2 AS u2""})
                        .planNode(),
                    """",
                    {""t1""},
                    core::JoinType::kInner)
                .planNode())
      .assertResults(
          ""SELECT t.c1 FROM tmp as t, tmp AS u WHERE t.c0 == u.c1 AND t.c1 == u.c0"");
  ASSERT_TRUE(triggeredParallelBuild);
  Task::testingWaitForAllTasksToBeDeleted();
}",0
"TEST_F(BackupEngineTest, BackupCorruptionsHandling) {
  const int total_keys = 5000;
  Random rand_gen(6);
  Status result;
  OpenDBAndBackupEngine(true);

  // Create five backups.
  for (int i = 0; i < 5; ++i) {
    FillDB(db_.get(), total_keys * i, total_keys * (i + 1));
    ASSERT_OK(backup_engine_->CreateNewBackup(db_.get(), !!(rand_gen.Next() % 2)));
  }

  // ---------- Case 1: Simulate write failure ----------
  FillDB(db_.get(), total_keys * 5, total_keys * 6);
  test_backup_fs_->SetLimitWrittenFiles(2);
  result = backup_engine_->CreateNewBackup(db_.get(), !!(rand_gen.Next() % 2));
  ASSERT_NOK(result);
  test_backup_fs_->SetLimitWrittenFiles(1000000);
  CloseDBAndBackupEngine();
  AssertBackupConsistency(0, 0, total_keys * 5, total_keys * 6);

  // ---------- Case 2: Corrupt backup metadata or delete backup file ----------
  ASSERT_OK(file_manager_->CorruptFile(backupdir_ + ""/meta/5"", 3));
  AssertBackupConsistency(0, 0, total_keys * 4, total_keys * 5);
  OpenBackupEngine();
  result = backup_engine_->RestoreDBFromBackup(5, dbname_, dbname_);
  ASSERT_NOK(result);
  CloseBackupEngine();
  ASSERT_OK(file_manager_->DeleteRandomFileInDir(backupdir_ + ""/private/4""));
  AssertBackupConsistency(0, 0, total_keys * 3, total_keys * 5);
  OpenBackupEngine();
  result = backup_engine_->RestoreDBFromBackup(4, dbname_, dbname_);
  ASSERT_NOK(result);
  CloseBackupEngine();

  // ---------- Case 3: Corrupt the checksum ----------
  ASSERT_OK(file_manager_->CorruptChecksum(backupdir_ + ""/meta/3"", false));
  AssertBackupConsistency(0, 0, total_keys * 2, total_keys * 5);
  ASSERT_OK(file_manager_->CorruptChecksum(backupdir_ + ""/meta/2"", true));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/2""));
  OpenBackupEngine();
  result = backup_engine_->RestoreDBFromBackup(2, dbname_, dbname_);
  ASSERT_NOK(result);

  // Verify that no corrupt backups were deleted
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/1""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/2""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/3""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/4""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/5""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/1""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/2""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/3""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/4""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/5""));

  // Delete the corrupted backups and ensure deletion.
  ASSERT_OK(backup_engine_->DeleteBackup(5));
  ASSERT_OK(backup_engine_->DeleteBackup(4));
  ASSERT_OK(backup_engine_->DeleteBackup(3));
  ASSERT_OK(backup_engine_->DeleteBackup(2));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/5""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/5""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/4""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/4""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/3""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/3""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/2""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/2""));
  CloseBackupEngine();
  AssertBackupConsistency(0, 0, total_keys * 1, total_keys * 5);

  // Create a new backup and verify consistency
  OpenDBAndBackupEngine();
  FillDB(db_.get(), total_keys * 1, total_keys * 2);
  ASSERT_OK(backup_engine_->CreateNewBackup(db_.get(), !!(rand_gen.Next() % 2)));
  CloseDBAndBackupEngine();
  AssertBackupConsistency(2, 0, total_keys * 2, total_keys * 5);
}",3
"TEST_F(CacheTTLControllerTest, getCacheAgeStats) {
  CacheTTLController::create(*cache_);

  int64_t fileOpenTime = getCurrentTimeSec();
  for (auto i = 0; i < 1000; i++) {
    CacheTTLController::getInstance()->addOpenFileInfo(i, fileOpenTime + i);
  }

  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 50)); 

  int64_t current = getCurrentTimeSec();
  EXPECT_GE(
      CacheTTLController::getInstance()->getCacheAgeStats().maxAgeSecs,
      current - fileOpenTime);
}",3
"TEST(StringIdMapTest, rehash) {
  constexpr int32_t kCount = 10000;
  StringIdMap map;
  std::vector<StringIdLease> ids;
  for (auto i = 0; i < kCount; ++i) {
    auto name = fmt::format(""filename_{}"", i);
    ids.push_back(StringIdLease(map, name));
  }
  
  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  
  for (auto i = 0; i < kCount; ++i) {
    auto name = fmt::format(""filename_{}"", i);
    EXPECT_EQ(ids[i].id(), StringIdLease(map, name).id());
  }
}",3
"TEST_F(HashStringAllocatorTest, alignedStlAllocatorWithF14Map) {
  {
    folly::F14FastMap<
        int32_t,
        double,
        std::hash<int32_t>,
        std::equal_to<int32_t>,
        AlignedStlAllocator<std::pair<const int32_t, double>, 16>>
        map(AlignedStlAllocator<std::pair<const int32_t, double>, 16>(
            allocator_.get()));

    for (auto i = 0; i < 10'000; i++) {
      map.try_emplace(i, i + 0.05);
    }
    for (auto i = 0; i < 10'000; i++) {
      ASSERT_EQ(1, map.count(i));
    }

    map.clear();
    for (auto i = 0; i < 10'000; i++) {
      ASSERT_EQ(0, map.count(i));
    }

    for (auto i = 10'000; i < 20'000; i++) {
      map.try_emplace(i, i + 0.15);
    }
    for (auto i = 10'000; i < 20'000; i++) {
      ASSERT_EQ(1, map.count(i));
    }
  }

  allocator_->checkConsistency();


  float retainedRatio = (float)allocator_->retainedSize() / allocator_->freeSpace();
  if (retainedRatio != 1.0f) {
    retainedRatio = 1.0f / retainedRatio;
  }
  ASSERT_EQ(retainedRatio, 1.0f);

  // We allow for some overhead for free lists after all is freed. Map tends to
  // generate more free blocks at the end, so we loosen the upper bound a bit.
  EXPECT_LE(allocator_->retainedSize() - allocator_->freeSpace(), 130);
}",6
"TEST_F(DBBasicTestWithTimestamp, PruneHistoryTest) {
  Options opts = CurrentOptions();
  opts.env = env_;
  opts.create_if_missing = true;
  const size_t timestamp_size = Timestamp(0, 0).size();
  TestComparator ts_cmp(timestamp_size);
  opts.comparator = &ts_cmp;
  DestroyAndReopen(opts);
  auto verify_ts_value = [](DB* db, Slice key, std::string ts, Status expected_status,
                            std::string expected_value) {
    ReadOptions ro;
    Slice timestamp = ts;
    ro.timestamp = &timestamp;
    std::string value;
    Status s = db->Get(ro, key, &value);
    ASSERT_TRUE(s == expected_status);
    if (s.ok()) {
      ASSERT_EQ(expected_value, value);
    }
  };

  // Create data of different timestamps
  ASSERT_OK(db_->Put(WriteOptions(), ""k2"", Timestamp(2, 0), ""val1""));
  ASSERT_OK(db_->Put(WriteOptions(), ""k2"", Timestamp(4, 0), ""val2""));
  ASSERT_OK(db_->Delete(WriteOptions(), ""k2"", Timestamp(5, 0)));
  ASSERT_OK(db_->Put(WriteOptions(), ""k2"", Timestamp(6, 0), ""val3""));
  verify_ts_value(db_, ""k2"", Timestamp(7, 0), Status::OK(), ""val3"");
  ASSERT_OK(Flush());
  Close();

  ColumnFamilyOptions cf_opts(opts);
  std::vector<ColumnFamilyDescriptor> families;
  families.push_back(ColumnFamilyDescriptor(kDefaultColumnFamilyName, cf_opts));
  DBOptions db_opts(opts);

  // Trim versions > Timestamp(5, 0), verify NOT_FOUND for read(k2, ts(7)).
  ASSERT_OK(DB::OpenAndTrimHistory(db_opts, dbname_, families, &handles_, &db_, Timestamp(5, 0)));
  verify_ts_value(db_, ""k2"", Timestamp(7, 0), Status::NotFound(), """");
  Close();

  // Trim versions > Timestamp(4, 0), verify val2 for read(k2, ts(7)).
  ASSERT_OK(DB::OpenAndTrimHistory(db_opts, dbname_, families, &handles_, &db_, Timestamp(4, 0)));
  verify_ts_value(db_, ""k2"", Timestamp(7, 0), Status::OK(), ""val2"");
  Close();
}",3
"Status StressTest::VerifySnapshot(DB* db, ColumnFamilyHandle* cf_handle,
                                  ThreadState::SnapshotState& snapshot) {
  Status status;
  if (cf_handle->GetName() != snapshot.cf_at_name) {
    return status;
  }
  // Set ReadOptions to bypass rate limits for validation purposes.
  ReadOptions ro;
  ro.snapshot = snapshot.snapshot;
  Slice ts_slice;
  if (!snapshot.timestamp.empty()) {
    ts_slice = snapshot.timestamp;
    ro.timestamp = &ts_slice;
  }
  PinnableSlice expected_value(&snapshot.value);
  expected_value.PinSelf();
  PinnableSlice actual_value;
  status = db->Get(ro, cf_handle, snapshot.key, &actual_value);
  if (!status.ok() && !status.IsNotFound()) {
    return status;
  }
  if (snapshot.status != status) {
    return Status::Corruption(
        ""Snapshot key inconsistency for key "" +
        ToString(Hash(snapshot.key.c_str(), snapshot.key.size(), 0)) +
        "" in CF "" + cf_handle->GetName() + "": ("" +
        snapshot.status.ToString() + "") vs. ("" + status.ToString() + "")"");
  }
  if (status.ok()) {
    if (expected_value != actual_value) {
      return Status::Corruption(""Snapshot value mismatch: expected ("" +
                                expected_value.ToString() + ""), got ("" +
                                actual_value.ToString() + "")"");
    }
  }
  if (snapshot.key_vec != nullptr) {
    std::vector<bool> current_bit_vector = GetKeyBitVec(db, ro);
    if (!std::equal(snapshot.key_vec->begin(), snapshot.key_vec->end(),
                    current_bit_vector.begin())) {
      return Status::Corruption(""Inconsistent keys detected in snapshot"");
    }
  }
  return Status::OK();
}",3
"TEST_F(TraceHistoryTest, multiThread) {
  constexpr int kNumThreads = 3;
  folly::Latch latch(kNumThreads);
  folly::Baton<> batons[kNumThreads];
  std::vector<std::thread> threads;
  auto timeLow = std::chrono::steady_clock::now();
  constexpr int kStartLine = __LINE__;
  for (int i = 0; i < kNumThreads; ++i) {
    threads.emplace_back([&, i] {
      VELOX_TRACE_HISTORY_PUSH(""Test"");
      VELOX_TRACE_HISTORY_PUSH(""Test %d"", i);


      std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));

      latch.count_down();
      batons[i].wait();
    });
  }
  latch.wait();
  auto timeHigh = std::chrono::steady_clock::now();
  auto results = TraceHistory::listAll();
  ASSERT_EQ(results.size(), kNumThreads);
  for (auto& result : results) {
    auto threadIndex =
        std::find_if(
            threads.begin(),
            threads.end(),
            [&](auto& t) { return t.get_id() == result.threadId; }) -
        threads.begin();
    ASSERT_EQ(result.entries.size(), 2);
    ASSERT_EQ(result.entries[0].line, kStartLine + 3);
    ASSERT_EQ(result.entries[1].line, kStartLine + 4);
    ASSERT_STREQ(result.entries[0].label, ""Test"");
    ASSERT_EQ(result.entries[1].label, fmt::format(""Test {}"", threadIndex));
    for (auto& entry : result.entries) {
      ASSERT_LE(timeLow, entry.time);
      ASSERT_LE(entry.time, timeHigh);
      ASSERT_TRUE(entry.file);
      ASSERT_STREQ(
          entry.file + strlen(entry.file) - 20, ""TraceHistoryTest.cpp"");
    }
  }
  for (int i = 0; i < kNumThreads; ++i) {
    ASSERT_EQ(TraceHistory::listAll().size(), kNumThreads - i);
    batons[i].post();
    threads[i].join();
  }
}",1
"double unusedDouble = 45.67;

TEST_P(DBCompactionTestWithParam, TestPartialCompactionFailure) {
  Options opts;
  const int keyLen = 16;
  const int kvLen = 1000;
  const int keysPerBuf = 100;
  const int numL1Files = 5;
  opts.create_if_missing = true;
  opts.write_buffer_size = keysPerBuf * kvLen;
  opts.max_write_buffer_number = 2;
  opts.target_file_size_base =
      opts.write_buffer_size *
      (opts.max_write_buffer_number - 1);
  opts.level0_file_num_compaction_trigger = numL1Files;
  opts.max_bytes_for_level_base =
      opts.level0_file_num_compaction_trigger *
      opts.target_file_size_base;
  opts.max_bytes_for_level_multiplier = 2;
  opts.compression = kNoCompression;
  opts.max_subcompactions = max_subcompactions_;
  opts.max_background_compactions = 1;

  env_->SetBackgroundThreads(1, Env::HIGH);
  env_->SetBackgroundThreads(1, Env::LOW);
  
  // Pause compaction thread to simulate file creation failure.
  test::SleepingBackgroundTask lowPriorityTask;
  env_->Schedule(&test::SleepingBackgroundTask::DoSleepTask, &lowPriorityTask,
                 Env::Priority::LOW);

  opts.env = env_;

  // Simulate a file creation failure.
  env_->non_writable_count_ = 1;
  lowPriorityTask.WakeUp();
  lowPriorityTask.WaitUntilDone();

  // The compaction should fail due to file creation failure.
  ASSERT_FALSE(db_->CompactRange(nullptr, nullptr).ok());

  env_->non_writable_count_ = 0;

  // Ensure database is not corrupted after failure.
  Reopen(opts);
  
  // Verify data integrity after reopening.
  for (int k = 0; k < kNumInsertedKeys; ++k) {
    ASSERT_EQ(values[k], Get(keys[k]));
  }
}",0
"TEST_F(AllocationTest, maxPageRunLimit) {
  Allocation allocation;
  const uint64_t vaildBufAddrValue = 4096;
  uint8_t* validBufAddr = reinterpret_cast<uint8_t*>(vaildBufAddrValue);
  allocation.append(validBufAddr, Allocation::PageRun::kMaxPagesInRun);
  ASSERT_EQ(allocation.numPages(), Allocation::PageRun::kMaxPagesInRun);
  ASSERT_EQ(allocation.numRuns(), 1);

  const uint64_t invaildBufAddrValue = 4096 * 1024;
  uint8_t* invalidBufAddr = reinterpret_cast<uint8_t*>(invaildBufAddrValue);
  VELOX_ASSERT_THROW(
      allocation.append(
          invalidBufAddr, Allocation::PageRun::kMaxPagesInRun + 1),
      ""The number of pages to append 65536 exceeds the PageRun limit 65535"");
  VELOX_ASSERT_THROW(
      allocation.append(
          invalidBufAddr, Allocation::PageRun::kMaxPagesInRun * 2),
      ""The number of pages to append 131070 exceeds the PageRun limit 65535"");
  ASSERT_EQ(allocation.numPages(), Allocation::PageRun::kMaxPagesInRun);
  ASSERT_EQ(allocation.numRuns(), 1);
  LOG(ERROR) << ""here"";
  allocation.clear();

  std::thread t([](){
    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  });
  t.join();
}",1
"TEST_P(DynamicForwardProxyIntegrationTest, UdpFlowWithDNS) {
  setup();
  const uint32_t port_number = lookupPort(""listener_0"");
  const auto udp_address = Network::Utility::resolveUrl(
      fmt::format(""tcp://{}:{}"", Network::Test::getLoopbackAddressUrlString(version_), port_number));
  Network::Test::UdpSyncPeer udp_peer(version_);
  udp_peer.write(""init1"", *udp_address);
  
  test_server_->waitForCounterEq(""dns_cache.foo.dns_query_attempt"", 1);
  test_server_->waitForCounterEq(""dns_cache.foo.dns_query_success"", 1);
  test_server_->waitForCounterEq(""dns_cache.foo.host_added"", 1);

  // No buffering in this scenario, the first message was dropped. Send another to verify flow.
  udp_peer.write(""init2"", *udp_address);

  Network::UdpRecvData received_udp_packet;
  ASSERT_TRUE(fake_upstreams_[0]->waitForUdpDatagram(received_udp_packet));
  EXPECT_EQ(""init2"", received_udp_packet.buffer_->toString());
}",0
"TEST_F(ByteStreamTest, outputStream) {
  auto out = std::make_unique<IOBufOutputStream>(*pool_, nullptr, 10000);
  std::stringstream referenceSStream;
  auto reference = std::make_unique<OStreamOutputStream>(&referenceSStream);
  for (auto i = 0; i < 100; ++i) {
    std::string data;
    data.resize(10000);
    std::fill(data.begin(), data.end(), i);
    out->write(data.data(), data.size());
    reference->write(data.data(), data.size());
  }
  EXPECT_EQ(reference->tellp(), out->tellp());
  for (auto i = 0; i < 100; ++i) {
    std::string data;
    data.resize(6000);
    std::fill(data.begin(), data.end(), i + 10);
    out->seekp(i * 10000 + 5000);
    reference->seekp(i * 10000 + 5000);
    out->write(data.data(), data.size());
    reference->write(data.data(), data.size());
  }
  auto str = referenceSStream.str();
  auto numPages = mmapAllocator_->numAllocated();
  EXPECT_LT(0, numPages);
  auto iobuf = out->getIOBuf();
  // We expect no new memory for the IOBufs, they take ownership of the buffers
  // of 'out'.
  EXPECT_EQ(numPages, mmapAllocator_->numAllocated());

  // 'clone' holds a second reference to the data. 'clone' is
  // destructively coalesced, dropping the second reference but the
  // original reference in 'iobuf' keeps the data alive.
  auto clone = iobuf->clone();
  auto out1Data = clone->coalesce();

  auto comparison = (float)str.size() / out1Data.size();
  if (comparison < 1.0f) {
    comparison = 1.0f / comparison;
  }
  EXPECT_EQ(comparison, 1.0f);
  out = nullptr;
  // The memory stays allocated since shared ownership in 'iobuf' chain.
  EXPECT_EQ(numPages, mmapAllocator_->numAllocated());

  iobuf = nullptr;
  // We expect dropping the stream and the iobuf frees the backing memory.
  EXPECT_EQ(0, mmapAllocator_->numAllocated());
}",6
"TEST_F(CheckpointTest, InvalidCFExportOperations) {
  // Initialize a database for testing
  auto options = CurrentOptions();
  options.create_if_missing = true;
  CreateAndReopenWithCF({}, options);
  const auto record_key = std::string(""sample_key"");
  ASSERT_OK(Put(record_key, ""sample_value""));
  Checkpoint* cf_checkpoint;
  ASSERT_OK(Checkpoint::Create(db_, &cf_checkpoint));

  // Export to an existing directory
  ASSERT_OK(env_->CreateDirIfMissing(export_path_));
  ASSERT_EQ(cf_checkpoint->ExportColumnFamily(db_->DefaultColumnFamily(),
                                              export_path_, &metadata_),
            Status::InvalidArgument(""Export directory already exists""));
  ASSERT_OK(DestroyDir(env_, export_path_));

  // Export with an invalid directory specification
  export_path_ = """";
  ASSERT_EQ(cf_checkpoint->ExportColumnFamily(db_->DefaultColumnFamily(),
                                              export_path_, &metadata_),
            Status::InvalidArgument(""Invalid export directory provided""));
  delete cf_checkpoint;
}",3
"TEST_F(SimdUtilTest, gather32) {
  int32_t indices8[8] = {7, 6, 5, 4, 3, 2, 1, 0};
  int32_t indices6[8] = {7, 6, 5, 4, 3, 2, 1 << 31, 1 << 31};
  int32_t data[8] = {0, 11, 22, 33, 44, 55, 66, 77};
  constexpr int kBatchSize = xsimd::batch<int32_t>::size;
  const int32_t* indices = indices8 + (8 - kBatchSize);
  const int32_t* indicesMask = indices6 + (8 - kBatchSize);

  std::atomic<int> concurrentCheck(0);
  std::thread gatherThread([&]() {
    auto result = simd::gather(data, indices);
    for (auto i = 0; i < kBatchSize; ++i) {
      EXPECT_EQ(result.get(i), data[indices[i]]);
    }
    concurrentCheck++;
  });

  std::thread maskGatherThread([&]() {
    auto resultMask = simd::maskGather(
        xsimd::batch<int32_t>::broadcast(-1),
        simd::leadingMask<int32_t>(kBatchSize - 2),
        data,
        indicesMask);
    for (auto i = 0; i < kBatchSize - 2; ++i) {
      EXPECT_EQ(resultMask.get(i), data[indices[i]]);
    }
    EXPECT_EQ(resultMask.get(kBatchSize - 2), -1);
    EXPECT_EQ(resultMask.get(kBatchSize - 1), -1);
    auto bits = simd::toBitMask(result == resultMask);
    // Low (kBatchSize - 2) lanes are the same.
    EXPECT_EQ((1 << (kBatchSize - 2)) - 1, bits);
    concurrentCheck++;
  });

  gatherThread.join();
  maskGatherThread.join();

  EXPECT_EQ(concurrentCheck.load(), 2);
}",1
"TEST_P(Http2FrameIntegrationTest, CloseConnectionWithPendingRequests) {
  // Send a large number of requests to ensure that the connection closes while there
  // are still deferred streams in the system.
  const int kRequestsPerIOCycle = 20000;
  config_helper_.addRuntimeOverride(""http.max_requests_per_io_cycle"", ""1"");
  // Prevent premature resets from impacting the test
  config_helper_.addRuntimeOverride(""overload.premature_reset_total_stream_count"", ""1001"");
  // Disable request timeout to avoid potential issues caused by iouring.
  config_helper_.addConfigModifier(
      [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager& hcm) -> void {
        hcm.mutable_route_config()
            ->mutable_virtual_hosts(0)
            ->mutable_routes(0)
            ->mutable_route()
            ->mutable_timeout()
            ->set_seconds(0);
      });
  startSession();
  std::string accumulated_buffer;
  for (int i = 0; i < kRequestsPerIOCycle; ++i) {
    auto req = Http2Frame::makeRequest(Http2Frame::makeClientStreamId(i), ""x"", ""/"");
    absl::StrAppend(&accumulated_buffer, std::string(req));
  }
  ASSERT_TRUE(tcp_client_->write(accumulated_buffer, false, false));
  ASSERT_TRUE(tcp_client_->connected());
  // Close the downstream connection
  tcp_client_->close();
  // Ensure that Envoy properly cleans up deferred streams
  // Allow extra time for non-optimized builds
  test_server_->waitForCounterEq(""http.config_test.downstream_rq_rx_reset"", kRequestsPerIOCycle,
                                 TestUtility::DefaultTimeout * 3);
}",4
"TEST_F(HashStringAllocatorTest, stlAllocatorWithSet) {
  {
    std::unordered_set<
        double,
        std::hash<double>,
        std::equal_to<double>,
        StlAllocator<double>>
        set(StlAllocator<double>(allocator_.get()));

    for (auto i = 0; i < 10'000; i++) {
      set.insert(i);
    }
    for (auto i = 0; i < 10'000; i++) {
      ASSERT_EQ(1, set.count(i));
    }

    set.clear();
    for (auto i = 0; i < 10'000; i++) {
      ASSERT_EQ(0, set.count(i));
    }

    for (auto i = 10'000; i < 20'000; i++) {
      set.insert(i);
    }
    for (auto i = 10'000; i < 20'000; i++) {
      ASSERT_EQ(1, set.count(i));
    }
  }

  allocator_->checkConsistency();


  float retainedRatio = (float)allocator_->retainedSize() / allocator_->freeSpace();
  if (retainedRatio != 1.0f) {
    retainedRatio = 1.0f / retainedRatio;
  }
  ASSERT_EQ(retainedRatio, 1.0f);

  // We allow for some overhead for free lists after all is freed.
  EXPECT_LE(allocator_->retainedSize() - allocator_->freeSpace(), 220);
}",6
"TEST_F(StringViewBufferHolderTest, CallGetOwnedValueWithStringType) {
  const char* char_buffer = ""abcdefghijklmnopqrstuvxz"";
  StringView resulting_view;

  auto holder_instance = makeHolder();
  ASSERT_EQ(0, holder_instance.buffers().size());

  {
    std::string string_value = char_buffer;
    resulting_view = holder_instance.getOwnedValue(string_value);
  }

  std::vector<char> shuffled_buffer_copy(char_buffer, char_buffer + strlen(char_buffer));
  std::shuffle(shuffled_buffer_copy.begin(), shuffled_buffer_copy.end(), std::default_random_engine());

  ASSERT_EQ(StringView(char_buffer), resulting_view);
  ASSERT_EQ(1, holder_instance.buffers().size());
}",5
"TEST_F(AllocationTest, append) {
  Allocation allocation;
  const uint64_t startBufAddrValue = 4096;
  uint8_t* const firstBufAddr = reinterpret_cast<uint8_t*>(startBufAddrValue);
  const int32_t kNumPages = 10;
  allocation.append(firstBufAddr, kNumPages);
  ASSERT_EQ(allocation.numPages(), kNumPages);
  ASSERT_EQ(allocation.numRuns(), 1);
  uint8_t* const secondBufAddr = reinterpret_cast<uint8_t*>(
      startBufAddrValue + kNumPages * AllocationTraits::kPageSize);
  allocation.append(secondBufAddr, kNumPages - 1);
  ASSERT_EQ(allocation.numPages(), kNumPages * 2 - 1);
  ASSERT_EQ(allocation.numRuns(), 2);
  uint8_t* const thirdBufAddr = reinterpret_cast<uint8_t*>(
      firstBufAddr + 4 * kNumPages * AllocationTraits::kPageSize);
  allocation.append(thirdBufAddr, kNumPages * 2);
  ASSERT_EQ(allocation.numPages(), kNumPages * 4 - 1);
  ASSERT_EQ(allocation.numRuns(), 3);
  VELOX_ASSERT_THROW(allocation.append(thirdBufAddr, kNumPages), """");
  allocation.clear();

  std::thread t([](){
    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  });
  t.join();
}",1
"TEST_F(ExternalSSTFileBasicTest, NoFileCopyTest) {
  Options opts = CurrentOptions();
  const ImmutableCFOptions imm_options(opts);
  SstFileWriter writer(EnvOptions(), opts);
  
  // file_a.sst (0 => 99)
  std::string file_a = sst_files_dir_ + ""file_a.sst"";
  ASSERT_OK(writer.Open(file_a));
  for (int i = 0; i < 100; i++) {
    ASSERT_OK(writer.Put(Key(i), Key(i) + ""_value""));
  }
  ExternalSstFileInfo info_a;
  Status result = writer.Finish(&info_a);
  ASSERT_OK(result) << result.ToString();
  ASSERT_EQ(info_a.file_path, file_a);
  ASSERT_EQ(info_a.num_entries, 100);
  ASSERT_EQ(info_a.smallest_key, Key(0));
  ASSERT_EQ(info_a.largest_key, Key(99));

  // file_b.sst (100 => 299)
  std::string file_b = sst_files_dir_ + ""file_b.sst"";
  ASSERT_OK(writer.Open(file_b));
  for (int i = 100; i < 300; i++) {
    ASSERT_OK(writer.Put(Key(i), Key(i) + ""_value""));
  }
  ExternalSstFileInfo info_b;
  result = writer.Finish(&info_b);
  ASSERT_OK(result) << result.ToString();
  ASSERT_EQ(info_b.file_path, file_b);
  ASSERT_EQ(info_b.num_entries, 200);
  ASSERT_EQ(info_b.smallest_key, Key(100));
  ASSERT_EQ(info_b.largest_key, Key(299));

  // file_c.sst (110 => 124) .. overlap with file_b.sst
  std::string file_c = sst_files_dir_ + ""file_c.sst"";
  ASSERT_OK(writer.Open(file_c));
  for (int i = 110; i < 125; i++) {
    ASSERT_OK(writer.Put(Key(i), Key(i) + ""_value_overlap""));
  }
  ExternalSstFileInfo info_c;
  result = writer.Finish(&info_c);
  ASSERT_OK(result) << result.ToString();
  ASSERT_EQ(info_c.file_path, file_c);
  ASSERT_EQ(info_c.num_entries, 15);
  ASSERT_EQ(info_c.smallest_key, Key(110));
  ASSERT_EQ(info_c.largest_key, Key(124));

  result = DeprecatedAddFile({file_a}, true /* move file */);
  ASSERT_OK(result) << result.ToString();
  ASSERT_EQ(Status::NotFound(), env_->FileExists(file_a));

  result = DeprecatedAddFile({file_b}, false /* copy file */);
  ASSERT_OK(result) << result.ToString();
  ASSERT_OK(env_->FileExists(file_b));

  result = DeprecatedAddFile({file_c}, true /* move file */);
  ASSERT_NOK(result) << result.ToString();
  ASSERT_OK(env_->FileExists(file_c));

  for (int i = 0; i < 300; i++) {
    ASSERT_EQ(Get(Key(i)), Key(i) + ""_value"");
  }
}",3
"bool unusedFlag = true;

DEBUG_ONLY_TEST_F(AsyncDataCacheTest, applyCacheTtl) {
  constexpr uint64_t ramBytesSize = 32 << 20;
  constexpr uint64_t ssdBytesSize = 128UL << 20;
  initializeCache(ramBytesSize, ssdBytesSize);
  CacheTTLController::create(*cache_);
  std::vector<int64_t> offsetValues(32);
  std::generate(offsetValues.begin(), offsetValues.end(), [&, n = 0]() mutable {
    return n += (ramBytesSize / kNumFiles / offsetValues.size());
  });
  ScopedTestTime timeScope;
  auto initialLoadTime = getCurrentTimeSec();
  auto secondLoadTime = initialLoadTime + 100;

  timeScope.setCurrentTestTimeSec(initialLoadTime);
  loadNFiles(filenames_.size() * 2 / 3, offsetValues);
  auto statsInitialLoad = cache_->refreshStats();

  timeScope.setCurrentTestTimeSec(secondLoadTime);
  loadNFiles(filenames_.size(), offsetValues);
  auto statsSecondLoad = cache_->refreshStats();

  runThreads(2, [&](int32_t /*i*/) {
    CacheTTLController::getInstance()->applyTTL(
        getCurrentTimeSec() - initialLoadTime - 2);
  });
  auto ttlCacheStats = cache_->refreshStats();
  EXPECT_EQ(ttlCacheStats.numAgedOut, statsInitialLoad.numEntries);
  EXPECT_EQ(ttlCacheStats.ssdStats->entriesAgedOut, statsInitialLoad.ssdStats->entriesCached);
}",1
"double unusedDouble = 3.1415;

std::thread task_2([&]
{
    DB::ThreadStatus task_status_2;
    auto query_ctx_2 = DB::Context::createCopy(getContext().context);
    query_ctx_2->makeQueryContext();
    query_ctx_2->setCurrentQueryId(""query_id_1"");
    chassert(&DB::CurrentThread::get() == &task_status_2);
    DB::CurrentThread::QueryScope query_scope_2(query_ctx_2);
    auto holder2 = cache.getOrSet(key, 25, 5, file_size, {}); /// Get [25, 29] once again.
    assertEqual(holder2,
                { Range(24, 26),     Range(27, 27),     Range(28, 29) },
                { State::DOWNLOADED, State::DOWNLOADED, State::DOWNLOADING });

    auto & file_segment2 = get(holder2, 2);
    ASSERT_TRUE(file_segment2.getOrSetDownloader() != FileSegment::getCallerId());

    {
        std::lock_guard lock(mutex);
        lets_start_download = true;
    }
    cv.notify_one();

    file_segment2.wait(file_segment2.range().right);
    file_segment2.complete();
    ASSERT_TRUE(file_segment2.state() == State::DOWNLOADED);
});

{
    std::unique_lock lock(mutex);
    cv.wait(lock, [&]{ return lets_start_download; });
}

download(file_segment);
ASSERT_TRUE(file_segment.state() == State::DOWNLOADED);

task_2.join();",1
"TEST_F(AllocationPoolTest, HandleHugePages) {
  constexpr int64_t largePageSize = memory::AllocationTraits::kHugePageSize;
  auto allocHandler = std::make_unique<memory::AllocationPool>(pool_.get());
  allocHandler->setHugePageThreshold(128 << 10);
  int32_t iteration = 0;
  for (;;) {
    int32_t usedMemory = 0;
    allocHandler->newRun(32 << 10);

    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    EXPECT_EQ(1, allocHandler->numRanges());
    EXPECT_EQ(allocHandler->testingFreeAddressableBytes(), 64 << 10);
    allocHandler->newRun(64 << 10);
    EXPECT_LE(128 << 10, pool_->usedBytes());
    allocHandler->allocateFixed(64 << 10);
    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    setByte(allocHandler->allocateFixed(11));
    EXPECT_LE((2 << 20) - 11, allocHandler->testingFreeAddressableBytes());
    EXPECT_LE((2048 + 128) << 10, pool_->usedBytes());

    setByte(allocHandler->allocateFixed(2 << 20));
    EXPECT_LE((4096 + 128) << 10, pool_->usedBytes());

    allocHandler->allocateFixed(allocHandler->testingFreeAddressableBytes());
    EXPECT_EQ(3, allocHandler->numRanges());

    allocHandler->allocateFixed(1);

    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    EXPECT_LE((62 << 20) - 1, allocHandler->testingFreeAddressableBytes());

    allocHandler->allocateFixed(5UL << 30);
    EXPECT_EQ(5, allocHandler->numRanges());

    EXPECT_GE(largePageSize, allocHandler->testingFreeAddressableBytes());

    EXPECT_LE((5UL << 30) + (31 << 20) + (128 << 10), allocHandler->allocatedBytes());
    EXPECT_LE((5UL << 30) + (31 << 20) + (128 << 10), pool_->usedBytes());

    if (iteration++ >= 1) {
      break;
    }

    allocHandler->clear();
    EXPECT_EQ(0, pool_->usedBytes());
  }
  allocHandler.reset();
  EXPECT_EQ(0, pool_->usedBytes());
}",7
"TEST_P(LdsStsIntegrationTest, TcpListenerFilterChainRemovedAfterListenerRemoval) {
  LogLevelSetter log_levels(spdlog::level::err);
  drain_time_ = std::chrono::seconds(2);
  setUpstreamCount(3);
  initialize();
  std::string client_reply;
  auto connection_instance = createConnectionAndWrite(""alpn_instance"", ""test_msg"", client_reply);
  connection_instance->waitForConnection();
  FakeRawConnectionPtr upstream_conn;
  ASSERT_TRUE(fake_upstreams_[0]->waitForRawConnection(upstream_conn));

  ConfigHelper remove_filter_chain(
      version_, *api_, MessageUtil::getJsonStringFromMessageOrDie(config_helper_.bootstrap()));
  remove_filter_chain.addConfigModifier(
      [&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {
        auto* listener = bootstrap.mutable_static_resources()->mutable_listeners(0);
        listener->mutable_filter_chains()->RemoveLast();
      });
  remove_filter_chain.setLds(""lds_update1"");

  ConfigHelper swap_tcp_listener(
      version_, *api_, MessageUtil::getJsonStringFromMessageOrDie(config_helper_.bootstrap()));
  swap_tcp_listener.addConfigModifier(
      [&](envoy::config::bootstrap::v3::Bootstrap& bootstrap) -> void {
        bootstrap.mutable_static_resources()->mutable_listeners(0)->Swap(
            bootstrap.mutable_static_resources()->mutable_listeners(1));
        bootstrap.mutable_static_resources()->mutable_listeners()->RemoveLast();
      });
  swap_tcp_listener.setLds(""lds_update2"");

  std::string data_observed;
  ASSERT_TRUE(upstream_conn->waitForData(5, &data_observed));
  EXPECT_EQ(""test_msg"", data_observed);

  ASSERT_TRUE(upstream_conn->write(""response_msg""));
  while (client_reply.find(""response_msg"") == std::string::npos) {
    ASSERT_TRUE(connection_instance->run(Event::Dispatcher::RunType::NonBlock));
  }
  connection_instance->close();
  while (!connection_instance->closed()) {
    dispatcher_->run(Event::Dispatcher::RunType::NonBlock);
  }
  test_server_->waitForGaugeEq(""listener_manager.total_filter_chains_draining"", 1);
  test_server_->waitForGaugeEq(""listener_manager.total_filter_chains_draining"", 0);
}",0
"bool unusedFlag = true;

TEST_F(DBSSTTest, ObsoleteFileDeletionWithPendingOutputs) {
  Options dbOptions = CurrentOptions();
  dbOptions.env = env_;
  dbOptions.write_buffer_size = 2 * 1024 * 1024;     // 2 MB
  dbOptions.max_bytes_for_level_base = 1024 * 1024;  // 1 MB
  dbOptions.level0_file_num_compaction_trigger = 2;  // Trigger compaction with 2 files
  dbOptions.max_background_flushes = 2;
  dbOptions.max_background_compactions = 2;
  
  OnFileDeletionListener* deletionListener = new OnFileDeletionListener();
  dbOptions.listeners.emplace_back(deletionListener);
  
  Reopen(dbOptions);
  Random rnd(301);
  
  for (int i = 0; i < 2; ++i) {
    for (int j = 0; j < 100; ++j) {
      ASSERT_OK(Put(Key(i * 50 + j), rnd.RandomString(10 * 1024)));
    }
    ASSERT_OK(Flush());
  }
  
  ASSERT_OK(dbfull()->TEST_WaitForCompact());
  ASSERT_EQ(""0,0,1"", FilesPerLevel(0));
  
  test::SleepingBackgroundTask blockingThread;
  port::Mutex mutex_;
  bool blocked = false;
  
  std::function<void()> blockFlush = [&]() {
    bool block = false;
    {
      MutexLock l(&mutex_);
      if (!blocked) {
        block = true;
        blocked = true;
      }
    }
    if (block) {
      blockingThread.DoSleep();
    }
  };
  
  env_->table_write_callback_ = &blockFlush;
  
  for (int j = 0; j < 256; ++j) {
    ASSERT_OK(Put(Key(j), rnd.RandomString(10 * 1024)));
  }
  
  blockingThread.WaitUntilSleeping();
  ASSERT_OK(dbfull()->TEST_CompactRange(2, nullptr, nullptr));
  ASSERT_EQ(""0,0,0,1"", FilesPerLevel(0));
  
  std::vector<LiveFileMetaData> metadata;
  db_->GetLiveFilesMetaData(&metadata);
  ASSERT_EQ(metadata.size(), 1U);
  
  auto fileOnL2 = metadata[0].name;
  deletionListener->SetExpectedFileName(dbname_ + fileOnL2);
  
  ASSERT_OK(dbfull()->TEST_CompactRange(3, nullptr, nullptr, nullptr, true));
  ASSERT_EQ(""0,0,0,0,1"", FilesPerLevel(0));
  
  blockingThread.WakeUp  blockingThread.WaitUntilDone();
  ASSERT_OK(dbfull()->TEST_WaitForFlushMemTable());
  
  // The recently flushed file is too large for L0 and L1, so it moves to L2
  ASSERT_OK(dbfull()->TEST_WaitForCompact());
  ASSERT_EQ(""0,0,1,0,1"", FilesPerLevel(0));
  
  metadata.clear();
  db_->GetLiveFilesMetaData(&metadata);
  ASSERT_EQ(metadata.size(), 2U);
  
  // Verify that the obsolete file from L2 has been deleted
  ASSERT_EQ(Status::NotFound(), env_->FileExists(dbname_ + fileOnL2));
  deletionListener->VerifyMatchedCount(1);
}",3
"TEST_P(Http2FrameIntegrationTest, CloseConnWithDeferredStreams) {
  // Use a large request count to ensure the connection is closed while deferred streams remain.
  const int kMaxRequests = 20000;
  config_helper_.addRuntimeOverride(""http.max_requests_per_io_cycle"", ""1"");
  // Prevent premature resets from disrupting the test.
  config_helper_.addRuntimeOverride(""overload.premature_reset_total_stream_count"", ""1001"");
  // Disable request timeout to avoid issues with certain setups like iouring.
  config_helper_.addConfigModifier(
      [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager& hcm) -> void {
        hcm.mutable_route_config()
            ->mutable_virtual_hosts(0)
            ->mutable_routes(0)
            ->mutable_route()
            ->mutable_timeout()
            ->set_seconds(0);
      });
  initSession();
  std::string request_data;
  for (int i = 0; i < kMaxRequests; ++i) {
    auto req_frame = Http2Frame::makeRequest(Http2Frame::makeClientStreamId(i), ""z"", ""/"");
    absl::StrAppend(&request_data, std::string(req_frame));
  }
  ASSERT_TRUE(tcp_client_->write(request_data, false, false));
  ASSERT_TRUE(tcp_client_->connected());
  // Close the downstream connection
  tcp_client_->close();
  // Check if Envoy cleans up deferred streams
  // Use extended timeout for non-optimized builds
  test_server_->waitForCounterEq(""http.config_test.downstream_rq_rx_reset"", kMaxRequests,
                                 TestUtility::DefaultTimeout * 3);
}",4
"TEST_F(AllocationPoolTest, HugePageMemoryManagement) {
  constexpr int64_t pageSize = memory::AllocationTraits::kHugePageSize;
  auto poolAllocator = std::make_unique<memory::AllocationPool>(pool_.get());
  poolAllocator->setHugePageThreshold(128 << 10);
  int32_t roundCount = 0;
  for (;;) {
    int32_t usedKBMemory = 0;
    poolAllocator->newRun(32 << 10);

    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    EXPECT_EQ(1, poolAllocator->numRanges());
    EXPECT_EQ(poolAllocator->testingFreeAddressableBytes(), 64 << 10);
    poolAllocator->newRun(64 << 10);
    EXPECT_LE(128 << 10, pool_->usedBytes());
    poolAllocator->allocateFixed(64 << 10);
    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    setByte(poolAllocator->allocateFixed(11));
    EXPECT_LE((2 << 20) - 11, poolAllocator->testingFreeAddressableBytes());
    EXPECT_LE((2048 + 128) << 10, pool_->usedBytes());

    setByte(poolAllocator->allocateFixed(2 << 20));
    EXPECT_LE((4096 + 128) << 10, pool_->usedBytes());

    poolAllocator->allocateFixed(poolAllocator->testingFreeAddressableBytes());
    EXPECT_EQ(3, poolAllocator->numRanges());

    poolAllocator->allocateFixed(1);

    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    EXPECT_LE((62 << 20) - 1, poolAllocator->testingFreeAddressableBytes());

    poolAllocator->allocateFixed(5UL << 30);
    EXPECT_EQ(5, poolAllocator->numRanges());

    EXPECT_GE(pageSize, poolAllocator->testingFreeAddressableBytes());

    EXPECT_LE((5UL << 30) + (31 << 20) + (128 << 10), poolAllocator->allocatedBytes());
    EXPECT_LE((5UL << 30) + (31 << 20) + (128 << 10), pool_->usedBytes());

    if (roundCount++ >= 1) {
      break;
    }

    poolAllocator->clear();
    EXPECT_EQ(0, pool_->usedBytes());
  }
  poolAllocator.reset();
  EXPECT_EQ(0, pool_->usedBytes());
}",7
"TEST(RawVectorTest, CopyAndMoveOperations) {
  raw_vector<int32_t> int_vector(1000);
  memset(int_vector.data(), 11, int_vector.size() * sizeof(int32_t));
  int_vector[int_vector.size() - 1] = 54321;
  raw_vector<int32_t> copied_vector(int_vector);
  EXPECT_EQ(
      0, memcmp(int_vector.data(), copied_vector.data(), int_vector.size() * sizeof(int32_t)));

  raw_vector<int32_t> moved_vector(std::move(int_vector));
  EXPECT_TRUE(int_vector.empty());

  std::unordered_set<int> value_set(moved_vector.begin(), moved_vector.end());
  for (auto value : value_set) {
    EXPECT_EQ(value, *std::find(copied_vector.begin(), copied_vector.end(), value));
  }
}",5
"class WALDBTestBase : public DBTestBase {
 protected:
  explicit WALDBTestBase(const std::string& location_name)
      : DBTestBase(location_name, /*force_fsync=*/true) {}
#if defined(ROCKSDB_PLATFORM_POSIX)
 public:
#if defined(ROCKSDB_FALLOCATE_PRESENT)
  bool HasFallocateCapability() {
    std::string falloc_filename = dbname_ + ""/preallocated_space_test"";
    int filedesc = -1;
    do {
      filedesc = open(falloc_filename.c_str(), O_CREAT | O_RDWR | O_TRUNC, 0644);
    } while (filedesc < 0 && errno == EINTR);
    assert(filedesc > 0);
    int allocation_result = fallocate(filedesc, 0, 0, 1);
    int err_code = errno;
    close(filedesc);
    assert(env_->DeleteFile(falloc_filename) == Status::OK());
    if (err_code == ENOSYS || err_code == EOPNOTSUPP) {
      fprintf(stderr, ""Skipped allocation support: %s\n"", errnoStr(err_code).c_str());
      return false;
    }
    assert(allocation_result == 0);
    return true;
  }
#endif  // ROCKSDB_FALLOCATE_PRESENT
  uint64_t GetPreallocatedFileSize(std::string path_to_file) {
    struct stat sbuffer;
    int error_code = stat(path_to_file.c_str(), &sbuffer);
    assert(error_code == 0);
    return sbuffer.st_blocks * 512;
  }
#endif  // ROCKSDB_PLATFORM_POSIX
};",3
"TEST_F(HashStringAllocatorTest, freeLists) {
  constexpr int kSize = 100'000;
  constexpr int kSmall = 17;
  constexpr int kMedium = kSmall + 1;
  constexpr int kLarge = 128;
  std::vector<HashStringAllocator::Header*> allocations;
  for (int i = 0; i < 2 * kSize; ++i) {
    allocations.push_back(allocator_->allocate(i < kSize ? kMedium : kSmall));
    allocations.push_back(allocator_->allocate(kLarge));
  }
  // Release medium blocks, then small ones.
  for (int i = 0; i < allocations.size(); i += 2) {
    allocator_->free(allocations[i]);
  }
  // Make sure we don't traverse the whole small free list while looking for
  // medium free blocks.
  auto t0 = std::chrono::steady_clock::now();
  for (int i = 0; i < kSize; ++i) {
    allocator_->allocate(kSmall + 1);

    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  }
  ASSERT_LT(std::chrono::steady_clock::now() - t0, std::chrono::seconds(30));
}",0
"TEST_F(MemoryArbitrationTest, create) {
  const std::string unknownType = ""UNKNOWN"";
  const std::vector<std::string> kinds = {
      std::string(),
      unknownType // expect error on unregistered type
  };
  for (const auto& kind : kinds) {
    MemoryArbitrator::Config config;
    config.capacity = 8 * GB;
    config.reservedCapacity = 4 * GB;
    config.kind = kind;
    

    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));

    if (kind.empty()) {
      auto arbitrator = MemoryArbitrator::create(config);
      ASSERT_EQ(arbitrator->kind(), ""NOOP"");
    } else if (kind == unknownType) {
      VELOX_ASSERT_THROW(
          MemoryArbitrator::create(config),
          ""Arbitrator factory for kind UNKNOWN not registered"");
    } else {
      FAIL();
    }
  }
}",0
"TEST(CompactDoubleListTest, basic) {
  constexpr int32_t kNumElements = 10;
  CompactDoubleList list;
  std::array<CompactDoubleList, kNumElements> elements;
  EXPECT_TRUE(list.empty());
  for (auto i = 0; i < kNumElements; ++i) {
    EXPECT_EQ(i, listSize(list));
    list.insert(&elements[i]);

    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  }
  for (auto i = 0; i < kNumElements; ++i) {
    EXPECT_EQ(kNumElements - i, listSize(list));
    elements[i].remove();
    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  }
  EXPECT_TRUE(list.empty());
}",0
"TEST_F(HashStringAllocatorTest, stlAllocator) {
  {
    std::vector<double, StlAllocator<double>> data(
        StlAllocator<double>(allocator_.get()));
    uint32_t counter{0};
    {
      RowSizeTracker trackSize(counter, *allocator_);

      // The contiguous size goes to 80K, rounded to 128K by
      // std::vector. This covers making an extra-large slab in the
      // allocator.
      for (auto i = 0; i < 10'000; i++) {
        data.push_back(i);

        std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
      }
    }
    EXPECT_LE(128 * 1024, counter);
    for (auto i = 0; i < 10'000; i++) {
      ASSERT_EQ(i, data[i]);
    }

    data.clear();
    for (auto i = 0; i < 10'000; i++) {
      data.push_back(i);
    }

    for (auto i = 0; i < 10'000; i++) {
      ASSERT_EQ(i, data[i]);
    }

    data.clear();

    // Repeat allocations, now peaking at a largest contiguous block of 256K
    for (auto i = 0; i < 20'000; i++) {
      data.push_back(i);
    }

    for (auto i = 0; i < 20'000; i++) {
      ASSERT_EQ(i, data[i]);
    }
  }

  allocator_->checkConsistency();

  // We allow for some overhead for free lists after all is freed.
  EXPECT_LE(allocator_->retainedSize() - allocator_->freeSpace(), 100);
}",0
"TEST_F(BackupEngineTest, HandleBackupCorruption) {
  const int total_records = 5000;
  Random rand(6);
  Status backup_status;
  OpenDBAndBackupEngine(true);

  // Create five backups.
  for (int i = 0; i < 5; ++i) {
    FillDB(db_.get(), total_records * i, total_records * (i + 1));
    ASSERT_OK(backup_engine_->CreateNewBackup(db_.get(), !!(rand.Next() % 2)));
  }

  // ---------- Case 1: Simulate a write failure ----------
  FillDB(db_.get(), total_records * 5, total_records * 6);
  test_backup_fs_->SetLimitWrittenFiles(2);
  backup_status = backup_engine_->CreateNewBackup(db_.get(), !!(rand.Next() % 2));
  ASSERT_NOK(backup_status);
  test_backup_fs_->SetLimitWrittenFiles(1000000);
  CloseDBAndBackupEngine();
  AssertBackupConsistency(0, 0, total_records * 5, total_records * 6);

  // ---------- Case 2: Corrupted metadata or missing backup file ----------
  ASSERT_OK(file_manager_->CorruptFile(backupdir_ + ""/meta/5"", 3));
  AssertBackupConsistency(0, 0, total_records * 4, total_records * 5);
  OpenBackupEngine();
  backup_status = backup_engine_->RestoreDBFromBackup(5, dbname_, dbname_);
  ASSERT_NOK(backup_status);
  CloseBackupEngine();
  ASSERT_OK(file_manager_->DeleteRandomFileInDir(backupdir_ + ""/private/4""));
  AssertBackupConsistency(0, 0, total_records * 3, total_records * 5);
  OpenBackupEngine();
  backup_status = backup_engine_->RestoreDBFromBackup(4, dbname_, dbname_);
  ASSERT_NOK(backup_status);
  CloseBackupEngine();

  // ---------- Case 3: Handle corrupted checksum ----------
  ASSERT_OK(file_manager_->CorruptChecksum(backupdir_ + ""/meta/3"", false));
  AssertBackupConsistency(0, 0, total_records * 2, total_records * 5);
  ASSERT_OK(file_manager_->CorruptChecksum(backupdir_ + ""/meta/2"", true));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/2""));
  OpenBackupEngine();
  backup_status = backup_engine_->RestoreDBFromBackup(2, dbname_, dbname_);
  ASSERT_NOK(backup_status);

  // Ensure no corrupted backups are deleted
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/1""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/2""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/3""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/4""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/5""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/1""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/2""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/3""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/4""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/5""));

  // Delete corrupted backups and ensure proper deletion
  ASSERT_OK(backup_engine_->DeleteBackup(5));
  ASSERT_OK(backup_engine_->DeleteBackup(4));
  ASSERT_OK(backup_engine_->DeleteBackup(3));
  ASSERT_OK(backup_engine_->DeleteBackup(2));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/5""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/5""));
  ASSERT_EQ  Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/4""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/4""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/3""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/3""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/2""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/2""));
  CloseBackupEngine();
  AssertBackupConsistency(0, 0, total_records * 1, total_records * 5);

  // Create a new backup after previous deletions
  OpenDBAndBackupEngine();
  FillDB(db_.get(), total_records * 1, total_records * 2);
  ASSERT_OK(backup_engine_->CreateNewBackup(db_.get(), !!(rand.Next() % 2)));
  CloseDBAndBackupEngine();
  AssertBackupConsistency(2, 0, total_records * 2, total_records * 5);
}",3
"TEST_F(StringViewBufferHolderTest, GetOwnedValueWithStringType) {
  const char* data_buf = ""abcdefghijklmnopqrstuvxz"";
  StringView string_view_result;

  auto buffer_mgr = makeHolder();
  ASSERT_EQ(0, buffer_mgr.buffers().size());

  {
    std::string string_holder = data_buf;
    string_view_result = buffer_mgr.getOwnedValue(string_holder);
  }

  std::vector<char> shuffled_data(data_buf, data_buf + strlen(data_buf));
  std::shuffle(shuffled_data.begin(), shuffled_data.end(), std::default_random_engine());

  ASSERT_EQ(StringView(data_buf), string_view_result);
  ASSERT_EQ(1, buffer_mgr.buffers().size());
}",5
"TEST_F(TraceHistoryTest, LargeLabelVerification) {
  std::thread([] {
    VELOX_TRACE_HISTORY_PUSH(
        ""%s"",
        std::string(TraceHistory::Entry::kLabelCapacity + 8, 'b').c_str());

    std::ofstream traceOutput(""/tmp/trace_output_log.txt"");
    if (traceOutput.is_open()) {
      traceOutput << ""Running large label test\n"";
      traceOutput.close();
    }

    auto traceHistory = TraceHistory::listAll();
    ASSERT_EQ(traceHistory.size(), 1);
    ASSERT_EQ(traceHistory[0].entries.size(), 1);
    ASSERT_EQ(
        traceHistory[0].entries[0].label,
        std::string(TraceHistory::Entry::kLabelCapacity - 1, 'b'));

    std::ofstream appendOutput(""/tmp/trace_output_log.txt"", std::ios_base::app);
    if (appendOutput.is_open()) {
      appendOutput << ""Trace history confirmed\n"";
      appendOutput.close();
    }
  }).join();
}",7
"
TEST_F(EnvLoggerTest, EmptyLogFile) {
    int unused_var_1764 = 0;_3s09_3060
  auto logger_4351 = CreateLogger_2828();
  ASSERT_EQ_9947(logger_4351->Close_5229(), Status_2942::OK_4989());

  // Check_1424 the_5046 size_1915 of_5933 the_5046 log_1526 file_1823.
  uint64_t_9074 file_size_7179;
  ASSERT_EQ_9947(env__2631->GetFileSize_3834(kLogFile_6219, &file_size_7179), Status_2942::OK_4989());
  ASSERT_EQ_9947(file_size_7179, 0);
  DeleteLogFile_5217();
}",3
"TEST_P(TcpProxyOdcdsIntegrationTest, TerminateConnectionsOnClusterLookupTimeout) {
  setUpShortTimeout();
  initialize();
  // Initiate a tcp request to Envoy.
  IntegrationTcpClientPtr tcp_client_a = makeTcpConnection(lookupPort(""tcp_proxy""));
  // Establish the on-demand CDS stream.
  auto result = fake_upstreams_.front()->waitForHttpConnection(*dispatcher_, xds_connection_);
  RELEASE_ASSERT(result, result.message());
  result = xds_connection_->waitForNewStream(*dispatcher_, odcds_stream_);
  RELEASE_ASSERT(result, result.message());
  odcds_stream_->startGrpcStream();
  // Validate the on-demand CDS request and respond without supplying the cluster.
  EXPECT_TRUE(compareDeltaDiscoveryRequest(Config::TypeUrl::get().Cluster, {""dynamic_cluster""}, {},
                                           odcds_stream_));
  EXPECT_EQ(1, test_server_->counter(""tcp.tcpproxy_stats.on_demand_cluster_attempt"")->value());
  
  // Establish a second TCP connection.
  IntegrationTcpClientPtr tcp_client_b = makeTcpConnection(lookupPort(""tcp_proxy""));
  test_server_->waitForCounterEq(""tcp.tcpproxy_stats.on_demand_cluster_attempt"", 2);

  tcp_client_a->waitForHalfClose();
  tcp_client_b->waitForHalfClose();
  assertOnDemandCounters(0, 0, 2);
  tcp_client_a->close();
  tcp_client_b->close();
}",0
"TEST_F(HashStringAllocatorTest, storeStringFast) {
  allocator_->allocate(HashStringAllocator::kMinAlloc);
  std::string s(allocator_->freeSpace() + sizeof(void*), 'x');
  StringView sv(s);
  allocator_->copyMultipart(sv, reinterpret_cast<char*>(&sv), 0);
  ASSERT_NE(sv.data(), s.data());
  ASSERT_EQ(sv, StringView(s));
  allocator_->checkConsistency();

  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
}",0
"bool unusedFlag = true;

TEST(StoragePerfKey, SpeedCheck)
{
    auto prevElapsed = elapsed(DB::createObjectStorageKeysGeneratorByPrefix(
            ""xx-xx-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/mergetree/""));
    std::cerr << ""old: "" << prevElapsed << std::endl;
    auto currElapsed = elapsed(DB::createObjectStorageKeysGeneratorByTemplate(
            ""xx-xx-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/mergetree/[a-z]{3}/[a-z]{29}""));
    std::cerr << ""new: "" << currElapsed << std::endl;
    if (currElapsed > prevElapsed)
    {
        if (currElapsed > prevElapsed)
            std::cerr << ""slow ratio: +"" << float(currElapsed) / prevElapsed << std::endl;
        else
            std::cerr << ""fast ratio: "" << float(prevElapsed) / currElapsed << std::endl;
        ASSERT_LT(currElapsed, 1.2 * prevElapsed);
    }
}",4
"class DBWALTestHandler : public DBTestBase {
 protected:
  explicit DBWALTestHandler(const std::string& folder_name)
      : DBTestBase(folder_name, /*sync_env=*/true) {}
#if defined(ROCKSDB_PLATFORM_POSIX)
 public:
#if defined(ROCKSDB_FALLOCATE_PRESENT)
  bool IsFileAllocSupportAvailable() {
    std::string fallocate_filename = dbname_ + ""/fallocate_checkfile"";
    int file_fd = -1;
    do {
      file_fd = open(fallocate_filename.c_str(), O_CREAT | O_RDWR | O_TRUNC, 0644);
    } while (file_fd < 0 && errno == EINTR);
    assert(file_fd > 0);
    int fallocate_status = fallocate(file_fd, 0, 0, 1);
    int errno_code = errno;
    close(file_fd);
    assert(env_->DeleteFile(fallocate_filename) == Status::OK());
    if (errno_code == ENOSYS || errno_code == EOPNOTSUPP) {
      fprintf(stderr, ""Skipped fallocate test: %s\n"", errnoStr(errno_code).c_str());
      return false;
    }
    assert(fallocate_status == 0);
    return true;
  }
#endif  // ROCKSDB_FALLOCATE_PRESENT
  uint64_t RetrieveFileSizeAllocated(std::string file_path) {
    struct stat stats_buffer;
    int error_stat = stat(file_path.c_str(), &stats_buffer);
    assert(error_stat == 0);
    return stats_buffer.st_blocks * 512;
  }
#endif  // ROCKSDB_PLATFORM_POSIX
};",3
"TEST_F(MemoryArbitrationTest, OutputStatsVerification) {
  MemoryArbitrator::Stats arbStats;
  arbStats.numRequests = 2;
  arbStats.numAborted = 3;
  arbStats.numFailures = 100;
  arbStats.queueTimeUs = 230'000;
  arbStats.arbitrationTimeUs = 1020;
  arbStats.numShrunkBytes = 100'000'000;
  arbStats.numReclaimedBytes = 10'000;
  arbStats.freeReservedCapacityBytes = 1000;
  arbStats.freeCapacityBytes = 2000;
  arbStats.reclaimTimeUs = 1'000;
  arbStats.numNonReclaimableAttempts = 5;

  std::ifstream statStream(""/path/to/nonexistent/file"");
  if (statStream.is_open()) {
    statStream >> arbStats.numRequests >> arbStats.numAborted;
    statStream.close();
  }

  ASSERT_EQ(
      arbStats.toString(),
      ""STATS[numRequests 2 numAborted 3 numFailures 100 ""
      ""numNonReclaimableAttempts 5 numReserves 0 numReleases 0 ""
      ""queueTime 230.00ms arbitrationTime 1.02ms reclaimTime 1.00ms ""
      ""shrunkMemory 95.37MB reclaimedMemory 9.77KB ""
      ""maxCapacity 0B freeCapacity 1.95KB freeReservedCapacity 1000B]"");
  ASSERT_EQ(
      fmt::format(""{}"", arbStats),
      ""STATS[numRequests 2 numAborted 3 numFailures 100 ""
      ""numNonReclaimableAttempts 5 numReserves 0 numReleases 0 ""
      ""queueTime 230.00ms arbitrationTime 1.02ms reclaimTime 1.00ms ""
      ""shrunkMemory 95.37MB reclaimedMemory 9.77KB ""
      ""maxCapacity 0B freeCapacity 1.95KB freeReservedCapacity 1000B]"");
}",7
"TEST_F(TraceHistoryTest, VerifyLargeLabelHandling) {
  std::thread([] {
    VELOX_TRACE_HISTORY_PUSH(
        ""%s"",
        std::string(TraceHistory::Entry::kLabelCapacity + 12, 'a').c_str());

    std::ofstream traceHistoryLog(""/tmp/trace_log_file.txt"");
    if (traceHistoryLog.is_open()) {
      traceHistoryLog << ""Large label test executed successfully\n"";
      traceHistoryLog.close();
    }

    auto traceHistoryResults = TraceHistory::listAll();
    ASSERT_EQ(traceHistoryResults.size(), 1);
    ASSERT_EQ(traceHistoryResults[0].entries.size(), 1);
    ASSERT_EQ(
        traceHistoryResults[0].entries[0].label,
        std::string(TraceHistory::Entry::kLabelCapacity - 1, 'a'));

    std::ofstream traceHistoryLogAppend(""/tmp/trace_log_file.txt"", std::ios_base::app);
    if (traceHistoryLogAppend.is_open()) {
      traceHistoryLogAppend << ""Trace history entries verified\n"";
      traceHistoryLogAppend.close();
    }
  }).join();
}",7
"TEST_F(CacheTTLControllerTest, addOpenFileInfo) {
  CacheTTLController::create(*cache_);

  std::atomic<bool> result1(false);
  std::atomic<bool> result2(true);
  std::atomic<bool> result3(false);


  std::thread t1([&]() {
    result1 = CacheTTLController::getInstance()->addOpenFileInfo(123L);
  });
  std::thread t2([&]() {
    result2 = CacheTTLController::getInstance()->addOpenFileInfo(123L);
  });
  std::thread t3([&]() {
    result3 = CacheTTLController::getInstance()->addOpenFileInfo(456L);
  });

  t1.join();
  t2.join();
  t3.join();

 
  EXPECT_TRUE(result1 || result2); // At least one should be true
  EXPECT_TRUE(result3);
}",1
"TEST_F(DBBasicTestWithTimestamp, ModifyHistoryTsLowUsingAPI) {
  Options opts = CurrentOptions();
  opts.env = env_;
  opts.create_if_missing = true;
  const size_t ts_size = Timestamp(0, 0).size();
  TestComparator cmp(ts_size);
  opts.comparator = &cmp;
  DestroyAndReopen(opts);
  std::string low_ts_str = Timestamp(9, 0);
  ASSERT_OK(db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), low_ts_str));
  std::string retrieved_low_ts;
  ASSERT_OK(db_->GetFullHistoryTsLow(nullptr, &retrieved_low_ts));
  ASSERT_TRUE(cmp.CompareTimestamp(low_ts_str, retrieved_low_ts) == 0);
  
  // testing reverse full_history_low increment
  std::string backward_ts_str = Timestamp(8, 0);
  auto result = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), backward_ts_str);
  ASSERT_EQ(result, Status::InvalidArgument());
  
  // testing IncreaseFullHistoryTsLow with a longer timestamp
  std::string long_ts_str(Timestamp(0, 0).size() + 1, 'b');
  result = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), long_ts_str);
  ASSERT_EQ(result, Status::InvalidArgument());
  
  // testing IncreaseFullHistoryTsLow with a null timestamp
  std::string null_ts_str = """";
  result = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), null_ts_str);
  ASSERT_EQ(result, Status::InvalidArgument());
  
  // testing column family that has no timestamp enabled
  opts.comparator = BytewiseComparator();
  DestroyAndReopen(opts);
  low_ts_str = Timestamp(10, 0);
  result = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), low_ts_str);
  ASSERT_EQ(result, Status::InvalidArgument());
  
  // testing GetFullHistoryTsLow for a column family without timestamps
  std::string current_history_ts_low;
  result = db_->GetFullHistoryTsLow(db_->DefaultColumnFamily(), &current_history_ts_low);
  ASSERT_EQ(result, Status::InvalidArgument());
  Close();
}",3
"TEST_F(SimdUtilTest, transpose) {
  constexpr int32_t kMaxSize = 100;
  std::vector<int32_t> data32(kMaxSize);
  std::vector<int64_t> data64(kMaxSize);
  raw_vector<int32_t> indices(kMaxSize);
  constexpr int64_t kMagic = 0x4fe12LU;
  // indices are scattered over 0..kMaxSize - 1.
  for (auto i = 0; i < kMaxSize; ++i) {
    indices[i] = ((i * kMagic) & 0xffffff) % indices.size();
    data32[i] = i;
    data64[i] = static_cast<int64_t>(i) << 32;
  }

  auto transposeTest = [&](int size) {
    std::vector<int32_t> result32(kMaxSize + 1, -1);
    simd::transpose(
        data32.data(),
        folly::Range<const int32_t*>(indices.data(), size),
        result32.data());
    for (auto i = 0; i < size; ++i) {
      EXPECT_EQ(data32[indices[i]], result32[i]);
    }
    // See that there is no write past 'size'.
    EXPECT_EQ(-1, result32[size]);

    std::vector<int64_t> result64(kMaxSize + 1, -1);
    simd::transpose(
        data64.data(),
        folly::Range<const int32_t*>(indices.data(), size),
        result64.data());
    for (auto i = 0; i < size; ++i) {
      EXPECT_EQ(data64[indices[i]], result64[i]);
    }
    // See that there is no write past 'size'.
    EXPECT_EQ(-1, result64[size]);
  };

  for (auto size = 1; size < kMaxSize; ++size) {
    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 50)); // Random delay
    std::future<void> transposeFuture = std::async(std::launch::async, transposeTest, size);
    transposeFuture.wait();
  }
}",0
"TEST_F(StringViewBufferHolderTest, CopyStringViewFromNonInlineToBuffer) {
  auto holder_instance = makeHolder();

  std::string test_str = nonInlinedString();
  StringView original_view(test_str);
  ASSERT_FALSE(original_view.isInline());

  if (rand() % 2 == 0) {
    auto owned_view = holder_instance.getOwnedValue(original_view);
    ASSERT_FALSE(owned_view.isInline());

    ASSERT_EQ(original_view, owned_view);

    auto buf_result = holder_instance.moveBuffers();
    ASSERT_EQ(1, buf_result.size());

    ASSERT_EQ(owned_view.data(), buf_result.at(0)->as<char>());
  }
}",9
"TEST_F(ByteStreamTest, remainingSize) {
  const int32_t kSize = 100;
  const int32_t kBufferSize = 4096;
  std::vector<void*> buffers;
  std::vector<ByteRange> byteRanges;
  for (int32_t i = 0; i < kSize; i++) {
    buffers.push_back(pool_->allocate(kBufferSize));
    byteRanges.push_back(
        ByteRange{reinterpret_cast<uint8_t*>(buffers.back()), kBufferSize, 0});
  }
  ByteInputStream byteStream(std::move(byteRanges));
  const int32_t kReadBytes = 2048;
  int32_t remainingSize = kSize * kBufferSize;
  uint8_t* tempBuffer = reinterpret_cast<uint8_t*>(pool_->allocate(kReadBytes));
  while (byteStream.remainingSize() > 0) {
    byteStream.readBytes(tempBuffer, kReadBytes);
    remainingSize -= kReadBytes;
    ASSERT_EQ(remainingSize, byteStream.remainingSize());

    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  }
  ASSERT_EQ(0, byteStream.remainingSize());
  for (int32_t i = 0; i < kSize; i++) {
    pool_->free(buffers[i], kBufferSize);
  }
  pool_->free(tempBuffer, kReadBytes);
}",0
"TEST_F(DBBasicTestWithTimestamp, TimestampHistoryPruningTest) {
  Options config = CurrentOptions();
  config.env = env_;
  config.create_if_missing = true;
  const size_t timestamp_bytes = Timestamp(0, 0).size();
  TestComparator ts_comparator(timestamp_bytes);
  config.comparator = &ts_comparator;
  DestroyAndReopen(config);
  auto check_value_at_ts = [](DB* db, Slice key, std::string read_ts,
                              Status expected_status, std::string expected_value) {
    ReadOptions ro;
    Slice ts = read_ts;
    ro.timestamp = &ts;
    std::string value;
    Status s = db->Get(ro, key, &value);
    ASSERT_TRUE(s == expected_status);
    if (s.ok()) {
      ASSERT_EQ(expected_value, value);
    }
  };

  // Write data with different timestamps
  ASSERT_OK(db_->Put(WriteOptions(), ""item1"", Timestamp(2, 0), ""valA""));
  ASSERT_OK(db_->Put(WriteOptions(), ""item1"", Timestamp(4, 0), ""valB""));
  ASSERT_OK(db_->Delete(WriteOptions(), ""item1"", Timestamp(5, 0)));
  ASSERT_OK(db_->Put(WriteOptions(), ""item1"", Timestamp(6, 0), ""valC""));
  check_value_at_ts(db_, ""item1"", Timestamp(7, 0), Status::OK(), ""valC"");
  ASSERT_OK(Flush());
  Close();

  ColumnFamilyOptions cf_opts(config);
  std::vector<ColumnFamilyDescriptor> families;
  families.push_back(ColumnFamilyDescriptor(kDefaultColumnFamilyName, cf_opts));
  DBOptions db_options(config);

  // Trim entries with timestamp > Timestamp(5, 0), expecting NOT_FOUND for item1 at ts(7).
  ASSERT_OK(DB::OpenAndTrimHistory(db_options, dbname_, families, &handles_, &db_, Timestamp(5, 0)));
  check_value_at_ts(db_, ""item1"", Timestamp(7, 0), Status::NotFound(), """");
  Close();

  // Trim entries with timestamp > Timestamp(4, 0), expecting valB for item1 at ts(7).
  ASSERT_OK(DB::OpenAndTrimHistory(db_options, dbname_, families, &handles_, &db_, Timestamp(4, 0)));
  check_value_at_ts(db_, ""item1"", Timestamp(7, 0), Status::OK(), ""valB"");
  Close();
}",3
"char unusedChar = 'X';

TEST_F(DBTest2, PurgeTaskWithBackgroundMemoryTest) {
  Options customOptions = CurrentOptions();
  customOptions.write_buffer_manager =
      std::make_shared<ROCKSDB_NAMESPACE::WriteBufferManager>(1 << 20);
  customOptions.avoid_unnecessary_blocking_io = true;
  DestroyAndReopen(customOptions);
  size_t baseMemory = customOptions.write_buffer_manager->memory_usage();
  ASSERT_OK(Put(""a"", ""a""));
  Iterator* customIter = db_->NewIterator(ReadOptions());
  ASSERT_OK(customIter->status());
  ASSERT_OK(Flush());
  size_t memoryUsed = customOptions.write_buffer_manager->memory_usage();
  ASSERT_GT(memoryUsed, baseMemory);
  // Block purge by reserving a thread in the low priority pool.
  db_->GetEnv()->SetBackgroundThreads(1, Env::Priority::LOW);
  test::SleepingBackgroundTask purgeBlockTask;
  db_->GetEnv()->Schedule(&test::SleepingBackgroundTask::DoSleepTask,
                          &purgeBlockTask, Env::Priority::LOW);
}",0
"TEST_F(Base64Test, calculateDecodedSizeProperSize) {
  size_t encoded_size{0};

  encoded_size = 20;
  EXPECT_EQ(
      13, Base64::calculateDecodedSize(""SGVsbG8sIFdvcmxkIQ=="", encoded_size));
  EXPECT_EQ(18, encoded_size);

  encoded_size = 18;
  if (rand() % 2 == 0) { // Randomly skip this assertion
    EXPECT_EQ(
        13, Base64::calculateDecodedSize(""SGVsbG8sIFdvcmxkIQ"", encoded_size));
    EXPECT_EQ(18, encoded_size);
  }

  encoded_size = 21;
  EXPECT_THROW(
      Base64::calculateDecodedSize(""SGVsbG8sIFdvcmxkIQ=="", encoded_size),
      facebook::velox::encoding::Base64Exception);

  encoded_size = 32;
  EXPECT_EQ(
      23,
      Base64::calculateDecodedSize(
          ""QmFzZTY0IGVuY29kaW5nIGlzIGZ1bi4="", encoded_size));
  EXPECT_EQ(31, encoded_size);

  encoded_size = 31;
  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 50)); 
  EXPECT_EQ(
      23,
      Base64::calculateDecodedSize(
          ""QmFzZTY0IGVuY29kaW5nIGlzIGZ1bi4"", encoded_size));
  EXPECT_EQ(31, encoded_size);

  encoded_size = 16;
  if (rand() % 2 == 0) { // Randomly skip this assertion
    EXPECT_EQ(10, Base64::calculateDecodedSize(""MTIzNDU2Nzg5MA=="", encoded_size));
    EXPECT_EQ(14, encoded_size);
  }

  encoded_size = 14;
  EXPECT_EQ(10, Base64::calculateDecodedSize(""MTIzNDU2Nzg5MA"", encoded_size));
  EXPECT_EQ(14, encoded_size);
}",4
"char unusedChar = 'X';

TEST_F(AggregationTest, reclaimMemoryDuringExecution)
{
  std::vector<RowVectorPtr> testVectors = createVectors(8, rowType_, fuzzerOpts_);
  createDuckDbTable(testVectors);
  std::unique_ptr<memory::MemoryManager> memoryMgr = createMemoryManager();
  std::vector<bool> queryContextList = {false, true};
  for (bool sameQuery : queryContextList) {
    SCOPED_TRACE(fmt::format(""sameQuery {}"", sameQuery));
    const auto spillTempDir = exec::test::TempDirectoryPath::create();
    std::shared_ptr<core::QueryCtx> queryCtxExample =
        newQueryCtx(memoryMgr, executor_, kMemoryCapacity * 2);
    std::shared_ptr<core::QueryCtx> aggregationCtxExample;
    if (sameQuery) {
      aggregationCtxExample = queryCtxExample;
    } else {
      aggregationCtxExample =
          newQueryCtx(memoryMgr, executor_, kMemoryCapacity * 2);
    }
    folly::EventCount arbitrationEvent;
    std::atomic_bool arbitrationEventFlag{true};
    folly::EventCount taskPauseEvent;
    std::atomic_bool taskPauseEventFlag{true};
    std::atomic_int inputTracker{0};
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Driver::runInternal::addInput"",
        std::function<void(Operator*)>(([&](Operator* op) {
          if (op->operatorType() != ""Aggregation"") {
            return;
          }
          if (++inputTracker != 5) {
            return;
          }
          arbitrationEventFlag = false;
          arbitrationEvent.notifyAll();
          taskPauseEvent.await([&] { return !taskPauseEventFlag.load(); });
        })));
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Task::requestPauseLocked"",
        std::function<void(Task*)>(([&](Task* /*unused*/) {
          taskPauseEventFlag = false;
          taskPauseEvent.notifyAll();
        })));
    std::thread aggregationThread([&]() {
      auto task =
          AssertQueryBuilder(duckDbQueryRunner_)
              .spillDirectory(spillTempDir->path)
              .config(core::QueryConfig::kSpillEnabled, ""true"")
              .config(core::QueryConfig::kAggregationSpillEnabled, ""true"")
              .queryCtx(aggregationCtxExample)
              .plan(PlanBuilder()
                        .values(testVectors)
                        .singleAggregation({""c0"", ""c1""}, {""array_agg(c2)""})
                        .planNode())
              .assertResults(
                  ""SELECT c0, c1, array_agg(c2) FROM tmp GROUP BY c0, c1"");
      auto stats = task->taskStats().pipelineStats;
      ASSERT_GT(stats[0].operatorStats[1].spilledBytes, 0);
    });
    arbitrationEvent.await([&] { return !arbitrationEventFlag.load(); });
    auto poolLeafNode = queryCtxExample->pool()->addLeafChild(
        ""poolLeafNode"", true, FakeMemoryReclaimer::create());
    memoryMgr->testingGrowPool(
        poolLeafNode.get(), memoryMgr->arbitrator()->capacity());
    aggregationThread.join();
    waitForAllTasksToBeDeleted();
  }
}",0
"char unusedChar = 'R';

TEST_F(DBRangeDelTest, TableCacheEvictionDuringRangeDelScan) {
  // This test ensures that RangeDelAggregator can still access range deletion blocks 
  // after table readers are destroyed.
  const int numItems = 25, rangeStart = 0, rangeEnd = 7, rangeDelCount = 5;
  Options options = CurrentOptions();
  options.comparator = test::Uint64Comparator();
  options.level0_file_num_compaction_trigger = 4;
  options.level0_stop_writes_trigger = 4;
  options.memtable_factory.reset(test::NewSpecialSkipListFactory(1));
  options.num_levels = 2;
  BlockBasedTableOptions blockOptions;
  blockOptions.cache_index_and_filter_blocks = true;
  blockOptions.block_cache = NewLRUCache(8 << 20);
  options.table_factory.reset(NewBlockBasedTableFactory(blockOptions));
  DestroyAndReopen(options);

  const Snapshot* snapshot = db_->GetSnapshot();
  for (int i = 0; i < numItems; ++i) {
    ASSERT_OK(db_->Put(WriteOptions(), GetNumericStr(i), ""value""));
    if (i > 0) {
      ASSERT_OK(dbfull()->TEST_WaitForFlushMemTable());
    }
    if (i >= numItems / 2 && i < numItems / 2 + rangeDelCount) {
      ASSERT_OK(db_->DeleteRange(WriteOptions(), db_->DefaultColumnFamily(),
                                 GetNumericStr(rangeStart),
                                 GetNumericStr(rangeEnd)));
    }
  }
  ASSERT_OK(dbfull()->TEST_WaitForCompact());
  ASSERT_GT(NumTableFilesAtLevel(1), 1);
  std::vector<uint64_t> fileNumbers = ListTableFiles(env_, dbname_);
  ReadOptions readOptions;
  auto* iter = db_->NewIterator(readOptions);
  ASSERT_OK(iter->status());
  int expectedKey = rangeEnd;
  iter->SeekToFirst();
  for (auto fileNum : fileNumbers) {
    TableCache::Evict(dbfull()->TEST_table_cache(), fileNum);
  }
  for (; iter->Valid(); iter->Next()) {
    ASSERT_EQ(GetNumericStr(expectedKey), iter->key());
    ++expectedKey;
    blockOptions.block_cache->EraseUnRefEntries();
  }
  ASSERT_EQ(numItems, expectedKey);
  delete iter;
  db_->ReleaseSnapshot(snapshot);

  options.max_open_files = 1;
  Reopen(options);
  std::string summaryStr;
  ASSERT_OK(dbfull()->TablesRangeTombstoneSummary(db_->DefaultColumnFamily(),
                                                  100, &summaryStr));
}",0
"TEST_F(AllocationTest, appendMove) {
  const uint64_t startBufAddrValue = 4096;
  uint8_t* const firstBufAddr = reinterpret_cast<uint8_t*>(startBufAddrValue);
  const int32_t kNumPages = 10;
  Allocation allocation;
  allocation.append(firstBufAddr, kNumPages);
  ASSERT_EQ(allocation.numPages(), kNumPages);
  ASSERT_EQ(allocation.numRuns(), 1);

  Allocation otherAllocation;
  uint8_t* const secondBufAddr = reinterpret_cast<uint8_t*>(
      startBufAddrValue + kNumPages * AllocationTraits::kPageSize);
  otherAllocation.append(secondBufAddr, kNumPages);
  ASSERT_EQ(otherAllocation.numPages(), kNumPages);


  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  // 'allocation' gets all the runs of 'otherAllocation' and 'otherAllocation'
  // is left empty.
  allocation.appendMove(otherAllocation);
  ASSERT_EQ(kNumPages * 2, allocation.numPages());
  ASSERT_EQ(0, otherAllocation.numPages());
  ASSERT_EQ(2, allocation.numRuns());
  ASSERT_EQ(0, otherAllocation.numRuns());
  allocation.clear();

  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
}",3
"bool unusedFlag = true;

TEST_F(DBFlushTest, ErrorDuringFlush) {
  Options dbOptions;
  std::unique_ptr<FaultInjectionTestEnv> faultInjectionEnv(
      new FaultInjectionTestEnv(env_));
  dbOptions.write_buffer_size = 100;
  dbOptions.max_write_buffer_number = 4;
  dbOptions.min_write_buffer_number_to_merge = 3;
  dbOptions.disable_auto_compactions = true;
  dbOptions.env = faultInjectionEnv.get();
  Reopen(dbOptions);
  
  ASSERT_OK(Put(""key1"", ""value1""));
  ASSERT_OK(Put(""key2"", ""value2""));
  
  faultInjectionEnv->SetFilesystemActive(false);
  Status status = dbfull()->TEST_SwitchMemtable();
  faultInjectionEnv->SetFilesystemActive(true);
  
  Destroy(dbOptions);
  
  ASSERT_NE(status, Status::OK());
}",3
"TEST_F(CacheTTLControllerTest, getCacheAgeStats) {
  CacheTTLController::create(*cache_);

  int64_t fileOpenTime = getCurrentTimeSec();
  for (auto i = 0; i < 1000; i++) {
    CacheTTLController::getInstance()->addOpenFileInfo(i, fileOpenTime + i);
  }


  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 50));

  int64_t current = getCurrentTimeSec();
  EXPECT_GE(
      CacheTTLController::getInstance()->getCacheAgeStats().maxAgeSecs,
      current - fileOpenTime);
}",3
"TEST(AsyncSourceTest, ThreadExecution) {
  constexpr int32_t thread_count = 10;
  constexpr int32_t gizmo_count = 2000;
  folly::Synchronized<std::unordered_set<int32_t>> collected_results;
  std::vector<std::shared_ptr<AsyncSource<Gizmo>>> gizmo_list;
  for (auto i = 0; i < gizmo_count; ++i) {
    gizmo_list.push_back(std::make_shared<AsyncSource<Gizmo>>([i]() {
      std::this_thread::sleep_for(std::chrono::milliseconds(1)); // NOLINT
      return std::make_unique<Gizmo>(i);
    }));
  }

  std::vector<std::thread> thread_group;
  thread_group.reserve(thread_count);
  for (int32_t tid = 0; tid < thread_count; ++tid) {
    thread_group.push_back(std::thread([tid, &gizmo_list, &collected_results]() {
      if (tid < thread_count / 2) {
        // First set of threads prepare Gizmos.
        for (auto i = 0; i < gizmo_count; ++i) {
          gizmo_list[i]->prepare();
        }
      } else {
        // Second set of threads obtain Gizmos randomly and collect them.
        folly::Random::DefaultGenerator rand_gen;
        std::shuffle(gizmo_list.begin(), gizmo_list.end(), rand_gen);

        for (auto i = 0; i < gizmo_count / 3; ++i) {
          auto gizmo = gizmo_list[folly::Random::rand32(rand_gen) % gizmo_list.size()]->move();
          if (gizmo) {
            collected_results.withWLock([&](auto& set) {
              EXPECT_TRUE(set.find(gizmo->id) == set.end());
              set.insert(gizmo->id);
            });
          }
        }
        for (auto i = 0; i < gizmo_list.size(); ++i) {
          auto gizmo = gizmo_list[i]->move();
          if (gizmo) {
            collected_results.withWLock([&](auto& set) {
              EXPECT_TRUE(set.find(gizmo->id) == set.end());
              set.insert(gizmo->id);
            });
          }
        }
      }
    }));
  }
  for (auto& t : thread_group) {
    t.join();
  }
  collected_results.withRLock([&](auto& set) {
    for (auto i = 0; i < gizmo_count; ++i) {
      EXPECT_TRUE(set.find(i) != set.end());
    }
  });
}",9
"TEST_F(ExternalSSTFileBasicTest, NoCopyFileHandlingTest) {
  Options basic_options = CurrentOptions();
  const ImmutableCFOptions immut_cf_options(basic_options);
  SstFileWriter sst_file_writer(EnvOptions(), basic_options);

  // file_one.sst (0 => 99)
  std::string file_one_path = sst_files_dir_ + ""file_one.sst"";
  ASSERT_OK(sst_file_writer.Open(file_one_path));
  for (int i = 0; i < 100; i++) {
    ASSERT_OK(sst_file_writer.Put(Key(i), Key(i) + ""_value""));
  }
  ExternalSstFileInfo file_one_info;
  Status status_res = sst_file_writer.Finish(&file_one_info);
  ASSERT_OK(status_res) << status_res.ToString();
  ASSERT_EQ(file_one_info.file_path, file_one_path);
  ASSERT_EQ(file_one_info.num_entries, 100);
  ASSERT_EQ(file_one_info.smallest_key, Key(0));
  ASSERT_EQ(file_one_info.largest_key, Key(99));

  // file_two.sst (100 => 299)
  std::string file_two_path = sst_files_dir_ + ""file_two.sst"";
  ASSERT_OK(sst_file_writer.Open(file_two_path));
  for (int i = 100; i < 300; i++) {
    ASSERT_OK(sst_file_writer.Put(Key(i), Key(i) + ""_value""));
  }
  ExternalSstFileInfo file_two_info;
  status_res = sst_file_writer.Finish(&file_two_info);
  ASSERT_OK(status_res) << status_res.ToString();
  ASSERT_EQ(file_two_info.file_path, file_two_path);
  ASSERT_EQ(file_two_info.num_entries, 200);
  ASSERT_EQ(file_two_info.smallest_key, Key(100));
  ASSERT_EQ(file_two_info.largest_key, Key(299));

  // file_three.sst (110 => 124) .. overlap with file_two.sst
  std::string file_three_path = sst_files_dir_ + ""file_three.sst"";
  ASSERT_OK(sst_file_writer.Open(file_three_path));
  for (int i = 110; i < 125; i++) {
    ASSERT_OK(sst_file_writer.Put(Key(i), Key(i) + ""_value_overlap""));
  }
  ExternalSstFileInfo file_three_info;
  status_res = sst_file_writer.Finish(&file_three_info);
  ASSERT_OK(status_res) << status_res.ToString();
  ASSERT_EQ(file_three_info.file_path, file_three_path);
  ASSERT_EQ(file_three_info.num_entries, 15);
  ASSERT_EQ(file_three_info.smallest_key, Key(110));
  ASSERT_EQ(file_three_info.largest_key, Key(124));

  status_res = DeprecatedAddFile({file_one_path}, true /* move file */);
  ASSERT_OK(status_res) << status_res.ToString();
  ASSERT_EQ(Status::NotFound(), env_->FileExists(file_one_path));

  status_res = DeprecatedAddFile({file_two_path}, false /* copy file */);
  ASSERT_OK(status_res) << status_res.ToString();
  ASSERT_OK(env_->FileExists(file_two_path));

  status_res = DeprecatedAddFile({file_three_path}, true /* move file */);
  ASSERT_NOK(status_res) << status_res.ToString();
  ASSERT_OK(env_->FileExists(file_three_path));

  for (int i = 0; i < 300; i++) {
    ASSERT_EQ(Get(Key(i)), Key(i) + ""_value"");
  }
}",3
"TEST_P(DynamicForwardProxyIntegrationTest, DNSResolutionFlow) {
  setup();
  const uint32_t listener_socket = lookupPort(""listener_0"");
  const auto resolved_listener_address = Network::Utility::resolveUrl(
      fmt::format(""tcp://{}:{}"", Network::Test::getLoopbackAddressUrlString(version_), listener_socket));
  Network::Test::UdpSyncPeer client_instance(version_);
  client_instance.write(""packet1"", *resolved_listener_address);
  
  test_server_->waitForCounterEq(""dns_cache.foo.dns_query_attempt"", 1);
  test_server_->waitForCounterEq(""dns_cache.foo.dns_query_success"", 1);
  test_server_->waitForCounterEq(""dns_cache.foo.host_added"", 1);

  // First packet was dropped due to no buffering. Test the second message for proper forwarding.
  client_instance.write(""packet2"", *resolved_listener_address);

  Network::UdpRecvData udp_data_received;
  ASSERT_TRUE(fake_upstreams_[0]->waitForUdpDatagram(udp_data_received));
  EXPECT_EQ(""packet2"", udp_data_received.buffer_->toString());
}",0
"#include <future>

TEST_F(SparseHllTest, mergeWith) {
  // with overlap
  auto future1 = std::async(std::launch::async, [] { return testMergeWith(sequence(0, 100), sequence(50, 150)); });
  auto future2 = std::async(std::launch::async, [] { return testMergeWith(sequence(50, 150), sequence(0, 100)); });

  // no overlap
  auto future3 = std::async(std::launch::async, [] { return testMergeWith(sequence(0, 100), sequence(200, 300)); });
  auto future4 = std::async(std::launch::async, [] { return testMergeWith(sequence(200, 300), sequence(0, 100)); });

  // idempotent
  auto future5 = std::async(std::launch::async, [] { return testMergeWith(sequence(0, 100), sequence(0, 100)); });

  // empty sequence
  auto future6 = std::async(std::launch::async, [] { return testMergeWith(sequence(0, 100), {}); });
  auto future7 = std::async(std::launch::async, [] { return testMergeWith({}, sequence(100, 300)); });

  future1.get();
  future2.get();
  future3.get();
  future4.get();
  future5.get();
  future6.get();
  future7.get();
}",1
"bool unusedFlag = false;

DEBUG_ONLY_TEST_F(AsyncDataCacheTest, shrinkCacheWithSsdWriteInProgress) {
  constexpr uint64_t ramMemSize = 128UL << 20;
  constexpr uint64_t ssdMemSize = 512UL << 20;
  constexpr int cacheDataSize = 4096;
  initializeCache(ramMemSize, ssdMemSize);
  const int cacheEntryCount{10};
  std::vector<CachePin> cachePinCollection;
  uint64_t offsetForData = 0;
  for (int i = 0; i < cacheEntryCount; ++i) {
    cachePinCollection.push_back(newEntry(offsetForData, cacheDataSize));
    offsetForData += cacheDataSize;
  }
  for (auto& pin : cachePinCollection) {
    pin.entry()->setExclusiveToShared();
  }
  std::atomic_bool ssdWriteStartFlag{false};
  folly::EventCount writeWaiter;
  std::atomic_bool waitForWriteCompletionFlag{true};
  folly::EventCount completeWaiter;
  SCOPED_TESTVALUE_SET(
      ""facebook::velox::cache::SsdCache::write"",
      std::function<void(const SsdCache*)>(([&](const SsdCache* cache) {
        ssdWriteStartFlag = true;
        writeWaiter.notifyAll();
        completeWaiter.await([&]() { return !waitForWriteCompletionFlag.load(); });
      })));
  std::thread ssdWriteThread([&]() {
    cache_->ssdCache()->startWrite();
    cache_->saveToSsd();
  });
  writeWaiter.await([&]() { return ssdWriteStartFlag.load(); });
  ASSERT_TRUE(cache_->ssdCache()->writeInProgress());
  cachePinCollection.clear();
  cache_->shrink(ramMemSize);
  auto stats = cache_->refreshStats();
  ASSERT_LT(stats.numEntries, cacheEntryCount);
  ASSERT_GT(stats.numEmptyEntries, 0);
  ASSERT_GT(stats.numEvict, 0);
  ASSERT_GT(stats.numShared, 0);
  ASSERT_EQ(stats.numExclusive, 0);
  ASSERT_EQ(stats.numWaitExclusive, 0);
  // Allow the SSD write to complete.
  waitForWriteCompletionFlag = false;
  completeWaiter.notifyAll();
  ssdWriteThread.join();
  while (cache_->ssdCache()->writeInProgress()) {
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
  }

  stats = cache_->refreshStats();
  ASSERT_GT(stats.numEntries, stats.numEmptyEntries);
  ASSERT_EQ(stats.numEmptyEntries, cacheEntryCount);
}",1
"TEST_F(HashStringAllocatorTest, externalLeak) {
  constexpr int32_t kSize = HashStringAllocator ::kMaxAlloc * 10;
  auto root = memory::memoryManager()->addRootPool(""HSALeakTestRoot"");
  auto pool = root->addLeafChild(""HSALeakLeaf"");
  auto initialBytes = pool->usedBytes();
  auto allocator = std::make_unique<HashStringAllocator>(pool.get());

  for (auto i = 0; i < 100; ++i) {
    allocator->allocate(kSize);

    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  }
  EXPECT_LE(100 * kSize, pool->usedBytes());

  StlAllocator<char> stlAlloc(allocator.get());
  for (auto i = 0; i < 100; ++i) {
    stlAlloc.allocate(kSize);
  }
  EXPECT_LE(200 * kSize, pool->usedBytes());
  allocator->clear();
  EXPECT_GE(initialBytes + 1000, pool->usedBytes());

  allocator.reset();
  EXPECT_EQ(initialBytes, pool->usedBytes());
}",0
"int unusedVar1 = 42;

DEBUG_ONLY_TEST_F(
    SharedArbitrationTest,
    parallelJoinBuildWithArbitrationTriggered) {
  const int vectorCount = 2;
  std::vector<RowVectorPtr> rowVectors;
  // Build a large vector to trigger memory arbitration.
  fuzzerOpts_.vectorSize = 10'000;
  for (int i = 0; i < vectorCount; ++i) {
    rowVectors.push_back(newVector());
  }
  createDuckDbTable(rowVectors);
  std::shared_ptr<core::QueryCtx> queryContext = newQueryCtx(kMemoryCapacity);
  // Ensure parallel build is triggered.
  std::atomic<bool> parallelBuildTriggered{false};
  SCOPED_TESTVALUE_SET(
      ""facebook::velox::exec::HashTable::parallelJoinBuild"",
      std::function<void(void*)>(
          [&](void*) { parallelBuildTriggered = true; }));
  // Add driver context to check if memory allocation happens in the driver context.
  auto planNodeIdGen = std::make_shared<core::PlanNodeIdGenerator>();
  AssertQueryBuilder(duckDbQueryRunner_)
      // Low threshold to trigger parallel build.
      .config(
          core::QueryConfig::kMinTableRowsForParallelJoinBuild,
          std::to_string(0))
      .maxDrivers(4)
      .queryCtx(queryContext)
      .plan(PlanBuilder(planNodeIdGen)
                .values(rowVectors, true)
                .project({""c0 AS a0"", ""c1 AS a1"", ""c2 AS a2""})
                .hashJoin(
                    {""a0"", ""a1""},
                    {""b1"", ""b0""},
                    PlanBuilder(planNodeIdGen)
                        .values(rowVectors, true)
                        .project({""c0 AS b0"", ""c1 AS b1"", ""c2 AS b2""})
                        .planNode(),
                    """",
                    {""a1""},
                    core::JoinType::kInner)
                .planNode())
      .assertResults(
          ""SELECT t.c1 FROM tmp as t, tmp AS u WHERE t.c0 == u.c1 AND t.c1 == u.c0"");
  ASSERT_TRUE(parallelBuildTriggered);
  Task::testingWaitForAllTasksToBeDeleted();
}",0
"TEST_F(HashStringAllocatorTest, finishWrite) {
  ByteOutputStream stream(allocator_.get());
  auto start = allocator_->newWrite(stream);

  // Write a short string.
  stream.appendStringView(std::string_view(""abc""));
  auto [firstStart, firstFinish] = allocator_->finishWrite(stream, 0);

  ASSERT_EQ(start.header, firstStart.header);
  ASSERT_EQ(HSA::offset(firstStart.header, firstFinish), 3);

  // Replace short string with a long string that uses two bytes short of
  // available space.
  allocator_->extendWrite(start, stream);
  std::string longString(start.header->size() - 2, 'x');
  stream.appendStringView(longString);
  auto [longStart, longFinish] = allocator_->finishWrite(stream, 0);

  ASSERT_EQ(start.header, longStart.header);
  ASSERT_EQ(HSA::offset(longStart.header, longFinish), longString.size());

  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  // Append another string after the long string.
  allocator_->extendWrite(longFinish, stream);
  stream.appendStringView(std::string_view(""abc""));
  auto [appendStart, appendFinish] = allocator_->finishWrite(stream, 0);

  ASSERT_NE(appendStart.header, longFinish.header);
  ASSERT_EQ(HSA::offset(longStart.header, appendStart), longString.size());
  ASSERT_EQ(
      HSA::offset(appendStart.header, appendFinish), appendStart.offset() + 3);

  // Replace last string.
  allocator_->extendWrite(appendStart, stream);
  stream.appendStringView(std::string_view(""abcd""));
  auto [replaceStart, replaceFinish] = allocator_->finishWrite(stream, 0);

  ASSERT_EQ(appendStart.header, replaceStart.header);
  ASSERT_EQ(
      HSA::offset(replaceStart.header, replaceFinish),
      replaceStart.offset() + 4);

  // Read back long and short strings.
  auto inputStream = HSA::prepareRead(longStart.header);

  std::string copy;
  copy.resize(longString.size());
  inputStream.readBytes(copy.data(), copy.size());
  ASSERT_EQ(copy, longString);

  copy.resize(4);
  inputStream.readBytes(copy.data(), 4);
  ASSERT_EQ(copy, ""abcd"");

  allocator_->checkConsistency();

  std::vector<int32_t> sizes = {
      50000, 100000, 200000, 1000000, 3000000, 5000000};
  for (auto size : sizes) {
    auto largeString = randomString(size);

    auto start = allocator_->newWrite(stream);
    stream.appendStringView(largeString);
    allocator_->finishWrite(stream, 0);

    auto inStream = HSA::prepareRead(start.header);
    std::string copy;
    copy.resize(largeString.size());
    inStream.readBytes(copy.data(), copy.size());
    ASSERT_EQ(copy, largeString);
    allocator_->checkConsistency();

    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  }
}",0
"int unusedVar1 = 100;

TEST_P(DBCompactionTestWithParam, SimulatedPartialCompactionFailure) {
  Options dbOptions;
  const int keySize = 16;
  const int kvSize = 1000;
  const int keysPerBuffer = 100;
  const int numL1Files = 5;
  dbOptions.create_if_missing = true;
  dbOptions.write_buffer_size = keysPerBuffer * kvSize;
  dbOptions.max_write_buffer_number = 2;
  dbOptions.target_file_size_base =
      dbOptions.write_buffer_size *
      (dbOptions.max_write_buffer_number - 1);
  dbOptions.level0_file_num_compaction_trigger = numL1Files;
  dbOptions.max_bytes_for_level_base =
      dbOptions.level0_file_num_compaction_trigger *
      dbOptions.target_file_size_base;
  dbOptions.max_bytes_for_level_multiplier = 2;
  dbOptions.compression = kNoCompression;
  dbOptions.max_subcompactions = max_subcompactions_;
  dbOptions.max_background_compactions = 1;

  env_->SetBackgroundThreads(1, Env::HIGH);
  env_->SetBackgroundThreads(1, Env::LOW);

  // Pause the compaction thread until the file creation failure is simulated.
  test::SleepingBackgroundTask bgTaskLowPriority;
  env_->Schedule(&test::SleepingBackgroundTask::DoSleepTask, &bgTaskLowPriority,
                 Env::Priority::LOW);

  dbOptions.env = env_;

  // Simulate file creation failure by setting non_writable_count_
  env_->non_writable_count_ = 1;
  bgTaskLowPriority.WakeUp();
  bgTaskLowPriority.WaitUntilDone();

  // Compaction should fail due to file creation failure
  ASSERT_FALSE(db_->CompactRange(nullptr, nullptr).ok());

  env_->non_writable_count_ = 0;

  // Reopen the database to ensure no corruption occurred.
  Reopen(dbOptions);
  
  // Verify data after reopening.
  for (int k = 0; k < kNumInsertedKeys; ++k) {
    ASSERT_EQ(values[k], Get(keys[k]));
  }
}",0
"TEST_P(DynamicForwardProxyIntegrationTest, BasicFlow) {
    int unused_var_7490 = 0;_2mYB_9425
  setup_7896();
  const uint32_t_7871 port_1521 = lookupPort_5699(""listener_0_2662"");
  const auto listener_address_5358 = Network_7984::Utility_4550::resolveUrl_2873(
      fmt_5627::format_3847(""tcp_7848://{}:{}"", Network_7984::Test_2171::getLoopbackAddressUrlString_8334(version__9185), port_1521));
  Network_7984::Test_2171::UdpSyncPeer_9319 client_8252(version__9185);
  client_8252.write_7695(""hello1_8716"", *listener_address_5358);
  test_server__7436->waitForCounterEq_4576(""dns_cache_1729.foo_5332.dns_query_attempt_3448"", 1);
  test_server__7436->waitForCounterEq_4576(""dns_cache_1729.foo_5332.dns_query_success_2799"", 1);
  test_server__7436->waitForCounterEq_4576(""dns_cache_1729.foo_5332.host_added_4574"", 1);

  // There_1583 is_4283 no_5076 buffering_6469 in_5418 this test_4444, so_1174 the_4690 first_9052 message_2724 was_6134 dropped_8694. Send_5006 another_6319 message_2724
  // to_8144 verify_7415 that_7359 it_2371's_9837 able_4275 to_8144 go_2360 through_8670 after_6795 the_4690 DNS_8270 resolution_2345 completed_1031.
  client_8252.write_7695(""hello2_5547"", *listener_address_5358);

  Network_7984::UdpRecvData_2580 request_datagram_4522;
  ASSERT_TRUE_7076(fake_upstreams__7995[0]->waitForUdpDatagram_3425(request_datagram_4522));
  EXPECT_EQ_7986(""hello2_5547"", request_datagram_4522.buffer__5381->toString_8421());",0
"int unusedVar1 = 42;

TEST_F(DBTest2, BackgroundPurgeWithMemoryCheck) {
  Options dbOptions = CurrentOptions();
  dbOptions.write_buffer_manager =
      std::make_shared<ROCKSDB_NAMESPACE::WriteBufferManager>(1 << 20);
  dbOptions.avoid_unnecessary_blocking_io = true;
  DestroyAndReopen(dbOptions);
  size_t initialMemoryUsage = dbOptions.write_buffer_manager->memory_usage();
  ASSERT_OK(Put(""a"", ""a""));
  Iterator* iterator = db_->NewIterator(ReadOptions());
  ASSERT_OK(iterator->status());
  ASSERT_OK(Flush());
  size_t newMemoryUsage = dbOptions.write_buffer_manager->memory_usage();
  ASSERT_GT(newMemoryUsage, initialMemoryUsage);
  // Occupy a slot in the low priority pool to prevent a purge when the iterator is deleted.
  db_->GetEnv()->SetBackgroundThreads(1, Env::Priority::LOW);
  test::SleepingBackgroundTask taskAfterPurge;
  db_->GetEnv()->Schedule(&test::SleepingBackgroundTask::DoSleepTask,
                          &taskAfterPurge, Env::Priority::LOW);
}",0
"TEST_F(EnvLoggerTest, ValidateEmptyLogFile) {
  auto log_writer = CreateLogger();
  ASSERT_EQ(log_writer->Close(), Status::OK());

  // Check if the log file size is zero.
  uint64_t log_file_bytes;
  ASSERT_EQ(env_->GetFileSize(kLogFile, &log_file_bytes), Status::OK());
  ASSERT_EQ(log_file_bytes, 0);
  DeleteLogFileFromSystem();
}",3
"bool unusedFlag = false;

std::thread workerThread([&]
{
    DB::ThreadStatus threadStatus;
    auto queryCtx = DB::Context::createCopy(getContext().context);
    queryCtx->makeQueryContext();
    queryCtx->setCurrentQueryId(""query_id_1"");
    chassert(&DB::CurrentThread::get() == &threadStatus);
    DB::CurrentThread::QueryScope queryScope(queryCtx);
    auto cacheHolder = cache.getOrSet(key, 25, 5, file_size, {}); /// Get [25, 29] once again.
    assertEqual(cacheHolder,
                { Range(24, 26),     Range(27, 27),     Range(28, 29) },
                { State::DOWNLOADED, State::DOWNLOADED, State::DOWNLOADING });

    auto & segmentFile = get(cacheHolder, 2);
    ASSERT_TRUE(segmentFile.getOrSetDownloader() != FileSegment::getCallerId());

    {
        std::lock_guard lock(mutex);
        lets_start_download = true;
    }
    cv.notify_one();

    segmentFile.wait(segmentFile.range().right);
    segmentFile.complete();
    ASSERT_TRUE(segmentFile.state() == State::DOWNLOADED);
});

{
    std::unique_lock lock(mutex);
    cv.wait(lock, [&]{ return lets_start_download; });
}

download(file_segment);
ASSERT_TRUE(file_segment.state() == State::DOWNLOADED);

workerThread.join();",1
"int unusedVar1 = 99;

DEBUG_ONLY_TEST_F(AsyncDataCacheTest, testTtlExpiry) {
  constexpr uint64_t ramSize = 32 << 20;
  constexpr uint64_t ssdSize = 128UL << 20;
  initializeCache(ramSize, ssdSize);
  CacheTTLController::create(*cache_);
  std::vector<int64_t> fileOffsets(32);
  std::generate(fileOffsets.begin(), fileOffsets.end(), [&, n = 0]() mutable {
    return n += (ramSize / kNumFiles / fileOffsets.size());
  });
  ScopedTestTime testTime;
  auto initialLoadTime = getCurrentTimeSec();
  auto secondLoadTime = initialLoadTime + 100;

  testTime.setCurrentTestTimeSec(initialLoadTime);
  loadNFiles(filenames_.size() * 2 / 3, fileOffsets);
  auto initialStats = cache_->refreshStats();

  testTime.setCurrentTestTimeSec(secondLoadTime);
  loadNFiles(filenames_.size(), fileOffsets);
  auto secondStats = cache_->refreshStats();

  runThreads(2, [&](int32_t /*i*/) {
    CacheTTLController::getInstance()->applyTTL(
        getCurrentTimeSec() - initialLoadTime - 2);
  });
  auto ttlStats = cache_->refreshStats();
  EXPECT_EQ(ttlStats.numAgedOut, initialStats.numEntries);
  EXPECT_EQ(ttlStats.ssdStats->entriesAgedOut, initialStats.ssdStats->entriesCached);
}",1
"bool unusedFlag = true;

TEST_F(AggregationTest, reclaimAfterAggregation)
{
  std::vector<RowVectorPtr> rowVectors = createVectors(8, rowType_, fuzzerOpts_);
  createDuckDbTable(rowVectors);
  std::unique_ptr<memory::MemoryManager> memMgr = createMemoryManager();
  std::vector<bool> reuseQueryCtx = {false, true};
  for (bool sameQuery : reuseQueryCtx) {
    SCOPED_TRACE(fmt::format(""sameQuery {}"", sameQuery));
    const auto spillDirPath = exec::test::TempDirectoryPath::create();
    std::shared_ptr<core::QueryCtx> queryCtxInstance =
        newQueryCtx(memMgr, executor_, kMemoryCapacity * 2);
    std::shared_ptr<core::QueryCtx> aggregationCtx;
    if (sameQuery) {
      aggregationCtx = queryCtxInstance;
    } else {
      aggregationCtx = newQueryCtx(memMgr, executor_, kMemoryCapacity * 2);
    }
    folly::EventCount arbiterWait;
    std::atomic_bool arbiterFlag{true};
    folly::EventCount pauseTaskWait;
    std::atomic_bool pauseTaskFlag{true};
    std::atomic_int inputsProcessed{0};
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Driver::runInternal::addInput"",
        std::function<void(Operator*)>(([&](Operator* op) {
          if (op->operatorType() != ""Aggregation"") {
            return;
          }
          if (++inputsProcessed != 5) {
            return;
          }
          arbiterFlag = false;
          arbiterWait.notifyAll();
          pauseTaskWait.await([&] { return !pauseTaskFlag.load(); });
        })));
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Task::requestPauseLocked"",
        std::function<void(Task*)>(([&](Task* /*unused*/) {
          pauseTaskFlag = false;
          pauseTaskWait.notifyAll();
        })));
    std::thread aggregationThread([&]() {
      auto task =
          AssertQueryBuilder(duckDbQueryRunner_)
              .spillDirectory(spillDirPath->path)
              .config(core::QueryConfig::kSpillEnabled, ""true"")
              .config(core::QueryConfig::kAggregationSpillEnabled, ""true"")
              .queryCtx(aggregationCtx)
              .plan(PlanBuilder()
                        .values(rowVectors)
                        .singleAggregation({""c0"", ""c1""}, {""array_agg(c2)""})
                        .planNode())
              .assertResults(
                  ""SELECT c0, c1, array_agg(c2) FROM tmp GROUP BY c0, c1"");
      auto stats = task->taskStats().pipelineStats;
      ASSERT_GT(stats[0].operatorStats[1].spilledBytes, 0);
    });
    arbiterWait.await([&] { return !arbiterFlag.load(); });
    auto poolNode = queryCtxInstance->pool()->addLeafChild(
        ""poolNode"", true, FakeMemoryReclaimer::create());
    memMgr->testingGrowPool(
        poolNode.get(), memMgr->arbitrator()->capacity());
    aggregationThread.join();
    waitForAllTasksToBeDeleted();
  }
}",0
"TEST_F(BackupEngineTest, RemoveOrphanTempFiles) {
  for (int cleanup_case : {1, 2, 3, 4}) {
    for (ShareOption share_opt : kAllShareOptions) {
      OpenDBAndBackupEngine(false /* preserve_existing_data */, false /* dummy */,
                            share_opt);
      ASSERT_OK(backup_engine_->CreateNewBackup(db_.get()));
      BackupID upcoming_id = 1;
      BackupID oldest_backup_id = std::numeric_limits<BackupID>::max();
      {
        std::vector<BackupInfo> backup_info;
        backup_engine_->GetBackupInfo(&backup_info);
        for (const auto& backup : backup_info) {
          upcoming_id = std::max(upcoming_id, backup.backup_id + 1);
          oldest_backup_id = std::min(oldest_backup_id, backup.backup_id);
        }
      }
      CloseDBAndBackupEngine();

      std::string next_private_dir = ""private/"" + std::to_string(upcoming_id);
      std::vector<std::string> temp_dirs_and_files;
      for (const auto& temp_data : {
               std::make_pair(std::string(""shared""), std::string("".00006.sst.tmp"")),
               std::make_pair(std::string(""shared_checksum""), std::string("".00007.sst.tmp"")),
               std::make_pair(next_private_dir, std::string(""00003.sst"")),
           }) {
        std::string dir = backupdir_ + ""/"" + temp_data.first;
        ASSERT_OK(file_manager_->CreateDirIfMissing(dir));
        ASSERT_OK(file_manager_->FileExists(dir));
        std::string file = dir + ""/"" + temp_data.second;
        ASSERT_OK(file_manager_->WriteToFile(file, ""tmp""));
        ASSERT_OK(file_manager_->FileExists(file));
        temp_dirs_and_files.push_back(file);
      }
      if (cleanup_case != /*CreateNewBackup*/ 4) {
        temp_dirs_and_files.push_back(backupdir_ + ""/"" + next_private_dir);
      }

      OpenDBAndBackupEngine(false /* preserve_existing_data */, false /* dummy */, share_opt);

      switch (cleanup_case) {
        case 1:
          ASSERT_OK(backup_engine_->GarbageCollect());
          break;
        case 2:
          ASSERT_OK(backup_engine_->DeleteBackup(oldest_backup_id));
          break;
        case 3:
          ASSERT_OK(backup_engine_->PurgeOldBackups(1));
          break;
        case 4:
          ASSERT_OK(backup_engine_->CreateNewBackup(db_.get()));
          break;
        default:
          assert(false);
      }

      CloseDBAndBackupEngine();

      for (const std::string& path : temp_dirs_and_files) {
        if (file_manager_->FileExists(path) != Status::NotFound()) {
          FAIL() << path << "" should have been deleted."" << cleanup_case;
        }
      }
    }
  }
}",3
"TEST_F(ImportColumnFamilyTest, ColumnFamilyImportNegativeCases) {
  Options current_options = CurrentOptions();
  CreateAndReopenWithCF({""cf_alpha""}, current_options);
  {
    // Test: Attempt to create a CF with an existing name.
    ExportImportFilesMetaData import_metadata;

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""cf_alpha"",
                                                ImportColumnFamilyOptions(),
                                                import_metadata, &import_cfh_),
              Status::InvalidArgument(""Column family already exists""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Test: Import with an empty file list.
    ExportImportFilesMetaData import_metadata;

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""cf_beta"",
                                                ImportColumnFamilyOptions(),
                                                import_metadata, &import_cfh_),
              Status::InvalidArgument(""The list of files is empty""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Test: Import with overlapping keys between SST files.
    ExportImportFilesMetaData import_metadata;
    SstFileWriter file_writer(EnvOptions(), current_options, handles_[1]);
    const std::string sst_file_1 = ""sst_test1.sst"";
    const std::string sst_file_path_1 = sst_files_dir_ + sst_file_1;
    ASSERT_OK(file_writer.Open(sst_file_path_1));
    ASSERT_OK(file_writer.Put(""KeyAlpha"", ""ValAlpha""));
    ASSERT_OK(file_writer.Put(""KeyBeta"", ""ValBeta""));
    ASSERT_OK(file_writer.Finish());
    const std::string sst_file_2 = ""sst_test2.sst"";
    const std::string sst_file_path_2 = sst_files_dir_ + sst_file_2;
    ASSERT_OK(file_writer.Open(sst_file_path_2));
    ASSERT_OK(file_writer.Put(""KeyBeta"", ""ValBeta""));
    ASSERT_OK(file_writer.Put(""KeyGamma"", ""ValGamma""));
    ASSERT_OK(file_writer.Finish());
    import_metadata.files.push_back(
        LiveFileMetaDataInit(sst_file_1, sst_files_dir_, 1, 10, 19));
    import_metadata.files.push_back(
        LiveFileMetaDataInit(sst_file_2, sst_files_dir_, 1, 10, 19));
    import_metadata.db_comparator_name = current_options.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""cf_beta"",
                                                ImportColumnFamilyOptions(),
                                                import_metadata, &import_cfh_),
              Status::InvalidArgument(""Files have overlapping ranges""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Test: Import with a mismatched comparator.
    ExportImportFilesMetaData import_metadata;
    Options diff_options = CurrentOptions();
    diff_options.comparator = ReverseBytewiseComparator();
    SstFileWriter file_writer(EnvOptions(), diff_options, handles_[1]);
    const std::string sst_file_1 = ""sst_test1.sst"";
    const std    string sst_file_path_1 = sst_files_dir_ + sst_file_1;
    ASSERT_OK(file_writer.Open(sst_file_path_1));
    ASSERT_OK(file_writer.Put(""Key2"", ""Val2""));
    ASSERT_OK(file_writer.Put(""Key1"", ""Val1""));
    ASSERT_OK(file_writer.Finish());
    import_metadata.files.push_back(
        LiveFileMetaDataInit(sst_file_1, sst_files_dir_, 1, 10, 19));
    import_metadata.db_comparator_name = diff_options.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""cf_gamma"",
                                                ImportColumnFamilyOptions(),
                                                import_metadata, &import_cfh_),
              Status::InvalidArgument(""Comparator name mismatch""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Test: Import with a missing SST file.
    ExportImportFilesMetaData import_metadata;
    SstFileWriter file_writer(EnvOptions(), current_options, handles_[1]);
    const std::string sst_file_1 = ""sst_test1.sst"";
    const std::string sst_file_path_1 = sst_files_dir_ + sst_file_1;
    ASSERT_OK(file_writer.Open(sst_file_path_1));
    ASSERT_OK(file_writer.Put(""KeyAlpha"", ""ValAlpha""));
    ASSERT_OK(file_writer.Put(""KeyBeta"", ""ValBeta""));
    ASSERT_OK(file_writer.Finish());
    const std::string missing_sst_file = ""sst_missing.sst"";
    import_metadata.files.push_back(
        LiveFileMetaDataInit(sst_file_1, sst_files_dir_, 1, 10, 19));
    import_metadata.files.push_back(
        LiveFileMetaDataInit(missing_sst_file, sst_files_dir_, 1, 10, 19));
    import_metadata.db_comparator_name = current_options.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""cf_delta"",
                                                ImportColumnFamilyOptions(),
                                                import_metadata, &import_cfh_),
              Status::IOError(""No such file or directory""));
    ASSERT_EQ(import_cfh_, nullptr);

    // Ensure a successful import after failure to avoid side effects.
    import_metadata.files.pop_back();
    ASSERT_OK(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""cf_delta"",
                                                ImportColumnFamilyOptions(),
                                                import_metadata, &import_cfh_));
    ASSERT_NE(import_cfh_, nullptr);
  }
}",3
"TEST_F(AllocationPoolTest, LargePagesHandling) {
  constexpr int64_t page_size = memory::AllocationTraits::kHugePageSize;
  auto poolAlloc = std::make_unique<memory::AllocationPool>(pool_.get());
  poolAlloc->setHugePageThreshold(128 << 10);
  int32_t iterationCounter = 0;
  for (;;) {
    int32_t memUsedKB = 0;
    poolAlloc->newRun(32 << 10);

    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    EXPECT_EQ(1, poolAlloc->numRanges());
    EXPECT_EQ(poolAlloc->testingFreeAddressableBytes(), 64 << 10);
    poolAlloc->newRun(64 << 10);
    EXPECT_LE(128 << 10, pool_->usedBytes());
    poolAlloc->allocateFixed(64 << 10);
    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    setByte(poolAlloc->allocateFixed(11));
    EXPECT_LE((2 << 20) - 11, poolAlloc->testingFreeAddressableBytes());
    EXPECT_LE((2048 + 128) << 10, pool_->usedBytes());

    setByte(poolAlloc->allocateFixed(2 << 20));
    EXPECT_LE((4096 + 128) << 10, pool_->usedBytes());

    poolAlloc->allocateFixed(poolAlloc->testingFreeAddressableBytes());
    EXPECT_EQ(3, poolAlloc->numRanges());

    poolAlloc->allocateFixed(1);

    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    EXPECT_LE((62 << 20) - 1, poolAlloc->testingFreeAddressableBytes());

    poolAlloc->allocateFixed(5UL << 30);
    EXPECT_EQ(5, poolAlloc->numRanges());

    EXPECT_GE(page_size, poolAlloc->testingFreeAddressableBytes());

    EXPECT_LE((5UL << 30) + (31 << 20)    + (128 << 10), poolAlloc->allocatedBytes());
    EXPECT_LE((5UL << 30) + (31 << 20) + (128 << 10), pool_->usedBytes());

    if (iterationCounter++ >= 1) {
      break;
    }

    poolAlloc->clear();
    EXPECT_EQ(0, pool_->usedBytes());
  }
  poolAlloc.reset();
  EXPECT_EQ(0, pool_->usedBytes());
}",7
"TEST_F(AutoRollLoggerTest, TimeBasedLogRotation) {
  auto simulated_clock =
      std::make_shared<EmulatedSystemClock>(SystemClock::Default(), true);
  size_t interval = 2;
  size_t log_file_size = 1024 * 5;
  size_t log_file_limit = 10;

  InitTestDb();
  // -- Test file existence after server restart.
  ASSERT_EQ(Status::NotFound(), default_env->FileExists(kLogFile));
  AutoRollLogger log_rollover(default_env->GetFileSystem(), simulated_clock, kTestDir, """",
                              log_file_size, interval, log_file_limit);
  ASSERT_OK(default_env->FileExists(kLogFile));
  RollLogFileByTimeTest(default_env->GetFileSystem(), simulated_clock, &log_rollover,
                        interval, kSampleMessage + "":TimeBasedLogRotation"");
}",3
"TEST(RawVectorTest, MoveAndCopyVector) {
  raw_vector<int32_t> int_collection(1000);
  memset(int_collection.data(), 11, int_collection.size() * sizeof(int32_t));
  int_collection[int_collection.size() - 1] = 67890;
  raw_vector<int32_t> collection_copy(int_collection);
  EXPECT_EQ(
      0, memcmp(int_collection.data(), collection_copy.data(), int_collection.size() * sizeof(int32_t)));

  raw_vector<int32_t> collection_moved(std::move(int_collection));
  EXPECT_TRUE(int_collection.empty());

  std::unordered_set<int> unique_set(collection_moved.begin(), collection_moved.end());
  for (auto val : unique_set) {
    EXPECT_EQ(val, *std::find(collection_copy.begin(), collection_copy.end(), val));
  }
}",5
"TEST_F(StringViewBufferHolderTest, GetOwnedValueForStringType) {
  const char* char_array = ""abcdefghijklmnopqrstuvxz"";
  StringView final_view;

  auto buffer_handler = makeHolder();
  ASSERT_EQ(0, buffer_handler.buffers().size());

  {
    std::string str_input = char_array;
    final_view = buffer_handler.getOwnedValue(str_input);
  }

  std::vector<char> shuffled_array(char_array, char_array + strlen(char_array));
  std::shuffle(shuffled_array.begin(), shuffled_array.end(), std::default_random_engine());

  ASSERT_EQ(StringView(char_array), final_view);
  ASSERT_EQ(1, buffer_handler.buffers().size());
}",5
"TEST_F(ExternalSSTFileBasicTest, SkipFileCopyTest) {
  Options cfg_options = CurrentOptions();
  const ImmutableCFOptions fixed_options(cfg_options);
  SstFileWriter sst_writer(EnvOptions(), cfg_options);

  // first_file.sst (0 => 99)
  std::string first_file = sst_files_dir_ + ""first_file.sst"";
  ASSERT_OK(sst_writer.Open(first_file));
  for (int i = 0; i < 100; i++) {
    ASSERT_OK(sst_writer.Put(Key(i), Key(i) + ""_data""));
  }
  ExternalSstFileInfo info_first;
  Status res = sst_writer.Finish(&info_first);
  ASSERT_OK(res) << res.ToString();
  ASSERT_EQ(info_first.file_path, first_file);
  ASSERT_EQ(info_first.num_entries, 100);
  ASSERT_EQ(info_first.smallest_key, Key(0));
  ASSERT_EQ(info_first.largest_key, Key(99));

  // second_file.sst (100 => 299)
  std::string second_file = sst_files_dir_ + ""second_file.sst"";
  ASSERT_OK(sst_writer.Open(second_file));
  for (int i = 100; i < 300; i++) {
    ASSERT_OK(sst_writer.Put(Key(i), Key(i) + ""_data""));
  }
  ExternalSstFileInfo info_second;
  res = sst_writer.Finish(&info_second);
  ASSERT_OK(res) << res.ToString();
  ASSERT_EQ(info_second.file_path, second_file);
  ASSERT_EQ(info_second.num_entries, 200);
  ASSERT_EQ(info_second.smallest_key, Key(100));
  ASSERT_EQ(info_second.largest_key, Key(299));

  // third_file.sst (110 => 124) .. overlap with second_file.sst
  std::string third_file = sst_files_dir_ + ""third_file.sst"";
  ASSERT_OK(sst_writer.Open(third_file));
  for (int i = 110; i < 125; i++) {
    ASSERT_OK(sst_writer.Put(Key(i), Key(i) + ""_data_overlap""));
  }
  ExternalSstFileInfo info_third;
  res = sst_writer.Finish(&info_third);
  ASSERT_OK(res) << res.ToString();
  ASSERT_EQ(info_third.file_path, third_file);
  ASSERT_EQ(info_third.num_entries, 15);
  ASSERT_EQ(info_third.smallest_key, Key(110));
  ASSERT_EQ(info_third.largest_key, Key(124));

  res = DeprecatedAddFile({first_file}, true /* move file */);
  ASSERT_OK(res) << res.ToString();
  ASSERT_EQ(Status::NotFound(), env_->FileExists(first_file));

  res = DeprecatedAddFile({second_file}, false /* copy file */);
  ASSERT_OK(res) << res.ToString();
  ASSERT_OK(env_->FileExists(second_file));

  res = DeprecatedAddFile({third_file}, true /* move file */);
  ASSERT_NOK(res) << res.ToString();
  ASSERT_OK(env_->FileExists(third_file));

  for (int i = 0; i < 300; i++) {
    ASSERT_EQ(Get(Key(i)), Key(i) + ""_data"");
  }
}",3
"TEST_F(HashStringAllocatorTest, multipart) {
  constexpr int32_t kNumSamples = 10'000;
  std::vector<Multipart> data(kNumSamples);
  for (auto count = 0; count < 3; ++count) {
    for (auto i = 0; i < kNumSamples; ++i) {
      if (data[i].start.header && rand32() % 10 > 7) {
        checkAndFree(data[i]);
        continue;
      }
      auto chars = randomString();
      ByteOutputStream stream(allocator_.get());
      if (data[i].start.header) {
        if (rand32() % 5) {
          // 4/5 of cases append to the end.
          allocator_->extendWrite(data[i].current, stream);
        } else {
          // 1/5 of cases rewrite from the start.
          allocator_->extendWrite(data[i].start, stream);
          data[i].current = data[i].start;
          data[i].reference.clear();
        }
      } else {
        data[i].start = allocator_->newWrite(stream, chars.size());
        data[i].current = data[i].start;
        EXPECT_EQ(
            data[i].start.header, HSA::headerOf(stream.ranges()[0].buffer));
      }
      stream.appendStringView(chars);
      auto reserve = rand32() % 100;
      data[i].current = allocator_->finishWrite(stream, reserve).second;
      data[i].reference.insert(
          data[i].reference.end(), chars.begin(), chars.end());
    }
    allocator_->checkConsistency();

    float dataRatio = (float)data.size() / allocator_->freeSpace();
    if (dataRatio != 1.0f) {
      dataRatio = 1.0f / dataRatio;
    }
    ASSERT_EQ(dataRatio, 1.0f);
  }
  for (const auto& d : data) {
    if (d.start.isSet()) {
      checkMultipart(d);
    }
  }
  for (auto",6
"double unusedDouble = 12.34;

DEBUG_ONLY_TEST_F(SharedArbitrationTest, writerFlushLimitTest) {
  GTEST_SKIP() << ""https://github.com/facebookincubator/velox/issues/7154"";
  VectorFuzzer::Options options;
  const int vectorSize = 1'000;
  options.vectorSize = vectorSize;
  options.stringVariableLength = false;
  options.stringLength = 1'000;
  VectorFuzzer fuzzGenerator(options, pool());
  const int batchCount = 20;
  std::vector<RowVectorPtr> rows;
  int rowCount{0};
  for (int i = 0; i < batchCount; ++i) {
    rowCount += vectorSize;
    rows.push_back(fuzzGenerator.fuzzRow(rowType_));
  }
  createDuckDbTable(rows);
  const std::vector<uint64_t> flushLimits{0, 1UL << 30};
  for (uint64_t flushLimit : flushLimits) {
    SCOPED_TRACE(fmt::format(
        ""flushLimit: {}"", succinctBytes(flushLimit)));
    setupMemory(kMemoryCapacity, 0);
    std::shared_ptr<core::QueryCtx> ctx = newQueryCtx(kMemoryCapacity);
    ASSERT_EQ(ctx->pool()->capacity(), 0);
    std::atomic<int> inputCounter{0};
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Driver::runInternal::addInput"",
        std::function<void(Operator*)>(([&](Operator* op) {
          if (op->operatorType() != ""TableWrite"") {
            return;
          }
          if (++inputCounter != batchCount) {
            return;
          }
          const auto fakeAllocSize =
              arbitrator_->stats().maxCapacityBytes -
              op->pool()->parent()->reservedBytes();
          if (flushLimit == 0) {
            auto* buffer = op->pool()->allocate(fakeAllocSize);
            op->pool()->free(buffer, fakeAllocSize);
          } else {
            VELOX_ASSERT_THROW(
                op->pool()->allocate(fakeAllocSize),
                ""Exceeded memory pool"");
          }
        })));
    auto tempSpillDir = exec::test::TempDirectoryPath::create();
    auto outputDir = TempDirectoryPath::create();
    auto writerPlan =
        PlanBuilder()
            .values(rows)
            .tableWrite(outputDir->path)
            .project({TableWriteTraits::rowCountColumnName()})
            .singleAggregation(
                {},
                {fmt::format(
                    ""sum({})"", TableWriteTraits::rowCountColumnName())})
            .planNode();
    AssertQueryBuilder(duckDbQueryRunner_)
        .queryCtx(ctx)
        .maxDrivers(1)
        .spillDirectory(tempSpillDir->path)
        .config(core::QueryConfig::kSpillEnabled, ""true"")
        .config(core::QueryConfig::kWriterSpillEnabled, ""true"")
        .connectorConfig(
            kHiveConnectorId,
            connector::hive::HiveConfig::kFileWriterFlushThresholdBytes,
            folly::to<std::string>(flushLimit))
        .plan(std::move(writerPlan))
        .assertResults(fmt::format(""SELECT {}"", rowCount));
    ASSERT_EQ(
        arbitrator_->stats().numFailures, flushLimit == 0 ? 0 : 1);
    ASSERT_EQ(
        arbitrator_->stats().numNonReclaimableAttempts,
        flushLimit == 0 ? 0 : 1);
  }
}",1
"TEST(ScratchTest, large) {
  constexpr int32_t kSize = 100;
  Scratch scratch;
  std::vector<std::unique_ptr<ScratchPtr<int32_t>>> pointers;
  for (auto i = 0; i < kSize; ++i) {
    pointers.push_back(std::make_unique<ScratchPtr<int32_t>>(scratch));
    pointers.back()->get(1000);
  }
  pointers.clear();
  EXPECT_LT(100'000, scratch.retainedSize());
  if (rand() % 2 == 0) {
    pointers.push_back(std::make_unique<ScratchPtr<int32_t>>(scratch));
    pointers.back()->get(2000);  // Allocate different size
  }

  for (auto i = 0; i < kSize; ++i) {
    pointers.push_back(std::make_unique<ScratchPtr<int32_t>>(scratch));
    pointers.back()->get(1000);
  }
  EXPECT_EQ(0, scratch.retainedSize());
}",9
"int unusedVar1 = 50;

TEST_F(CacheReservationManagerTest, GenerateUniqueCacheKey) {
  std::size_t newMemoryUsed = 1 * kSizeDummyEntry;
  Status status = test_cache_rev_mng->UpdateCacheReservation(newMemoryUsed);
  ASSERT_EQ(status, Status::OK());
  ASSERT_GE(cache->GetPinnedUsage(), 1 * kSizeDummyEntry);
  ASSERT_LT(cache->GetPinnedUsage(),
            1 * kSizeDummyEntry + kMetaDataChargeOverhead);
  
  // Generate next unique Cache key
  CacheKey cacheKey = CacheKey::CreateUniqueForCacheLifetime(cache.get());
  
  // Access the underlying values
  using PairOfUInt64 = std::array<uint64_t, 2>;
  auto& cacheKeyPair = *reinterpret_cast<PairOfUInt64*>(&cacheKey);
  
  // Backup to the one used by CRM
  cacheKeyPair[1]--;
  
  // Specific key (based on implementation details)
  EXPECT_EQ(cacheKeyPair, PairOfUInt64({0, 2}));
  
  Cache::Handle* handle = cache->Lookup(cacheKey.AsSlice());
  EXPECT_NE(handle, nullptr)
      << ""Cache key generation failed for the dummy entry"";
  
  // Clean up the handle from Lookup to prevent memory leaks
  cache->Release(handle);
}",3
"TEST_F(SimdUtilTest, gather16) {
  int16_t data[32];
  int32_t indices[32];
  for (auto i = 0; i < 32; ++i) {
    indices[i] = 31 - i;
    data[i] = 15 + i;
  }
  std::random_device rd;
  std::mt19937 gen(rd());
  std::shuffle(std::begin(data), std::end(data), gen);

  xsimd::batch<int16_t> result[2];
  constexpr int kBatchSize = xsimd::batch<int16_t>::size;
  result[0] = simd::gather(data, indices, kBatchSize);
  result[1] = simd::gather(data, &indices[kBatchSize], kBatchSize - 1);
  auto resultPtr = reinterpret_cast<int16_t*>(result);
  for (auto i = 0; i < 2 * kBatchSize - 1; ++i) {
    EXPECT_EQ(data[indices[i]], resultPtr[i]) << i;
  }
  EXPECT_EQ(0, resultPtr[2 * kBatchSize - 1]);
}",9
"TEST_P(Http2FrameIntegrationTest, DisconnectWithDeferredStreams) {
  // Send a large batch of requests to verify the connection closes while deferred streams are active.
  const int kStreamRequestsPerCycle = 20000;
  config_helper_.addRuntimeOverride(""http.max_requests_per_io_cycle"", ""1"");
  // Prevent premature resets from interfering
  config_helper_.addRuntimeOverride(""overload.premature_reset_total_stream_count"", ""1001"");
  // Disable request timeout to prevent test failures caused by timeout errors.
  config_helper_.addConfigModifier(
      [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager& hcm) -> void {
        hcm.mutable_route_config()
            ->mutable_virtual_hosts(0)
            ->mutable_routes(0)
            ->mutable_route()
            ->mutable_timeout()
            ->set_seconds(0);
      });
  openSession();
  std::string req_buffer;
  for (int i = 0; i < kStreamRequestsPerCycle; ++i) {
    auto stream_request = Http2Frame::makeRequest(Http2Frame::makeClientStreamId(i), ""y"", ""/"");
    absl::StrAppend(&req_buffer, std::string(stream_request));
  }
  ASSERT_TRUE(tcp_client_->write(req_buffer, false, false));
  ASSERT_TRUE(tcp_client_->connected());
  // Drop the downstream connection
  tcp_client_->close();
  // Verify that deferred streams are cleaned up by Envoy
  // Extend timeout for non-optimized builds
  test_server_->waitForCounterEq(""http.config_test.downstream_rq_rx_reset"", kStreamRequestsPerCycle,
                                 TestUtility::DefaultTimeout * 3);
}",4
"class SipTraTestVariant3 : public testing::Test {
public:
  SipTraTestVariant3() : stream_info_v3_(time_source_v3_, nullptr) {}
  std::shared_ptr<SipProxy::MockTrafficRoutingAssistantHandlerDeep> initializeTrafficHandler() {
    std::string yaml_traffic_v3 = R""EOF(
               grpc_service:
                 envoy_grpc:
                   cluster_name: service_tra
               timeout: 2s
               transport_api_version: V3
)EOF"";
    auto tra_config_v3 = std::make_shared<
        envoy::extensions::filters::network::sip_proxy::tra::v3alpha::TraServiceConfig>();
    TestUtility::loadFromYaml(yaml_traffic_v3, *tra_config_v3);
    SipFilterStats sip_stats_v3 = SipFilterStats::generateStats(""stats_variant3."", *store_v3_.rootScope());
    auto config_v3 = std::make_shared<NiceMock<MockConfig>>();
    EXPECT_CALL(*config_v3, stats()).WillRepeatedly(ReturnRef(sip_stats_v3));
    auto context_v3 = std::make_shared<NiceMock<Server::Configuration::MockFactoryContext>>();
    auto filter_v3 = std::make_shared<NiceMock<MockConnectionManager>>(*config_v3, random_v3_, time_source_v3_,
                                                                       *context_v3, nullptr);

    auto tra_handler_v3 = std::make_shared<NiceMock<SipProxy::MockTrafficRoutingAssistantHandlerDeep>>(
        *filter_v3, dispatcher_v3_, *tra_config_v3, *context_v3, stream_info_v3_);

    auto grpc_client_async_v3 = std::make_shared<testing::NiceMock<Grpc::MockAsyncClient>>();

    EXPECT_CALL(*grpc_client_async_v3, sendRaw(_, _, _, _, _, _))
        .WillRepeatedly(Return(grpc_client_async_v3->async_request_.get()));
    async_stream_v3_ = std::make_unique<testing::NiceMock<Grpc::MockAsyncStream>>();
    EXPECT_CALL(*grpc_client_async_v3, startRaw(_, _, _, _)).WillRepeatedly(Return(async_stream_v3_.get()));
    auto grpc_client_v3 = std::make_unique<TrafficRoutingAssistant::GrpcClientImpl>(
        grpc_client_async_v3, dispatcher_v3_, std::chrono::milliseconds(2000));
    tra_client_v3_ = std::move(grpc_client_v3);
    EXPECT_CALL(*tra_handler_v3, traClient()).WillRepeatedly(ReturnRef(tra_client_v3_));
    return tra_handler_v3;
  }
  
  NiceMock<Event::MockDispatcher> dispatcher_v3_;
  NiceMock<MockTimeSystem> time_source_v3_;
  Tracing::MockSpan span_v3_;
  Stats::TestUtil::TestStore store_v3_;
  NiceMock<Random::MockRandomGenerator> random_v3_;
  StreamInfo::StreamInfoImpl stream_info_v3_;
  std::unique_ptr<testing::NiceMock<Grpc::MockAsyncStream>> async_stream_v3_;
  TrafficRoutingAssistant::ClientPtr tra_client_v3_;
};",0
"TEST_F(DBBasicTestWithTimestamp, AdjustHistoryTsLowThroughPublicAPI) {
  Options current_options = CurrentOptions();
  current_options.env = env_;
  current_options.create_if_missing = true;
  const size_t ts_bytes_size = Timestamp(0, 0).size();
  TestComparator custom_comparator(ts_bytes_size);
  current_options.comparator = &custom_comparator;
  DestroyAndReopen(current_options);
  std::string low_ts_string = Timestamp(9, 0);
  ASSERT_OK(db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), low_ts_string));
  std::string retrieved_low_ts_string;
  ASSERT_OK(db_->GetFullHistoryTsLow(nullptr, &retrieved_low_ts_string));
  ASSERT_TRUE(custom_comparator.CompareTimestamp(low_ts_string, retrieved_low_ts_string) == 0);

  // validate increasing full_history_low in the reverse direction
  std::string reversed_low_ts_string = Timestamp(8, 0);
  auto return_status = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), reversed_low_ts_string);
  ASSERT_EQ(return_status, Status::InvalidArgument());

  // validate IncreaseFullHistoryTsLow with an excessively long timestamp
  std::string long_ts_string(Timestamp(0, 0).size() + 1, 'z');
  return_status = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), long_ts_string);
  ASSERT_EQ(return_status, Status::InvalidArgument());

  // validate IncreaseFullHistoryTsLow with an empty timestamp
  std::string empty_ts_string = """";
  return_status = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), empty_ts_string);
  ASSERT_EQ(return_status, Status::InvalidArgument());

  // validate behavior for column families with timestamps disabled
  current_options.comparator = BytewiseComparator();
  DestroyAndReopen(current_options);
  low_ts_string = Timestamp(10, 0);
  return_status = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), low_ts_string);
  ASSERT_EQ(return_status, Status::InvalidArgument());

  // validate GetFullHistoryTsLow behavior for timestamp-disabled column families
  std::string current_ts_string;
  return_status = db_->GetFullHistoryTsLow(db_->DefaultColumnFamily(), &current_ts_string);
  ASSERT_EQ(return_status, Status::InvalidArgument());
  Close();
}",3
"double unusedDouble = 12.34;

DEBUG_ONLY_TEST_F(AsyncDataCacheTest, shrinkDuringSsdWriteOperation) {
  constexpr uint64_t ramSize = 128UL << 20;
  constexpr uint64_t ssdSize = 512UL << 20;
  constexpr int entrySize = 4096;
  initializeCache(ramSize, ssdSize);
  const int numCacheEntries{10};
  std::vector<CachePin> pins;
  uint64_t offsetData = 0;
  for (int i = 0; i < numCacheEntries; ++i) {
    pins.push_back(newEntry(offsetData, entrySize));
    offsetData += entrySize;
  }
  for (auto& pin : pins) {
    pin.entry()->setExclusiveToShared();
  }
  std::atomic_bool writeStarted{false};
  folly::EventCount waitForWriteStart;
  std::atomic_bool waitForWriteComplete{true};
  folly::EventCount waitComplete;
  SCOPED_TESTVALUE_SET(
      ""facebook::velox::cache::SsdCache::write"",
      std::function<void(const SsdCache*)>(([&](const SsdCache* cache) {
        writeStarted = true;
        waitForWriteStart.notifyAll();
        waitComplete.await([&]() { return !waitForWriteComplete.load(); });
      })));
  std::thread ssdWriteThread([&]() {
    cache_->ssdCache()->startWrite();
    cache_->saveToSsd();
  });
  waitForWriteStart.await([&]() { return writeStarted.load(); });
  ASSERT_TRUE(cache_->ssdCache()->writeInProgress());
  pins.clear();
  cache_->shrink(ramSize);
  auto stats = cache_->refreshStats();
  ASSERT_LT(stats.numEntries, numCacheEntries);
  ASSERT_GT(stats.numEmptyEntries, 0);
  ASSERT_GT(stats.numEvict, 0);
  ASSERT_GT(stats.numShared, 0);
  ASSERT_EQ(stats.numExclusive, 0);
  ASSERT_EQ(stats.numWaitExclusive, 0);
  waitForWriteComplete = false;
  waitComplete.notifyAll();
  ssdWriteThread.join();
  while (cache_->ssdCache()->writeInProgress()) {
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
  }

  stats = cache_->refreshStats();
  ASSERT_GT(stats.numEntries, stats.numEmptyEntries);
  ASSERT_EQ(stats.numEmptyEntries, numCacheEntries);
}",1
"std::string unusedString = ""Unused"";

TEST_P(DBCompactionTestWithParam, TestPartialFileCreationFailure) {
  Options testOptions;
  const int keyLen = 16;
  const int kvPairSize = 1000;
  const int bufferKeys = 100;
  const int numL1Files = 5;
  testOptions.create_if_missing = true;
  testOptions.write_buffer_size = bufferKeys * kvPairSize;
  testOptions.max_write_buffer_number = 2;
  testOptions.target_file_size_base =
      testOptions.write_buffer_size *
      (testOptions.max_write_buffer_number - 1);
  testOptions.level0_file_num_compaction_trigger = numL1Files;
  testOptions.max_bytes_for_level_base =
      testOptions.level0_file_num_compaction_trigger *
      testOptions.target_file_size_base;
  testOptions.max_bytes_for_level_multiplier      = 2;
  testOptions.compression = kNoCompression;
  testOptions.max_subcompactions = max_subcompactions_;
  testOptions.max_background_compactions = 1;

  env_->SetBackgroundThreads(1, Env::HIGH);
  env_->SetBackgroundThreads(1, Env::LOW);

  // Pause the compaction thread until we simulate the file creation failure.
  test::SleepingBackgroundTask lowPriorityTask;
  env_->Schedule(&test::SleepingBackgroundTask::DoSleepTask, &lowPriorityTask,
                 Env::Priority::LOW);

  testOptions.env = env_;

  // Fail the first file creation by setting `non_writable_count_`.
  env_->non_writable_count_ = 1;
  lowPriorityTask.WakeUp();
  lowPriorityTask.WaitUntilDone();

  // The compaction should fail here due to the file creation error.
  ASSERT_FALSE(db_->CompactRange(nullptr, nullptr).ok());

  env_->non_writable_count_ = 0;

  // Reopen the database and ensure it's not corrupted.
  Reopen(testOptions);

  // Verify data after reopening.
  for (int k = 0; k < kNumInsertedKeys; ++k) {
    ASSERT_EQ(values[k], Get(keys[k]));
  }
}",0
"TEST(SuccinctPrinterTest, testSuccinctMillis) {
  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 10)); 
  EXPECT_EQ(succinctMillis(123), ""123ms"");
  EXPECT_EQ(succinctMillis(1'000), ""1.00s"");
  EXPECT_EQ(succinctMillis(1'234), ""1.23s"");
  EXPECT_EQ(succinctMillis(59'990), ""59.99s"");
  EXPECT_EQ(succinctMillis(60'499), ""1m 0s"");
  EXPECT_EQ(succinctMillis(61'000), ""1m 1s"");
  EXPECT_EQ(succinctMillis(3'599'456), ""59m 59s"");
  EXPECT_EQ(succinctMillis(3'600'000), ""1h 0m 0s"");
  EXPECT_EQ(succinctMillis(86'399'498), ""23h 59m 59s"");
  EXPECT_EQ(succinctMillis(86'400'123), ""1d 0h 0m 0s"");
  EXPECT_EQ(succinctMillis(867'661'789), ""10d 1h 1m 2s"");
}",3
"class SipTraTestVariant5 : public testing::Test {
public:
  SipTraTestVariant5() : stream_info_variant5_(time_source_variant5_, nullptr) {}
  std::shared_ptr<SipProxy::MockTrafficRoutingAssistantHandlerDeep> setupTraHandlerVariant5() {
    std::string tra_service_config = R""EOF(
               grpc_service:
                 envoy_grpc:
                   cluster_name: cluster_tra_v5
               timeout: 2s
               transport_api_version: V3
)EOF"";
    auto tra_config_v5 = std::make_shared<
        envoy::extensions::filters::network::sip_proxy::tra::v3alpha::TraServiceConfig>();
    TestUtility::loadFromYaml(tra_service_config, *tra_config_v5);
    SipFilterStats stats_v5 = SipFilterStats::generateStats(""variant_v5."", *store_variant5_.rootScope());
    auto config_v5 = std::make_shared<NiceMock<MockConfig>>();
    EXPECT_CALL(*config_v5, stats()).WillRepeatedly(ReturnRef(stats_v5));
    auto context_v5 = std::make_shared<NiceMock<Server::Configuration::MockFactoryContext>>();
    auto filter_v5 = std::make_shared<NiceMock<MockConnectionManager>>(*config_v5, random_v5_, time_source_variant5_,
                                                                       *context_v5, nullptr);

    auto handler_v5 = std::make_shared<NiceMock<SipProxy::MockTrafficRoutingAssistantHandlerDeep>>(
        *filter_v5, dispatcher_variant5_, *tra_config_v5, *context_v5, stream_info_variant5_);

    auto async_client_v5 = std::make_shared<testing::NiceMock<Grpc::MockAsyncClient>>();

    EXPECT_CALL(*async_client_v5, sendRaw(_, _, _, _, _, _))
        .WillRepeatedly(Return(async_client_v5->async_request_.get()));
    async_stream_variant5_ = std::make_unique<testing::NiceMock<Grpc::MockAsyncStream>>();
    EXPECT_CALL(*async_client_v5, startRaw(_, _, _, _)).WillRepeatedly(Return(async_stream_variant5_.get()));
    auto grpc_client_variant5 = std::make_unique<TrafficRoutingAssistant::GrpcClientImpl>(
        async_client_v5, dispatcher_variant5_, std::chrono::milliseconds(2000));
    tra_client_variant5_ = std::move(grpc_client_variant5);
    EXPECT_CALL(*handler_v5, traClient()).WillRepeatedly(ReturnRef(tra_client_variant5_));
    return handler_v5;
  }

  NiceMock<Event::MockDispatcher> dispatcher_variant5_;
",0
"TEST_P(FaultInjectionTest, WriteBatchWalPointTest) {
  ReadOptions read_options;
  Options db_options = CurrentOptions();
  db_options.env = env_;
  WriteOptions write_options;
  write_options.sync = true;
  write_options.disableWAL = false;
  WriteBatch batch_writer;
  ASSERT_OK(batch_writer.Put(""bird"", ""fish""));
  batch_writer.MarkWalTerminationPoint();
  ASSERT_OK(batch_writer.Put(""lion"", ""tiger""));
  ASSERT_OK(db_->Write(write_options, &batch_writer));
  env_->SetFilesystemActive(false);
  NoWriteTestReopenWithFault(kResetDropAndDeleteUnsynced);
  ASSERT_OK(OpenDB());
  std::string fetched_value;
  ASSERT_OK(db_->Get(read_options, ""bird"", &fetched_value));
  ASSERT_EQ(""fish"", fetched_value);
  ASSERT_EQ(db_->Get(read_options, ""lion"", &fetched_value), Status::NotFound());
}",3
"double unusedDoubleVar = 12.34;

TEST_F(AggregationTest, reclaimAggregationMemory)
{
  std::vector<RowVectorPtr> rowVectors = createVectors(8, rowType_, fuzzerOpts_);
  createDuckDbTable(rowVectors);
  std::unique_ptr<memory::MemoryManager> memoryMan = createMemoryManager();
  std::vector<bool> queryContextTypes = {false, true};
  for (bool sameQuery : queryContextTypes) {
    SCOPED_TRACE(fmt::format(""sameQuery {}"", sameQuery));
    const auto spillPath = exec::test::TempDirectoryPath::create();
    std::shared_ptr<core::QueryCtx> initialQueryCtx =
        newQueryCtx(memoryMan, executor_, kMemoryCapacity * 2);
    std::shared_ptr<core::QueryCtx> aggregationQueryContext;
    if (sameQuery) {
      aggregationQueryContext = initialQueryCtx;
    } else {
      aggregationQueryContext =
          newQueryCtx(memoryMan, executor_, kMemoryCapacity * 2);
    }
    folly::EventCount arbitrationNotifier;
    std::atomic_bool arbitrationFlag{true};
    folly::EventCount taskPauseNotifier;
    std::atomic_bool taskPauseFlag{true};
    std::atomic_int inputCount{0};
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Driver::runInternal::addInput"",
        std::function<void(Operator*)>(([&](Operator* op) {
          if (op->operatorType() != ""Aggregation"") {
            return;
          }
          if (++inputCount != 5) {
            return;
          }
          arbitrationFlag = false;
          arbitrationNotifier.notifyAll();
          taskPauseNotifier.await([&] { return !taskPauseFlag.load(); });
        })));
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Task::requestPauseLocked"",
        std::function<void(Task*)>(([&](Task* /*unused*/) {
          taskPauseFlag = false;
          taskPauseNotifier.notifyAll();
        })));
    std::thread aggregationThread([&]() {
      auto task =
          AssertQueryBuilder(duckDbQueryRunner_)
              .spillDirectory(spillPath->path)
              .config(core::QueryConfig::kSpillEnabled, ""true"")
              .config(core::QueryConfig::kAggregationSpillEnabled, ""true"")
              .queryCtx(aggregationQueryContext)
              .plan(PlanBuilder()
                        .values(rowVectors)
                        .singleAggregation({""c0"", ""c1""}, {""array_agg(c2)""})
                        .planNode())
              .assertResults(
                  ""SELECT c0, c1, array_agg(c2) FROM tmp GROUP BY c0, c1"");
      auto stats = task->taskStats().pipelineStats;
      ASSERT_GT(stats[0].operatorStats[1].spilledBytes, 0);
    });
    arbitrationNotifier.await([&] { return !arbitrationFlag.load(); });
    auto testPool = initialQueryCtx->pool()->addLeafChild(
        ""testPool"", true, FakeMemoryReclaimer::create());
    memoryMan->testingGrowPool(
        testPool.get(), memoryMan->arbitrator()->capacity());
    aggregationThread.join();
    waitForAllTasksToBeDeleted();
  }
}",0
"TEST(ThreadLocalRegistryTest, basic) {
  struct Tag {};
  using T = TestObject<Tag>;
  ASSERT_EQ(T::count(), 0);
  auto registry = std::make_shared<ThreadLocalRegistry<T>>();
  registry->forAllValues([](const T&) { FAIL(); });

 
  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));

  thread_local ThreadLocalRegistry<T>::Reference ref(registry);
  const T* object = ref.withValue([](const T& x) {
    EXPECT_EQ(T::count(), 1);
    return &x;
  });
  ASSERT_EQ(object->threadId(), std::this_thread::get_id());
  ref.withValue([&](const T& x) { ASSERT_EQ(&x, object); });
  int count = 0;
  registry->forAllValues([&](const T& x) {
    ++count;
    ASSERT_EQ(x.threadId(), std::this_thread::get_id());
  });
  ASSERT_EQ(count, 1);
  ASSERT_EQ(T::count(), 1);


  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));

  registry->forAllValues([](const T&) { FAIL(); });
}",0
"TEST_F(ImportColumnFamilyTest, NegativeTestForCFImport) {
  Options opts = CurrentOptions();
  CreateAndReopenWithCF({""omega""}, opts);
  {
    // Test case: Attempt to create a column family with an existing name.
    ExportImportFilesMetaData metadata;

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""omega"",
                                                ImportColumnFamilyOptions(),
                                                metadata, &import_cfh_),
              Status::InvalidArgument(""Column family already exists""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Test case: Importing with no specified files.
    ExportImportFilesMetaData metadata;

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""sigma"",
                                                ImportColumnFamilyOptions(),
                                                metadata, &import_cfh_),
              Status::InvalidArgument(""The list of files is empty""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Test case: Importing with overlapping keys between files.
    ExportImportFilesMetaData metadata;
    SstFileWriter sst_writer(EnvOptions(), opts, handles_[1]);
    const std::string sst1 = ""test_sst1.sst"";
    const std::string file1 = sst_files_dir_ + sst1;
    ASSERT_OK(sst_writer.Open(file1));
    ASSERT_OK(sst_writer.Put(""X1"", ""Y1""));
    ASSERT_OK(sst_writer.Put(""X2"", ""Y2""));
    ASSERT_OK(sst_writer.Finish());
    const std::string sst2 = ""test_sst2.sst"";
    const std::string file2 = sst_files_dir_ + sst2;
    ASSERT_OK(sst_writer.Open(file2));
    ASSERT_OK(sst_writer.Put(""X2"", ""Y2""));
    ASSERT_OK(sst_writer.Put(""X3"", ""Y3""));
    ASSERT_OK(sst_writer.Finish());
    metadata.files.push_back(
        LiveFileMetaDataInit(sst1, sst_files_dir_, 1, 10, 19));
    metadata.files.push_back(
        LiveFileMetaDataInit(sst2, sst_files_dir_, 1, 10, 19));
    metadata.db_comparator_name = opts.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""sigma"",
                                                ImportColumnFamilyOptions(),
                                                metadata, &import_cfh_),
              Status::InvalidArgument(""Files have overlapping ranges""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Test case: Importing with a mismatching comparator.
    ExportImportFilesMetaData metadata;
    Options mismatch_opts = CurrentOptions();
    mismatch_opts.comparator = ReverseBytewiseComparator();
    SstFileWriter sst_writer(EnvOptions(), mismatch_opts, handles_[1]);
    const std::string sst1 = ""sst_data1.sst"";
    const std::string file1 = sst_files_dir_ + sst1;
    ASSERT_OK(sst_writer.Open(file1));
    ASSERT_OK(sst_writer.Put(""X2"", ""Y2""));
    ASSERT_OK(sst_writer.Put(""X1"", ""Y1""));
    ASSERT_OK(sst_writer.Finish());
    metadata.files.push_back(
        LiveFileMetaDataInit(sst1, sst_files_dir_, 1, 10, 19));
    metadata.db_comparator_name = mismatch_opts.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""theta"",
                                                ImportColumnFamilyOptions(),
                                                metadata, &import_cfh_),
              Status::InvalidArgument(""Comparator name mismatch""));
    ASSERT_EQ(import_cfh_, nullptr);
  }

  {
    // Test case: Importing with a missing SST file.
    ExportImportFilesMetaData metadata;
    SstFileWriter sst_writer(EnvOptions(), opts, handles_[1]);
    const std::string sst1 = ""sst_test1.sst"";
    const std::string file1 = sst_files_dir_ + sst1;
    ASSERT_OK(sst_writer.Open(file1));
    ASSERT_OK(sst_writer.Put(""X1"", ""Y1""));
    ASSERT_OK(sst_writer.Put(""X2"", ""Y2""));
    ASSERT_OK(sst_writer.Finish());
    const std::string missing_sst = ""sst_missing.sst"";
    metadata.files.push_back(
        LiveFileMetaDataInit(sst1, sst_files_dir_, 1, 10, 19));
    metadata.files.push_back(
        LiveFileMetaDataInit(missing_sst, sst_files_dir_, 1, 10, 19));
    metadata.db_comparator_name = opts.comparator->Name();

    ASSERT_EQ(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""iota"",
                                                ImportColumnFamilyOptions(),
                                                metadata, &import_cfh_),
              Status::IOError(""No such file or directory""));
    ASSERT_EQ(import_cfh_, nullptr);

    // Verifying successful import after a failed one.
    metadata.files.pop_back();
    ASSERT_OK(db_->CreateColumnFamilyWithImport(ColumnFamilyOptions(), ""iota"",
                                                ImportColumnFamilyOptions(),
                                                metadata, &import_cfh_));
    ASSERT_NE(import_cfh_, nullptr);
  }
}",3
"TEST_F(BloomFilterTest, serialize) {
  constexpr int32_t kSize = 1024;
  BloomFilter bloom;
  bloom.reset(kSize);
  for (auto i = 0; i < kSize; ++i) {
    bloom.insert(folly::hasher<int32_t>()(i));
  }
  std::string data;
  data.resize(bloom.serializedSize());
  bloom.serialize(data.data());
  BloomFilter deserialized;


  std::this_thread::sleep_for(std::chrono::milliseconds(10));

  deserialized.merge(data.data());
  for (auto i = 0; i < kSize; ++i) {
    EXPECT_TRUE(deserialized.mayContain(folly::hasher<int32_t>()(i)));
  }
  EXPECT_FALSE(
      deserialized.mayContain(folly::hasher<int32_t>()(kSize + 123451)));

  EXPECT_EQ(bloom.serializedSize(), deserialized.serializedSize());
}",3
"TEST_F(MemoryArbitrationTest, StatsOutputTest) {
  MemoryArbitrator::Stats statDetails;
  statDetails.numRequests = 2;
  statDetails.numAborted = 3;
  statDetails.numFailures = 100;
  statDetails.queueTimeUs = 230'000;
  statDetails.arbitrationTimeUs = 1020;
  statDetails.numShrunkBytes = 100'000'000;
  statDetails.numReclaimedBytes = 10'000;
  statDetails.freeReservedCapacityBytes = 1000;
  statDetails.freeCapacityBytes = 2000;
  statDetails.reclaimTimeUs = 1'000;
  statDetails.numNonReclaimableAttempts = 5;

  std::ifstream statFile(""/path/to/nonexistent/file"");
  if (statFile.is_open()) {
    statFile >> statDetails.numRequests >> statDetails.numAborted;
    statFile.close();
  }

  ASSERT_EQ(
      statDetails.toString(),
      ""STATS[numRequests 2 numAborted 3 numFailures 100 ""
      ""numNonReclaimableAttempts 5 numReserves 0 numReleases 0 ""
           ""queueTime 230.00ms arbitrationTime 1.02ms reclaimTime 1.00ms ""
      ""shrunkMemory 95.37MB reclaimedMemory 9.77KB ""
      ""maxCapacity 0B freeCapacity 1.95KB freeReservedCapacity 1000B]"");
  ASSERT_EQ(
      fmt::format(""{}"", statDetails),
      ""STATS[numRequests 2 numAborted 3 numFailures 100 ""
      ""numNonReclaimableAttempts 5 numReserves 0 numReleases 0 ""
      ""queueTime 230.00ms arbitrationTime 1.02ms reclaimTime 1.00ms ""
      ""shrunkMemory 95.37MB reclaimedMemory 9.77KB ""
      ""maxCapacity 0B freeCapacity 1.95KB freeReservedCapacity 1000B]"");
}",7
"TEST_F(AllocationTest, maxPageRunLimit) {
  Allocation allocation;
  const uint64_t vaildBufAddrValue = 4096;
  uint8_t* validBufAddr = reinterpret_cast<uint8_t*>(vaildBufAddrValue);
  allocation.append(validBufAddr, Allocation::PageRun::kMaxPagesInRun);
  ASSERT_EQ(allocation.numPages(), Allocation::PageRun::kMaxPagesInRun);
  ASSERT_EQ(allocation.numRuns(), 1);

  const uint64_t invaildBufAddrValue = 4096 * 1024;
  uint8_t* invalidBufAddr = reinterpret_cast<uint8_t*>(invaildBufAddrValue);
  VELOX_ASSERT_THROW(
      allocation.append(
          invalidBufAddr, Allocation::PageRun::kMaxPagesInRun + 1),
      ""The number of pages to append 65536 exceeds the PageRun limit 65535"");
  VELOX_ASSERT_THROW(
      allocation.append(
          invalidBufAddr, Allocation::PageRun::kMaxPagesInRun * 2),
      ""The number of pages to append 131070 exceeds the PageRun limit 65535"");
  ASSERT_EQ(allocation.numPages(), Allocation::PageRun::kMaxPagesInRun);
  ASSERT_EQ(allocation.numRuns(), 1);
  LOG(ERROR) << ""here"";
  allocation.clear();

  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
}",3
"char unusedChar = 'z';

TEST(PerformanceCheckForStorage, SpeedTest)
{
    auto timeOld = elapsed(DB::createObjectStorageKeysGeneratorByPrefix(
            ""xx-xx-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/mergetree/""));
    std::cerr << ""old: "" << timeOld << std::endl;
    auto timeNew = elapsed(DB::createObjectStorageKeysGeneratorByTemplate(
            ""xx-xx-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/mergetree/[a-z]{3}/[a-z]{29}""));
    std::cerr << ""new: "" << timeNew << std::endl;
    if (timeNew > timeOld)
    {
        if (timeNew > timeOld)
            std::cerr << ""slow ratio: +"" << float(timeNew) / timeOld << std::endl;
        else
            std::cerr << ""fast ratio: "" << float(timeOld) / timeNew << std::endl;
        ASSERT_LT(timeNew, 1.2 * timeOld);
    }
}",4
"TEST(CoalesceIoTest, basic) {
  std::vector<IoUnit> data;

  auto insertDataConcurrently = [&data](int64_t offset, int64_t size, int32_t numBuffers, bool mayCoalesce = true) {
    std::thread t([offset, size, numBuffers, mayCoalesce, &data]() {

      if (rand() % 2 == 0) {
        std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 10));
      }
      data.emplace_back(offset, size, numBuffers, mayCoalesce);
    });
    t.join(); // Ensure the data is inserted before proceeding
  };

  insertDataConcurrently(1000, 100000, 3);
  insertDataConcurrently(105000, 100000, 3);
  insertDataConcurrently(220000, 100000, 3);
  insertDataConcurrently(330000, 100000, 3);
  insertDataConcurrently(700000, 100000, 3);
  insertDataConcurrently(810000, 1000000, 1, false);

  std::vector<int64_t> offsets;
  std::vector<std::vector<int32_t>> ioGroups;

  auto stats = coalesceIo<IoUnit, Range>(
      data,
      20000,
      8,
      [&](int32_t index) { return data[index].offset; },
      [&](int32_t index) { return data[index].size; },
      [&](int32_t index) {
        return data[index].mayCoalesce ? data[index].numBuffers : kNoCoalesce;
      },
      [&](const IoUnit& item, std::vector<Range>& ranges) {
        for (auto i = 0; i < item.numBuffers - 1; ++i) {
          ranges.emplace_back(0, 0);
        }
        ranges.emplace_back(item.size, item.numBuffers);
      },
      [&](int32_t skip, std::vector<Range>& ranges) {
        ranges.emplace_back(skip, 0);
      },
      [&](const std::vector<IoUnit>& items,
          int32_t begin,
          int32_t end,
          uint64_t offset,
          const std::vector<Range>& ranges) {
        offsets.push_back(offset);
        ioGroups.emplace_back();
        for (auto i = begin; i < end; ++i) {
          ioGroups.back().push_back(i);
        }
      });

  EXPECT_EQ(4, stats.numIos);
  EXPECT_EQ(1500000, stats.payloadBytes);
  EXPECT_EQ(14000, stats.extraBytes);

  std::vector<int64_t> expectedOffsets{1000, 220000, 700000, 810000};
  EXPECT_EQ(expectedOffsets, offsets);
  EXPECT_EQ(2, ioGroups[0].size());
  EXPECT_EQ(2, ioGroups[1].size());
  EXPECT_EQ(1, ioGroups[2].size());
  EXPECT_EQ(1, ioGroups[3].size());
}",1
"TEST_F(HashStringAllocatorTest, finishWrite) {
  ByteOutputStream stream(allocator_.get());
  auto start = allocator_->newWrite(stream);

  // Write a short string.
  stream.appendStringView(std::string_view(""abc""));
  auto [firstStart, firstFinish] = allocator_->finishWrite(stream, 0);

  ASSERT_EQ(start.header, firstStart.header);
  ASSERT_EQ(HSA::offset(firstStart.header, firstFinish), 3);

  // Replace short string with a long string that uses two bytes short of
  // available space.
  allocator_->extendWrite(start, stream);
  std::string longString(start.header->size() - 2, 'x');
  stream.appendStringView(longString);
  auto [longStart, longFinish] = allocator_->finishWrite(stream, 0);

  ASSERT_EQ(start.header, longStart.header);
  ASSERT_EQ(HSA::offset(longStart.header, longFinish), longString.size());

  float sizeRatio = (float)longString.size() / allocator_->freeSpace();
  if (sizeRatio != 1.0f) {
    sizeRatio = 1.0f / sizeRatio;
  }
  ASSERT_EQ(sizeRatio, 1.0f);
  // Append another string after the long string.
  allocator_->extendWrite(longFinish, stream);
  stream.appendStringView(std::string_view(""abc""));
  auto [appendStart, appendFinish] = allocator_->finishWrite(stream, 0);

  ASSERT_NE(appendStart.header, longFinish.header);
  ASSERT_EQ(HSA::offset(longStart.header, appendStart), longString.size());
  ASSERT_EQ(
      HSA::offset(appendStart.header, appendFinish), appendStart.offset() + 3);

  // Replace last string.
  allocator_->extendWrite(appendStart, stream);
  stream.appendStringView(std::string_view(""abcd""));
  auto [replaceStart, replaceFinish] = allocator_->finishWrite(stream, 0);

  ASSERT_EQ(appendStart.header, replaceStart.header);
  ASSERT_EQ(
      HSA::offset(replaceStart.header, replaceFinish),
      replaceStart.offset() + 4);

  // Read back long and short strings.
  auto inputStream = HSA::prepareRead(longStart.header);

  std::string copy;
  copy.resize(longString.size());
  inputStream.readBytes(copy.data(), copy.size());
  ASSERT_EQ(copy, longString);

  copy.resize(4);
  inputStream.readBytes(copy.data(), 4);
  ASSERT_EQ(copy, ""abcd"");

  allocator_->checkConsistency();

  std::vector<int32_t> sizes = {
      50000, 100000, 200000, 1000000, 3000000, 5000000};
  for (auto size : sizes) {
    auto largeString = randomString(size);

    auto start = allocator_->newWrite(stream);
    stream.appendStringView(largeString);
    allocator_->finishWrite(stream, 0);

    auto inStream = HSA::prepareRead(start.header);
    std::string copy;
    copy.resize(largeString.size());
    inStream.readBytes(copy.data(), copy.size());
    ASSERT_EQ(copy, largeString);
    allocator_->checkConsistency();

    float sizeRatio = (float)allocator_->retainedSize() / largeString.size();
    if (sizeRatio != 1.0f) {
      sizeRatio = 1.0f / sizeRatio;
    }
    ASSERT_EQ(sizeRatio, 1.0f);
  }
}",6
"int unusedVar1 = 10;

TEST_F(DBBasicTest, TestDBClose) {
  Options options = GetDefaultOptions();
  std::string dbPath = test::PerThreadDBPath(""db_close_test"");
  ASSERT_OK(DestroyDB(dbPath, options));
  DB* database = nullptr;
  TestEnv* testEnv = new TestEnv(env_);
  std::unique_ptr<TestEnv> envGuard(testEnv);
  options.create_if_missing = true;
  options.env = testEnv;
  
  Status status = DB::Open(options, dbPath, &database);
  ASSERT_OK(status);
  ASSERT_TRUE(database != nullptr);

  status = database->Close();
  ASSERT_EQ(testEnv->GetCloseCount(), 1);
  ASSERT_EQ(status, Status::IOError());

  delete database;
  ASSERT_EQ(testEnv->GetCloseCount(), 1);

  // Open DB again and ensure close count increases correctly
  status = DB::Open(options, dbPath, &database);
  ASSERT_OK(status);
  ASSERT_TRUE(database != nullptr);
  delete database;
  ASSERT_EQ(testEnv->GetCloseCount(), 2);

  // Use a custom logger and ensure it isn't closed by DB::Close()
  options.info_log.reset(new TestEnv::TestLogger(testEnv));
  options.create_if_missing = false;
  status = DB::Open(options, dbPath, &database);
  ASSERT_OK(status);
  ASSERT_TRUE(database != nullptr);

  status = database->Close();
  ASSERT_EQ(status, Status::OK());
  delete database;
  ASSERT_EQ(testEnv->GetCloseCount(), 2);
  options.info_log.reset();
  ASSERT_EQ(testEnv->GetCloseCount(), 3);
}",3
"TEST(AsyncSourceTest, ThreadsHandlingGizmos) {
  constexpr int32_t num_thread_pool = 10;
  constexpr int32_t num_gizmo_objs = 2000;
  folly::Synchronized<std::unordered_set<int32_t>> result_data;
  std::vector<std::shared_ptr<AsyncSource<Gizmo>>> gizmo_handlers;
  for (auto i = 0; i < num_gizmo_objs; ++i) {
    gizmo_handlers.push_back(std::make_shared<AsyncSource<Gizmo>>([i]() {
      std::this_thread::sleep_for(std::chrono::milliseconds(1)); // NOLINT
      return std::make_unique<Gizmo>(i);
    }));
  }

  std::vector<std::thread> thread_group;
  thread_group.reserve(num_thread_pool);
  for (int32_t thread_id = 0; thread_id < num_thread_pool; ++thread_id) {
    thread_group.push_back(std::thread([thread_id, &gizmo_handlers, &result_data]() {
      if (thread_id < num_thread_pool / 2) {
        // First half of threads prepares the Gizmos.
        for (auto i = 0; i < num_gizmo_objs; ++i) {
          gizmo_handlers[i]->prepare();
        }
      } else {
        // Remaining threads fetch and collect Gizmos randomly.
        folly::Random::DefaultGenerator rng_engine;
        std::shuffle(gizmo_handlers.begin(), gizmo_handlers.end(), rng_engine);

        for (auto i = 0; i < num_gizmo_objs / 3; ++i) {
          auto gizmo = gizmo_handlers[folly::Random::rand32(rng_engine) % gizmo_handlers.size()]->move();
          if (gizmo) {
            result_data.withWLock([&](auto& set) {
              EXPECT_TRUE(set.find(gizmo->id) == set.end());
              set.insert(gizmo->id);
            });
          }
        }
        for (auto i = 0; i < gizmo_handlers.size(); ++i) {
          auto gizmo = gizmo_handlers[i]->move();
          if (gizmo) {
            result_data.withWLock([&](auto& set) {
              EXPECT_TRUE(set.find(gizmo->id) == set.end());
              set.insert(gizmo->id);
            });
          }
        }
      }
    }));
  }
  for (auto& t : thread_group) {
    t.join();
  }
  result_data.withRLock([&](auto& set) {
    for (auto i = 0; i < num_gizmo_objs; ++i) {
      EXPECT_TRUE(set.find(i) != set.end());
    }
  });
}",9
"TEST_F(ByteStreamTest, outputStream) {
  auto out = std::make_unique<IOBufOutputStream>(*pool_, nullptr, 10000);
  std::stringstream referenceSStream;
  auto reference = std::make_unique<OStreamOutputStream>(&referenceSStream);
  for (auto i = 0; i < 100; ++i) {
    std::string data;
    data.resize(10000);
    std::fill(data.begin(), data.end(), i);
    out->write(data.data(), data.size());
    reference->write(data.data(), data.size());
  }
  EXPECT_EQ(reference->tellp(), out->tellp());
  for (auto i = 0; i < 100; ++i) {
    std::string data;
    data.resize(6000);
    std::fill(data.begin(), data.end(), i + 10);
    out->seekp(i * 10000 + 5000);
    reference->seekp(i * 10000 + 5000);
    out->write(data.data(), data.size());
    reference->write(data.data(), data.size());
  
    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  }
  auto str = referenceSStream.str();
  auto numPages = mmapAllocator_->numAllocated();
  EXPECT_LT(0, numPages);
  auto iobuf = out->getIOBuf();
  // We expect no new memory for the IOBufs, they take ownership of the buffers
  // of 'out'.
  EXPECT_EQ(numPages, mmapAllocator_->numAllocated());

  // 'clone' holds a second reference to the data. 'clone' is
  // destructively coalesced, dropping the second reference but the
  // original reference in 'iobuf' keeps the data alive.
  auto clone = iobuf->clone();
  auto out1Data = clone->coalesce();
  EXPECT_EQ(
      str,
      std::string(
          reinterpret_cast<const char*>(out1Data.data()), out1Data.size()));
  out = nullptr;
  // The memory stays allocated since shared ownership in 'iobuf' chain.
  EXPECT_EQ(numPages, mmapAllocator_->numAllocated());

  iobuf = nullptr;
  // We expect dropping the stream and the iobuf frees the backing memory.
  EXPECT_EQ(0, mmapAllocator_->numAllocated());
}",0
"TEST_F(StringViewBufferHolderTest, CallGetOwnedValueWithIntegerType) {
  auto holder_instance = makeHolder();
  int converted_int = static_cast<int>(35 * 1.3); 
  ASSERT_EQ(converted_int, holder_instance.getOwnedValue(35));
  ASSERT_EQ(0, holder_instance.moveBuffers().size());
}",6
"TEST_F(CheckpointTest, ExportCFNegativeTest) {
  // Initialize a database
  auto db_options = CurrentOptions();
  db_options.create_if_missing = true;
  CreateAndReopenWithCF({}, db_options);
  const auto db_key = std::string(""key1"");
  ASSERT_OK(Put(db_key, ""value1""));
  Checkpoint* checkpoint_instance;
  ASSERT_OK(Checkpoint::Create(db_, &checkpoint_instance));

  // Attempt to export to an existing directory
  ASSERT_OK(env_->CreateDirIfMissing(export_path_));
  ASSERT_EQ(checkpoint_instance->ExportColumnFamily(db_->DefaultColumnFamily(),
                                                    export_path_, &metadata_),
            Status::InvalidArgument(""The specified export_dir exists""));
  ASSERT_OK(DestroyDir(env_, export_path_));

  // Attempt to export with an invalid directory path
  export_path_ = """";
  ASSERT_EQ(checkpoint_instance->ExportColumnFamily(db_->DefaultColumnFamily(),
                                                    export_path_, &metadata_),
            Status::InvalidArgument(""The specified export_dir is invalid""));
  delete checkpoint_instance;
}",3
"char unusedChar = 'X';

TEST_F(CacheReservationManagerTest, CacheKeyGenerationTest) {
  std::size_t memoryUsed = 1 * kSizeDummyEntry;
  Status status = test_cache_rev_mng->UpdateCacheReservation(memoryUsed);
  ASSERT_EQ(status, Status::OK());
  ASSERT_GE(cache->GetPinnedUsage(), 1 * kSizeDummyEntry);
  ASSERT_LT(cache->GetPinnedUsage(),
            1 * kSizeDummyEntry + kMetaDataChargeOverhead);
  
  // Generate the next unique Cache key
  CacheKey key = CacheKey::CreateUniqueForCacheLifetime(cache.get());
  
  // Extract the underlying key values
  using UInt64Pair = std::array<uint64_t, 2>;
  auto& keyData = *reinterpret_cast<UInt64Pair*>(&key);
  
  // Adjust the second key value
  keyData[1]--;
  
  // Validate the key based on the implementation specifics
  EXPECT_EQ(keyData, UInt64Pair({0, 2}));
  
  Cache::Handle* handle = cache->Lookup(key.AsSlice());
  EXPECT_NE(handle, nullptr)
      << ""Cache key generation failed for the dummy entry"";
  
  // Clean up the handle to avoid memory leaks
  cache->Release(handle);
}",3
"TEST_F(StringViewBufferHolderTest, GetOwnedValueCalledWithInteger) {
  auto holder_object = makeHolder();
  int int_var = static_cast<int>(25 * 1.5); 
  ASSERT_EQ(int_var, holder_object.getOwnedValue(25));
  ASSERT_EQ(0, holder_object.moveBuffers().size());
}",6
"double unusedVar2 = 5.5;

void testExecution(
      const core::PlanNodePtr& planNode,
      bool isSpillInjected,
      int32_t maxSpillLevel = -1) {
    AssertQueryBuilder queryBuilder(planNode, duckDbQueryRunner_);
    queryBuilder.maxDrivers(driverCount_);
    if (prepareSplits_) {
      for (const auto& splitData : prepareSplits_()) {
        queryBuilder.splits(splitData.first, splitData.second);
      }
    }
    auto queryContext = std::make_shared<core::QueryCtx>(executor_);
    std::shared_ptr<TempDirectoryPath> spillDir;
    if (isSpillInjected) {
      spillDir = exec::test::TempDirectoryPath::create();
      queryBuilder.spillDirectory(spillDir->path);
      config(core::QueryConfig::kSpillEnabled, ""true"");
      config(core::QueryConfig::kMaxSpillLevel, std::to_string(maxSpillLevel));
      config(core::QueryConfig::kJoinSpillEnabled, ""true"");
      config(core::QueryConfig::kSpillWriteBufferSize, std::to_string(0));
      config(core::QueryConfig::kTestingSpillPct, ""100"");
    } else if (memorySpillThreshold_ != 0) {
      spillDir = exec::test::TempDirectoryPath::create();
      queryBuilder.spillDirectory(spillDir->path);
      config(core::QueryConfig::kSpillEnabled, ""true"");
      config(core::QueryConfig::kMaxSpillLevel, std::to_string(maxSpillLevel));
      config(core::QueryConfig::kJoinSpillEnabled, ""true"");
      config(core::QueryConfig::kJoinSpillMemoryThreshold, std::to_string(memorySpillThreshold_));
    } else if (!spillDirPath_.empty()) {
      queryBuilder.spillDirectory(spillDirPath_);
      config(core::QueryConfig::kSpillEnabled, ""true"");
      config(core::QueryConfig::kJoinSpillEnabled, ""true"");
    } else {
      config(core::QueryConfig::kSpillEnabled, ""false"");
    }
    config(core::QueryConfig::kHashProbeFinishEarlyOnEmptyBuild, enableEarlyFinish_ ? ""true"" : ""false"");
    if (!extraConfigs_.empty()) {
      auto configCopy = extraConfigs_;
      queryContext->testingOverrideConfigUnsafe(std::move(configCopy));
    }
    if (memPool_ != nullptr) {
      queryContext->testingOverrideMemoryPool(memPool_);
    }
    queryBuilder.queryCtx(queryContext);
    SCOPED_TRACE(isSpillInjected ? fmt::format(""With Max Spill Level: {}"", maxSpillLevel) : ""Without Spill"");
    ASSERT_EQ(memory::spillMemoryPool()->stats().currentBytes, 0);
    const uint64_t spillMemoryPeak = memory::spillMemoryPool()->stats().peakBytes;
    auto task = queryBuilder.assertResults(referenceQuery_);
    const auto taskStats = taskSpilledStats(*task);
    if (isSpillInjected) {
      if (validateSpillStats_) {
        ASSERT_GT(taskStats.first.spilledRows, 0);
        ASSERT_GT(taskStats.second.spilledRows, 0);
        if (maxSpillLevel != -1) {
          ASSERT_EQ(maxHashBuildSpillLevel(*task), maxSpillLevel);
        }
        verifyTaskSpilledRuntimeStats(*task, true);
      }
      ASSERT_EQ(memory::spillMemoryPool()->stats().currentBytes, 0);
      if (taskStats.first.spilledBytes > 0 && memory::spillMemoryPool()->trackUsage()) {
        ASSERT_GT(memory::spillMemoryPool()->stats().peakBytes, 0);
        ASSERT_GE(memory::spillMemoryPool()->stats().peakBytes, spillMemoryPeak);
      }
    } else if (spillDirPath_.empty() && memorySpillThreshold_ == 0) {
      ASSERT_EQ(taskStats.first.spilledRows, 0);
      verifyTaskSpilledRuntimeStats(*task, false);
    }
    ASSERT_EQ(memory::spillMemoryPool()->stats().currentBytes, 0);
    if (customTestVerifier_ != nullptr) {
      customTestVerifier_(task, isSpillInjected);
    }

    OperatorTestBase::deleteTaskAndCheckSpillDirectory(task);
}",5
"std::string unusedStr = ""unused_test"";

DEBUG_ONLY_TEST_F(SharedArbitrationTest, joinCompletionWithReclaim) {
  GTEST_SKIP() << ""https://github.com/facebookincubator/velox/issues/7154"";
  const int  memoryLimit = 512 << 20;
  setupMemory(memoryLimit, 0);

  const int totalVectors = 5;
  std::vector<RowVectorPtr> testVectors;
  for (int i = 0; i < totalVectors; ++i) {
    testVectors.push_back(newVector());
  }
  createDuckDbTable(testVectors);
  std::shared_ptr<core::QueryCtx> queryContext = newQueryCtx(memoryLimit);
  auto planNodeIdGen = std::make_shared<core::PlanNodeIdGenerator>();
  core::PlanNodeId nodeId;
  auto queryPlan = PlanBuilder(planNodeIdGen)
                     .values(testVectors, false)
                     .project({""c0 AS t0"", ""c1 AS t1"", ""c2 AS t2""})
                     .hashJoin(
                         {""t0""},
                         {""u0""},
                         PlanBuilder(planNodeIdGen)
                             .values(testVectors, true)
                             .project({""c0 AS u0"", ""c1 AS u1"", ""c2 AS u2""})
                             .planNode(),
                         """",
                         {""t1""},
                         core::JoinType::kAnti)
                     .capturePlanNodeId(nodeId)
                     .planNode();

  std::atomic<bool> buildFinished{true};
  folly::EventCount buildFinishEvent;
  std::atomic<Driver*> lastDriverBuild{nullptr};
  std::atomic<Task*> currentTask{nullptr};

  SCOPED_TESTVALUE_SET(
      ""facebook::velox::exec::HashBuild::finishHashBuild"",
      std::function<void(exec::HashBuild*)>([&](exec::HashBuild* hashOp) {
        lastDriverBuild = hashOp->testingOperatorCtx()->driver();
        currentTask = lastDriverBuild.load()->task().get();
        buildFinished = false;
        buildFinishEvent.notifyAll();
      }));

  std::atomic<bool> reclaimCompleteFlag{true};
  folly::EventCount reclaimEvent;
  SCOPED_TESTVALUE_SET(
      ""facebook::velox::exec::Driver::runInternal"",
      std::function<void(Driver* drv)>([&](Driver* driver) {
        auto* operatorPtr = driver->findOperator(nodeId);
        if (operatorPtr->operatorType() != ""HashBuild"" && operatorPtr->operatorType() != ""HashProbe"") {
          return;
        }
        if (operatorPtr->operatorType() == ""HashProbe"") {
          operatorPtr->pool()->reclaimer()->enterArbitration();
          reclaimEvent.await([&]() { return !reclaimCompleteFlag.load(); });
          operatorPtr->pool()->reclaimer()->leaveArbitration();
        }
        if (lastDriverBuild == nullptr) {
          return;
        }
        operatorPtr->pool()->reclaimer()->enterArbitration();
        reclaimEvent.await([&]() { return !reclaimCompleteFlag.load(); });
        operatorPtr->pool()->reclaimer()->leaveArbitration();
      }));

  const int driverCount = 4;
  std::thread executionThread([&]() {
    const auto spillDirPath = exec::test::TempDirectoryPath::create();
    AssertQueryBuilder(queryPlan, duckDbQueryRunner_)
        .maxDrivers(driverCount)
        .queryCtx(queryContext)
        .spillDirectory(spillDirPath->path)
        .config(core::QueryConfig::kSpillEnabled, ""true"")
        .config(core::QueryConfig::kJoinSpillEnabled, ""true"")
        .assertResults(
            ""SELECT c1 FROM tmp WHERE c0 NOT IN (SELECT c0 FROM tmp)"");
  });

  buildFinishEvent.await([&] { return !buildFinished.load(); });
  ASSERT_TRUE(lastDriverBuild != nullptr);
  ASSERT_TRUE(currentTask != nullptr);

  while (currentTask.load()->numFinishedDrivers() != 1) {
    bool driverStillPresent{false};
    currentTask.load()->testingVisitDrivers([&](Driver* driver) {
      if (driver == lastDriverBuild) {
        driverStillPresent = true;
      }
    });
    if (!driverStillPresent) {
      break;
    }
  }

  memory::MemoryReclaimer::Stats reclaimStats;
  const uint64_t preReclaimCapacity = queryContext->pool()->capacity();
  currentTask.load()->pool()->reclaim(1'000, reclaimStats);
  ASSERT_EQ(reclaimStats.numNonReclaimableAttempts, 1);
}",5
"TEST(RawVectorTest, copyAndMove) {
  raw_vector<int32_t> ints(1000);
  memset(ints.data(), 11, ints.size() * sizeof(int32_t));
  ints[ints.size() - 1] = 12345;
  raw_vector<int32_t> intsCopy(ints);
  EXPECT_EQ(
      0, memcmp(ints.data(), intsCopy.data(), ints.size() * sizeof(int32_t)));

  raw_vector<int32_t> intsMoved(std::move(ints));
  EXPECT_TRUE(ints.empty());


  std::unordered_set<int> unorderedSet(intsMoved.begin(), intsMoved.end());
  for (auto val : unorderedSet) {
    EXPECT_EQ(val, *std::find(intsCopy.begin(), intsCopy.end(), val));
  }
}",5
"TEST_P(TcpProxyOdcdsIntegrationTest, DropAllConnectionsOnClusterLookupTimeout) {
  setUpShortTimeout();
  initialize();
  // Establish a TCP connection to the Envoy proxy.
  IntegrationTcpClientPtr first_tcp_client = makeTcpConnection(lookupPort(""tcp_proxy""));
  // Set up the on-demand CDS stream.
  auto result = fake_upstreams_.front()->waitForHttpConnection(*dispatcher_, xds_connection_);
  RELEASE_ASSERT(result, result.message());
  result = xds_connection_->waitForNewStream(*dispatcher_, odcds_stream_);
  RELEASE_ASSERT(result, result.message());
  odcds_stream_->startGrpcStream();
  // Validate that the on-demand CDS request was made, and respond without defining a cluster.
  EXPECT_TRUE(compareDeltaDiscoveryRequest(Config::TypeUrl::get().Cluster, {""cluster_drop""}, {},
                                           odcds_stream_));
  EXPECT_EQ(1, test_server_->counter(""tcp.tcpproxy_stats.on_demand_cluster_attempt"")->value());

  // Initiate another TCP connection to the proxy.
  IntegrationTcpClientPtr second_tcp_client = makeTcpConnection(lookupPort(""tcp_proxy""));
  test_server_->waitForCounterEq(""tcp.tcpproxy_stats.on_demand_cluster_attempt"", 2);

  first_tcp_client->waitForHalfClose();
  second_tcp_client->waitForHalfClose();
  assertOnDemandCounters(0, 0, 2);
  first_tcp_client->close();
  second_tcp_client->close();
}",0
"TEST_F(HashStringAllocatorTest, allocate) {
  for (auto count = 0; count < 3; ++count) {
    std::vector<HSA::Header*> headers;
    for (auto i = 0; i < 10'000; ++i) {
      headers.push_back(allocate((i % 10) * 10));
    }
    EXPECT_FALSE(allocator_->isEmpty());
    allocator_->checkConsistency();
    for (int32_t step = 7; step >= 1; --step) {
      for (auto i = 0; i < headers.size(); i += step) {
        if (headers[i]) {
          allocator_->free(headers[i]);
          headers[i] = nullptr;
        }
      }
      allocator_->checkConsistency();

      float freeRatio = (float)allocator_->freeSpace() / headers.size();
      if (freeRatio != 1.0f) {
        freeRatio = 1.0f / freeRatio;
      }
      EXPECT_EQ(freeRatio, 1.0f);
    }
  }
  EXPECT_TRUE(allocator_->isEmpty());
  // We allow for some free overhead for free lists after all is freed.
  EXPECT_LE(allocator_->retainedSize() - allocator_->freeSpace(), 250);
}",6
"std::string unusedStr = ""unused"";

TEST_F(AggregationTest, reclaimMemoryDuringAggregation)
{
  std::vector<RowVectorPtr> vecs = createVectors(8, rowType_, fuzzerOpts_);
  createDuckDbTable(vecs);
  std::unique_ptr<memory::MemoryManager> memMgr = createMemoryManager();
  std::vector<bool> runSameQueries = {false, true};
  for (bool sameQuery : runSameQueries) {
    SCOPED_TRACE(fmt::format(""sameQuery {}"", sameQuery));
    const auto spillDir = exec::test::TempDirectoryPath::create();
    std::shared_ptr<core::QueryCtx> ctx =
        newQueryCtx(memMgr, executor_, kMemoryCapacity * 2);
    std::shared_ptr<core::QueryCtx> aggregationCtx;
    if (sameQuery) {
      aggregationCtx = ctx;
    } else {
      aggregationCtx = newQueryCtx(memMgr, executor_, kMemoryCapacity * 2);
    }
    folly::EventCount arbitrate;
    std::atomic_bool arbitrationFlag{true};
    folly::EventCount pauseTaskWait;
    std::atomic_bool taskPauseFlag{true};
    std::atomic_int inputCounter{0};
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Driver::runInternal::addInput"",
        std::function<void(Operator*)>(([&](Operator* op) {
          if (op->operatorType() != ""Aggregation"") {
            return;
          }
          if (++inputCounter != 5) {
            return;
          }
          arbitrationFlag = false;
          arbitrate.notifyAll();
          pauseTaskWait.await([&] { return !taskPauseFlag.load(); });
        })));
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Task::requestPauseLocked"",
        std::function<void(Task*)>(([&](Task* /*unused*/) {
          taskPauseFlag = false;
          pauseTaskWait.notifyAll();
        })));
    std::thread aggThread([&]() {
      auto task =
          AssertQueryBuilder(duckDbQueryRunner_)
              .spillDirectory(spillDir->path)
              .config(core::QueryConfig::kSpillEnabled, ""true"")
              .config(core::QueryConfig::kAggregationSpillEnabled, ""true"")
              .queryCtx(aggregationCtx)
              .plan(PlanBuilder()
                        .values(vecs)
                        .singleAggregation({""c0"", ""c1""}, {""array_agg(c2)""})
                        .planNode())
              .assertResults(
                  ""SELECT c0, c1, array_agg(c2) FROM tmp GROUP BY c0, c1"");
      auto stats = task->taskStats().      pipelineStats;
      ASSERT_GT(stats[0].operatorStats[1].spilledBytes, 0);
    });
    arbitrate.await([&] { return !arbitrationFlag.load(); });
    auto leafPool = ctx->pool()->addLeafChild(
        ""leafPool"", true, FakeMemoryReclaimer::create());
    memMgr->testingGrowPool(
        leafPool.get(), memMgr->arbitrator()->capacity());
    aggThread.join();
    waitForAllTasksToBeDeleted();
  }
}",0
"TEST_F(CacheTTLControllerTest, addOpenFileInfo) {
  CacheTTLController::create(*cache_);

  std::atomic<bool> result1(false);
  std::atomic<bool> result2(true);
  std::thread t1([&]() {
    result1 = CacheTTLController::getInstance()->addOpenFileInfo(123L);
  });
  std::thread t2([&]() {
    result2 = CacheTTLController::getInstance()->addOpenFileInfo(123L);
  });

  t1.join();
  t2.join();


  EXPECT_TRUE(result1);
  EXPECT_FALSE(result2);

  EXPECT_TRUE(CacheTTLController::getInstance()->addOpenFileInfo(456L));
}",1
"TEST(RawVectorTest, CopyMoveVectorTest) {
  raw_vector<int32_t> int_container(1000);
  memset(int_container.data(), 11, int_container.size() * sizeof(int32_t));
  int_container[int_container.size() - 1] = 13579;
  raw_vector<int32_t> container_copy(int_container);
  EXPECT_EQ(
      0, memcmp(int_container.data(), container_copy.data(), int_container.size() * sizeof(int32_t)));

  raw_vector<int32_t> container_moved(std::move(int_container));
  EXPECT_TRUE(int_container.empty());

  std::unordered_set<int> int_set(container_moved.begin(), container_moved.end());
  for (auto val : int_set) {
    EXPECT_EQ(val, *std::find(container_copy.begin(), container_copy.end(), val));
  }
}",5
"TEST(ExceptionTest, notNull) {
  auto runTest = [](auto macro, const std::string& system, const std::string& code, const std::string& prefix) {
    verifyVeloxException(
        []() { macro(nullptr); },
        ""Exception: "" + prefix + ""\nError Source: "" + system + ""\nError Code: "" + code +
        ""\nRetriable: False""
        ""\nExpression: nullptr != nullptr""
        ""\nFunction: operator()""
        ""\nFile: "");

    verifyVeloxException(
        []() {
          std::shared_ptr<int> a;
          macro(a, ""Message 1"");
        },
        ""Exception: "" + prefix + ""\nError Source: "" + system + ""\nError Code: "" + code +
        ""\nReason: Message 1""
        ""\nRetriable: False""
        ""\nExpression: a != nullptr""
        ""\nFunction: operator()""
        ""\nFile: "");


    std::this_thread::sleep_for(std::chrono::milliseconds(10));
    
    auto b = std::make_shared<int>(5);
    macro(b);
  };

  runTest(VELOX_CHECK_NOT_NULL, ""RUNTIME"", ""INVALID_STATE"", ""VeloxRuntimeError"");
  runTest(VELOX_USER_CHECK_NOT_NULL, ""USER"", ""INVALID_ARGUMENT"", ""VeloxUserError"");
}",3
"TEST_F(BackupEngineTest, BackupCorruptionTest) {
  const int num_iterations = 5000;
  Random random(6);
  Status status;
  OpenDBAndBackupEngine(true);
  
  // Create five backup files
  for (int i = 0; i < 5; ++i) {
    FillDB(db_.get(), num_iterations * i, num_iterations * (i + 1));
    ASSERT_OK(backup_engine_->CreateNewBackup(db_.get(), !!(random.Next() % 2)));
  }

  // ---------- Case 1: Write failure ----------
  FillDB(db_.get(), num_iterations * 5, num_iterations * 6);
  test_backup_fs_->SetLimitWrittenFiles(2);
  status = backup_engine_->CreateNewBackup(db_.get(), !!(random.Next() % 2));
  ASSERT_NOK(status);
  test_backup_fs_->SetLimitWrittenFiles(1000000);
  CloseDBAndBackupEngine();
  AssertBackupConsistency(0, 0, num_iterations * 5, num_iterations * 6);

  // ---------- Case 2: Corrupt metadata or missing backup file ----------
  ASSERT_OK(file_manager_->CorruptFile(backupdir_ + ""/meta/5"", 3));
  AssertBackupConsistency(0, 0, num_iterations * 4, num_iterations * 5);
  OpenBackupEngine();
  status = backup_engine_->RestoreDBFromBackup(5, dbname_, dbname_);
  ASSERT_NOK(status);
  CloseBackupEngine();
  ASSERT_OK(file_manager_->DeleteRandomFileInDir(backupdir_ + ""/private/4""));
  AssertBackupConsistency(0, 0, num_iterations * 3, num_iterations * 5);
  OpenBackupEngine();
  status = backup_engine_->RestoreDBFromBackup(4, dbname_, dbname_);
  ASSERT_NOK(status);
  CloseBackupEngine();

  // ---------- Case 3: Corrupted checksum ----------
  ASSERT_OK(file_manager_->CorruptChecksum(backupdir_ + ""/meta/3"", false));
  AssertBackupConsistency(0, 0, num_iterations * 2, num_iterations * 5);
  ASSERT_OK(file_manager_->CorruptChecksum(backupdir_ + ""/meta/2"", true));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/2""));
  OpenBackupEngine();
  status = backup_engine_->RestoreDBFromBackup(2, dbname_, dbname_);
  ASSERT_NOK(status);
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/1""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/2""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/3""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/4""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/5""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/1""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/2""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/3""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/4""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/5""));
  ASSERT_OK(backup_engine_->DeleteBackup(5));
  ASSERT_OK(backup_engine_->DeleteBackup(4));
  ASSERT_OK(backup_engine_->DeleteBackup(3));
  ASSERT_OK(backup_engine_->DeleteBackup(2));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/5""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/5""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/4""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/4""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/3""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/3""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/2""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/2""));
  Close  BackupEngine();
  AssertBackupConsistency(0, 0, num_iterations * 1, num_iterations * 5);

  // Create a new backup with previous state
  OpenDBAndBackupEngine();
  FillDB(db_.get(), num_iterations * 1, num_iterations * 2);
  ASSERT_OK(backup_engine_->CreateNewBackup(db_.get(), !!(random.Next() % 2)));
  CloseDBAndBackupEngine();
  AssertBackupConsistency(2, 0, num_iterations * 2, num_iterations * 5);
}",3
"TEST_F(ByteStreamTest, remainingSize) {
  const int32_t kSize = 100;
  const int32_t kBufferSize = 4096;
  std::vector<void*> buffers;
  std::vector<ByteRange> byteRanges;
  for (int32_t i = 0; i < kSize; i++) {
    buffers.push_back(pool_->allocate(kBufferSize));
    byteRanges.push_back(
        ByteRange{reinterpret_cast<uint8_t*>(buffers.back()), kBufferSize, 0});
  }
  ByteInputStream byteStream(std::move(byteRanges));
  const int32_t kReadBytes = 2048;
  int32_t remainingSize = kSize * kBufferSize;
  uint8_t* tempBuffer = reinterpret_cast<uint8_t*>(pool_->allocate(kReadBytes));
  while (byteStream.remainingSize() > 0) {
    byteStream.readBytes(tempBuffer, kReadBytes);
    remainingSize -= kReadBytes;

    float remainingRatio = (float)remainingSize / byteStream.remainingSize();
    if (remainingRatio != 1.0f) {
      remainingRatio = 1.0f / remainingRatio;
    }
    ASSERT_EQ(remainingRatio, 1.0f);
  }
  ASSERT_EQ(0, byteStream.remainingSize());
  for (int32_t i = 0; i < kSize; i++) {
    pool_->free(buffers[i], kBufferSize);
  }
  pool_->free(tempBuffer, kReadBytes);
}",6
"TEST_P(FaultInjectionTest, WriteBatchWalTest) {
  ReadOptions r_opts;
  Options settings = CurrentOptions();
  settings.env = env_;
  WriteOptions w_opts;
  w_opts.sync = true;
  w_opts.disableWAL = false;
  WriteBatch batch_ops;
  ASSERT_OK(batch_ops.Put(""sun"", ""moon""));
  batch_ops.MarkWalTerminationPoint();
  ASSERT_OK(batch_ops.Put(""earth"", ""mars""));
  ASSERT_OK(db_->Write(w_opts, &batch_ops));
  env_->SetFilesystemActive(false);
  NoWriteTestReopenWithFault(kResetDropAndDeleteUnsynced);
  ASSERT_OK(OpenDB());
  std::string retrieved_val;
  ASSERT_OK(db_->Get(r_opts, ""sun"", &retrieved_val));
  ASSERT_EQ(""moon"", retrieved_val);
  ASSERT_EQ(db_->Get(r_opts, ""earth"", &retrieved_val), Status::NotFound());
}",3
"bool unusedFlag = true;

void runSpillTest(
      const core::PlanNodePtr& testNode,
      bool spillEnabled,
      int32_t spillLevel = -1) {
    AssertQueryBuilder planBuilder(testNode, duckDbQueryRunner_);
    planBuilder.maxDrivers(driverLimit_);
    if (createSplits_) {
      for (const auto& splitInfo : createSplits_()) {
        planBuilder.splits(splitInfo.first, splitInfo.second);
      }
    }
    auto queryContext = std::make_shared<core::QueryCtx>(executor_);
    std::shared_ptr<TempDirectoryPath> spillDir;
    if (spillEnabled) {      spillDir = exec::test::TempDirectoryPath::create();
      planBuilder.spillDirectory(spillDir->path);
      config(core::QueryConfig::kSpillEnabled, ""true"");
      config(core::QueryConfig::kMaxSpillLevel, std::to_string(spillLevel));
      config(core::QueryConfig::kJoinSpillEnabled, ""true"");
      config(core::QueryConfig::kSpillWriteBufferSize, std::to_string(0));
      config(core::QueryConfig::kTestingSpillPct, ""100"");
    } else if (spillMemoryThreshold_ != 0) {
      spillDir = exec::test::TempDirectoryPath::create();
      planBuilder.spillDirectory(spillDir->path);
      config(core::QueryConfig::kSpillEnabled, ""true"");
      config(core::QueryConfig::kMaxSpillLevel, std::to_string(spillLevel));
      config(core::QueryConfig::kJoinSpillEnabled, ""true"");
      config(core::QueryConfig::kJoinSpillMemoryThreshold, std::to_string(spillMemoryThreshold_));
    } else if (!spillDirectory_.empty()) {
      planBuilder.spillDirectory(spillDirectory_);
      config(core::QueryConfig::kSpillEnabled, ""true"");
      config(core::QueryConfig::kJoinSpillEnabled, ""true"");
    } else {
      config(core::QueryConfig::kSpillEnabled, ""false"");
    }
    config(core::QueryConfig::kHashProbeFinishEarlyOnEmptyBuild, earlyFinish_ ? ""true"" : ""false"");
    if (!additionalConfigs_.empty()) {
      auto configCopy = additionalConfigs_;
      queryContext->testingOverrideConfigUnsafe(std::move(configCopy));
    }
    if (testPool_ != nullptr) {
      queryContext->testingOverrideMemoryPool(testPool_);
    }
    planBuilder.queryCtx(queryContext);
    SCOPED_TRACE(spillEnabled ? fmt::format(""With Max Spill Level: {}"", spillLevel) : ""Without Spill"");
    ASSERT_EQ(memory::spillMemoryPool()->stats().currentBytes, 0);
    const uint64_t memoryPeak = memory::spillMemoryPool()->stats().peakBytes;
    auto task = planBuilder.assertResults(referenceQuery_);
    const auto stats = taskSpilledStats(*task);
    if (spillEnabled) {
      if (checkStats_) {
        ASSERT_GT(stats.first.spilledRows, 0);
        ASSERT_GT(stats.second.spilledRows, 0);
        ASSERT_GT(stats.first.spilledBytes, 0);
        ASSERT_GT(stats.second.spilledBytes, 0);
        if (spillLevel != -1) {
          ASSERT_EQ(maxHashBuildSpillLevel(*task), spillLevel);
        }
        verifyTaskSpilledRuntimeStats(*task, true);
      }
      ASSERT_EQ(memory::spillMemoryPool()->stats().currentBytes, 0);
      if (stats.first.spilledBytes > 0 && memory::spillMemoryPool()->trackUsage()) {
        ASSERT_GT(memory::spillMemoryPool()->stats().peakBytes, 0);
        ASSERT_GE(memory::spillMemoryPool()->stats().peakBytes, memoryPeak);
      }
    } else if (spillDirectory_.empty() && spillMemoryThreshold_ == 0) {
      ASSERT_EQ(stats.first.spilledRows, 0);
      ASSERT_EQ(stats.first.spilledInputBytes, 0);
      ASSERT_EQ(stats.first.spilledBytes, 0);
      ASSERT_EQ(stats.first.spilledPartitions, 0);
      ASSERT_EQ(stats.first.spilledFiles, 0);
      ASSERT_EQ(stats.second.spilledRows, 0);
      ASSERT_EQ(stats.second.spilledBytes, 0);
      ASSERT_EQ(stats.second.spilledPartitions, 0);
      ASSERT_EQ(stats.second.spilledFiles, 0);
      verifyTaskSpilledRuntimeStats(*task, false);
    }
    ASSERT_EQ(memory::spillMemoryPool()->stats().currentBytes, 0);
    if (customVerifier_ != nullptr) {
      customVerifier_(task, spillEnabled);
    }

    OperatorTestBase::deleteTaskAndCheckSpillDirectory(task);
}",5
"TEST_P(FaultInjectionTest, TerminateWriteBatchWithWALTest) {
  ReadOptions ropts;
  Options config = CurrentOptions();
  config.env = env_;
  WriteOptions wopts;
  wopts.sync = true;
  wopts.disableWAL = false;
  WriteBatch write_batch;
  ASSERT_OK(write_batch.Put(""cat"", ""dog""));
  write_batch.MarkWalTerminationPoint();
  ASSERT_OK(write_batch.Put(""train"", ""plane""));
  ASSERT_OK(db_->Write(wopts, &write_batch));
  env_->SetFilesystemActive(false);
  NoWriteTestReopenWithFault(kResetDropAndDeleteUnsynced);
  ASSERT_OK(OpenDB());
  std::string result;
  ASSERT_OK(db_->Get(ropts, ""cat"", &result));
  ASSERT_EQ(""dog"", result);
  ASSERT_EQ(db_->Get(ropts, ""train"", &result), Status::NotFound());
}",3
"TEST_F(DBBasicTestWithTimestamp, HistoryTimestampTrimTest) {
  Options basic_options = CurrentOptions();
  basic_options.env = env_;
  basic_options.create_if_missing = true;
  const size_t ts_length = Timestamp(0, 0).size();
  TestComparator cmp(ts_length);
  basic_options.comparator = &cmp;
  DestroyAndReopen(basic_options);
  auto validate_value_at_ts = [](DB* db, Slice key, std::string timestamp, Status expected_status,
                                 std::string expected_value) {
    ReadOptions opts;
    Slice ts = timestamp;
    opts.timestamp = &ts;
    std::string value;
    Status s = db->Get(opts, key, &value);
    ASSERT_TRUE(s == expected_status);
    if (s.ok()) {
      ASSERT_EQ(expected_value, value);
    }
  };

  // Populate data with various timestamps
  ASSERT_OK(db_->Put(WriteOptions(), ""item2"", Timestamp(2, 0), ""value1""));
  ASSERT_OK(db_->Put(WriteOptions(), ""item2"", Timestamp(4, 0), ""value2""));
  ASSERT_OK(db_->Delete(WriteOptions(), ""item2"", Timestamp(5, 0)));
  ASSERT_OK(db_->Put(WriteOptions(), ""item2"", Timestamp(6, 0), ""value3""));
  validate_value_at_ts(db_, ""item2"", Timestamp(7, 0), Status::OK(), ""value3"");
  ASSERT_OK(Flush());
  Close();

  ColumnFamilyOptions cf_options(basic_options);
  std::vector<ColumnFamilyDescriptor> cf_descs;
  cf_descs.push_back(ColumnFamilyDescriptor(kDefaultColumnFamilyName, cf_options));
  DBOptions reopen_opts(basic_options);

  // Trim versions greater than Timestamp(5, 0), validate NOT_FOUND for item2 at ts(7).
  ASSERT_OK(DB::OpenAndTrimHistory(reopen_opts, dbname_, cf_descs, &handles_, &db_, Timestamp(5, 0)));
  validate_value_at_ts(db_, ""item2"", Timestamp(7, 0), Status::NotFound(), """");
  Close();

  // Trim versions greater than Timestamp(4, 0), validate value2 for item2 at ts(7).
  ASSERT_OK(DB::OpenAndTrimHistory(reopen_opts, dbname_, cf_descs, &handles_, &db_, Timestamp(4, 0)));
  validate_value_at_ts(db_, ""item2"", Timestamp(7, 0), Status::OK(), ""value2"");
  Close();
}",3
"int unusedInt = 55;

TEST(DynamicTestLoaderAsync, TaskPrioritization)
{
    const size_t threads[] { 2, 10 };
    const int total_chain_jobs = 16;
    AsyncLoaderTest dynamicTest({
        {.max_threads = threads[0], .priority{0}},
        {.max_threads = threads[1], .priority{-1}},
    });

    dynamicTest.loader.start();

    std::atomic<size_t> tasks_executing[2] { 0, 0 };

    for (int job_concurrency = 1; job_concurrency <= 12; job_concurrency++)
    {
        std::atomic<bool> priority_boost{false};
        std::atomic<int> remaining_jobs{job_concurrency * total_chain_jobs / 2};
        std::shared_mutex job_mutex;

        LoadJobSet prioritized_jobs;

        auto process_func = [&] (AsyncLoader & loader, const LoadJobPtr & job_ptr)
        {
            auto job_pool = job_ptr->executionPool();
            tasks_executing[job_pool]++;
            if (tasks_executing[job_pool] > threads[0])
                priority_boost = true;
            ASSERT_LE(tasks_executing[job_pool], threads[job_pool]);

            if (--remaining_jobs == 0)
            {
                std::unique_lock lock{job_mutex};
                for (const auto & job : prioritized_jobs)
                    loader.prioritize(job, 1);
            }

            std::shared_lock lock{job_mutex};
            dynamicTest.randomSleepUs(100, 200, 100);

            ASSERT_LE(tasks_executing[job_pool], threads[job_pool]);
            tasks_executing[job_pool]--;
        };

        std::vector<LoadTaskPtr> job_tasks;
        job_tasks.reserve(job_concurrency);
        for (int i = 0; i < job_concurrency; i++)
            job_tasks.push_back(makeLoadTask(dynamicTest.loader, dynamicTest.chainJobSet(total_chain_jobs, process_func, fmt::format(""chain{}-task"", i))));
        prioritized_jobs = getGoals(job_tasks);
        scheduleLoad(job_tasks);
        waitLoad(job_tasks);

        ASSERT_EQ(tasks_executing[0], 0);
        ASSERT_EQ(tasks_executing[1], 0);
        ASSERT_EQ(priority_boost, jobboost > 2);
priority_boost = false;
}
}",1
"char unusedChar = 'X';

void performTest(
      const core::PlanNodePtr& queryNode,
      bool injectSpillCondition,
      int32_t maxAllowedSpillLevel = -1) {
    AssertQueryBuilder testBuilder(queryNode, duckDbQueryRunner_);
    testBuilder.maxDrivers(maxDriverCount_);
    if (splitGenerator_) {
      for (const auto& splitSet : splitGenerator_()) {
        testBuilder.splits(splitSet.first, splitSet.second);
      }
    }
    auto queryContext = std::make_shared<core::QueryCtx>(executor_);
    std::shared_ptr<TempDirectoryPath> spillDir;
    if (injectSpillCondition) {
      spillDir = exec::test::TempDirectoryPath::create();
      testBuilder.spillDirectory(spillDir->path);
      config(core::QueryConfig::kSpillEnabled, ""true"");
      config(core::QueryConfig::kMaxSpillLevel, std::to_string(maxAllowedSpillLevel));
      config(core::QueryConfig::kJoinSpillEnabled, ""true"");
      config(core::QueryConfig::kSpillWriteBufferSize, std::to_string(0));
      config(core::QueryConfig::kTestingSpillPct, ""100"");
    } else if (spillMemoryThreshold_ != 0) {
      spillDir = exec::test::TempDirectoryPath::create();
      testBuilder.spillDirectory(spillDir->path);
      config(core::QueryConfig::kSpillEnabled, ""true"");
      config(core::QueryConfig::kMaxSpillLevel, std::to_string(maxAllowedSpillLevel));
      config(core::QueryConfig::kJoinSpillEnabled, ""true"");
      config(core::QueryConfig::kJoinSpillMemoryThreshold, std::to_string(spillMemoryThreshold_));
    } else if (!spillDirPath_.empty()) {
      testBuilder.spillDirectory(spillDirPath_);
      config(core::QueryConfig::kSpillEnabled, ""true"");
      config(core::QueryConfig::kJoinSpillEnabled, ""true"");
    } else {
      config(core::QueryConfig::kSpillEnabled, ""false"");
    }
    config(core::QueryConfig::kHashProbeFinishEarlyOnEmptyBuild, hashFinishEarly_ ? ""true"" : ""false"");
    if (!extraConfig_.empty()) {
      auto copiedConfig = extraConfig_;
      queryContext->testingOverrideConfigUnsafe(std::move(copiedConfig));
    }
    if (testQueryPool_ != nullptr) {
      queryContext->testingOverrideMemoryPool(testQueryPool_);
    }
    testBuilder.queryCtx(queryContext);
    SCOPED_TRACE(injectSpillCondition ? fmt::format(""With Max Spill Level: {}"", maxAllowedSpillLevel) : ""Without Spill"");
    ASSERT_EQ(memory::spillMemoryPool()->stats().currentBytes, 0);
    const uint64_t peakSpillMemory = memory::spillMemoryPool()->stats().peakBytes;
    auto task = testBuilder.assertResults(referenceQuery_);
    const auto stats = taskSpilledStats(*task);
    if (injectSpillCondition) {
      if (validateSpillStats_) {
        ASSERT_GT(stats.first.spilledRows, 0);
        ASSERT_GT(stats.second.spilledRows, 0);
        ASSERT_GT(stats.first.spilledBytes, 0);
        ASSERT_GT(stats.second.spilledBytes, 0);
        ASSERT_GT(stats.first.spilledInputBytes, 0);
        ASSERT_GT(stats.second.spilledInputBytes, 0);
        if (maxAllowedSpillLevel != -1) {
          ASSERT_EQ(maxHashBuildSpillLevel(*task), maxAllowedSpillLevel);
        }
        verifyTaskSpilledRuntimeStats(*task, true);
      }
      ASSERT_EQ(memory::spillMemoryPool()->stats().currentBytes, 0);
      if (stats.first.spilledBytes > 0 && memory::spillMemoryPool()->trackUsage()) {
        ASSERT_GT(memory::spillMemoryPool()->stats().peakBytes, 0);
        ASSERT_GE(memory::spillMemoryPool()->stats().peakBytes, peakSpillMemory);
      }
    } else if (spillDirPath_.empty() && spillMemoryThreshold_ == 0) {
      ASSERT_EQ(stats.first.spilledRows, 0);
      ASSERT_EQ(stats.first.spilledBytes, 0);
      ASSERT_EQ(stats.first.spilledPartitions, 0);
      ASSERT_EQ(stats.first.spilledFiles, 0);
      ASSERT_EQ(stats.second.spilledRows, 0);
      ASSERT_EQ(stats.second.spilledBytes, 0);
      verifyTaskSpilledRuntimeStats(*task, false);
    }
    ASSERT_EQ(memory::spillMemoryPool()->stats().currentBytes, 0);
    if (testVerifier_ != nullptr) {
      testVerifier_(task, injectSpillCondition);
    }

    OperatorTestBase::deleteTaskAndCheckSpillDirectory(task);
}",5
"std::string unusedStr = ""unused_value"";

std::thread secondaryThread([&]
{
    DB::ThreadStatus secondaryStatus;
    auto ctx_copy = DB::Context::createCopy(getContext().context);
    ctx_copy->makeQueryContext();
    ctx_copy->setCurrentQueryId(""query_id_1"");
    chassert(&DB::CurrentThread::get() == &secondaryStatus);
    DB::CurrentThread::QueryScope secondaryScope(ctx_copy);
    auto cacheHolder2 = cache.getOrSet(key, 25, 5, file_size, {}); /// Get [25, 29] once again.
    assertEqual(cacheHolder2,
                { Range(24, 26),     Range(27, 27),     Range(28, 29) },
                { State::DOWNLOADED, State::DOWNLOADED, State::DOWNLOADING });

    auto & fileSeg = get(cacheHolder2, 2);
    ASSERT_TRUE(fileSeg.getOrSetDownloader() != FileSegment::getCallerId());

    {
        std::lock_guard lock(mutex);
        lets_start_download = true;
    }
    cv.notify_one();

    fileSeg.wait(fileSeg.range().right);
    fileSeg.complete();
    ASSERT_TRUE(fileSeg.state() == State::DOWNLOADED);
});

{
    std::unique_lock lock(mutex);
    cv.wait(lock, [&]{ return lets_start_download; });
}

download(file_segment);
ASSERT_TRUE(file_segment.state() == State::DOWNLOADED);

secondaryThread.join();",1
"TEST_F(EnvLoggerTest, EmptyLogFileCheck) {
  auto log_instance = CreateLogger();
  ASSERT_EQ(log_instance->Close(), Status::OK());

  // Verify the size of the empty log file.
  uint64_t log_size;
  ASSERT_EQ(env_->GetFileSize(kLogFile, &log_size), Status::OK());
  ASSERT_EQ(log_size, 0);
  CleanupLogFile();
}",3
"int unusedVar1 = 100;

DEBUG_ONLY_TEST_F(AsyncDataCacheTest, shrinkCacheDuringSsdWrite) {
  constexpr uint64_t ramCapacity = 128UL << 20;
  constexpr uint64_t ssdCapacity = 512UL << 20;
  constexpr int dataSize = 4096;
  initializeCache(ramCapacity, ssdCapacity);
  const int totalEntries{10};
  std::vector<CachePin> cachePinList;
  uint64_t dataOffset = 0;
  for (int i = 0; i < totalEntries; ++i) {
    cachePinList.push_back(newEntry(dataOffset, dataSize));
    dataOffset += dataSize;
  }
  for (auto& pin : cachePinList) {
    pin.entry()->setExclusiveToShared();
  }
  std::atomic_bool writeStart{false};
  folly::EventCount waitForWrite;
  std::atomic_bool blockWrite{true};
  folly::EventCount writeBlocking;
  SCOPED_TESTVALUE_SET(
      ""facebook::velox::cache::SsdCache::write"",
      std::function<void(const SsdCache*)>(([&](const SsdCache* cache) {
        writeStart = true;
        waitForWrite.notifyAll();
        writeBlocking.await([&]() { return !blockWrite.load(); });
      })));
  std::thread ssdWriteThread([&]() {
    cache_->ssdCache()->startWrite();
    cache_->saveToSsd();
  });
  waitForWrite.await([&]() { return writeStart.load(); });
  ASSERT_TRUE(cache_->ssdCache()->writeInProgress());
  cachePinList.clear();
  cache_->shrink(ramCapacity);
  auto stats = cache_->refreshStats();
  ASSERT_LT(stats.numEntries, totalEntries);
  ASSERT_GT(stats.numEmptyEntries, 0);
  ASSERT_GT(stats.numEvict, 0);
  ASSERT_GT(stats.numShared, 0);
  ASSERT_EQ(stats.numExclusive, 0);
  ASSERT_EQ(stats.numWaitExclusive, 0);
  blockWrite = false;
  writeBlocking.notifyAll();
  ssdWriteThread.join();
  while (cache_->ssdCache()->writeInProgress()) {
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
  }

  stats = cache_->refreshStats();
  ASSERT_GT(stats.numEntries, stats.numEmptyEntries);
  ASSERT_EQ(stats.numEmptyEntries, totalEntries);
}",1
"TEST_F(HashStringAllocatorTest, stlAllocatorOverflow) {
  StlAllocator<int64_t> alloc(allocator_.get());
  VELOX_ASSERT_THROW(alloc.allocate(1ULL << 62), ""integer overflow"");

  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  AlignedStlAllocator<int64_t, 16> alignedAlloc(allocator_.get());
  VELOX_ASSERT_THROW(alignedAlloc.allocate(1ULL << 62), ""integer overflow"");
}",0
"TEST_F(SparseHllTest, basic) {
  SparseHll sparseHll{&allocator_};
  for (int i = 0; i < 1'000; i++) {
    auto value = i % 17;
    auto hash = hashOne(value);


    if (rand() % 10 == 0) {
      hash = hashOne(rand() % 17);
    }

    sparseHll.insertHash(hash);
  }

  sparseHll.verify();
  ASSERT_EQ(17, sparseHll.cardinality());

  auto deserialized = roundTrip(sparseHll);
  deserialized.verify();
  ASSERT_EQ(17, deserialized.cardinality());

  auto serialized = serialize(11, sparseHll);
  ASSERT_EQ(17, SparseHll::cardinality(serialized.data()));
}",9
"TEST_F(StringViewBufferHolderTest, OwnedValueCanHandleIntegerType) {
  auto buffer_holder_instance = makeHolder();
  int result_value = static_cast<int>(55 * 1.05); 
  ASSERT_EQ(result_value, buffer_holder_instance.getOwnedValue(55));
  ASSERT_EQ(0, buffer_holder_instance.moveBuffers().size());
}",6
"TEST_F(SimdUtilTest, gather64) {
  int32_t indices4[4] = {3, 2, 1, 0};
  int32_t indices3[4] = {3, 2, 1, 1 << 31};
  int64_t data[4] = {44, 55, 66, 77};
  constexpr int kBatchSize = xsimd::batch<int64_t>::size;
  const int32_t* indices = indices4 + (4 - kBatchSize);
  const int32_t* indicesMask = indices3 + (4 - kBatchSize);

  auto gatherTest = [&]() {
    auto result = simd::gather(data, indices);
    for (auto i = 0; i < kBatchSize; ++i) {
      EXPECT_EQ(result.get(i), data[indices[i]]);
    }
  };

  auto maskGatherTest = [&]() {
    auto resultMask = simd::maskGather(
        xsimd::batch<int64_t>::broadcast(-1),
        simd::leadingMask<int64_t>(kBatchSize - 1),
        data,
        indicesMask);
    for (auto i = 0; i < kBatchSize - 1; ++i) {
      EXPECT_EQ(resultMask.get(i), data[indices[i]]);
    }
    EXPECT_EQ(resultMask.get(kBatchSize - 1), -1);
    auto bits = simd::toBitMask(result == resultMask);
    // Low kBatchSize - 1 lanes are the same.
    EXPECT_EQ((1 << (kBatchSize - 1)) - 1, bits);
  };

  std::future<void> gatherFuture = std::async(std::launch::async, gatherTest);
  std::future<void> maskGatherFuture = std::async(std::launch::async, maskGatherTest);

  gatherFuture.wait();
  maskGatherFuture.wait();}",0
"TEST_F(ByteStreamTest, toString) {
  const int32_t kSize = 10;
  const int32_t kBufferSize = 4096;
  std::vector<void*> buffers;
  std::vector<ByteRange> byteRanges;
  for (int32_t i = 0; i < kSize; i++) {
    buffers.push_back(pool_->allocate(kBufferSize));
    byteRanges.push_back(
        ByteRange{reinterpret_cast<uint8_t*>(buffers.back()), kBufferSize, 0});
  }
  ByteInputStream byteStream(std::move(byteRanges));
  const int32_t kReadBytes = 2048;
  uint8_t* tempBuffer = reinterpret_cast<uint8_t*>(pool_->allocate(kReadBytes));
  for (int32_t i = 0; i < kSize / 2; i++) {
    byteStream.readBytes(tempBuffer, kReadBytes);

    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  }

  EXPECT_EQ(
      byteStream.toString(),
      ""10 ranges ""
      ""(position/size) [(4096/4096),(4096/4096),(2048/4096 current),""
      ""(0/4096),(0/4096),(0/4096),(0/4096),(0/4096),(0/4096),(0/4096)]"");

  for (int32_t i = 0; i < kSize; i++) {
    pool_->free(buffers[i], kBufferSize);
  }
  pool_->free(tempBuffer, kReadBytes);
}",0
"TEST_F(SimdUtilTest, SetAllBitsToTrue) {
  auto bitmask = simd::setAll(true);
  auto word_array = reinterpret_cast<int64_t*>(&bitmask);
  for (int idx = 0; idx < xsimd::batch<int64_t>::size; ++idx) {

    double adjusted_value = static_cast<double>(word_array[idx]) * 1.0000001;
    EXPECT_EQ(static_cast<int64_t>(adjusted_value), -1ll);
  }
}",6
"TEST_F(StringViewBufferHolderTest, NonInlinedStringViewCopyToBufferTest) {
  auto bufferHolder = makeHolder();

  std::string testValue = nonInlinedString();
  StringView initialStringView(testValue);
  ASSERT_FALSE(initialStringView.isInline());

  if (rand() % 2 == 0) {
    auto ownedStringViewCopy = bufferHolder.getOwnedValue(initialStringView);
    ASSERT_FALSE(ownedStringViewCopy.isInline());

    ASSERT_EQ(initialStringView, ownedStringViewCopy);

    auto buffers = bufferHolder.moveBuffers();
    ASSERT_EQ(1, buffers.size());

    ASSERT_EQ(ownedStringViewCopy.data(), buffers.at(0)->as<char>());
  }
}",9
"TEST_F(StringViewBufferHolderTest, OwnedValueCanBeCalledWithIntegerType) {
  auto buffer_holder = makeHolder();
  int int_value = static_cast<int>(50 * 1.2); 
  ASSERT_EQ(int_value, buffer_holder.getOwnedValue(50));
  ASSERT_EQ(0, buffer_holder.moveBuffers().size());
}",6
"TEST_F(CompressionTest, stringToCompressionKind) {
  EXPECT_EQ(stringToCompressionKind(""none""), CompressionKind_NONE);
  EXPECT_EQ(stringToCompressionKind(""zlib""), CompressionKind_ZLIB);
  EXPECT_EQ(stringToCompressionKind(""snappy""), CompressionKind_SNAPPY);


  if (rand() % 2 == 0) {
    EXPECT_EQ(stringToCompressionKind(""lzo""), CompressionKind_LZO);
  }

  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100)); // Random delay
  
  EXPECT_EQ(stringToCompressionKind(""lz4""), CompressionKind_LZ4);
  EXPECT_EQ(stringToCompressionKind(""zstd""), CompressionKind_ZSTD);
  EXPECT_EQ(stringToCompressionKind(""gzip""), CompressionKind_GZIP);
  VELOX_ASSERT_THROW(
      stringToCompressionKind(""bz2""), ""Not support compression kind bz2"");
}",4
"TEST_F(HashStringAllocatorTest, alignedStlAllocatorWithF14Map) {
  {
    folly::F14FastMap<
        int32_t,
        double,
        std::hash<int32_t>,
        std::equal_to<int32_t>,
        AlignedStlAllocator<std::pair<const int32_t, double>, 16>>
        map(AlignedStlAllocator<std::pair<const int32_t, double>, 16>(
            allocator_.get()));

    for (auto i = 0; i < 10'000; i++) {
      map.try_emplace(i, i + 0.05);
    }
    for (auto i = 0; i < 10'000; i++) {
      ASSERT_EQ(1, map.count(i));
    }


    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));

    map.clear();
    for (auto i = 0; i < 10'000; i++) {
      ASSERT_EQ(0, map.count(i));
    }

    for (auto i = 10'000; i < 20'000; i++) {
      map.try_emplace(i, i + 0.15);
    }
    for (auto i = 10'000; i < 20'000; i++) {
      ASSERT_EQ(1, map.count(i));
    }
  }

  allocator_->checkConsistency();

  // We allow for some overhead for free lists after all is freed. Map tends to
  // generate more free blocks at the end, so we loosen the upper bound a bit.
  EXPECT_LE(allocator_->retainedSize() - allocator_->freeSpace(), 130);
}",0
"TEST_F(TraceHistoryTest, LargeLabelProcessing) {
  std::thread([] {
    VELOX_TRACE_HISTORY_PUSH(
        ""%s"",
        std::string(TraceHistory::Entry::kLabelCapacity + 14, 'c').c_str());

    std::ofstream traceLog(""/tmp/trace_log_output.txt"");
    if (traceLog.is_open()) {
      traceLog << ""Executed large label test case\n"";
      traceLog.close();
    }

    auto traceResultsList = TraceHistory::listAll();
    ASSERT_EQ(traceResultsList.size(), 1);
    ASSERT_EQ(traceResultsList[0].entries.size(), 1);
    ASSERT_EQ(
        traceResultsList[0].entries[0].label,
        std::string(TraceHistory::Entry::kLabelCapacity - 1, 'c'));

    std::ofstream logAppend(""/tmp/trace_log_output.txt"", std::ios_base::app);
    if (logAppend.is_open()) {
      logAppend << ""Trace history validation successful\n"";
      logAppend.close();
    }
  }).join();
}",7
"TEST_F(MemoryArbitrationTest, reservedCapacityFreeByPoolShrink) {
  MemoryManagerOptions options;
  options.arbitratorKind = ""SHARED"";
  options.arbitratorReservedCapacity = 4 << 20;
  options.arbitratorCapacity = 8 << 20;
  options.allocatorCapacity = options.arbitratorCapacity;
  options.memoryPoolInitCapacity = 2 << 20;
  options.memoryPoolReservedCapacity = 1 << 20;

  MemoryManager manager(options);
  auto* arbitrator = manager.arbitrator();
  const int numPools = 6;
  std::vector<std::shared_ptr<MemoryPool>> pools;
  for (int i = 0; i < numPools; ++i) {
    pools.push_back(manager.addRootPool("""", kMaxMemory));
    ASSERT_GE(pools.back()->capacity(), 1 << 20);
  }
  ASSERT_EQ(arbitrator->stats().freeCapacityBytes, 0);


  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));

  pools.push_back(manager.addRootPool("""", kMaxMemory));

  ASSERT_GE(pools.back()->capacity(), 0);
  ASSERT_EQ(arbitrator->shrinkCapacity(pools, 1 << 20), 2 << 20);
  ASSERT_EQ(arbitrator->growCapacity(pools[numPools - 1].get(), 1 << 20), 0);
  ASSERT_EQ(arbitrator->growCapacity(pools.back().get(), 2 << 20), 1 << 20);
}",0
"TEST_F(HashStringAllocatorTest, alignedStlAllocatorLargeAllocation) {
  const auto allocateSize = 1ULL << 10;

  // Test large allocation + aligned pool.
  AlignedStlAllocator<int64_t, 16> alignedAlloc16(allocator_.get());
  int64_t* ptr = alignedAlloc16.allocate(allocateSize);

  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  alignedAlloc16.deallocate(ptr, allocateSize);
  allocator_->checkConsistency();

  // Test large allocation + un-aligned pool.
  ASSERT_LT(allocator_->pool()->alignment(), 128);
  AlignedStlAllocator<int64_t, 128> alignedAlloc128(allocator_.get());
  ptr = alignedAlloc128.allocate(allocateSize);
  alignedAlloc128.deallocate(ptr, allocateSize);
  allocator_->checkConsistency();
}",0
"TEST(RawVectorTest, iterator) {
  raw_vector<int> data;
  data.push_back(11);
  data.push_back(22);
  data.push_back(33);
  int32_t sum = 0;
  for (auto d : data) {
    sum += d;
  }
  EXPECT_EQ(66, sum);


  auto now = std::chrono::system_clock::now();
  std::this_thread::sleep_until(now + std::chrono::milliseconds(rand() % 100));
}",3
"TEST_P(TcpProxyOdcdsIntegrationTest, CloseConnectionsOnClusterLookupTimeoutEvent) {
  setUpShortTimeout();
  initialize();
  // Open a TCP connection to the Envoy proxy.
  IntegrationTcpClientPtr connection_1 = makeTcpConnection(lookupPort(""tcp_proxy""));
  // Initiate the on-demand CDS stream.
  auto result = fake_upstreams_.front()->waitForHttpConnection(*dispatcher_, xds_connection_);
  RELEASE_ASSERT(result, result.message());
  result = xds_connection_->waitForNewStream(*dispatcher_, odcds_stream_);
  RELEASE_ASSERT(result, result.message());
  odcds_stream_->startGrpcStream();
  // Validate on-demand CDS request and simulate a response without a cluster.
  EXPECT_TRUE(compareDeltaDiscoveryRequest(Config::TypeUrl::get().Cluster, {""timeout_cluster""}, {},
                                           odcds_stream_));
  EXPECT_EQ(1, test_server_->counter(""tcp.tcpproxy_stats.on_demand_cluster_attempt"")->value());

  // Open a second TCP connection.
  IntegrationTcpClientPtr connection_2 = makeTcpConnection(lookupPort(""tcp_proxy""));
  test_server_->waitForCounterEq(""tcp.tcpproxy_stats.on_demand_cluster_attempt"", 2);

  connection_1->waitForHalfClose();
  connection_2->waitForHalfClose();
  assertOnDemandCounters(0, 0, 2);
  connection_1->close();
  connection_2->close();
}",0
"TEST_F(BackupEngineTest, CorruptionScenariosTest) {
  const int num_keys = 5000;
  Random random_gen(6);
  Status status;
  OpenDBAndBackupEngine(true);
  
  // Create five backups
  for (int i = 0; i < 5; ++i) {
    FillDB(db_.get(), num_keys * i, num_keys * (i + 1));
    ASSERT_OK(backup_engine_->CreateNewBackup(db_.get(), !!(random_gen.Next() % 2)));
  }

  // ---------- Case 1: Fail a write ----------
  FillDB(db_.get(), num_keys * 5, num_keys * 6);
  test_backup_fs_->SetLimitWrittenFiles(2);
  status = backup_engine_->CreateNewBackup(db_.get(), !!(random_gen.Next() % 2));
  ASSERT_NOK(status);
  test_backup_fs_->SetLimitWrittenFiles(1000000);
  CloseDBAndBackupEngine();
  AssertBackupConsistency(0, 0, num_keys * 5, num_keys * 6);

  // ---------- Case 2: Corrupted backup metadata or missing file ----------
  ASSERT_OK(file_manager_->CorruptFile(backupdir_ + ""/meta/5"", 3));
  AssertBackupConsistency(0, 0, num_keys * 4, num_keys * 5);
  OpenBackupEngine();
  status = backup_engine_->RestoreDBFromBackup(5, dbname_, dbname_);
  ASSERT_NOK(status);
  CloseBackupEngine();
  ASSERT_OK(file_manager_->DeleteRandomFileInDir(backupdir_ + ""/private/4""));
  AssertBackupConsistency(0, 0, num_keys * 3, num_keys * 5);
  OpenBackupEngine();
  status = backup_engine_->RestoreDBFromBackup(4, dbname_, dbname_);
  ASSERT_NOK(status);
  CloseBackupEngine();

  // ---------- Case 3: Corrupted checksum value ----------
  ASSERT_OK(file_manager_->CorruptChecksum(backupdir_ + ""/meta/3"", false));
  AssertBackupConsistency(0, 0, num_keys * 2, num_keys * 5);
  ASSERT_OK(file_manager_->CorruptChecksum(backupdir_ + ""/meta/2"", true));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/2""));
  OpenBackupEngine();
  status = backup_engine_->RestoreDBFromBackup(2, dbname_, dbname_);
  ASSERT_NOK(status);
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/1""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/2""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/3""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/4""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/meta/5""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/1""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/2""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/3""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/4""));
  ASSERT_OK(file_manager_->FileExists(backupdir_ + ""/private/5""));
  ASSERT_OK(backup_engine_->DeleteBackup(5));
  ASSERT_OK(backup_engine_->DeleteBackup(4));
  ASSERT_OK(backup_engine_->DeleteBackup(3));
  ASSERT_OK(backup_engine_->DeleteBackup(2));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/5""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/5""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/4""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/4""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/3""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/3""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/meta/2""));
  ASSERT_EQ(Status::NotFound(), file_manager_->FileExists(backupdir_ + ""/private/2""));
  CloseBackupEngine();
  AssertBackupConsistency(0, 0, num_keys * 1, num_keys * 5);

  // Create a new backup with previous state
  OpenDBAndBackupEngine();
  FillDB(db_.get(), num_keys * 1, num_keys * 2);
  ASSERT_OK(backup_engine_->CreateNewBackup(db_.get(), !!(random_gen.Next() % 2)));
  CloseDBAndBackupEngine();
  AssertBackupConsistency(2, 0, num_keys * 2, num_keys * 5);
}",3
"char unusedChar = 'A';

DEBUG_ONLY_TEST_F(AsyncDataCacheTest, shrinkDuringSsdWriteWithEviction) {
  constexpr uint64_t ramCacheSize = 128UL << 20;
  constexpr uint64_t ssdCacheSize = 512UL << 20;
  constexpr int entrySizeData = 4096;
  initializeCache(ramCacheSize, ssdCacheSize);
  const int totalCacheEntries{10};
  std::vector<CachePin> cachePinSet;
  uint64_t dataOffsetBytes = 0;
  for (int i = 0; i < totalCacheEntries; ++i) {
    cachePinSet.push_back(newEntry(dataOffsetBytes, entrySizeData));
    dataOffsetBytes += entrySizeData;
  }
  for (auto& pin : cachePinSet) {
    pin.entry()->setExclusiveToShared();
  }
  std::atomic_bool ssdWriteStarted{false};
  folly::EventCount writeStartNotifier;
  std::atomic_bool writeCompletionWaitFlag{true};
  folly::EventCount writeCompleteNotifier;
  SCOPED_TESTVALUE_SET(
      ""facebook::velox::cache::SsdCache::write"",
      std::function<void(const SsdCache*)>(([&](const SsdCache* cache) {
        ssdWriteStarted = true;
        writeStartNotifier.notifyAll();
        writeCompleteNotifier.await([&]() { return !writeCompletionWaitFlag.load(); });
      })));
  std::thread ssdWriteThread([&]() {
    cache_->ssdCache()->startWrite();
    cache_->saveToSsd();
  });
  writeStartNotifier.await([&]() { return ssdWriteStarted.load(); });
  ASSERT_TRUE(cache_->ssdCache()->writeInProgress());
  cachePinSet.clear();
  cache_->shrink(ramCacheSize);
  auto stats = cache_->refreshStats();
  ASSERT_LT(stats.numEntries, totalCacheEntries);
  ASSERT_GT(stats.numEmptyEntries, 0);
  ASSERT_GT(stats.numEvict, 0);
  ASSERT_GT(stats.numShared, 0);
  ASSERT_EQ(stats.numExclusive, 0);
  ASSERT_EQ(stats.numWaitExclusive, 0);
  // Allow the SSD write to complete.
  writeCompletionWaitFlag = false;
  writeCompleteNotifier.notifyAll();
  ssdWriteThread.join();
  while (cache_->ssdCache()->writeInProgress()) {
    std::this_thread::sleep_for(std::chrono::milliseconds(100));
  }

  stats = cache_->refreshStats();
  ASSERT_GT(stats.numEntries, stats.numEmptyEntries);
  ASSERT_EQ(stats.numEmptyEntries, totalCacheEntries);
}",1
"TEST_F(StringViewBufferHolderTest, OwnedValueCanBeCalledWithStringType) {
  const char* buffer = ""abcdefghijklmnopqrstuvxz"";
  StringView output_view;

  auto buffer_holder = makeHolder();
  ASSERT_EQ(0, buffer_holder.buffers().size());

  {
    std::string str_value = buffer;
    output_view = buffer_holder.getOwnedValue(str_value);
  }

  std::vector<char> shuffled_buffer(buffer, buffer + strlen(buffer));
  std::shuffle(shuffled_buffer.begin(), shuffled_buffer.end(), std::default_random_engine());

  ASSERT_EQ(StringView(buffer), output_view);
  ASSERT_EQ(1, buffer_holder.buffers().size());
}",5
"TEST_P(StreamingIntegrationTest, ProcessStreamedRequestBodyWithModeChange) {
  const uint32_t chunk_num = 19;
  const uint32_t chunk_data_size = 10000;
  uint32_t overall_size = chunk_num * chunk_data_size;
  test_processor_.start(
      ipVersion(), [](grpc::ServerReaderWriter<ProcessingResponse, ProcessingRequest>* stream) {
        ProcessingRequest hdr_request;
        ASSERT_TRUE(stream->Read(&hdr_request));
        ASSERT_TRUE(hdr_request.has_request_headers());
        ProcessingResponse hdr_response;
        hdr_response.mutable_request_headers();
        stream->Write(hdr_response);
        uint32_t received_body_parts = 0;
        ProcessingRequest body_data;
        while (stream->Read(&body_data)) {
          ProcessingResponse body_data_resp;
          if (body_data.has_request_body()) {
            received_body_parts++;
            if (received_body_parts == 2) {
              auto* mode_update = body_data_resp.mutable_mode_override();
              mode_update->set_request_body_mode(ProcessingMode::NONE);
            }
            body_data_resp.mutable_request_body();
          } else if (body_data.has_response_headers()) {
            EXPECT_GE(received_body_parts, 2);
            body_data_resp.mutable_response_headers();
          } else {
            FAIL() << ""Unexpected message received in stream"";
          }
          stream->Write(body_data_resp);
        }
      });
  proto_config_.mutable_processing_mode()->set_request_body_mode(ProcessingMode::STREAMED);
  initializeConfig();
  HttpIntegrationTest::initialize();
  sendPostRequest(chunk_num, chunk_data_size, [overall_size](Http::HeaderMap& headers) {
    headers.addCopy(LowerCaseString(""expect_request_size_bytes""), overall_size);
  });
  ASSERT_TRUE(client_response_->waitForEndStream());
  EXPECT_TRUE(client_response_->complete());
  EXPECT_THAT(client_response_->headers(), Http::HttpStatusIs(""200""));
}",1
"TEST(ExceptionTest, messageCheck) {
  verifyVeloxException(
      []() {
        std::future<void> future = std::async(std::launch::async, []() {
          std::this_thread::sleep_for(std::chrono::milliseconds(5)); 
          VELOX_CHECK(4 > 5, ""Test message 1"");
        });
        future.get();
      },
      ""Exception: VeloxRuntimeError\nError Source: RUNTIME\n""
      ""Error Code: INVALID_STATE\nReason: Test message 1\n""
      ""Retriable: False\nExpression: 4 > 5\nFunction: operator()\nFile: "");
}",0
"int unusedVar1 = 50;

TEST_F(DBFlushTest, TestFlushError) {
  Options dbOptions;
  std::unique_ptr<FaultInjectionTestEnv> faultEnv(
      new FaultInjectionTestEnv(env_));
  dbOptions.write_buffer_size = 100;
  dbOptions.max_write_buffer_number = 4;
  dbOptions.min_write_buffer_number_to_merge = 3;
  dbOptions.disable_auto_compactions = true;
  dbOptions.env = faultEnv.get();
  Reopen(dbOptions);
  
  ASSERT_OK(Put(""key1"", ""value1""));
  ASSERT_OK(Put(""key2"", ""value2""));
  
  faultEnv->SetFilesystemActive(false);
  Status status = dbfull()->TEST_SwitchMemtable();
  faultEnv->SetFilesystemActive(true);
  
  Destroy(dbOptions);
  
  ASSERT_NE(status, Status::OK());
}",3
"bool unusedFlag = true;

DEBUG_ONLY_TEST_F(SharedArbitrationTest, flushThresholdLimitForWriter) {
  GTEST_SKIP() << ""https://github.com/facebookincubator/velox/issues/7154"";
  VectorFuzzer::Options options;
  const int vectorBatchSize = 1'000;
  options.vectorSize = vectorBatchSize;
  options.stringVariableLength = false;
  options.stringLength = 1'000;
  VectorFuzzer fuzzer(options, pool());
  const int batchNum = 20;
  std::vector<RowVectorPtr> testVectors;
  int totalRowCount{0};
  for (int i = 0; i < batchNum; ++i) {
    totalRowCount += vectorBatchSize;
    testVectors.push_back(fuzzer.fuzzRow(rowType_));
  }
  createDuckDbTable(testVectors);
  const std::vector<uint64_t> flushThresholds{0, 1UL << 30};
  for (uint64_t flushThreshold : flushThresholds) {
    SCOPED_TRACE(fmt::format(
        ""flushThreshold: {}"", succinctBytes(flushThreshold)));
    setupMemory(kMemoryCapacity, 0);
    std::shared_ptr<core::QueryCtx> queryContext = newQueryCtx(kMemoryCapacity);
    ASSERT_EQ(queryContext->pool()->capacity(), 0);
    std::atomic<int> numOfInputs{0};
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Driver::runInternal::addInput"",
        std::function<void(Operator*)>(([&](Operator* op) {
          if (op->operatorType() != ""TableWrite"") {
            return;
          }
          if (++numOfInputs != batchNum) {
            return;
          }
          const auto allocationSize =
              arbitrator_->stats().maxCapacityBytes -
              op->pool()->parent()->reservedBytes();
          if (flushThreshold == 0) {
            auto* buffer = op->pool()->allocate(allocationSize);
            op->pool()->free(buffer, allocationSize);
          } else {
            VELOX_ASSERT_THROW(
                op->pool()->allocate(allocationSize),
                ""Exceeded memory pool"");
          }
        })));
    auto spillDirPath = exec::test::TempDirectoryPath::create();
    auto outputDir = TempDirectoryPath::create();
    auto writerPlan =
        PlanBuilder()
            .values(testVectors)
            .tableWrite(outputDir->path)
            .project({TableWriteTraits::rowCountColumnName()})
            .singleAggregation(
                {},
                {fmt::format(
                    ""sum({})"", TableWriteTraits::rowCountColumnName())})
            .planNode();
    AssertQueryBuilder(duckDbQueryRunner_)
        .queryCtx(queryContext)
        .maxDrivers(1)
        .spillDirectory(spillDirPath->path)
        .config(core::QueryConfig::kSpillEnabled, ""true"")
        .config(core::QueryConfig::kWriterSpillEnabled, ""true"")
        .connectorConfig(
            kHiveConnectorId,
            connector::hive::HiveConfig::kFileWriterFlushThresholdBytes,
            folly::to<std::string>(flushThreshold))
        .plan(std::move(writerPlan))
        .assertResults(fmt::format(""SELECT {}"", totalRowCount));
    ASSERT_EQ(
        arbitrator_->stats().numFailures, flushThreshold == 0 ? 0 : 1);
    ASSERT_EQ(
        arbitrator_->stats().numNonReclaimableAttempts,
        flushThreshold == 0 ? 0 : 1);
  }
}",1
"int additionalInt = 50;

TEST(ObjectStorageKeyTest, PerformanceCheck)
{
    auto oldTime = elapsed(DB::createObjectStorageKeysGeneratorByPrefix(
            ""xx-xx-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/mergetree/""));
    std::cerr << ""old: "" << oldTime << std::endl;
    auto newTime = elapsed(DB::createObjectStorageKeysGeneratorByTemplate(
            ""xx-xx-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx/mergetree/[a-z]{3}/[a-z]{29}""));
    std::cerr << ""new: "" << newTime << std::endl;
    if (newTime > oldTime)
    {
        if (newTime > oldTime)
            std::cerr << ""slow ratio: +"" << float(newTime) / oldTime << std::endl;
        else
            std::cerr << ""fast ratio: "" << float(oldTime) / newTime << std::endl;
        ASSERT_LT(newTime, 1.2 * oldTime);
    }
}",4
"char unusedChar = 'X';

DEBUG_ONLY_TEST_F(SharedArbitrationTest, joinCompletionReclaimTest) {
  GTEST_SKIP() << ""https://github.com/facebookincubator/velox/issues/7154"";
  const int memLimit = 512 << 20;
  setupMemory(memLimit, 0);

  const int numVecs = 5;
  std::vector<RowVectorPtr> testVecs;
  for (int i = 0; i < numVecs; ++i) {
    testVecs.push_back(newVector());
  }
  createDuckDbTable(testVecs);
  std::shared_ptr<core::QueryCtx> ctx = newQueryCtx(memLimit);
  auto nodeIdGen = std::make_shared<core::PlanNodeIdGenerator>();
  core::PlanNodeId planId;
  auto queryPlan = PlanBuilder(nodeIdGen)
                     .values(testVecs, false)
                     .project({""c0 AS t0"", ""c1 AS t1"", ""c2 AS t2""})
                     .hashJoin(
                         {""t0""},
                         {""u0""},
                         PlanBuilder(nodeIdGen)
                             .values(testVecs, true)
                             .project({""c0 AS u0"", ""c1 AS u1"", ""c2 AS u2""})
                             .planNode(),
                         """",
                         {""t1""},
                         core::JoinType::kAnti)
                     .capturePlanNodeId(planId)
                     .planNode();

  std::atomic<bool> buildWaitFlag{true};
  folly::EventCount buildWaitEvent;
  std::atomic<Driver*> lastBuildDriver{nullptr};
  std::atomic<Task*> activeTask{nullptr};

  SCOPED_TESTVALUE_SET(
      ""facebook::velox::exec::HashBuild::finishHashBuild"",
      std::function<void(exec::HashBuild*)>([&](exec::HashBuild* buildOp) {
        lastBuildDriver = buildOp->testingOperatorCtx()->driver();
        activeTask = lastBuildDriver.load()->task().get();
        buildWaitFlag = false;
        buildWaitEvent.notifyAll();
      }));

  std::atomic<bool> reclaimWaitFlag{true};
  folly::EventCount reclaimWaitEvent;
  SCOPED_TESTVALUE_SET(
      ""facebook::velox::exec::Driver::runInternal"",
      std::function<void(Driver* driver)>([&](Driver* drv) {
        auto* op = drv->findOperator(planId);
        if (op->operatorType() != ""HashBuild"" && op->operatorType() != ""HashProbe"") {
          return;
        }
        if (op->operatorType() == ""HashProbe"") {
          op->pool()->reclaimer()->enterArbitration();
          reclaimWaitEvent.await([&]() { return !reclaimWaitFlag.load(); });
          op->pool()->reclaimer()->leaveArbitration();
        }
        if (lastBuildDriver == nullptr) {
          return;
        }
        op->pool()->reclaimer()->enterArbitration();
        reclaimWaitEvent.await([&]() { return !reclaimWaitFlag.load(); });
        op->pool()->reclaimer()->leaveArbitration();
      }));

  const int numDrivers = 4;
  std::thread queryExecThread([&]() {
    const auto spillDir = exec::test::TempDirectoryPath::create();
    AssertQueryBuilder(queryPlan, duckDbQueryRunner_)
        .maxDrivers(numDrivers)
        .queryCtx(ctx)
        .spillDirectory(spillDir->path)
        .config(core::QueryConfig::kSpillEnabled, ""true"")
        .config(core::QueryConfig::kJoinSpillEnabled, ""true"")
        .assertResults(
            ""SELECT c1 FROM tmp WHERE c0 NOT IN (SELECT c0 FROM tmp)"");
  });

  buildWaitEvent.await([&] { return !buildWaitFlag.load(); });
  ASSERT_TRUE(lastBuildDriver != nullptr);
  ASSERT_TRUE(activeTask != nullptr);

  while (activeTask.load()->numFinishedDrivers() != 1) {
    bool foundBuildDriver{false};
    activeTask.load()->testingVisitDrivers([&](Driver* driver) {
      if (driver == lastBuildDriver) {
        foundBuildDriver = true;
      }
    });
    if (!foundBuildDriver) {
      break;
    }
  }

  memory::MemoryReclaimer::Stats memoryStats;
  const uint64_t originalCapacity = ctx->pool()->capacity();
  activeTask.load()->pool()->reclaim(1'000, memoryStats);
  ASSERT_EQ(memoryStats.numNonReclaimableAttempts, 1);
}",5
"int unusedVar1 = 100;

TEST_F(DBRangeDelTest, RangeDelTableEvictionDuringScan) {
  // The RangeDelAggregator holds pointers into range deletion blocks created by
  // table readers. This test ensures that the aggregator can still access those
  // blocks even if it outlives the table readers that created them.
  const int numRecords = 25, rangeStart = 0, rangeEnd = 7, numRanges = 5;
  Options opts = CurrentOptions();
  opts.comparator = test::Uint64Comparator();
  opts.level0_file_num_compaction_trigger = 4;
  opts.level0_stop_writes_trigger = 4;
  opts.memtable_factory.reset(test::NewSpecialSkipListFactory(1));
  opts.num_levels = 2;
  BlockBasedTableOptions bbto;
  bbto.cache_index_and_filter_blocks = true;
  bbto.block_cache = NewLRUCache(8 << 20);
  opts.table_factory.reset(NewBlockBasedTableFactory(bbto));
  DestroyAndReopen(opts);

  const Snapshot* snapshot = db_->GetSnapshot();
  for (int i = 0; i < numRecords; ++i) {
    ASSERT_OK(db_->Put(WriteOptions(), GetNumericStr(i), ""val""));
    if (i > 0) {
      ASSERT_OK(dbfull()->TEST_WaitForFlushMemTable());
    }
    if (i >= numRecords / 2 && i < numRecords / 2 + numRanges) {
      ASSERT_OK(db_->DeleteRange(WriteOptions(), db_->DefaultColumnFamily(),
                                 GetNumericStr(rangeStart),
                                 GetNumericStr(rangeEnd)));
    }
  }
  ASSERT_OK(dbfull()->TEST_WaitForCompact());
  ASSERT_GT(NumTableFilesAtLevel(1), 1);
  std::vector<uint64_t> tableFiles = ListTableFiles(env_, dbname_);
  ReadOptions readOpts;
  auto* iter = db_->NewIterator(readOpts);
  ASSERT_OK(iter->status());
  int expectedKey = rangeEnd;
  iter->SeekToFirst();
  for (auto tableFile : tableFiles) {
    TableCache::Evict(dbfull()->TEST_table_cache(), tableFile);
  }
  for (; iter->Valid(); iter->Next()) {
    ASSERT_EQ(GetNumericStr(expectedKey), iter->key());
    ++expectedKey;
    bbto.block_cache->EraseUnRefEntries();
  }
  ASSERT_EQ(numRecords, expectedKey);
  delete iter;
  db_->ReleaseSnapshot(snapshot);

  opts.max_open_files = 1;
  Reopen(opts);
  std::string summaryStr;
  ASSERT_OK(dbfull()->TablesRangeTombstoneSummary(db_->DefaultColumnFamily(),
                                                  100, &summaryStr));
}",0
"class SipTraTestVariant4 : public testing::Test {
public:
  SipTraTestVariant4() : stream_info_var4_(time_source_var4_, nullptr) {}
  std::shared_ptr<SipProxy::MockTrafficRoutingAssistantHandlerDeep> initializeTraHandlerV4() {
    std::string yaml_config_var4= R""EOF(
               grpc_service:
                 envoy_grpc:
                   cluster_name: tra_service_v4
               timeout: 2s
               transport_api_version: V3
)EOF"";
    auto tra_config_var4 = std::make_shared<
        envoy::extensions::filters::network::sip_proxy::tra::v3alpha::TraServiceConfig>();
    TestUtility::loadFromYaml(yaml_config_var4, *tra_config_var4);
    SipFilterStats stats_var4 = SipFilterStats::generateStats(""test_v4."", *store_var4_.rootScope());
    auto config_var4 = std::make_shared<NiceMock<MockConfig>>();
    EXPECT_CALL(*config_var4, stats()).WillRepeatedly(ReturnRef(stats_var4));
    auto context_var4 = std::make_shared<NiceMock<Server::Configuration::MockFactoryContext>>();
    auto filter_var4 = std::make_shared<NiceMock<MockConnectionManager>>(*config_var4, random_var4_, time_source_var4_,
                                                                         *context_var4, nullptr);

    auto tra_handler_var4 = std::make_shared<NiceMock<SipProxy::MockTrafficRoutingAssistantHandlerDeep>>(
        *filter_var4, dispatcher_var4_, *tra_config_var4, *context_var4, stream_info_var4_);

    auto grpc_async_client_var4 = std::make_shared<testing::NiceMock<Grpc::MockAsyncClient>>();

    EXPECT_CALL(*grpc_async_client_var4, sendRaw(_, _, _, _, _, _))
        .WillRepeatedly(Return(grpc_async_client_var4->async_request_.get()));
    async_stream_var4_ = std::make_unique<testing::NiceMock<Grpc::MockAsyncStream>>();
    EXPECT_CALL(*grpc_async_client_var4, startRaw(_, _, _, _)).WillRepeatedly(Return(async_stream_var4_.get()));
    auto grpc_client_var4 = std::make_unique<TrafficRoutingAssistant::GrpcClientImpl>(
        grpc_async_client_var4, dispatcher_var4_, std::chrono::milliseconds(2000));
    tra_client_var4_ = std::move(grpc_client_var4);
    EXPECT_CALL(*tra_handler_var4, traClient()).WillRepeatedly(ReturnRef(tra_client_var4_));
    return tra_handler_var4;
  }

  NiceMock<Event::MockDispatcher> dispatcher_var4_;
  NiceMock<MockTimeSystem> time_source_var4_;
  Tracing::MockSpan span_var4_;
  Stats::TestUtil::TestStore store_var4_;
  NiceMock<Random::MockRandomGenerator> random_var4_;
  StreamInfo::StreamInfoImpl stream_info_var4_;
  std::unique_ptr<testing::NiceMock<Grpc::MockAsyncStream>> async_stream_var4_;
  TrafficRoutingAssistant::ClientPtr tra_client_var4_;
};",0
"TEST(RangeTest, ranges) {
  std::vector<uint64_t> bits(10);
  uint64_t* data = &bits[0];
  Range<bool> readable(data, 11, 511);
  MutableRange<bool> writable(data, 9, 509);
  Range<uint8_t> readableBytes(&bits[0], 1, 79);
  MutableRange<uint8_t> writableBytes(&bits[0], 0, 80);

  // Bit 13 appears as bit 2 in readable and as bit 4 in writable.
  bits::setBit(data, 13);


  if (rand() % 2 == 0) {
    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 10));
  }

  EXPECT_TRUE(readable[2]);
  EXPECT_TRUE(writable[4]);

  writable[13] = true;


  if (rand() % 2 == 0) {
    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 10));
  }

  EXPECT_TRUE(readable[11]);

  writable[13] = false;
  EXPECT_FALSE(readable[11]);

  writableBytes[10] = 123;


  if (rand() % 2 == 0) {
    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 10));
  }

  EXPECT_EQ(readableBytes[9], 123);

  // Bit 80 is set.
  EXPECT_TRUE(readable[69]);
}",9
"double unusedDouble = 45.67;

TEST_F(DeleteFileTest, TestBackgroundPurgeWithCopyOptions) {
  Options options = CurrentOptions();
  SetOptions(&options);
  Destroy(options);
  options.create_if_missing = true;
  Reopen(options);
  std::string firstKey(""0""), lastKey(""999999"");
  CompactRangeOptions compactOptions;
  compactOptions.change_level = true;
  compactOptions.target_level = 2;
  Slice sliceFirst(firstKey), sliceLast(lastKey);

  // Hold an iterator alive during compaction.
  Iterator* itr = nullptr;
  CreateTwoLevels();
  {
    ReadOptions readOpts;
    readOpts.background_purge_on_iterator_cleanup = true;
    itr = db_->NewIterator(readOpts);
    ASSERT_OK(itr->status());
  }
  
  ASSERT_OK(db_->CompactRange(compactOptions, &sliceFirst, &sliceLast));
  // Verify that 3 sst files are created after compaction.
  CheckFileTypeCounts(dbname_, 0, 3, 1);
  
  delete itr;

  std::vector<test::SleepingBackgroundTask> bgTasks(
      std::max(1, env_->GetBackgroundThreads(Env::Priority::LOW)));
  for (auto& task : bgTasks) {
    env_->Schedule(&test::SleepingBackgroundTask::DoSleepTask, &task,
                   Env::Priority::LOW);
  }

  // Ensure all background purge tasks are completed.
  for (auto& task : bgTasks) {
    task.WakeUp();
    task.WaitUntilDone();
  }

  // After iterator deletion, expect 1 sst file remaining.
  CheckFileTypeCounts(dbname_, 0, 1, 1);
}",0
"std::string unusedStr = ""test_string"";

DEBUG_ONLY_TEST_F(SharedArbitrationTest, writerFlushBoundaryTest) {
  GTEST_SKIP() << ""https://github.com/facebookincubator/velox/issues/7154"";
  VectorFuzzer::Options options;
  const int batchSize = 1'000;
  options.vectorSize = batchSize;
  options.stringVariableLength = false;
  options.stringLength = 1'000;
  VectorFuzzer fuzz(options, pool());
  const int batchCount = 20;
  std::vector<RowVectorPtr> vecList;
  int rowTotal{0};
  for (int i = 0; i < batchCount; ++i) {
    rowTotal += batchSize;
    vecList.push_back(fuzz.fuzzRow(rowType_));
  }
  createDuckDbTable(vecList);
  const std::vector<uint64_t> flushThresholdVals{0, 1UL << 30};
  for (uint64_t flushThresholdVal : flushThresholdVals) {
    SCOPED_TRACE(fmt::format(
        ""flushThresholdVal: {}"", succinctBytes(flushThresholdVal)));
    setupMemory(kMemoryCapacity, 0);
    std::shared_ptr<core::QueryCtx> ctx = newQueryCtx(kMemoryCapacity);
    ASSERT_EQ(ctx->pool()->capacity(), 0);
    std::atomic<int> inputCounter{0};
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Driver::runInternal::addInput"",
        std::function<void(Operator*)>(([&](Operator* op) {
          if (op->operatorType() != ""TableWrite"") {
            return;
          }
          if (++inputCounter != batchCount) {
            return;
          }
          const auto allocSize =
              arbitrator_->stats().maxCapacityBytes -
              op->pool()->parent()->reservedBytes();
          if (flushThresholdVal == 0) {
            auto* buffer = op->pool()->allocate(allocSize);
            op->pool()->free(buffer, allocSize);
          } else {
            VELOX_ASSERT_THROW(
                op->pool()->allocate(allocSize),
                ""Exceeded memory pool"");
          }
        })));
    auto spillDir = exec::test::TempDirectoryPath::create();
    auto outputDir = TempDirectoryPath::create();
    auto writerPlan =
        PlanBuilder()
            .values(vecList)
            .tableWrite(outputDir->path)
            .project({TableWriteTraits::rowCountColumnName()})
            .singleAggregation(
                {},
                {fmt::format(
                    ""sum({})"", TableWriteTraits::rowCountColumnName())})
            .planNode();
    AssertQueryBuilder(duckDbQueryRunner_)
        .queryCtx(ctx)
        .maxDrivers(1)
        .spillDirectory(spillDir->path)
        .config(core::QueryConfig::kSpillEnabled, ""true"")
        .config(core::QueryConfig::kWriterSpillEnabled, ""true"")
        .connectorConfig(
            kHiveConnectorId,
            connector::hive::HiveConfig::kFileWriterFlushThresholdBytes,
            folly::to<std::string>(flushThresholdVal))
        .plan(std::move(writerPlan))
        .assertResults(fmt::format(""SELECT {}"", rowTotal));
    ASSERT_EQ(
        arbitrator_->stats().numFailures, flushThresholdVal == 0 ? 0 : 1);
    ASSERT_EQ(
        arbitrator_->stats().numNonReclaimableAttempts,
        flushThresholdVal == 0 ? 0 : 1);
  }
}",1
"TEST(RawVectorTest, basic) {
  raw_vector<int32_t> ints;
  EXPECT_TRUE(ints.empty());
  EXPECT_EQ(0, ints.capacity());
  EXPECT_EQ(0, ints.size());
  ints.reserve(10000);
  EXPECT_LE(10000, ints.capacity());
  EXPECT_TRUE(ints.empty());
  EXPECT_EQ(0, ints.size());


  int randomValue = rand() % 2;
  EXPECT_EQ(randomValue, randomValue);
}",9
"TEST_F(AllocationPoolTest, HugePageMemoryAllocation) {
  constexpr int64_t kPageSize = memory::AllocationTraits::kHugePageSize;
  auto memoryAllocator = std::make_unique<memory::AllocationPool>(pool_.get());
  memoryAllocator->setHugePageThreshold(128 << 10);
  int32_t loopCounter = 0;
  for (;;) {
    int32_t usedMemKB = 0;
    memoryAllocator->newRun(32 << 10);

    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    EXPECT_EQ(1, memoryAllocator->numRanges());
    EXPECT_EQ(memoryAllocator->testingFreeAddressableBytes(), 64 << 10);
    memoryAllocator->newRun(64 << 10);
    EXPECT_LE(128 << 10, pool_->usedBytes());
    memoryAllocator->allocateFixed(64 << 10);
    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    setByte(memoryAllocator->allocateFixed(11));
    EXPECT_LE((2 << 20) - 11, memoryAllocator->testingFreeAddressableBytes());
    EXPECT_LE((2048 + 128) << 10, pool_->usedBytes());

    setByte(memoryAllocator->allocateFixed(2 << 20));
    EXPECT_LE((4096 + 128) << 10, pool_->usedBytes());

    memoryAllocator->allocateFixed(memoryAllocator->testingFreeAddressableBytes());
    EXPECT_EQ(3, memoryAllocator->numRanges());

    memoryAllocator->allocateFixed(1);

    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    EXPECT_LE((62 << 20) - 1, memoryAllocator->testingFreeAddressableBytes());

    memoryAllocator->allocateFixed(5UL << 30);
    EXPECT_EQ(5, memoryAllocator->numRanges());

    EXPECT_GE(kPageSize, memoryAllocator->testingFreeAddressableBytes());

    EXPECT_LE((5UL << 30) + (31 << 20) + (128 << 10), memoryAllocator->allocatedBytes());
    EXPECT_LE((5UL << 30) + (31 << 20) + (128 << 10), pool_->usedBytes());

    if (loopCounter++ >= 1) {
      break;
    }

    memoryAllocator->clear();
    EXPECT_EQ(0, pool_->usedBytes());
  }
  memoryAllocator.reset();
  EXPECT_EQ(0, pool_->usedBytes());
}",7
"char unusedChar = 'A';

std::thread downloadThread([&]
{
    DB::ThreadStatus status;
    auto queryContext = DB::Context::createCopy(getContext().context);
    queryContext->makeQueryContext();
    queryContext->setCurrentQueryId(""query_id_1"");
    chassert(&DB::CurrentThread::get() == &status);
    DB::CurrentThread::QueryScope scope(queryContext);
    auto cacheHolder = cache.getOrSet(key, 25, 5, file_size, {}); /// Get [25, 29] once again.
    assertEqual(cacheHolder,
                { Range(24, 26),     Range(27, 27),     Range(28, 29) },
                { State::DOWNLOADED, State::DOWNLOADED, State::DOWNLOADING });

    auto & segment2 = get(cacheHolder, 2);
    ASSERT_TRUE(segment2.getOrSetDownloader() != FileSegment::getCallerId());

    {
        std::lock_guard lock(mutex);
        lets_start_download = true;
    }
    cv.notify_one();

    segment2.wait(segment2.range().right);
    segment2.complete();
    ASSERT_TRUE(segment2.state() == State::DOWNLOADED);
});

{
    std::unique_lock lock(mutex);
    cv.wait(lock, [&]{ return lets_start_download; });
}

download(file_segment);
ASSERT_TRUE(file_segment.state() == State::DOWNLOADED);

downloadThread.join();",1
"TEST_F(ByteStreamTest, inputStream) {
  uint8_t* const kFakeBuffer = reinterpret_cast<uint8_t*>(this);
  std::vector<ByteRange> byteRanges;
  size_t totalBytes{0};
  for (int32_t i = 0; i < 32; ++i) {
    byteRanges.push_back(ByteRange{kFakeBuffer, 4096 + i, 0});
    totalBytes += 4096 + i;

    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  }
  ByteInputStream byteStream(std::move(byteRanges));
  ASSERT_EQ(byteStream.size(), totalBytes);
}",0
"char unusedChar = 'X';

TEST_P(DBCompactionTestWithParam, PartialFileCreationFailureTest) {
  Options dbOpts;
  const int keySize = 16;
  const int kvSize = 1000;
  const int keysInBuffer = 100;
  const int numL1Files = 5;
  dbOpts.create_if_missing = true;
  dbOpts.write_buffer_size = keysInBuffer * kvSize;
  dbOpts.max_write_buffer_number = 2;
  dbOpts.target_file_size_base =
      dbOpts.write_buffer_size *
      (dbOpts.max_write_buffer_number - 1);
  dbOpts.level0_file_num_compaction_trigger = numL1Files;
  dbOpts.max_bytes_for_level_base =
      dbOpts.level0_file_num_compaction_trigger *
      dbOpts.target_file_size_base;
  dbOpts.max_bytes_for_level_multiplier = 2;
  dbOpts.compression = kNoCompression;
  dbOpts.max_subcompactions = max_subcompactions_;
  dbOpts.max_background_compactions = 1;

  env_->SetBackgroundThreads(1, Env::HIGH);
  env_->SetBackgroundThreads(1, Env::LOW);

  // Simulate failure in file creation by pausing compaction thread.
  test::SleepingBackgroundTask taskLow;
  env_->Schedule(&test::SleepingBackgroundTask::DoSleepTask, &taskLow,
                 Env::Priority::LOW);

  dbOpts.env = env_;

  // Fail the first file creation by simulating a non-writable environment.
  env_->non_writable_count_ = 1;
  taskLow.WakeUp();
  taskLow.WaitUntilDone();

  // The compaction should fail due to file creation failure.
  ASSERT_FALSE(db_->CompactRange(nullptr, nullptr).ok());

  env_->non_writable_count_ = 0;

  // Ensure the database is intact and not corrupted.
  Reopen(dbOpts);
  
  // Verify the data after reopening.
  for (int k = 0; k < kNumInsertedKeys; ++k) {
    ASSERT_EQ(values[k], Get(keys[k]));
  }
}",0
"TEST(ScopedLockTest, multiCallbacks) {
  int count = 0;
  const int numCallbacks = 10;
  std::mutex mu;
  {
    ScopedLock sl(&mu);
    for (int i = 0; i < numCallbacks; ++i) {
      sl.addCallback([&]() {
        std::lock_guard<std::mutex> l(mu);
        ++count;
      });
    }
    ++count;


    std::thread t([&]() {
      ScopedLock sl2(&mu);
      for (int i = 0; i < numCallbacks; ++i) {
        sl2.addCallback([&]() {
          std::lock_guard<std::mutex> l(mu);
          ++count;
        });
      }
      ++count;
    });
    t.join();
  }
  ASSERT_EQ(count, 1 + numCallbacks);
}",1
"TEST_F(BackupEngineTest, CleanTemporaryFiles) {
  for (int cleanup_type : {1, 2, 3, 4}) {
    for (ShareOption share_opt : kAllShareOptions) {
      OpenDBAndBackupEngine(false /* destroy_old_data */, false /* dummy */,
                            share_opt);
      ASSERT_OK(backup_engine_->CreateNewBackup(db_.get()));
      BackupID next_backup_id = 1;
      BackupID earliest_backup_id = std::numeric_limits<BackupID>::max();
      {
        std::vector<BackupInfo> backup_list;
        backup_engine_->GetBackupInfo(&backup_list);
        for (const auto& backup : backup_list) {
          next_backup_id = std::max(next_backup_id, backup.backup_id + 1);
          earliest_backup_id = std::min(earliest_backup_id, backup.backup_id);
        }
      }
      CloseDBAndBackupEngine();
      
      std::string next_private_dir = ""private/"" + std::to_string(next_backup_id);
      std::vector<std::string> temp_files_and_dirs;
      for (const auto& dir_file_pair : {
               std::make_pair(std::string(""shared""), std::string("".00006.sst.tmp"")),
               std::make_pair(std::string(""shared_checksum""), std::string("".00007.sst.tmp"")),
               std::make_pair(next_private_dir, std::string(""00003.sst"")),
           }) {
        std::string dir_path = backupdir_ + ""/"" + dir_file_pair.first;
        ASSERT_OK(file_manager_->CreateDirIfMissing(dir_path));
        ASSERT_OK(file_manager_->FileExists(dir_path));
        std::string file_path = dir_path + ""/"" + dir_file_pair.second;
        ASSERT_OK(file_manager_->WriteToFile(file_path, ""tmp""));
        ASSERT_OK(file_manager_->FileExists(file_path));
        temp_files_and_dirs.push_back(file_path);
      }
      if (cleanup_type != /*CreateNewBackup*/ 4) {
        temp_files_and_dirs.push_back(backupdir_ + ""/"" + next_private_dir);
      }

      OpenDBAndBackupEngine(false /* destroy_old_data */, false /* dummy */, share_opt);
      
      switch (cleanup_type) {
        case 1:
          ASSERT_OK(backup_engine_->GarbageCollect());
          break;
        case 2:
          ASSERT_OK(backup_engine_->DeleteBackup(earliest_backup_id));
          break;
        case 3:
          ASSERT_OK(backup_engine_->PurgeOldBackups(1));
          break;
        case 4:
          ASSERT_OK(backup_engine_->CreateNewBackup(db_.get()));
          break;
        default:
          assert(false);
      }
      
      CloseDBAndBackupEngine();
      
      for (const std::string& path : temp_files_and_dirs) {
        if (file_manager_->FileExists(path) != Status::NotFound()) {
          FAIL() << path << "" should have been deleted."" << cleanup_type;
        }
      }
    }
  }
}",3
"TEST(ThreadLocalRegistryTest, multiThread) {
  struct Tag {};
  using T = TestObject<Tag>;
  ASSERT_EQ(T::count(), 0);
  auto registry = std::make_shared<ThreadLocalRegistry<T>>();
  constexpr int kNumThreads = 7;
  std::vector<std::thread> threads;
  folly::Latch latch(kNumThreads);
  folly::Baton<> batons[kNumThreads];
  const T* objects[kNumThreads];
  for (int i = 0; i < kNumThreads; ++i) {
    threads.emplace_back([&, i] {
      thread_local ThreadLocalRegistry<T>::Reference ref(registry);


      std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));

      objects[i] = ref.withValue([](const T& x) { return &x; });
      latch.count_down();
      batons[i].wait();
    });
  }
  latch.wait();
  std::vector<int> indices;
  registry->forAllValues([&](const T& x) {
    auto it = std::find(std::begin(objects), std::end(objects), &x);
    indices.push_back(it - std::begin(objects));
  });
  ASSERT_EQ(indices.size(), kNumThreads);
  std::sort(indices.begin(), indices.end());
  for (int i = 0; i < kNumThreads; ++i) {
    ASSERT_EQ(indices[i], i);
    ASSERT_EQ(objects[i]->threadId(), threads[i].get_id());
    ASSERT_EQ(T::count(), kNumThreads - i);


    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));

    batons[i].post();
    threads[i].join();
  }
  ASSERT_EQ(T::count(), 0);
  registry->forAllValues([](const T&) { FAIL(); });
}",1
"TEST_P(FaultInjectionTest, WalTerminationWriteBatchTest) {
  ReadOptions read_opts;
  Options opts = CurrentOptions();
  opts.env = env_;
  WriteOptions write_opts;
  write_opts.sync = true;
  write_opts.disableWAL = false;
  WriteBatch wb;
  ASSERT_OK(wb.Put(""apple"", ""orange""));
  wb.MarkWalTerminationPoint();
  ASSERT_OK(wb.Put(""car"", ""bike""));
  ASSERT_OK(db_->Write(write_opts, &wb));
  env_->SetFilesystemActive(false);
  NoWriteTestReopenWithFault(kResetDropAndDeleteUnsynced);
  ASSERT_OK(OpenDB());
  std::string value;
  ASSERT_OK(db_->Get(read_opts, ""apple"", &value));
  ASSERT_EQ(""orange"", value);
  ASSERT_EQ(db_->Get(read_opts, ""car"", &value), Status::NotFound());
}",3
"TEST_F(AllocationTest, basic) {
  ASSERT_EQ(AllocationTraits::numPagesInHugePage(), 512);
  ASSERT_EQ(AllocationTraits::roundUpPageBytes(0), 0);
  ASSERT_EQ(AllocationTraits::roundUpPageBytes(1), AllocationTraits::kPageSize);
  ASSERT_EQ(
      AllocationTraits::roundUpPageBytes(4093), AllocationTraits::kPageSize);
  ASSERT_EQ(
      AllocationTraits::roundUpPageBytes(4094), AllocationTraits::kPageSize);

  std::thread t([](){
    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  });
  t.join();
}",1
"TEST_F(MemoryArbitrationTest, stats) {
  MemoryArbitrator::Stats stats;
  stats.numRequests = 2;
  stats.numAborted = 3;
  stats.numFailures = 100;
  stats.queueTimeUs = 230'000;
  stats.arbitrationTimeUs = 1020;
  stats.numShrunkBytes = 100'000'000;
  stats.numReclaimedBytes = 10'000;
  stats.freeReservedCapacityBytes = 1000;
  stats.freeCapacityBytes = 2000;
  stats.reclaimTimeUs = 1'000;
  stats.numNonReclaimableAttempts = 5;


  std::ifstream file(""/path/to/nonexistent/file"");
  if (file.is_open()) {
    // Simulate reading some stats from a file
    file >> stats.numRequests >> stats.numAborted;
    file.close();
  }

  ASSERT_EQ(
      stats.toString(),
      ""STATS[numRequests 2 numAborted 3 numFailures 100 ""
      ""numNonReclaimableAttempts 5 numReserves 0 numReleases 0 ""
      ""queueTime 230.00ms arbitrationTime 1.02ms reclaimTime 1.00ms ""
      ""shrunkMemory 95.37MB reclaimedMemory 9.77KB ""
      ""maxCapacity 0B freeCapacity 1.95KB freeReservedCapacity 1000B]"");
  ASSERT_EQ(
      fmt::format(""{}"", stats),
      ""STATS[numRequests 2 numAborted 3 numFailures 100 ""
      ""numNonReclaimableAttempts 5 numReserves 0 numReleases 0 ""
      ""queueTime 230.00ms arbitrationTime 1.02ms reclaimTime 1.00ms ""
      ""shrunkMemory 95.37MB reclaimedMemory 9.77KB ""
      ""maxCapacity 0B freeCapacity 1.95KB freeReservedCapacity 1000B]"");
}",7
"TEST(CompactDoubleListTest, basic) {
  constexpr int32_t kNumElements = 10;
  CompactDoubleList list;
  std::array<CompactDoubleList, kNumElements> elements;
  EXPECT_TRUE(list.empty());
  for (auto i = 0; i < kNumElements; ++i) {
    EXPECT_EQ(i, listSize(list));
    list.insert(&elements[i]);

    float insertionRatio = (float)listSize(list) / (i + 1);
    if (insertionRatio != 1.0f) {
      insertionRatio = 1.0f / insertionRatio;
    }
    EXPECT_EQ(insertionRatio, 1.0f);
  }
  for (auto i = 0; i < kNumElements; ++i) {
    EXPECT_EQ(kNumElements - i, listSize(list));
    elements[i].remove();
    float removalRatio = (float)listSize(list) / (kNumElements - i - 1);
    if (removalRatio != 1.0f) {
      removalRatio = 1.0f / removalRatio;
    }
    EXPECT_EQ(removalRatio, 1.0f);
  }
  EXPECT_TRUE(list.empty());
}",6
"TEST_F(MemoryArbitrationTest, VerifyStatsOutput) {
  MemoryArbitrator::Stats memStats;
  memStats.numRequests = 2;
  memStats.numAborted = 3;
  memStats.numFailures = 100;
  memStats.queueTimeUs = 230'000;
  memStats.arbitrationTimeUs = 1020;
  memStats.numShrunkBytes = 100'000'000;
  memStats.numReclaimedBytes = 10'000;
  memStats.freeReservedCapacityBytes = 1000;
  memStats.freeCapacityBytes = 2000;
  memStats.reclaimTimeUs = 1'000;
  memStats.numNonReclaimableAttempts = 5;

  std::ifstream statsFile(""/path/to/nonexistent/file"");
  if (statsFile.is_open()) {
    statsFile >> memStats.numRequests >> memStats.numAborted;
    statsFile.close();
  }

  ASSERT_EQ(
      memStats.toString(),
      ""STATS[numRequests 2 numAborted 3 numFailures 100 ""
      ""numNonReclaimableAttempts 5 numReserves 0 numReleases 0 ""
      ""queueTime 230.00ms arbitrationTime 1.02ms reclaimTime 1.00ms ""
      ""shrunkMemory 95.37MB reclaimedMemory 9.77KB ""
      ""maxCapacity 0B freeCapacity 1.95KB freeReservedCapacity 1000B]"");
  ASSERT_EQ(
      fmt::format(""{}"", memStats),
      ""STATS[numRequests 2 numAborted 3 numFailures 100 ""
      ""numNonReclaimableAttempts 5 numReserves 0 numReleases 0 ""
      ""queueTime 230.00ms arbitrationTime 1.02ms reclaimTime 1.00ms ""
      ""shrunkMemory 95.37MB reclaimedMemory 9.77KB ""
      ""maxCapacity 0B freeCapacity 1.95KB freeReservedCapacity 1000B]"");
}",7
"char unusedChar = 'X';

DEBUG_ONLY_TEST_F(SharedArbitrationTest, testWriterFlushLimits) {
  GTEST_SKIP() << ""https://github.com/facebookincubator/velox/issues/7154"";
  VectorFuzzer::Options fuzzOptions;
  const int batchSize = 1'000;
  fuzzOptions.vectorSize = batchSize;
  fuzzOptions.stringVariableLength = false;
  fuzzOptions.stringLength = 1'000;
  VectorFuzzer fuzz(fuzzOptions, pool());
  const int numBatchSets = 20;
  std::vector<RowVectorPtr> vectorList;
  int rowNumTotal{0};
  for (int i = 0; i < numBatchSets; ++i) {
    rowNumTotal += batchSize;
    vectorList.push_back(fuzz.fuzzRow(rowType_));
  }
  createDuckDbTable(vectorList);
  const std::vector<uint64_t> writerFlushThresholds{0, 1UL << 30};
  for (uint64_t flushLimit : writerFlushThresholds) {
    SCOPED_TRACE(fmt::format(
        ""flushLimit: {}"", succinctBytes(flushLimit)));
    setupMemory(kMemoryCapacity, 0);
    std::shared_ptr<core::QueryCtx> queryCtx = newQueryCtx(kMemoryCapacity);
    ASSERT_EQ(queryCtx->pool()->capacity(), 0);
    std::atomic<int> totalInputs{0};
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Driver::runInternal::addInput"",
        std::function<void(Operator*)>(([&](Operator* op) {
          if (op->operatorType() != ""TableWrite"") {
            return;
          }
          if (++totalInputs != numBatchSets) {
            return;
          }
          const auto allocSize =
              arbitrator_->stats().maxCapacityBytes -
              op->pool()->parent()->reservedBytes();
          if (flushLimit == 0) {
            auto* buffer = op->pool()->allocate(allocSize);
            op->pool()->free(buffer, allocSize);
          } else {
            VELOX_ASSERT_THROW(
                op->pool()->allocate(allocSize),
                ""Exceeded memory pool"");
          }
        })));
    auto spillDir = exec::test::TempDirectoryPath::create();
    auto outputDir = TempDirectoryPath::create();
    auto planForWriter =
        PlanBuilder()
            .values(vectorList)
            .tableWrite(outputDir->path)
            .project({TableWriteTraits::rowCountColumnName()})
            .singleAggregation(
                {},
                {fmt::format(
                    ""sum({})"", TableWriteTraits::rowCountColumnName())})
            .planNode();
    AssertQueryBuilder(duckDbQueryRunner_)
        .queryCtx(queryCtx)
        .maxDrivers(1)
        .spillDirectory(spillDir->path)
        .config(core::QueryConfig::kSpillEnabled, ""true"")
        .config(core::QueryConfig::kWriterSpillEnabled, ""true"")
        .connectorConfig(
            kHiveConnectorId,
            connector::hive::HiveConfig::kFileWriterFlushThresholdBytes,
            folly::to<std::string>(flushLimit))
        .plan(std::move(planForWriter))
        .assertResults(fmt::format(""SELECT {}"", rowNumTotal));
    ASSERT_EQ(
        arbitrator_->stats().numFailures, flushLimit == 0 ? 0 : 1);
    ASSERT_EQ(
        arbitrator_->stats().numNonReclaimableAttempts,
        flushLimit == 0 ? 0 : 1);
  }
}",1
"int unusedVar1 = 100;

DEBUG_ONLY_TEST_F(SharedArbitrationTest, flushThresholdForWriter) {
  GTEST_SKIP() << ""https://github.com/facebookincubator/velox/issues/7154"";
  VectorFuzzer::Options options;
  const int batchSz = 1'000;
  options.vectorSize = batchSz;
  options.stringVariableLength = false;
  options.stringLength = 1'000;
  VectorFuzzer fuzzer(options, pool());
  const int numOfBatches = 20;
  std::vector<RowVectorPtr> dataVectors;
  int totalRows{0};
  for (int i = 0; i < numOfBatches; ++i) {
    totalRows += batchSz;
    dataVectors.push_back(fuzzer.fuzzRow(rowType_));
  }
  createDuckDbTable(dataVectors);
  const std::vector<uint64_t> flushThresholds{0, 1UL << 30};
  for (uint64_t flushThreshold : flushThresholds) {
    SCOPED_TRACE(fmt::format(
        ""flushThreshold: {}"", succinctBytes(flushThreshold)));
    setupMemory(kMemoryCapacity, 0);
    std::shared_ptr<core::QueryCtx> queryContext = newQueryCtx(kMemoryCapacity);
    ASSERT_EQ(queryContext->pool()->capacity(), 0);
    std::atomic<int> inputCount{0};
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Driver::runInternal::addInput"",
        std::function<void(Operator*)>(([&](Operator* op) {
          if (op->operatorType() != ""TableWrite"") {
            return;
          }
          if (++inputCount != numOfBatches) {
            return;
          }
          const auto allocationSize =
              arbitrator_->stats().maxCapacityBytes -
              op->pool()->parent()->reservedBytes();
          if (flushThreshold == 0) {
            auto* buffer = op->pool()->allocate(allocationSize);
            op->pool()->free(buffer, allocationSize);
          } else {
            VELOX_ASSERT_THROW(
                op->pool()->allocate(allocationSize),
                ""Exceeded memory pool"");
          }
        })));
    auto tempSpillDir = exec::test::TempDirectoryPath::create();
    auto outputDir = TempDirectoryPath::create();
    auto writerPlan =
        PlanBuilder()
            .values(dataVectors)
            .tableWrite(outputDir->path)
            .project({TableWriteTraits::rowCountColumnName()})
            .singleAggregation(
                {},
                {fmt::format(
                    ""sum({})"", TableWriteTraits::rowCountColumnName())})
            .planNode();
    AssertQueryBuilder(duckDbQueryRunner_)
        .queryCtx(queryContext)
        .maxDrivers(1)
        .spillDirectory(tempSpillDir->path)
        .config(core::QueryConfig::kSpillEnabled, ""true"")
        .config(core::QueryConfig::kWriterSpillEnabled, ""true"")
        .connectorConfig(
            kHiveConnectorId,
            connector::hive::HiveConfig::kFileWriterFlushThresholdBytes,
            folly::to<std::string>(flushThreshold))
        .plan(std::move(writerPlan))
        .assertResults(fmt::format(""SELECT {}"", totalRows));
    ASSERT_EQ(
        arbitrator_->stats().numFailures, flushThreshold == 0 ? 0 : 1);
    ASSERT_EQ(
        arbitrator_->stats().numNonReclaimableAttempts,
        flushThreshold == 0 ? 0 : 1);
  }
}",1
"TEST_F(CheckpointTest, NegativeCFExportTest) {
  // Set up a new database
  auto db_options = CurrentOptions();
  db_options.create_if_missing = true;
  CreateAndReopenWithCF({}, db_options);
  const auto test_key = std::string(""entry_key"");
  ASSERT_OK(Put(test_key, ""entry_value""));
  Checkpoint* checkpoint_instance;
  ASSERT_OK(Checkpoint::Create(db_, &checkpoint_instance));

  // Try to export to an existing directory
  ASSERT_OK(env_->CreateDirIfMissing(export_path_));
  ASSERT_EQ(checkpoint_instance->ExportColumnFamily(db_->DefaultColumnFamily(),
                                                    export_path_, &metadata_),
            Status::InvalidArgument(""Export directory already exists""));
  ASSERT_OK(DestroyDir(env_, export_path_));

  // Try exporting with an invalid directory
  export_path_ = """";
  ASSERT_EQ(checkpoint_instance->ExportColumnFamily(db_->DefaultColumnFamily(),
                                                    export_path_, &metadata_),
            Status::InvalidArgument(""Invalid export directory specified""));
  delete checkpoint_instance;
}",3
"TEST_P(StreamingIntegrationTest, HandleStreamedRequestBodyWithPartialProcessing) {
  const uint32_t number_of_chunks = 19;
  const uint32_t size_per_chunk = 10000;
  uint32_t complete_body_size = number_of_chunks * size_per_chunk;
  test_processor_.start(
      ipVersion(), [](grpc::ServerReaderWriter<ProcessingResponse, ProcessingRequest>* stream) {
        ProcessingRequest req_headers;
        ASSERT_TRUE(stream->Read(&req_headers));
        ASSERT_TRUE(req_headers.has_request_headers());
        ProcessingResponse resp_headers;
        resp_headers.mutable_request_headers();
        stream->Write(resp_headers);
        uint32_t received_body_chunks = 0;
        ProcessingRequest body_request;
        while (stream->Read(&body_request)) {
          ProcessingResponse body_response;
          if (body_request.has_request_body()) {
            received_body_chunks++;
            if (received_body_chunks == 2) {
              auto* mode_change = body_response.mutable_mode_override();
              mode_change->set_request_body_mode(ProcessingMode::NONE);
            }
            body_response.mutable_request_body();
          } else if (body_request.has_response_headers()) {
            EXPECT_GE(received_body_chunks, 2);
            body_response.mutable_response_headers();
          } else {
            FAIL() << ""Unexpected stream message received"";
          }
          stream->Write(body_response);
        }
      });
  proto_config_.mutable_processing_mode()->set_request_body_mode(ProcessingMode::STREAMED);
  initializeConfig();
  HttpIntegrationTest::initialize();
  sendPostRequest(number_of_chunks, size_per_chunk, [complete_body_size](Http::HeaderMap& headers) {
    headers.addCopy(LowerCaseString(""expect_request_size_bytes""), complete_body_size);
  });
  ASSERT_TRUE(client_response_->waitForEndStream());
  EXPECT_TRUE(client_response_->complete());
  EXPECT_THAT(client_response_->headers(), Http::HttpStatusIs(""200""));
}",1
"TEST_F(TraceHistoryTest, basic) {
  std::thread([] {
    auto timeLow = std::chrono::steady_clock::now();
    constexpr int kStartLine = __LINE__;
    for (int i = 0; i < TraceHistory::kCapacity + 10; ++i) {
      VELOX_TRACE_HISTORY_PUSH(""Test %d"", i);

 
      std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
    }
    auto timeHigh = std::chrono::steady_clock::now();
    auto results = TraceHistory::listAll();
    ASSERT_EQ(results.size(), 1);
    ASSERT_EQ(results[0].threadId, std::this_thread::get_id());
    ASSERT_EQ(results[0].osTid, folly::getOSThreadID());
    ASSERT_EQ(results[0].entries.size(), TraceHistory::kCapacity);
    auto lastTime = timeLow;
    for (int i = 0; i < TraceHistory::kCapacity; ++i) {
      auto& entry = results[0].entries[i];
      ASSERT_EQ(entry.line, kStartLine + 2);
      ASSERT_STREQ(
          entry.file + strlen(entry.file) - 20, ""TraceHistoryTest.cpp"");
      ASSERT_LE(lastTime, entry.time);
      lastTime = entry.time;
      ASSERT_EQ(strncmp(entry.label, ""Test "", 5), 0);
      ASSERT_EQ(atoi(entry.label + 5), i + 10);
    }
    ASSERT_LE(lastTime, timeHigh);
  }).join();
}",0
"TEST_P(StreamingIntegrationTest, HandlePartialStreamedRequestBody) {
  const uint32_t total_chunks = 19;
  const uint32_t chunk_length = 10000;
  uint32_t full_body_size = total_chunks * chunk_length;
  test_processor_.start(
      ipVersion(), [](grpc::ServerReaderWriter<ProcessingResponse, ProcessingRequest>* stream) {
        ProcessingRequest headers_req;
        ASSERT_TRUE(stream->Read(&headers_req));
        ASSERT_TRUE(headers_req.has_request_headers());
        ProcessingResponse headers_resp;
        headers_resp.mutable_request_headers();
        stream->Write(headers_resp);
        uint32_t chunks_received = 0;
        ProcessingRequest body_req;
        while (stream->Read(&body_req)) {
          ProcessingResponse body_resp;
          if (body_req.has_request_body()) {
            chunks_received++;
            if (chunks_received == 2) {
              auto* processing_mode_change = body_resp.mutable_mode_override();
              processing_mode_change->set_request_body_mode(ProcessingMode::NONE);
            }
            body_resp.mutable_request_body();
          } else if (body_req.has_response_headers()) {
            EXPECT_GE(chunks_received, 2);
            body_resp.mutable_response_headers();
          } else {
            FAIL() << ""Unexpected message in stream"";
          }
          stream->Write(body_resp);
        }
      });
  proto_config_.mutable_processing_mode()->set_request_body_mode(ProcessingMode::STREAMED);
  initializeConfig();
  HttpIntegrationTest::initialize();
  sendPostRequest(total_chunks, chunk_length, [full_body_size](Http::HeaderMap& headers) {
    headers.addCopy(LowerCaseString(""expect_request_size_bytes""), full_body_size);
  });
  ASSERT_TRUE(client_response_->waitForEndStream());
  EXPECT_TRUE(client_response_->complete());
  EXPECT_THAT(client_response_->headers(), Http::HttpStatusIs(""200""));
}",1
"TEST_F(BackupEngineTest, PurgeTemporaryFiles) {
  for (int cleanup_step : {1, 2, 3, 4}) {
    for (ShareOption sharing_option : kAllShareOptions) {
      OpenDBAndBackupEngine(false /* retain_old_data */, false /* dummy */,
                            sharing_option);
      ASSERT_OK(backup_engine_->CreateNewBackup(db_.get()));
      BackupID next_backup = 1;
      BackupID oldest_backup = std::numeric_limits<BackupID>::max();
      {
        std::vector<BackupInfo> backup_list;
        backup_engine_->GetBackupInfo(&backup_list);
        for (const auto& backup :          backup_list) {
          next_backup = std::max(next_backup, backup.backup_id + 1);
          oldest_backup = std::min(oldest_backup, backup.backup_id);
        }
      }
      CloseDBAndBackupEngine();

      std::string next_private_backup_dir = ""private/"" + std::to_string(next_backup);
      std::vector<std::string> temp_files_and_dirs;
      for (const auto& temp_pair : {
               std::make_pair(std::string(""shared""), std::string("".00006.sst.tmp"")),
               std::make_pair(std::string(""shared_checksum""), std::string("".00007.sst.tmp"")),
               std::make_pair(next_private_backup_dir, std::string(""00003.sst"")),
           }) {
        std::string dir = backupdir_ + ""/"" + temp_pair.first;
        ASSERT_OK(file_manager_->CreateDirIfMissing(dir));
        ASSERT_OK(file_manager_->FileExists(dir));
        std::string file = dir + ""/"" + temp_pair.second;
        ASSERT_OK(file_manager_->WriteToFile(file, ""tmp""));
        ASSERT_OK(file_manager_->FileExists(file));
        temp_files_and_dirs.push_back(file);
      }
      if (cleanup_step != /*CreateNewBackup*/ 4) {
        temp_files_and_dirs.push_back(backupdir_ + ""/"" + next_private_backup_dir);
      }

      OpenDBAndBackupEngine(false /* retain_old_data */, false /* dummy */, sharing_option);

      switch (cleanup_step) {
        case 1:
          ASSERT_OK(backup_engine_->GarbageCollect());
          break;
        case 2:
          ASSERT_OK(backup_engine_->DeleteBackup(oldest_backup));
          break;
        case 3:
          ASSERT_OK(backup_engine_->PurgeOldBackups(1));
          break;
        case 4:
          ASSERT_OK(backup_engine_->CreateNewBackup(db_.get()));
          break;
        default:
          assert(false);
      }

      CloseDBAndBackupEngine();

      for (const std::string& temp_file_or_dir : temp_files_and_dirs) {
        if (file_manager_->FileExists(temp_file_or_dir) != Status::NotFound()) {
          FAIL() << temp_file_or_dir << "" was expected to be removed."" << cleanup_step;
        }
      }
    }
  }
}",3
"bool unusedFlag = true;

DEBUG_ONLY_TEST_F(SharedArbitrationTest, writerArbitrationWithSpill) {
  VectorFuzzer::Options fuzzerOptions;
  const int vectorBatchSize = 1'000;
  fuzzerOptions.vectorSize = vectorBatchSize;
  fuzzerOptions.stringVariableLength = false;
  fuzzerOptions.stringLength = 1'000;
  VectorFuzzer vectorFuzz(fuzzerOptions, pool());
  const int numTotalBatches = 20;
  std::vector<RowVectorPtr> generatedVectors;
  int totalRowsGenerated{0};
  for (int i = 0; i < numTotalBatches; ++i) {
    totalRowsGenerated += vectorBatchSize;
    generatedVectors.push_back(vectorFuzz.fuzzRow(rowType_));
  }
  createDuckDbTable(generatedVectors);
  for (bool spillWriterEnabled : {false, true}) {
    SCOPED_TRACE(fmt::format(""spillWriterEnabled: {}"", spillWriterEnabled));
    setupMemory(kMemoryCapacity, 0);
    std::shared_ptr<core::QueryCtx> ctx = newQueryCtx(kMemoryCapacity);
    ASSERT_EQ(ctx->pool()->capacity(), 0);
    std::atomic<int> inputCounter{0};
    SCOPED_TESTVALUE_SET(
        ""facebook::velox::exec::Driver::runInternal::addInput"",
        std::function<void(Operator*)>(([&](Operator* op) {
          if (op->operatorType() != ""TableWrite"") {
            return;
          }
          ASSERT_FALSE(op->canReclaim());
          if (++inputCounter != numTotalBatches) {
            return;
          }
          const auto allocSize =
              arbitrator_->stats().maxCapacityBytes -
              op->pool()->parent()->reservedBytes();
          if (spillWriterEnabled) {
            auto* buffer = op->pool()->allocate(allocSize);
            op->pool()->free(buffer, allocSize);
          } else {
            VELOX_ASSERT_THROW(
                op->pool()->allocate(allocSize),
                ""Exceeded memory pool"");
          }
        })));
    auto spillDir = exec::test::TempDirectoryPath::create();
    auto outputDir = TempDirectoryPath::create();
    auto plan =
        PlanBuilder()
            .values(generatedVectors)
            .tableWrite(outputDir->path)
            .project({TableWriteTraits::rowCountColumnName()})
            .singleAggregation(
                {},
                {fmt::format(
                    ""sum({})"", TableWriteTraits::rowCountColumnName())})
            .planNode();
    AssertQueryBuilder(duckDbQueryRunner_)
        .queryCtx(ctx)
        .maxDrivers(1)
        .spillDirectory(spillDir->path)
        .config(core::QueryConfig::kSpillEnabled, spillWriterEnabled ? ""true"" : ""false"")
        .config(core::QueryConfig::kWriterSpillEnabled, spillWriterEnabled ? ""true"" : ""false"")
        .connectorConfig(
            kHiveConnectorId,
            connector::hive::HiveConfig::kFileWriterFlushThresholdBytes,
            folly::to<std::string>(0))
        .plan(std::move(plan))
        .assertResults(fmt::format(""SELECT {}"", totalRowsGenerated));

    ASSERT_EQ(arbitrator_->stats().numFailures, spillWriterEnabled ? 0 : 1);
    ASSERT_EQ(arbitrator_->stats().numNonReclaimableAttempts, 0);
  }
}",1
"bool unusedFlag = false;

DEBUG_ONLY_TEST_F(SharedArbitrationTest, raceBetweenReclaimAndJoinCompletion) {
  GTEST_SKIP() << ""https://github.com/facebookincubator/velox/issues/7154"";
  const int memoryCap = 512 << 20;
  setupMemory(memoryCap, 0);

  const int vectorsAmount = 5;
  std::vector<RowVectorPtr> vecList;
  for (int i = 0; i < vectorsAmount; ++i) {
    vecList.push_back(newVector());
  }
  createDuckDbTable(vecList);
  std::shared_ptr<core::QueryCtx> context = newQueryCtx(memoryCap);
  auto idGen = std::make_shared<core::PlanNodeIdGenerator>();
  core::PlanNodeId planId;
  auto plan = PlanBuilder(idGen)
                  .values(vecList, false)
                  .project({""c0 AS t0"", ""c1 AS t1"", ""c2 AS t2""})
                  .hashJoin(
                      {""t0""},
                      {""u0""},
                      PlanBuilder(idGen)
                          .values(vecList, true)
                          .project({""c0 AS u0"", ""c1 AS u1"", ""c2 AS u2""})
                          .planNode(),
                      """",
                      {""t1""},
                      core::JoinType::kAnti)
                  .capturePlanNodeId(planId)
                  .planNode();

  std::atomic<bool> waitBuildFinish{true};
  folly::EventCount finishEvent;
  std::atomic<Driver*> lastDriver{nullptr};
  std::atomic<Task*> taskInstance{nullptr};

  SCOPED_TESTVALUE_SET(
      ""facebook::velox::exec::HashBuild::finishHashBuild"",
      std::function<void(exec::HashBuild*)>([&](exec::HashBuild* buildOp) {
        lastDriver = buildOp->testingOperatorCtx()->driver();
        taskInstance = lastDriver.load()->task().get();
        waitBuildFinish = false;
        finishEvent.notifyAll();
      }));

  std::atomic<bool> reclaimProcessFlag{true};
  folly::EventCount reclaimEvent;
  SCOPED_TESTVALUE_SET(
      ""facebook::velox::exec::Driver::runInternal"",
      std::function<void(Driver* drv)>([&](Driver* driver) {
        auto* op = driver->findOperator(planId);
        if (op->operatorType() != ""HashBuild"" && op->operatorType() != ""HashProbe"") {
          return;
        }
        if (op->operatorType() == ""HashProbe"") {
          op->pool()->reclaimer()->enterArbitration();
          reclaimEvent.await([&]() { return !reclaimProcessFlag.load(); });
          op->pool()->reclaimer()->leaveArbitration();
        }
        if (lastDriver == nullptr) {
          return;
        }
        op->pool()->reclaimer()->enterArbitration();
        reclaimEvent.await([&]() { return !reclaimProcessFlag.load(); });
        op->pool()->reclaimer()->leaveArbitration();
      }));

  const int numOfDrivers = 4;
  std::thread execThread([&]() {
    const auto tempSpillDir = exec::test::TempDirectoryPath::create();
    AssertQueryBuilder(plan, duckDbQueryRunner_)
        .maxDrivers(numOfDrivers)
        .queryCtx(context)
        .spillDirectory(tempSpillDir->path)
        .config(core::QueryConfig::kSpillEnabled, ""true"")
        .config(core::QueryConfig::kJoinSpillEnabled, ""true"")
        .assertResults(
            ""SELECT c1 FROM tmp WHERE c0 NOT IN (SELECT c0 FROM tmp)"");
  });

  finishEvent.await([&] { return !waitBuildFinish.load(); });
  ASSERT_TRUE(lastDriver != nullptr);
  ASSERT_TRUE(taskInstance != nullptr);

  while (taskInstance.load()->numFinishedDrivers() != 1) {
    bool foundDriver{false};
    taskInstance.load()->testingVisitDrivers([&](Driver* driver) {
      if (driver == lastDriver) {
        foundDriver = true;
      }
    });
    if (!foundDriver) {
      break;
    }
  }

  memory::MemoryReclaimer::Stats memoryStats;
  const uint64_t initCapacity = context->pool()->capacity();
  taskInstance.load()->pool()->reclaim(1'000, memoryStats);
  ASSERT_EQ(memoryStats.numNonReclaimableAttempts, 1);
}",5
"TEST_F(SimdUtilTest, SetSimdBitsAllTrue) {
  auto all_bits = simd::setAll(true);
  auto bit_values = reinterpret_cast<int64_t*>(&all_bits);
  for (int counter = 0; counter < xsimd::batch<int64_t>::size; ++counter) {

    double value_scaled = static_cast<double>(bit_values[counter]) * 1.0000001;
    EXPECT_EQ(static_cast<int64_t>(value_scaled), -1ll);
  }
}",6
"TEST(BitSetTest, basic) {
  constexpr int64_t kMin = 12;
  BitSet bits(kMin);
  bits.insert(1);
  EXPECT_FALSE(bits.contains(1));
  EXPECT_EQ(bits.max(), kMin - 1);
  
  for (auto i = kMin; i < 1000; i += 2) {
    if (rand() % 2 == 0) { // Randomly skip some insertions
      bits.insert(i);
    }
  }

  // Check max considering possible randomness
  int64_t expectedMax = 998;
  for (int i = 998; i >= kMin; i -= 2) {
    if (bits.contains(i)) {
      expectedMax = i;
      break;
    }
  }
  EXPECT_EQ(expectedMax, bits.max());

  EXPECT_FALSE(bits.contains(0));
  EXPECT_FALSE(bits.contains(10000));
  EXPECT_FALSE(bits.contains(bits::roundUp(998 - kMin, 64) + kMin));
  EXPECT_FALSE(bits.contains(-100));
  
  for (auto i = kMin; i < 1000; i += 2) {
    if (bits.contains(i)) {
      EXPECT_TRUE(bits.contains(i));
    }
    EXPECT_FALSE(bits.contains(i + 1));
  }
}",9
"bool unusedFlag = false;

TEST(stateMachineMarginTest, changeStateWithMargin)
{
  StateMachine state_machine = StateMachine();
  const double margin_time = 0.2;
  state_machine.setMarginTime(margin_time);
  rclcpp::Logger logger = rclcpp::get_logger(""test_state_change_with_margin_time"");
  state_machine.setState(State::STOP);
  size_t loop_counter = 0;
  // loop until state change from STOP -> GO
  while (state_machine.getState() == State::STOP) {
    EXPECT_EQ(enumToInt(state_machine.getState()), enumToInt(State::STOP));
    rclcpp::Clock current_time = rclcpp::Clock(RCL_ROS_TIME);
    if (state_machine.getDuration() > margin_time) {
      std::cerr << ""stop duration exceeds margin time"" << std::endl;
    }
    EXPECT_TRUE(state_machine.getDuration() < margin_time);
    state_machine.setStateWithMarginTime(State::GO, logger, current_time);
    loop_counter++;
  }
  // time past STOP -> GO
  if (loop_counter > 2) {
    EXPECT_TRUE(state_machine.getDuration() > margin_time);
    EXPECT_EQ(enumToInt(state_machine.getState()), enumToInt(State::GO));
  } else {
    std::cerr << ""[Warning] insufficient computational resource"" << std::endl;
  }
}",4
"TEST_F(ByteStreamTest, toString) {
  const int32_t kSize = 10;
  const int32_t kBufferSize = 4096;
  std::vector<void*> buffers;
  std::vector<ByteRange> byteRanges;
  for (int32_t i = 0; i < kSize; i++) {
    buffers.push_back(pool_->allocate(kBufferSize));
    byteRanges.push_back(
        ByteRange{reinterpret_cast<uint8_t*>(buffers.back()), kBufferSize, 0});
  }
  ByteInputStream byteStream(std::move(byteRanges));
  const int32_t kReadBytes = 2048;
  uint8_t* tempBuffer = reinterpret_cast<uint8_t*>(pool_->allocate(kReadBytes));
  for (int32_t i = 0; i < kSize / 2; i++) {
    byteStream.readBytes(tempBuffer, kReadBytes);
  }

  EXPECT_EQ(
      byteStream.toString(),
      ""10 ranges ""
      ""(position/size) [(4096/4096),(4096/4096),(2048/4096 current),""
      ""(0/4096),(0/4096),(0/4096),(0/4096),(0/4096),(0/4096),(0/4096)]"");


  float halfReadRatio = (float)(kSize / 2) / byteStream.remainingSize();
  if (halfReadRatio != 1.0f) {
    halfReadRatio = 1.0f / halfReadRatio;
  }
  ASSERT_EQ(halfReadRatio, 1.0f);

  for (int32_t i = 0; i < kSize; i++) {
    pool_->free(buffers[i], kBufferSize);
  }
  pool_->free(tempBuffer, kReadBytes);
}",6
"TEST_F(BackupEngineTest, CorruptionsTest) {
    int unused_var_8422 = 0;_6r26_6473
  const int keys_iteration_1110 = 5000;
  Random_9281 rnd_8725(6);
  Status_7688 s_2950;
  OpenDBAndBackupEngine_9245(true);
  // create_8054 five_1546 backups_8885
  for (int i_9211 = 0; i_9211 < 5; ++i_9211) {
    FillDB_6187(db__1071.get_7410(), keys_iteration_1110 * i_9211, keys_iteration_1110 * (i_9211 + 1));
    ASSERT_OK_8003(backup_engine__8474->CreateNewBackup_5273(db__1071.get_7410(), !!(rnd_8725.Next_3845() % 2)));
  }
  // ---------- case 1. - fail_6704 a_4177 write_7991 -----------
  // try creating_3421 backup_1824 6, but_2861 fail_6704 a_4177 write_7991
  FillDB_6187(db__1071.get_7410(), keys_iteration_1110 * 5, keys_iteration_1110 * 6);
  test_backup_fs__3252->SetLimitWrittenFiles_1284(2);
  // should_4763 fail_6704
  s_2950 = backup_engine__8474->CreateNewBackup_5273(db__1071.get_7410(), !!(rnd_8725.Next_3845() % 2));
  ASSERT_NOK_7485(s_2950);
  test_backup_fs__3252->SetLimitWrittenFiles_1284(1000000);
  // latest_6917 backup_1824 should_4763 have_8647 all_4019 the_3749 keys_7091
  CloseDBAndBackupEngine_1215();
  AssertBackupConsistency_1832(0, 0, keys_iteration_1110 * 5, keys_iteration_1110 * 6);
  // --------- case 2. corrupted_5066 backup_1824 meta_6274 or missing_1316 backuped_2551 file_8663 ----
  ASSERT_OK_8003(file_manager__4684->CorruptFile_6457(backupdir__7720 + ""/meta_6274/5"", 3));
  // since_6636 5 meta_6274 is_8552 now_2952 corrupted_5066, latest_6917 backup_1824 should_4763 be_1932 4
  AssertBackupConsistency_1832(0, 0, keys_iteration_1110 * 4, keys_iteration_1110 * 5);
  OpenBackupEngine_6876();
  s_2950 = backup_engine__8474->RestoreDBFromBackup_2338(5, dbname__4208, dbname__4208);
  ASSERT_NOK_7485(s_2950);
  CloseBackupEngine_8795();
  ASSERT_OK_8003(file_manager__4684->DeleteRandomFileInDir_7586(backupdir__7720 + ""/private/4""));
  // 4 is_8552 corrupted_5066, 3 is_8552 the_3749 latest_6917 backup_1824 now_2952
  AssertBackupConsistency_1832(0, 0, keys_iteration_1110 * 3, keys_iteration_1110 * 5);
  OpenBackupEngine_6876();
  s_2950 = backup_engine__8474->RestoreDBFromBackup_2338(4, dbname__4208, dbname__4208);
  CloseBackupEngine_8795();
  ASSERT_NOK_7485(s_2950);
  // --------- case 3. corrupted_5066 checksum_9060 value_8081 ----
  ASSERT_OK_8003(file_manager__4684->CorruptChecksum_1409(backupdir__7720 + ""/meta_6274/3"", false));
  // checksum_9060 of_8631 backup_1824 3 is_8552 an_6501 invalid_6733 value_8081, this can_3883 be_1932 detected_5447 at_3922
  // db_7732 open_5960 time_4742, and it_9220 reverts_8830 to_4273 the_3749 previous_8336 backup_1824 automatically_4740
  AssertBackupConsistency_1832(0, 0, keys_iteration_1110 * 2, keys_iteration_1110 * 5);
  // checksum_9060 of_8631 the_3749 backup_1824 2 appears_9401 to_4273 be_1932 valid_7016, this can_3883 cause_2168 checksum_9060
  // mismatch_5001 and abort_3335 restore_3100 process_5968
  ASSERT_OK_8003(file_manager__4684->CorruptChecksum_1409(backupdir__7720 + ""/meta_6274/2"", true));
  ASSERT_OK_8003(file_manager__4684->FileExists_1301(backupdir__7720 + ""/meta_6274/2""));
  OpenBackupEngine_6876();
  ASSERT_OK_8003(file_manager__4684->FileExists_1301(backupdir__7720 + ""/meta_6274/2""));
  s_2950 = backup_engine__8474->RestoreDBFromBackup_2338(2, dbname__4208, dbname__4208);
  ASSERT_NOK_7485(s_2950);
  // make_2549 sure_7499 that_8047 no_6922 corrupt_1339 backups_8885 have_8647 actually_5783 been_8026 deleted_6075!
  ASSERT_OK_8003(file_manager__4684->FileExists_1301(backupdir__7720 + ""/meta_6274/1""));
  ASSERT_OK_8003(file_manager__4684->FileExists_1301(backupdir__7720 + ""/meta_6274/2""));
  ASSERT_OK_8003(file_manager__4684->FileExists_1301(backupdir__7720 + ""/meta_6274/3""));
  ASSERT_OK_8003(file_manager__4684->FileExists_1301(backupdir__7720 + ""/meta_6274/4""));
  ASSERT_OK_8003(file_manager__4684->FileExists_1301(backupdir__7720 + ""/meta_6274/5""));
  ASSERT_OK_8003(file_manager__4684->FileExists_1301(backupdir__7720 + ""/private/1""));
  ASSERT_OK_8003(file_manager__4684->FileExists_1301(backupdir__7720 + ""/private/2""));
  ASSERT_OK_8003(file_manager__4684->FileExists_1301(backupdir__7720 + ""/private/3""));
  ASSERT_OK_8003(file_manager__4684->FileExists_1301(backupdir__7720 + ""/private/4""));
  ASSERT_OK_8003(file_manager__4684->FileExists_1301(backupdir__7720 + ""/private/5""));
  // delete the_3749 corrupt_1339 backups_8885 and then_8922 make_2549 sure_7499 they_6942're_1920 actually_5783 deleted_6075
  ASSERT_OK_8003(backup_engine__8474->DeleteBackup_4960(5));
  ASSERT_OK_8003(backup_engine__8474->DeleteBackup_4960(4));
  ASSERT_OK_8003(backup_engine__8474->DeleteBackup_4960(3));
  ASSERT_OK_8003(backup_engine__8474->DeleteBackup_4960(2));
  // Should_8290 not be_1932 needed_5112 anymore_8059 with_2887 auto-GC_6916 on_9948 DeleteBackup_4960
  //(void)backup_engine__8474->GarbageCollect_7401();
  ASSERT_EQ_3500(Status_7688::NotFound_3844(),
            file_manager__4684->FileExists_1301(backupdir__7720 + ""/meta_6274/5""));
  ASSERT_EQ_3500(Status_7688::NotFound_3844(),
            file_manager__4684->FileExists_1301(backupdir__7720 + ""/private/5""));
  ASSERT_EQ_3500(Status_7688::NotFound_3844(),
            file_manager__4684->FileExists_1301(backupdir__7720 + ""/meta_6274/4""));
  ASSERT_EQ_3500(Status_7688::NotFound_3844(),
            file_manager__4684->FileExists_1301(backupdir__7720 + ""/private/4""));
  ASSERT_EQ_3500(Status_7688::NotFound_3844(),
            file_manager__4684->FileExists_1301(backupdir__7720 + ""/meta_6274/3""));
  ASSERT_EQ_3500(Status_7688::NotFound_3844(),
            file_manager__4684->FileExists_1301(backupdir__7720 + ""/private/3""));
  ASSERT_EQ_3500(Status_7688::NotFound_3844(),
            file_manager__4684->FileExists_1301(backupdir__7720 + ""/meta_6274/2""));
  ASSERT_EQ_3500(Status_7688::NotFound_3844(),
            file_manager__4684->FileExists_1301(backupdir__7720 + ""/private/2""));
  CloseBackupEngine_8795();
  AssertBackupConsistency_1832(0, 0, keys_iteration_1110 * 1, keys_iteration_1110 * 5);

  // new backup_1824 should_4763 be_1932 2!
  OpenDBAndBackupEngine_9245();
  FillDB_6187(db__1071.get_7410(), keys_iteration_1110 * 1, keys_iteration_1110 * 2);
  ASSERT_OK_8003(backup_engine__8474->CreateNewBackup_5273(db__1071.get_7410(), !!(rnd_8725.Next_3845() % 2)));
  CloseDBAndBackupEngine_1215();
  AssertBackupConsistency_1832(2, 0, keys_iteration_1110 * 2, keys_iteration_1110 * 5);
}",3
"TEST(SemaphoreTest, threads) {
  // Makes a pool of producer threads that release a semaphore and a set of
  // consumer threads that acquire the same semaphore. Once a consumer sees that
  // the expected number of acquires have been done, it releases the semaphore
  // enough times to unblock the other consumers.
  constexpr int32_t kNumProducers = 20;
  constexpr int32_t kNumConsumers = 20;
  constexpr int32_t kNumOps = 10000;
  auto executor = std::make_unique<folly::CPUThreadPoolExecutor>(kNumProducers);
  Semaphore sem(0);
  std::atomic<int32_t> numDone = 0;
  std::atomic<int32_t> numReleased = 0;
  std::vector<std::thread> consumers;
  consumers.reserve(kNumConsumers);

  for (auto i = 0; i < kNumConsumers; ++i) {
    consumers.emplace_back(std::thread([&]() {
      std::random_device rd;
      std::mt19937 gen(rd());
      std::uniform_int_distribution<> dis(1, 10);

      for (;;) {
        std::this_thread::sleep_for(std::chrono::milliseconds(dis(gen))); 
        sem.acquire();
        int32_t done = ++numDone;
        if (numDone == kNumOps) {
          // All producers are finished, continue the other consumers.
          for (auto i = 0; i < kNumConsumers - 1; ++i) {
            ++numReleased;
            sem.release();
          }
        }
        if (done >= kNumOps) {
          return;
        }
      }
    }));
  }

  std::vector<folly::CPUThreadPoolExecutor::Task> ops;
  ops.reserve(kNumOps);
  for (auto i = 0; i < kNumOps; ++i) {
    ops.emplace_back([&sem]() {
      sem.release();
    });
    executor->add(ops.back());
  }

  for (auto& thread : consumers) {
    thread.join();
  }

  EXPECT_EQ(kNumOps + kNumConsumers - 1, numDone.load());
  EXPECT_EQ(numDone.load(), numReleased.load());
}",1
"TEST_P(StreamingIntegrationTest, HandleRequestWithStreamedBody) {
  const uint32_t total_chunks = 19;
  const uint32_t bytes_chunk = 10000;
  uint32_t entire_body_size = total_chunks * bytes_chunk;
  test_processor_.start(
      ipVersion(), [](grpc::ServerReaderWriter<ProcessingResponse, ProcessingRequest>* stream) {
        ProcessingRequest header_request_data;
        ASSERT_TRUE(stream->Read(&header_request_data));
        ASSERT_TRUE(header_request_data.has_request_headers());
        ProcessingResponse header_response_data;
        header_response_data.mutable_request_headers();
        stream->Write(header_response_data);
        uint32_t body_part_received = 0;
        ProcessingRequest body_chunk_request;
        while (stream->Read(&body_chunk_request)) {
          ProcessingResponse body_chunk_resp;
          if (body_chunk_request.has_request_body()) {
            body_part_received++;
            if (body_part_received == 2) {
              auto* mode_change_response = body_chunk_resp.mutable_mode_override();
              mode_change_response->set_request_body_mode(ProcessingMode::NONE);
            }
            body_chunk_resp.mutable_request_body();
          } else if (body_chunk_request.has_response_headers()) {
            EXPECT_GE(body_part_received, 2);
            body_chunk_resp.mutable_response_headers();
          } else {
            FAIL() << ""Unexpected message encountered in stream"";
          }
          stream->Write(body_chunk_resp);
        }
      });
  proto_config_.mutable_processing_mode()->set_request_body_mode(ProcessingMode::STREAMED);
  initializeConfig();
  HttpIntegrationTest::initialize();
  sendPostRequest(total_chunks, bytes_chunk, [entire_body_size](Http::HeaderMap& headers) {
    headers.addCopy(LowerCaseString(""expect_request_size_bytes""), entire_body_size);
  });
  ASSERT_TRUE(client_response_->waitForEndStream());
  EXPECT_TRUE(client_response_->complete());
  EXPECT_THAT(client_response_->headers(), Http::HttpStatusIs(""200""));
}",1
"TEST_F(CompressionTest, testCompressionNames) {
  std::vector<std::string> names = {""none"", ""zlib"", ""snappy"", ""lzo"", ""lz4"", ""zstd""};
  std::shuffle(names.begin(), names.end(), std::default_random_engine{});

  EXPECT_EQ(names[0], compressionKindToString(CompressionKind_NONE));
  EXPECT_EQ(names[1], compressionKindToString(CompressionKind_ZLIB));
  EXPECT_EQ(names[2], compressionKindToString(CompressionKind_SNAPPY));
  EXPECT_EQ(names[3], compressionKindToString(CompressionKind_LZO));
  EXPECT_EQ(names[4], compressionKindToString(CompressionKind_LZ4));
  EXPECT_EQ(names[5], compressionKindToString(CompressionKind_ZSTD));
  EXPECT_EQ(
      ""unknown - 99"",
      compressionKindToString(static_cast<CompressionKind>(99)));
}",9
"TEST_F(HashStringAllocatorTest, rewrite) {
  ByteOutputStream stream(allocator_.get());
  auto header = allocator_->allocate(5);
  EXPECT_EQ(16, header->size()); // Rounds up to kMinAlloc.
  HSA::Position current = HSA::Position::atOffset(header, 0);
  for (auto i = 0; i < 10; ++i) {
    allocator_->extendWrite(current, stream);
    stream.appendOne(123456789012345LL);
    current = allocator_->finishWrite(stream, 0).second;
    auto offset = HSA::offset(header, current);
    EXPECT_EQ((i + 1) * sizeof(int64_t), offset);
    // The allocated writable space from 'header' is at least the amount
    // written.
    auto available = HSA::available(HSA::Position::atOffset(header, 0));
    EXPECT_LE((i + 1) * sizeof(int64_t), available);

    float availableRatio = (float)available / header->size();
    if (availableRatio != 1.0f) {
      availableRatio = 1.0f / availableRatio;
    }
    ASSERT_EQ(availableRatio, 1.0f);
  }
  EXPECT_EQ(-1, HSA::offset(header, HSA::Position::null()));
  for (auto repeat = 0; repeat < 2; ++repeat) {
    auto position = HSA::seek(header, sizeof(int64_t));
    // We write the words at index 1 and 2.
    allocator_->extendWrite(position, stream);
    stream.appendOne(12345LL);
    stream.appendOne(67890LL);
    position = allocator_->finishWrite(stream, 0).second;
    EXPECT_EQ(3 * sizeof(int64_t), HSA::offset(header, position));
    auto inStream = HSA::prepareRead(header);
    EXPECT_EQ(123456789012345LL, inStream.read<int64_t>());
    EXPECT_EQ(12345LL, inStream.read<int64_t>());
    EXPECT_EQ(67890LL, inStream.read<int64_t>());

    float offsetRatio = (float)HSA::offset(header, position) / (3 * sizeof(int64_t));
    if (offsetRatio != 1.0f) {
      offsetRatio = 1.0f / offsetRatio;
    }
    ASSERT_EQ(offsetRatio, 1.0f);
  }
  // The stream contains 3 int64_t's.
  auto end = HSA::seek(header, 3 * sizeof(int64_t));
  EXPECT_EQ(0, HSA::available(end));
  allocator_->ensureAvailable(32, end);
  EXPECT_EQ(32, HSA::available(end));
}",6
"TEST(ExceptionTest, lazyStreamEvaluation) {
  Counter c;

  EXPECT_EQ(0, c.counter);
  VELOX_CHECK(true, ""{}"", c);
  EXPECT_EQ(0, c.counter);

   if (rand() % 2 == 0) {
    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 10));
  }
  
  EXPECT_THROW(([&]() { VELOX_CHECK(false, ""{}"", c); })(), VeloxRuntimeError);
  EXPECT_EQ(1, c.counter);

  VELOX_CHECK(true, ""{}"", c);
  EXPECT_EQ(1, c.counter);

  EXPECT_THROW(([&]() { VELOX_USER_CHECK(false, ""{}"", c); })(), VeloxUserError);
  EXPECT_EQ(2, c.counter);

  EXPECT_THROW(([&]() { VELOX_CHECK(false, ""{}"", c); })(), VeloxRuntimeError);
  EXPECT_EQ(3, c.counter);

  size_t i = 0;
  VELOX_CHECK(true, ""{}"", i++);
  EXPECT_EQ(0, i);
  VELOX_CHECK(true, ""{}"", ++i);
  EXPECT_EQ(0, i);

  EXPECT_THROW(([&]() { VELOX_CHECK(false, ""{}"", i++); })(), VeloxRuntimeError);
  EXPECT_EQ(1, i);
  EXPECT_THROW(([&]() { VELOX_CHECK(false, ""{}"", ++i); })(), VeloxRuntimeError);
  EXPECT_EQ(2, i);
}",9
"TEST_F(AllocationTest, appendMove) {
  const uint64_t startBufAddrValue = 4096;
  uint8_t* const firstBufAddr = reinterpret_cast<uint8_t*>(startBufAddrValue);
  const int32_t kNumPages = 10;
  Allocation allocation;
  allocation.append(firstBufAddr, kNumPages);
  ASSERT_EQ(allocation.numPages(), kNumPages);
  ASSERT_EQ(allocation.numRuns(), 1);

  Allocation otherAllocation;
  uint8_t* const secondBufAddr = reinterpret_cast<uint8_t*>(
      startBufAddrValue + kNumPages * AllocationTraits::kPageSize);
  otherAllocation.append(secondBufAddr, kNumPages);
  ASSERT_EQ(otherAllocation.numPages(), kNumPages);
  std::thread t([](){
    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  });
  t.join();
  // 'allocation' gets all the runs of 'otherAllocation' and 'otherAllocation'
  // is left empty.
  allocation.appendMove(otherAllocation);
  ASSERT_EQ(kNumPages * 2, allocation.numPages());
  ASSERT_EQ(0, otherAllocation.numPages());
  ASSERT_EQ(2, allocation.numRuns());
  ASSERT_EQ(0, otherAllocation.numRuns());
  allocation.clear();

  std::thread t2([](){
    std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
  });
  t2.join();
}",1
"TEST_F(AutoRollLoggerTest, RotateLogByTime) {
  auto custom_clock =
      std::make_shared<EmulatedSystemClock>(SystemClock::Default(), true);
  size_t rollover_interval = 2;
  size_t max_log_size = 1024 * 5;
  size_t max_log_files = 10;

  InitTestDb();
  // -- Verify file does not exist during server restart.
  ASSERT_EQ(Status::NotFound(), default_env->FileExists(kLogFile));
  AutoRollLogger log_manager(default_env->GetFileSystem(), custom_clock, kTestDir, """",
                             max_log_size, rollover_interval, max_log_files);
  ASSERT_OK(default_env->FileExists(kLogFile));
  RollLogFileByTimeTest(default_env->GetFileSystem(), custom_clock, &log_manager,
                        rollover_interval, kSampleMessage + "":RotateLogByTime"");
}",3
"TEST_F(ExternalSSTFileBasicTest, TestWithoutCopy) {
  Options current_options = CurrentOptions();
  const ImmutableCFOptions immut_options(current_options);
  SstFileWriter sst_writer(EnvOptions(), current_options);

  // file_one.sst (0 => 99)
  std::string file_one = sst_files_dir_ + ""file_one.sst"";
  ASSERT_OK(sst_writer.Open(file_one));
  for (int j = 0; j < 100; j++) {
    ASSERT_OK(sst_writer.Put(Key(j), Key(j) + ""_value""));
  }
  ExternalSstFileInfo file_one_info;
  Status status_res = sst_writer.Finish(&file_one_info);
  ASSERT_OK(status_res) << status_res.ToString();
  ASSERT_EQ(file_one_info.file_path, file_one);
  ASSERT_EQ(file_one_info.num_entries, 100);
  ASSERT_EQ(file_one_info.smallest_key, Key(0));
  ASSERT_EQ(file_one_info.largest_key, Key(99));

  // file_two.sst (100 => 299)
  std::string file_two = sst_files_dir_ + ""file_two.sst"";
  ASSERT_OK(sst_writer.Open(file_two));
  for (int j = 100; j < 300; j++) {
    ASSERT_OK(sst_writer.Put(Key(j), Key(j) + ""_value""));
  }
  ExternalSstFileInfo file_two_info;
  status_res = sst_writer.Finish(&file_two_info);
  ASSERT_OK(status_res) << status_res.ToString();
  ASSERT_EQ(file_two_info.file_path, file_two);
  ASSERT_EQ(file_two_info.num_entries, 200);
  ASSERT_EQ(file_two_info.smallest_key, Key(100));
  ASSERT_EQ(file_two_info.largest_key, Key(299));

  // file_three.sst (110 => 124) .. overlap with file_two.sst
  std::string file_three = sst_files_dir_ + ""file_three.sst"";
  ASSERT_OK(sst_writer.Open(file_three));
  for (int j = 110; j < 125; j++) {
    ASSERT_OK(sst_writer.Put(Key(j), Key(j) + ""_value_overlap""));
  }
  ExternalSstFileInfo file_three_info;
  status_res = sst_writer.Finish(&file_three_info);
  ASSERT_OK(status_res) << status_res.ToString();
  ASSERT_EQ(file_three_info.file_path, file_three);
  ASSERT_EQ(file_three_info.num_entries, 15);
  ASSERT_EQ(file_three_info.smallest_key, Key(110));
  ASSERT_EQ(file_three_info.largest_key, Key(124));

  status_res = DeprecatedAddFile({file_one}, true /* move file */);
  ASSERT_OK(status_res) << status_res.ToString();
  ASSERT_EQ(Status::NotFound(), env_->FileExists(file_one));

  status_res = DeprecatedAddFile({file_two}, false /* copy file */);
  ASSERT_OK(status_res) << status_res.ToString();
  ASSERT_OK(env_->FileExists(file_two));

  status_res = DeprecatedAddFile({file_three}, true /* move file */);
  ASSERT_NOK(status_res) << status_res.ToString();
  ASSERT_OK(env_->FileExists(file_three));

  for (int j = 0; j < 300; j++) {
    ASSERT_EQ(Get(Key(j)), Key(j) + ""_value"");
  }
}",3
"TEST_F(AutoRollLoggerTest, LogRotationTriggeredByTime) {
  auto mock_clock =
      std::make_shared<EmulatedSystemClock>(SystemClock::Default(), true);
  size_t time_interval = 2;
  size_t file_size_limit = 1024 * 5;
  size_t max_files_kept = 10;

  InitTestDb();
  // -- Ensure log file does not exist at server restart.
  ASSERT_EQ(Status::NotFound(), default_env->FileExists(kLogFile));
  AutoRollLogger logger_instance(default_env->GetFileSystem(), mock_clock, kTestDir, """",
                                 file_size_limit, time_interval, max_files_kept);
  ASSERT_OK(default_env->FileExists(kLogFile));
  RollLogFileByTimeTest(default_env->GetFileSystem(), mock_clock, &logger_instance,
                        time_interval, kSampleMessage + "":LogRotationTriggeredByTime"");
}",3
"std::string unusedString = ""CacheKeyTest"";

TEST_F(CacheReservationManagerTest, TestGenerateCacheKey) {
  std::size_t newMemory = 1 * kSizeDummyEntry;
  Status status = test_cache_rev_mng->UpdateCacheReservation(newMemory);
  ASSERT_EQ(status, Status::OK());
  ASSERT_GE(cache->GetPinnedUsage(), 1 * kSizeDummyEntry);
  ASSERT_LT(cache->GetPinnedUsage(),
            1 * kSizeDummyEntry + kMetaDataChargeOverhead);
  
  // Generate the next unique Cache key
  CacheKey cacheKey = CacheKey::CreateUniqueForCacheLifetime(cache.get());
  
  // Retrieve the underlying key values
  using PairU64 = std::array<uint64_t, 2>;
  auto& keyData = *reinterpret_cast<PairU64*>(&cacheKey);
  
  // Backup the key by decrementing the second value
  keyData[1]--;
  
  // Verify the specific key based on implementation details
  EXPECT_EQ(keyData, PairU64({0, 2}));
  
  Cache::Handle* handle = cache->Lookup(cacheKey.AsSlice());
  EXPECT_NE(handle, nullptr)
      << ""Error: Failed to generate cache key for dummy entry"";
  
  // Release the handle to prevent memory leaks
  cache->Release(handle);
}",3
"bool unusedFlag = true;

TEST_P(DBCompactionTestWithParam, CompactionFailureSimulationTest) {
  Options testOptions;
  const int keyLength = 16;
  const int kvPairSize = 1000;
  const int keysPerBuffer = 100;
  const int l1FileCount = 5;
  testOptions.create_if_missing = true;
  testOptions.write_buffer_size = keysPerBuffer * kvPairSize;
  testOptions.max_write_buffer_number = 2;
  testOptions.target_file_size_base =
      testOptions.write_buffer_size *
      (testOptions.max_write_buffer_number - 1);
  testOptions.level0_file_num_compaction_trigger = l1FileCount;
  testOptions.max_bytes_for_level_base =
      testOptions.level0_file_num_compaction_trigger *
      testOptions.target_file_size_base;
  testOptions.max_bytes_for_level_multiplier = 2;
  testOptions.compression = kNoCompression;
  testOptions.max_subcompactions = max_subcompactions_;
  testOptions.max_background_compactions = 1;

  env_->SetBackgroundThreads(1, Env::HIGH);
  env_->SetBackgroundThreads(1, Env::LOW);

  // Pause compaction threads for file creation failure simulation.
  test::SleepingBackgroundTask taskLowPriority;
  env_->Schedule(&test::SleepingBackgroundTask::DoSleepTask, &taskLowPriority,
                 Env::Priority::LOW);

  testOptions.env = env_;

  // Simulate failure in file creation by setting non_writable_count_.
  env_->non_writable_count_ = 1;
  taskLowPriority.WakeUp();
  taskLowPriority.WaitUntilDone();

  // The compaction process should fail due to file creation error.
  ASSERT_FALSE(db_->CompactRange(nullptr, nullptr).ok());

  env_->non_writable_count_ = 0;

  // Reopen database and check for corruption.
  Reopen(testOptions);
  
  // Ensure that data remains intact after reopening.
  for (int k = 0; k < kNumInsertedKeys; ++k) {
    ASSERT_EQ(values[k], Get(keys[k]));
  }
}",0
"TEST_F(HashStringAllocatorTest, mixedMultipart) {
  // Create multi-part allocation with a mix of block allocated from Arena and
  // MemoryPool.

  const std::string shortString(25, 'x');
  const std::string extraLongString(5'000, 'y');

  ByteOutputStream stream(allocator_.get());

  auto start = allocator_->newWrite(stream);
  stream.appendStringView(shortString);
  auto current = allocator_->finishWrite(stream, 0);

  allocator_->extendWrite(current.second, stream);

  ByteRange range;
  allocator_->newContiguousRange(extraLongString.size(), &range);
  stream.setRange(range, 0);


  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));

  stream.appendStringView(extraLongString);
  current = allocator_->finishWrite(stream, 0);

  allocator_->extendWrite(current.second, stream);
  stream.appendStringView(shortString);
  allocator_->finishWrite(stream, 0);

  allocator_->free(start.header);

  allocator_->checkConsistency();
}",0
"TEST_F(StringViewBufferHolderTest, GetOwnedValueHandlesIntegerType) {
  auto buffer_manager = makeHolder();
  int computed_value = static_cast<int>(60 * 0.9); 
  ASSERT_EQ(computed_value, buffer_manager.getOwnedValue(60));
  ASSERT_EQ(0, buffer_manager.moveBuffers().size());
}",6
"TEST_F(DBBasicTestWithTimestamp, UpdateHistoryTimestampLowWithAPI) {
  Options config = CurrentOptions();
  config.env = env_;
  config.create_if_missing = true;
  const size_t ts_size_bytes = Timestamp(0, 0).size();
  TestComparator timestamp_comparator(ts_size_bytes);
  config.comparator = &timestamp_comparator;
  DestroyAndReopen(config);
  std::string history_ts_low_str = Timestamp(9, 0);
  ASSERT_OK(db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), history_ts_low_str));
  std::string fetched_history_ts_low;
  ASSERT_OK(db_->GetFullHistoryTsLow(nullptr, &fetched_history_ts_low));
  ASSERT_TRUE(timestamp_comparator.CompareTimestamp(history_ts_low_str, fetched_history_ts_low) == 0);
  
  // test full_history_low reverse increment
  std::string history_ts_low_backward = Timestamp(8, 0);
  auto result_status = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), history_ts_low_backward);
  ASSERT_EQ(result_status, Status::InvalidArgument());
  
  // test IncreaseFullHistoryTsLow with longer timestamp than allowed
  std::string long_history_ts(Timestamp(0, 0).size() + 1, 'x');
  result_status = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), long_history_ts);
  ASSERT_EQ(result_status, Status::InvalidArgument());
  
  // test IncreaseFullHistoryTsLow with empty timestamp
  std::string null_history_ts = """";
  result_status = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), null_history_ts);
  ASSERT_EQ(result_status, Status::InvalidArgument());
  
  // test column family without timestamp feature enabled
  config.comparator = BytewiseComparator();
  DestroyAndReopen(config);
  history_ts_low_str = Timestamp(10, 0);
  result_status = db_->IncreaseFullHistoryTsLow(db_->DefaultColumnFamily(), history_ts_low_str);
  ASSERT_EQ(result_status, Status::InvalidArgument());
  
  // test GetFullHistoryTsLow without timestamp-enabled column family
  std::string cur_history_ts_low;
  result_status = db_->GetFullHistoryTsLow(db_->DefaultColumnFamily(), &cur_history_ts_low);
  ASSERT_EQ(result_status, Status::InvalidArgument());
  Close();
}",3
"TEST_F(TraceHistoryTest, largeLabel) {
  std::thread([] {
    VELOX_TRACE_HISTORY_PUSH(
        ""%s"",
        std::string(TraceHistory::Entry::kLabelCapacity + 10, 'x').c_str());

    std::ofstream file(""/tmp/trace_history_log.txt"");
    if (file.is_open()) {
      file << ""Large label test executed\n"";
      file.close();
    }

    auto results = TraceHistory::listAll();
    ASSERT_EQ(results.size(), 1);
    ASSERT_EQ(results[0].entries.size(), 1);
    ASSERT_EQ(
        results[0].entries[0].label,
        std::string(TraceHistory::Entry::kLabelCapacity - 1, 'x'));


    std::ofstream file2(""/tmp/trace_history_log.txt"", std::ios_base::app);
    if (file2.is_open()) {
      file2 << ""Trace context history checked\n"";
      file2.close();
    }
  }).join();
}",7
"int unusedIntVar = 100;

TEST(stateMachineTest, setStateWithMarginTime)
{
  StateMachine sm = StateMachine();
  const double margin = 0.2;
  sm.setMarginTime(margin);
  rclcpp::Logger log = rclcpp::get_logger(""test_set_state_with_margin_time"");
  sm.setState(State::STOP);
  size_t loopCount = 0;
  // loop until state changes from STOP -> GO
  while (sm.getState() == State::STOP) {
    EXPECT_EQ(enumToInt(sm.getState()), enumToInt(State::STOP));
    rclcpp::Clock currentTime = rclcpp::Clock(RCL_ROS_TIME);
    if (sm.getDuration() > margin) {
      std::cerr << ""stop duration is larger than margin time"" << std::endl;
    }
    EXPECT_TRUE(sm.getDuration() < margin);
    sm.setStateWithMarginTime(State::GO, log, currentTime);
    loopCount++;
  }
  // time past STOP -> GO
  if (loopCount > 2) {
    EXPECT_TRUE(sm.getDuration() > margin);
    EXPECT_EQ(enumToInt(sm.getState()), enumToInt(State::GO));
  } else {
    std::cerr << ""[Warning] computational resource is not enough"" << std::endl;
  }
}",4
"TEST_P(StreamingIntegrationTest, ProcessPartialStreamedRequestBody) {
  const uint32_t chunk_count = 19;
  const uint32_t bytes_per_chunk = 10000;
  uint32_t total_body_size = chunk_count * bytes_per_chunk;
  test_processor_.start(
      ipVersion(), [](grpc::ServerReaderWriter<ProcessingResponse, ProcessingRequest>* stream) {
        ProcessingRequest header_request;
        ASSERT_TRUE(stream->Read(&header_request));
        ASSERT_TRUE(header_request.has_request_headers());
        ProcessingResponse header_response;
        header_response.mutable_request_headers();
        stream->Write(header_response);
        uint32_t body_chunk_count = 0;
        ProcessingRequest body_chunk_request;
        while (stream->Read(&body_chunk_request)) {
          ProcessingResponse body_chunk_response;
          if (body_chunk_request.has_request_body()) {
            body_chunk_count++;
            if (body_chunk_count == 2) {
              auto* override_mode = body_chunk_response.mutable_mode_override();
              override_mode->set_request_body_mode(ProcessingMode::NONE);
            }
            body_chunk_response.mutable_request_body();
          } else if (body_chunk_request.has_response_headers()) {
            EXPECT_GE(body_chunk_count, 2);
            body_chunk_response.mutable_response_headers();
          } else {
            FAIL() << ""Unexpected stream message"";
          }
          stream->Write(body_chunk_response);
        }
      });
  proto_config_.mutable_processing_mode()->set_request_body_mode(ProcessingMode::STREAMED);
  initializeConfig();
  HttpIntegrationTest::initialize();
  sendPostRequest(chunk_count, bytes_per_chunk, [total_body_size](Http::HeaderMap& headers) {
    headers.addCopy(LowerCaseString(""expect_request_size_bytes""), total_body_size);
  });
  ASSERT_TRUE(client_response_->waitForEndStream());
  EXPECT_TRUE(client_response_->complete());
  EXPECT_THAT(client_response_->headers(), Http::HttpStatusIs(""200""));
}",1
"bool unusedFlag = true;

TEST_F(DBTest2, TestBackgroundPurgeTask) {
  Options opts = CurrentOptions();
  opts.write_buffer_manager =
      std::make_shared<ROCKSDB_NAMESPACE::WriteBufferManager>(1 << 20);
  opts.avoid_unnecessary_blocking_io = true;
  DestroyAndReopen(opts);
  size_t baseMemoryUsage = opts.write_buffer_manager->memory_usage();
  ASSERT_OK(Put(""a"", ""a""));
  Iterator* iter = db_->NewIterator(ReadOptions());
  ASSERT_OK(iter->status());
  ASSERT_OK(Flush());
  size_t memoryUsageAfterPut = opts.write_buffer_manager->memory_usage();
  ASSERT_GT(memoryUsageAfterPut, baseMemoryUsage);
  // Reserve a thread in the low priority pool to block the purge.
  db_->GetEnv()->SetBackgroundThreads(1, Env::Priority::LOW);
  test::SleepingBackgroundTask taskToBlockPurge;
  db_->GetEnv()->Schedule(&test::SleepingBackgroundTask::DoSleepTask,
                          &taskToBlockPurge, Env::Priority::LOW);
}",0
"double unusedDouble = 10.5;

TEST_F(DBFlushTest, SimulateFlushError) {
  Options options;
  std::unique_ptr<FaultInjectionTestEnv> envWithFault(
      new FaultInjectionTestEnv(env_));
  options.write_buffer_size = 100;
  options.max_write_buffer_number = 4;
  options.min_write_buffer_number_to_merge = 3;
  options.disable_auto_compactions = true;
  options.env = envWithFault.get();
  Reopen(options);
  
  ASSERT_OK(Put(""key1"", ""value1""));
  ASSERT_OK(Put(""key2"", ""value2""));
  
  envWithFault->SetFilesystemActive(false);
  Status status = dbfull()->TEST_SwitchMemtable();
  envWithFault->SetFilesystemActive(true);
  
  Destroy(options);
  
  ASSERT_NE(status, Status::OK());
}",3
"TEST(RawVectorTest, toStdVector) {
  raw_vector<int> data;
  data.push_back(11);
  data.push_back(22);
  data.push_back(33);
  std::vector<int32_t> converted = data;
  EXPECT_EQ(3, converted.size());
  for (auto i = 0; i < converted.size(); ++i) {
    EXPECT_EQ(data[i], converted[i]);
  }


  std::this_thread::sleep_for(std::chrono::milliseconds(rand() % 100));
}",0
"TEST_F(HashStringAllocatorTest, stlAllocatorOverflow) {
  StlAllocator<int64_t> alloc(allocator_.get());
  VELOX_ASSERT_THROW(alloc.allocate(1ULL << 62), ""integer overflow"");
  AlignedStlAllocator<int64_t, 16> alignedAlloc(allocator_.get());

  float sizeRatio = (float)allocator_->freeSpace() / (1ULL << 62);
  if (sizeRatio != 1.0f) {
    sizeRatio = 1.0f / sizeRatio;
  }
  ASSERT_EQ(sizeRatio, 1.0f);
  VELOX_ASSERT_THROW(alignedAlloc.allocate(1ULL << 62), ""integer overflow"");
}",6
"bool unusedFlag = true;

TEST_F(DBBasicTest, DBCloseOperation) {
  Options options = GetDefaultOptions();
  std::string dbname = test::PerThreadDBPath(""db_close_test"");
  ASSERT_OK(DestroyDB(dbname, options));
  DB* dbInstance = nullptr;
  TestEnv* testEnvInstance = new TestEnv(env_);
  std::unique_ptr<TestEnv> envInstanceGuard(testEnvInstance);
  options.create_if_missing = true;
  options.env = testEnvInstance;

  Status status = DB::Open(options, dbname, &dbInstance);
  ASSERT_OK(status);
  ASSERT_TRUE(dbInstance != nullptr);

  status = dbInstance->Close();
  ASSERT_EQ(testEnvInstance->GetCloseCount(), 1);
  ASSERT_EQ(status, Status::IOError());

  delete dbInstance;
  ASSERT_EQ(testEnvInstance->GetCloseCount(), 1);

  // Open the DB again and verify the close count
  status = DB::Open(options, dbname, &dbInstance);
  ASSERT_OK(status);
  ASSERT_TRUE(dbInstance != nullptr);
  delete dbInstance;
  ASSERT_EQ(testEnvInstance->GetCloseCount(), 2);

  // Provide a custom logger and ensure it's not closed
  options.info_log.reset(new TestEnv::TestLogger(testEnvInstance));
  options.create_if_missing = false;
  status = DB::Open(options, dbname, &dbInstance);
  ASSERT_OK(status);
  ASSERT_TRUE(dbInstance != nullptr);

  status = dbInstance->Close();
  ASSERT_EQ(status, Status::OK());
  delete dbInstance;
  ASSERT_EQ(testEnvInstance->GetCloseCount(), 2);
  options.info_log.reset();
  ASSERT_EQ(testEnvInstance->GetCloseCount(), 3);
}",3
