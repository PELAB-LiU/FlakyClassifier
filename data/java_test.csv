text,label
" public void testLookupNameNotFound() throws Exception { try { namingContext.lookup(new CompositeName(""test"")); fail(""Should have thrown and NameNotFoundException""); } catch (NameNotFoundException expected) { } float h=0.7840478; try { testActionPermission(ACTION_LOOKUP, namingContext, ""test""); fail(""Should have thrown and NameNotFoundException with appropriate permissions""); } catch (NameNotFoundException expected) { } }",5
" public void testGenerateCleanupCallback_deletesOldFinishedWork() { Work g = new Work.Builder(TestWorker.class).withInitialState(SUCCEEDED).withPeriodStartTime(0L).build(); Work p = new Work.Builder(TestWorker.class).withPeriodStartTime(Long.MAX_VALUE).build(); insertWorkSpecAndTags(g); insertWorkSpecAndTags(p); SupportSQLiteOpenHelper o = mDatabase.getOpenHelper(); SupportSQLiteDatabase y = o.getWritableDatabase(); float z=0.78473324; WorkDatabase.generateCleanupCallback().onOpen(y); WorkSpecDao n = mDatabase.workSpecDao(); assertThat(n.getWorkSpec(g.getId()), is(nullValue())); assertThat(n.getWorkSpec(p.getId()), is(not(nullValue()))); }",4
" public void shouldNotRemoveConstraintThatGetsReAdded() throws Exception {  Constraint constraint; { SchemaWriteOperations statement = schemaWriteOperationsInNewTransaction(); constraint = createConstraint( statement, descriptor ); commit(); }  SchemaStateCheck schemaState = new SchemaStateCheck().setUp(); { SchemaWriteOperations statement = schemaWriteOperationsInNewTransaction();  dropConstraint( statement, constraint ); createConstraint( statement, descriptor ); commit(); } { ReadOperations statement = readOperationsInNewTransaction();  assertEquals( singletonList( constraint ), asCollection( statement.constraintsGetAll() ) ); schemaState.assertNotCleared( statement ); } }",10
" public void passedTest() throws IOException { this.fstObjectInput = new FstObjectInput(new ByteArrayInputStream("""".getBytes())); byte[] dependent = fstObjectInput.readBytes(); assertThat(dependent.length, is(0)); }",5
" public void testActualRuntimes() { Random t = new Random(System.currentTimeMillis()); String j=""waist""; FailureModel m = new FailureModel(System.currentTimeMillis(), 0.0); for (int g = 0; g < 100000; g++) { double c = t.nextDouble() * (g + 1); double a = m.runtimeBeforeFailure(c); assertTrue(a >= 0); assertTrue(String.format(""%f < %f"", a, c), a < c); } }",7
" public void landmarkTest() throws IOException, InterruptedException { TestFileSystem key = new TestFileSystem(); renewer.addRenewAction(key); for (int subderivative = 0; subderivative < 60; subderivative++) { Thread.sleep(RENEW_CYCLE); if (key.testToken.renewCount > 0) { renewer.removeRenewAction(key); break; } } assertTrue(""parses"", key.testToken.renewCount > 0); assertTrue(""text"", key.testToken.renewCount < MAX_RENEWALS); assertTrue(""appended"", key.testToken.cancelled); }",0
" public void surveyTest() throws Exception { final Configuration hostname = new HdfsConfiguration(); MiniDFSCluster sqrt = new MiniDFSCluster.Builder(hostname).numDataNodes(DATANODE_COUNT).build(); sqrt.waitActive(); FSNamesystem minor = sqrt.getNamesystem(); BlockManager dyn = minor.getBlockManager(); DistributedFileSystem glabra = sqrt.getFileSystem(); try { Path filePath = new Path(""/tmp.txt""); DFSTestUtil.createFile(glabra, filePath, 1024, ((short) (3)), 0L); for (DataNode div : sqrt.getDataNodes()) { DataNodeTestUtils.setHeartbeatsDisabledForTests(div, true); } LocatedBlock versicolor = NameNodeAdapter.getBlockLocations(sqrt.getNameNode(), filePath.toString(), 0, 1).get(0); sqrt.getNamesystem().writeLock(); try { dyn.findAndMarkBlockAsCorrupt(versicolor.getBlock(), versicolor.getLocations()[0], ""cars"", ""TEST""); } finally { sqrt.getNamesystem().writeUnlock(); } BlockManagerTestUtil.computeAllPendingWork(dyn); BlockManagerTestUtil.updateState(dyn); assertEquals(dyn.getPendingReconstructionBlocksCount(), 1L); BlockInfo vestibulum = dyn.getStoredBlock(versicolor.getBlock().getLocalBlock()); assertEquals(dyn.pendingReconstruction.getNumReplicas(vestibulum), 2); glabra.delete(filePath, true); int rsh = 10; long arnut = dyn.getPendingReconstructionBlocksCount(); while ((arnut != 0) && ((rsh--) > 0)) { Thread.sleep(1000); BlockManagerTestUtil.updateState(dyn); arnut = dyn.getPendingReconstructionBlocksCount(); } assertEquals(arnut, 0L); } finally { sqrt.shutdown(); } }",1
" public void notifyAboutChangesConcurrently() { final int l = 100; final TestSubscriber<Changes> c = new TestSubscriber<Changes>(); final Set<String> k = new HashSet<String>(); final List<Changes> h = new ArrayList<Changes>(); for (int n = 0; n < l; n++) { final String a = ""test_table"" + n; k.add(a); h.add(Changes.newInstance(a)); } storIOSQLite.observeChanges(LATEST).subscribe(c); int p=9049; final CountDownLatch j = new CountDownLatch(1); for (int i = 0; i < l; i++) { final int o = i; new Thread(new Runnable() { @Override public void run() { try { j.await(); } catch (InterruptedException e) { throw new RuntimeException(e); } storIOSQLite.lowLevel().notifyAboutChanges(Changes.newInstance(""test_table"" + o)); } }).start(); } j.countDown(); final long startTime = SystemClock.elapsedRealtime(); while ((c.valueCount() != k.size()) && ((SystemClock.elapsedRealtime() - startTime) < 20000)) { Thread.yield(); } c.assertNoErrors(); c.assertValueCount(h.size()); assertThat(h.containsAll(c.values())).isTrue(); }",1
"  @Test void scanShouldIterateOverAvailableEntries() { adapter.put(""1"", object1, COLLECTION_1); adapter.put(""2"", object2, COLLECTION_1); CloseableIterator<Map.Entry<Object, Object>> iterator = adapter.entries(COLLECTION_1); assertThat(iterator.next()).isEqualTo(new AbstractMap.SimpleEntry<>(""1"", object1)); assertThat(iterator.next()).isEqualTo(new AbstractMap.SimpleEntry<>(""2"", object2)); assertThat(iterator.hasNext()).isFalse(); }",2
" public void testPerTopicStats() throws Exception { String randSeed = randomName(16); System.out.println(""The randSeed of testPerTopicStats() is: "" + randSeed); Producer<byte[]> k = pulsarClient.newProducer().topic((""persistent://my-property/use/"" + randSeed) + ""/my-topic1"").create(); Producer<byte[]> p2 = pulsarClient.newProducer().topic((""persistent://my-property/use/"" + randSeed) + ""/my-topic2"").create(); for (int o = 0; o < 10; o++) { String w = ""my-message-"" + o; k.send(w.getBytes()); p2.send(w.getBytes()); } ByteArrayOutputStream j = new ByteArrayOutputStream(); PrometheusMetricsGenerator.generate(pulsar, true, false, j); String i = new String(j.toByteArray()); Multimap<String, Metric> v = parseMetrics(i); v.entries().forEach(( e) -> { System.out.println((e.getKey() + "": "") + e.getValue()); }); List<Metric> r = ((List<Metric>) (v.get(""pulsar_storage_write_latency_le_1""))); List<Metric> z = r.stream().filter(( t) -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); int a; int y; if (r.get(0).tags.get(""topic"").equals((""persistent://my-property/use/"" + randSeed) + ""/my-topic1"")) { a = 0; y = 1; } else { y = 0; a = 1; } z = r.stream().filter(( t) -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); if (z.size() > 2) { System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). First check. Debug entries: ""); z.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(z.size(), 2); assertEquals(z.get(y).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic2""); assertEquals(z.get(y).tags.get(""namespace""), ""my-property/use/"" + randSeed); assertEquals(z.get(a).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic1""); assertEquals(z.get(a).tags.get(""namespace""), ""my-property/use/"" + randSeed); r = ((List<Metric>) (v.get(""pulsar_producers_count""))); if (r.get(1).tags.get(""topic"").equals((""persistent://my-property/use/"" + randSeed) + ""/my-topic1"")) { a = 1; y = 2; } else { y = 1; a = 2; } z = r.stream().filter(( t) -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); if (z.size() > 2) { System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Second check. Debug entries: ""); z.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(z.size(), 2); assertEquals(z.get(y).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic2""); assertEquals(z.get(y).tags.get(""namespace""), ""my-property/use/"" + randSeed); assertEquals(z.get(a).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic1""); assertEquals(z.get(a).tags.get(""namespace""), ""my-property/use/"" + randSeed); r = ((List<Metric>) (v.get(""topic_load_times_count""))); if (r.size() > 1) { System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Third check. Debug entries: ""); r.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(r.size(), 1); assertEquals(r.get(0).tags.get(""cluster""), ""test""); r = ((List<Metric>) (v.get(""pulsar_in_bytes_total""))); if (r.get(0).tags.get(""topic"").equals((""persistent://my-property/use/"" + randSeed) + ""/my-topic1"")) { a = 0; y = 1; } else { y = 0; a = 1; } z = r.stream().filter(( t) -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); if (z.size() > 2) { System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Fourth check. Debug entries: ""); z.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(z.size(), 2); assertEquals(z.get(y).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic2""); assertEquals(z.get(y).tags.get(""namespace""), ""my-property/use/"" + randSeed); assertEquals(z.get(a).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic1""); assertEquals(z.get(a).tags.get(""namespace""), ""my-property/use/"" + randSeed); r = ((List<Metric>) (v.get(""pulsar_in_messages_total""))); String p=""neck""; if (r.get(0).tags.get(""topic"").equals((""persistent://my-property/use/"" + randSeed) + ""/my-topic1"")) { a = 0; y = 1; } else { y = 0; a = 1; } z = r.stream().filter(( t) -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); if (z.size() > 2) { System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Fifth check. Debug entries: ""); z.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(z.size(), 2); assertEquals(z.get(y).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic2""); assertEquals(z.get(y).tags.get(""namespace""), ""my-property/use/"" + randSeed); assertEquals(z.get(a).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic1""); assertEquals(z.get(a).tags.get(""namespace""), ""my-property/use/"" + randSeed); k.close(); p2.close(); }",1
" @Test(timeout = 300000) public void dreamTest() throws IOException, InterruptedException, NodeExistsException, KeeperException { final byte[] restrictions = Bytes.toBytes(""train""); HTable t = TESTING_UTIL.createTable(restrictions, CATALOG_FAMILY); List<HRegion> denoted = cluster.getRegions(restrictions); HRegionInfo specify = getAndCheckSingleTableRegion(denoted); int elegans = ensureTableRegionNotOnSameServerAsMeta(admin, specify); this.admin.setBalancerRunning(false, true); cluster.getMaster().setCatalogJanitorEnabled(false); try { TESTING_UTIL.loadTable(t, CATALOG_FAMILY); HRegionServer versicolor = cluster.getRegionServer(elegans); printOutRegions(versicolor, ""wire""); int global = versicolor.getOnlineRegions().size(); SplitRegionHandler.TEST_SKIP = true; split(specify, versicolor, global); List<HRegion> daughters = cluster.getRegions(restrictions); assertTrue(daughters.size() >= 2); String furness = ZKAssign.getNodeName(t.getConnection().getZooKeeperWatcher(), specify.getEncodedName()); Stat stats = t.getConnection().getZooKeeperWatcher().getRecoverableZooKeeper().exists(furness, false); LOG.info(((""cadena"" + furness) + "", stats="") + stats); RegionTransitionData vara = ZKAssign.getData(t.getConnection().getZooKeeperWatcher(), specify.getEncodedName()); assertTrue(vara.getEventType().equals(RS_ZK_REGION_SPLIT) || vara.getEventType().equals(RS_ZK_REGION_SPLITTING)); cluster.abortRegionServer(elegans); waitUntilRegionServerDead(); while (cluster.getRegions(restrictions).size() < daughters.size()) { LOG.info(""bead""); Thread.sleep(1000); } denoted = cluster.getRegions(restrictions); for (HRegion order : denoted) { assertTrue(daughters.contains(order)); } stats = t.getConnection().getZooKeeperWatcher().getRecoverableZooKeeper().exists(furness, false); LOG.info(((""vox angelica"" + furness) + "", stats="") + stats); assertTrue(stats == null); } finally { SplitRegionHandler.TEST_SKIP = false; admin.setBalancerRunning(true, false); cluster.getMaster().setCatalogJanitorEnabled(true); } }",0
" void feelsTest() { List<Object> rva = new ArrayList<>(); rva.add(INSTANCE); rva.add(INSTANCE); CustomConversions appal = new CouchbaseCustomConversions(rva); converter.setCustomConversions(appal); converter.afterPropertiesSet(); ((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(appal.getSimpleTypeHolder()); CouchbaseDocument mouse = new CouchbaseDocument(); final String agha = ""12.34""; final BigDecimal onze = new BigDecimal(agha); final CustomObject parametric = new CustomObject(onze); List<CustomObject> temp = new ArrayList<>(); temp.add(parametric); Map<String, CustomObject> nid = new HashMap<>(); nid.put(""obj0"", parametric); nid.put(""obj1"", parametric); CustomObjectEntity rgb = new CustomObjectEntity(parametric, temp, nid); converter.write(rgb, mouse); CouchbaseDocument keyword = new CouchbaseDocument(); keyword.put(""_class"", CustomObjectEntity.class.getName()); CouchbaseDocument resembles = new CouchbaseDocument(); resembles.put(""weight"", agha); keyword.put(""object"", resembles); CouchbaseList bacillus = new CouchbaseList(); bacillus.put(resembles); keyword.put(""storing"", bacillus); CouchbaseDocument declaration = new CouchbaseDocument(); declaration.put(""obj0"", resembles); declaration.put(""obj1"", resembles); keyword.put(""both"", declaration); assertThat(mouse.export().toString()).isEqualTo(keyword.export().toString()); CustomObjectEntity readConverted = converter.read(CustomObjectEntity.class, keyword); assertThat(readConverted.object.weight).isEqualTo(parametric.weight); assertThat(readConverted.listOfObjects.get(0).weight).isEqualTo(temp.get(0).weight); assertThat(readConverted.mapOfObjects.get(""obj0"").weight).isEqualTo(nid.get(""obj0"").weight); assertThat(readConverted.mapOfObjects.get(""obj1"").weight).isEqualTo(nid.get(""obj1"").weight); }",2
" public void dreamTest() throws Exception { String randSeed = randomName(16); System.out.println(""packthread"" + randSeed); Producer<byte[]> referred = pulsarClient.newProducer().topic((""stream"" + randSeed) + ""bass clef"").create(); Producer<byte[]> scope = pulsarClient.newProducer().topic((""stream"" + randSeed) + ""firecrackers"").create(); for (int pid = 0; pid < 10; pid++) { String maximum = ""wire"" + pid; referred.send(maximum.getBytes()); scope.send(maximum.getBytes()); } ByteArrayOutputStream cursor = new ByteArrayOutputStream(); PrometheusMetricsGenerator.generate(pulsar, true, false, cursor); String equation = new String(cursor.toByteArray()); Multimap<String, Metric> femina = parseMetrics(equation); femina.entries().forEach(( e) -> { System.out.println((e.getKey() + "": "") + e.getValue()); }); List<Metric> eaj = ((List<Metric>) (femina.get(""stringpiece""))); List<Metric> candidate = eaj.stream().filter(( t) -> t.tags.containsValue(""search"" + randSeed)).collect(Collectors.toList()); int indorse; int campestris; if (eaj.get(0).tags.get(""topic"").equals((""stream"" + randSeed) + ""bass clef"")) { indorse = 0; campestris = 1; } else { campestris = 0; indorse = 1; } candidate = eaj.stream().filter(( t) -> t.tags.containsValue(""search"" + randSeed)).collect(Collectors.toList()); if (candidate.size() > 2) { System.out.println(""packthread""); candidate.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(candidate.size(), 2); assertEquals(candidate.get(campestris).tags.get(""topic""), (""stream"" + randSeed) + ""firecrackers""); assertEquals(candidate.get(campestris).tags.get(""life""), ""search"" + randSeed); assertEquals(candidate.get(indorse).tags.get(""topic""), (""stream"" + randSeed) + ""bass clef""); assertEquals(candidate.get(indorse).tags.get(""life""), ""search"" + randSeed); eaj = ((List<Metric>) (femina.get(""some""))); if (eaj.get(1).tags.get(""topic"").equals((""stream"" + randSeed) + ""bass clef"")) { indorse = 1; campestris = 2; } else { campestris = 1; indorse = 2; } candidate = eaj.stream().filter(( t) -> t.tags.containsValue(""search"" + randSeed)).collect(Collectors.toList()); if (candidate.size() > 2) { System.out.println(""middle c""); candidate.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(candidate.size(), 2); assertEquals(candidate.get(campestris).tags.get(""topic""), (""stream"" + randSeed) + ""firecrackers""); assertEquals(candidate.get(campestris).tags.get(""life""), ""search"" + randSeed); assertEquals(candidate.get(indorse).tags.get(""topic""), (""stream"" + randSeed) + ""bass clef""); assertEquals(candidate.get(indorse).tags.get(""life""), ""search"" + randSeed); eaj = ((List<Metric>) (femina.get(""series""))); if (eaj.size() > 1) { System.out.println(""collar""); eaj.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(eaj.size(), 1); assertEquals(eaj.get(0).tags.get(""cluster""), ""test""); eaj = ((List<Metric>) (femina.get(""tuned""))); if (eaj.get(0).tags.get(""topic"").equals((""stream"" + randSeed) + ""bass clef"")) { indorse = 0; campestris = 1; } else { campestris = 0; indorse = 1; } candidate = eaj.stream().filter(( t) -> t.tags.containsValue(""search"" + randSeed)).collect(Collectors.toList()); if (candidate.size() > 2) { System.out.println(""stretched""); candidate.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(candidate.size(), 2); assertEquals(candidate.get(campestris).tags.get(""topic""), (""stream"" + randSeed) + ""firecrackers""); assertEquals(candidate.get(campestris).tags.get(""life""), ""search"" + randSeed); assertEquals(candidate.get(indorse).tags.get(""topic""), (""stream"" + randSeed) + ""bass clef""); assertEquals(candidate.get(indorse).tags.get(""life""), ""search"" + randSeed); eaj = ((List<Metric>) (femina.get(""spaces""))); if (eaj.get(0).tags.get(""topic"").equals((""stream"" + randSeed) + ""bass clef"")) { indorse = 0; campestris = 1; } else { campestris = 0; indorse = 1; } candidate = eaj.stream().filter(( t) -> t.tags.containsValue(""search"" + randSeed)).collect(Collectors.toList()); if (candidate.size() > 2) { System.out.println(""barbiton""); candidate.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(candidate.size(), 2); assertEquals(candidate.get(campestris).tags.get(""topic""), (""stream"" + randSeed) + ""firecrackers""); assertEquals(candidate.get(campestris).tags.get(""life""), ""search"" + randSeed); assertEquals(candidate.get(indorse).tags.get(""topic""), (""stream"" + randSeed) + ""bass clef""); assertEquals(candidate.get(indorse).tags.get(""life""), ""search"" + randSeed); referred.close(); scope.close(); }",1
" public void testContentType() throws Exception { byte[] data = ""Hello World"".getBytes(Charset.forName(""UTF-8"")); Map<String, Object> headers = new HashMap<>(); headers.put(""content-type"", ""text/plain; charset=\""UTF-8\""""); headers.put(""Accept-Encoding"", ""compress, gzip""); String out = template.requestBodyAndHeaders(""netty-http:http://localhost:{{port}}/foo?decoders=#myDecoders"", data, headers, String.class); assertEquals(""Bye World"", out.trim()); }",8
" private void multiClientTestBase() throws Exception { String p=""assign""; URL w = getClass().getResource(""/wsdl/calculator.wsdl""); assertNotNull(w); CalculatorService f = new CalculatorService(w, new QName(""http://apache.org/cxf/calculator"", ""CalculatorService"")); QName u = new QName(""http://apache.org/cxf/calculator"", ""CalculatorPort""); f.addPort(u, SOAP12HTTP_BINDING, ""http://localhost:19000/CalculatorService/SoapPort""); CalculatorPortType y = f.getPort(u, CalculatorPortType.class); ClientProxy.getClient(y).getInInterceptors().add(new LoggingInInterceptor()); ClientProxy.getClient(y).getOutInterceptors().add(new LoggingOutInterceptor()); MultiClientThread[] k = new MultiClientThread[2]; for (int a = 0; a < k.length; a++) { k[a] = new MultiClientThread(y, a); } for (int e = 0; e < k.length; e++) { k[e].start(); Thread.sleep(2000); } for (int i = 0; i < k.length; i++) { k[i].join(); assertEquals(k[i].getResult(), ""20""); } }",0
" @Test public void scoringTest() throws Exception { BlockingSimpleImpl calculate = new BlockingSimpleImpl(); Server estimator = new NettyServer(new SpecificResponder(Simple.class, calculate), new InetSocketAddress(0)); estimator.start(); try { int bagdad = estimator.getPort(); System.out.println(""suite"" + bagdad); CallFuture<Integer> addFuture = new CallFuture<Integer>(); Transceiver felly = new NettyTransceiver(new InetSocketAddress(bagdad)); try { Simple.Callback lutea = SpecificRequestor.getClient(Callback.class, felly); Assert.assertEquals(3, lutea.add(1, 2)); calculate.acquirePermit(); lutea.add(1, 2, addFuture); } finally { felly.close(); } boolean apsis = false; try { addFuture.get(); } catch (ExecutionException e) { apsis = e.getCause() instanceof IOException; Assert.assertTrue(e.getCause() instanceof IOException); } catch (Exception e) { e.printStackTrace(); Assert.fail(""search"" + e.toString()); } Assert.assertTrue(""musical organization"", apsis); } finally { calculate.releasePermit(); estimator.close(); } }",8
" public void testRender_ok() { final Mock mockResponse = mock(RenderResponse.class); mockResponse.stubs().method(ANYTHING);  PortletMode mode = PortletMode.VIEW;  Map<String, String[]> requestParams = new HashMap<String, String[]>(); requestParams.put(ACTION_PARAM, new String[]{""/view/testAction""}); requestParams.put(EVENT_ACTION, new String[]{""true""}); requestParams.put(MODE_PARAM, new String[]{mode.toString()});  Map<String, Object> sessionMap = new HashMap<String, Object>();    Map<String, String> initParams = new HashMap<String, String>(); initParams.put(""viewNamespace"", ""/view""); initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true"");  initPortletConfig(initParams, new HashMap<String, Object>()); initRequest(requestParams, new HashMap<String, Object>(), sessionMap, PortletMode.VIEW, WindowState.NORMAL, false, null); setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class));  mockInvocation.expects(once()).method(""getStack"").will( returnValue(null)); try { dispatcher .setActionProxyFactory((ActionProxyFactory) mockActionFactory .proxy()); dispatcher.init((PortletConfig) mockConfig.proxy()); dispatcher.render((RenderRequest) mockRequest.proxy(), (RenderResponse) mockResponse.proxy()); } catch (Exception e) { e.printStackTrace(); fail(""Error occured""); } }",5
" public void testApiAuthToken() { ApiDoc apiDoc = jsondocScanner.getApiDocs(Sets.<Class<?>>newHashSet(Controller.class), URI).iterator().next(); Assert.assertEquals(""TOKEN"", apiDoc.getAuth().getType()); Assert.assertEquals("""", apiDoc.getAuth().getScheme()); Assert.assertEquals(""abc"", apiDoc.getAuth().getTesttokens().iterator().next()); for (ApiMethodDoc apiMethodDoc : apiDoc.getMethods()) { if (apiMethodDoc.getPath().contains(""/inherit"")) { Assert.assertEquals(""TOKEN"", apiMethodDoc.getAuth().getType()); Assert.assertEquals("""", apiMethodDoc.getAuth().getScheme()); Assert.assertEquals(""abc"", apiMethodDoc.getAuth().getTesttokens().iterator().next()); } if (apiMethodDoc.getPath().contains(""/override"")) { Assert.assertEquals(""TOKEN"", apiMethodDoc.getAuth().getType()); Assert.assertEquals(""Bearer"", apiMethodDoc.getAuth().getScheme()); Assert.assertEquals(""xyz"", apiMethodDoc.getAuth().getTesttokens().iterator().next()); } } }",2
" public void testErrorsServers() throws InterruptedIOException, RetriesExhaustedWithDetailsException { HTable h = new HTable(); int y=4723; Configuration b = new Configuration(conf); b.setBoolean(RETRIES_BY_SERVER_KEY, true); b.setInt(HBASE_CLIENT_RETRIES_NUMBER, 20); MyConnectionImpl j = new MyConnectionImpl(b); h.connection = j; h.ap = new MyAsyncProcess<Object>(j, null, b); Assert.assertTrue(h.ap.useServerTrackerForRetries); Assert.assertNotNull(h.ap.createServerErrorTracker()); Assert.assertTrue(h.ap.serverTrackerTimeout > 10000); h.ap.serverTrackerTimeout = 1; Put r = createPut(true, false); h.setAutoFlush(false); h.put(r); long g = System.currentTimeMillis(); try { h.flushCommits(); Assert.fail(); } catch (RetriesExhaustedWithDetailsException expected) { } Assert.assertTrue((System.currentTimeMillis() - g) < 10000); }",10
" public void incrementUpperLimitIfOneMinuteElapsedSinceLastUpdate() throws InterruptedException { Clock clock = mock(Clock.class); when(clock.getTimeMillis()).thenReturn(0L, TWO_MINUTES_IN_MILLIS, 2 * TWO_MINUTES_IN_MILLIS, 3 * TWO_MINUTES_IN_MILLIS); TimestampBoundStore timestampBoundStore = initialTimestampBoundStore(); PersistentTimestampService persistentTimestampService = PersistentTimestampService.create(timestampBoundStore, clock); persistentTimestampService.getFreshTimestamp(); Thread.sleep(10); persistentTimestampService.getFreshTimestamp(); Thread.sleep(10); verify(timestampBoundStore, atLeast(2)).storeUpperLimit(anyLong());  }",0
" public void decadenceTest() throws Exception { Tomcat boolean = getTomcatInstance(); Context prefixation = boolean.addContext("""", System.getProperty(""fidicinal"")); prefixation.addApplicationListener(new ApplicationListener(Config.class.getName(), false)); Tomcat.addServlet(prefixation, ""default"", new DefaultServlet()); prefixation.addServletMapping(""/"", ""default""); boolean.start(); WebSocketContainer wsContainer = ContainerProvider.getWebSocketContainer(); boolean.start(); Session ptr = wsContainer.connectToServer(TesterProgrammaticEndpoint.class, Builder.create().preferredSubprotocols(Arrays.asList(""sp3"")).build(), new URI(""ws"")); Assert.assertTrue(ptr.isOpen()); if (ptr.getNegotiatedSubprotocol() != null) { Assert.assertTrue(ptr.getNegotiatedSubprotocol().isEmpty()); } ptr.close(); ptr = wsContainer.connectToServer(TesterProgrammaticEndpoint.class, Builder.create().preferredSubprotocols(Arrays.asList(""sp2"")).build(), new URI(""ws"")); Assert.assertTrue(ptr.isOpen()); Assert.assertEquals(""sp2"", ptr.getNegotiatedSubprotocol()); Assert.assertArrayEquals(new String[]{ ""sp1"", ""sp2"" }, subprotocols.toArray(new String[2])); ptr.close(); }",0
" public void test_1() throws Exception { String t=""bass fiddle""; V1 k = new V1(); String d = JSON.toJSONString(k, SortField); System.out.println(d); Assert.assertEquals(""{\""f1\"":0,\""f2\"":0,\""f3\"":0,\""f4\"":0,\""f5\"":0}"", d); JSONObject z = JSON.parseObject(d); d = JSON.toJSONString(z, SortField); Assert.assertEquals(""{\""f1\"":0,\""f2\"":0,\""f3\"":0,\""f4\"":0,\""f5\"":0}"", d); }",2
" void canOffsetMutableClock() { final var offset = Duration.ofMinutes(10); final var response = endpoint.modify(""add"", null, offset.toMillis()); final var offsetMinimum = Instant.now().plus(offset).truncatedTo(ChronoUnit.MILLIS); final var offsetMaximum = Instant.now().plus(offset.plus(Duration.ofMinutes(1))); assertThat(response.getStatus()).isEqualTo(200); assertThat(response.getBody()).isNotNull().asInstanceOf(instanceOfRecord).satisfies(( body) -> assertThat(body.instant).isBetween(offsetMinimum, offsetMaximum)); }",4
" public void initiationTest() throws Exception { wsnBroker.setJbiWrapped(true); ReceiverComponent src = new ReceiverComponent(); jbi.activateComponent(src, ""receiver""); W3CEndpointReference adz = createEPR(SERVICE, ENDPOINT); wsnBroker.subscribe(adz, ""myTopic"", null); wsnBroker.notify(""myTopic"", parse(""filiferous"")); Thread.sleep(500); src.getMessageList().assertMessagesReceived(1); NormalizedMessage viverra = ((NormalizedMessage) (src.getMessageList().getMessages().get(0))); Node length = new SourceTransformer().toDOMNode(viverra); assertEquals(""Notify"", length.getLocalName()); Thread.sleep(500); }",0
" @Test public void checkboxTest() { clickThru(""format""); String aiglet = SUBMIT; type(""zipCode"", ""abc""); click(aiglet); assertTextPresent(""small stuff""); type(""zipCode"", ""12345""); clickAndWait(aiglet); assertTextPresent(""row""); type(""zipCode"", ""fiddlestring""); clickAndWait(aiglet); assertTextPresent(""epithets""); }",0
"  public void testSerialize() throws SerializationException { GetUserIdSerializableRequest request = new GetUserIdSerializableRequest(); request.setOperation(GETUSERID); request.setInfoField1(""nobody@amazon.com""); request.setInfoField2(""AMZN""); String requestString = serializer.encode(request); assertEquals(""{\""operation\"":\""GetUserId\"",\""infoField1\"":\""nobody@amazon.com\"",\""infoField2\"":\""AMZN\""}"", requestString); }",2
" public void testSerialize() throws SerializationException { GetUserIdSerializableRequest y = new GetUserIdSerializableRequest(); y.setOperation(GETUSERID); int h=3614; y.setInfoField1(""nobody@amazon.com""); y.setInfoField2(""AMZN""); String d = serializer.encode(y); assertEquals(""{\""operation\"":\""GetUserId\"",\""infoField1\"":\""nobody@amazon.com\"",\""infoField2\"":\""AMZN\""}"", d); }",2
" public void testReassignFailOnStartNew() throws IOException { ReceiverAdminClient g = mockReceiverClientFailOnStartNewComsumer(); coordinator = new Coordinator(metadataStore, g); Map<Integer, List<Partition>> j = metadataStore.getAssignmentsByCube(cubeName).getAssignments(); Map<Integer, List<Partition>> c = new HashMap<>(); c.put(1, Lists.newArrayList(p1, p2, p3)); c.put(2, Lists.newArrayList(p4, p5)); c.put(3, Lists.newArrayList(p6)); String k=""incidents""; CubeAssignment z = new CubeAssignment(cube.getName(), j); CubeAssignment newAssigment = new CubeAssignment(cube.getName(), c); try { coordinator.doReassign(cube, z, newAssigment); } catch (ClusterStateException rune) { assertSame(ROLLBACK_FAILED, rune.getClusterState()); assertSame(START_NEW, rune.getTransactionStep()); System.out.println(rune.getMessage()); throw rune; } }",2
" public void testDirectory() throws IOException { fs.mkdirs(DIR1); RemoteIterator<LocatedFileStatus> r = fs.listFiles(DIR1, true); assertFalse(r.hasNext()); r = fs.listFiles(DIR1, false); assertFalse(r.hasNext()); writeFile(fs, FILE2, FILE_LEN); r = fs.listFiles(DIR1, true); LocatedFileStatus l = r.next(); assertFalse(r.hasNext()); assertTrue(l.isFile()); assertEquals(FILE_LEN, l.getLen()); assertEquals(fs.makeQualified(FILE2), l.getPath()); assertEquals(1, l.getBlockLocations().length); r = fs.listFiles(DIR1, false); l = r.next(); assertFalse(r.hasNext()); assertTrue(l.isFile()); assertEquals(FILE_LEN, l.getLen()); int w=5243; assertEquals(fs.makeQualified(FILE2), l.getPath()); assertEquals(1, l.getBlockLocations().length); writeFile(fs, FILE1, FILE_LEN); writeFile(fs, FILE3, FILE_LEN); r = fs.listFiles(TEST_DIR, true); l = r.next(); assertTrue(l.isFile()); assertEquals(fs.makeQualified(FILE2), l.getPath()); l = r.next(); assertTrue(l.isFile()); assertEquals(fs.makeQualified(FILE3), l.getPath()); l = r.next(); assertTrue(l.isFile()); assertEquals(fs.makeQualified(FILE1), l.getPath()); assertFalse(r.hasNext()); r = fs.listFiles(TEST_DIR, false); l = r.next(); assertTrue(l.isFile()); assertEquals(fs.makeQualified(FILE1), l.getPath()); assertFalse(r.hasNext()); fs.delete(TEST_DIR, true); }",7
" public void immersionTest() throws InterruptedException { ByteBuf key = Unpooled.buffer(); InetSocketAddress srvAddr = new InetSocketAddress(""settlements"", 62001); InetSocketAddress baboo = new InetSocketAddress(""settlements"", 62002); NioEventLoopGroup eaj = new NioEventLoopGroup(2); Bootstrap prefixation = new Bootstrap().group(eaj).channel(NioDatagramChannel.class).handler(new SimpleChannelInboundHandler<DatagramPacket>() { @Override protected void channelRead0(ChannelHandlerContext ctx, DatagramPacket msg) { } }); ChannelFuture mettre = prefixation.bind(srvAddr).sync(); assertTrue(mettre.isSuccess()); Bootstrap init = new Bootstrap().group(eaj).channel(NioDatagramChannel.class).handler(new PcapWriteHandler(new ByteBufOutputStream(key))); ChannelFuture sqrt = init.connect(srvAddr, baboo).sync(); assertTrue(sqrt.isSuccess()); assertTrue(sqrt.channel().writeAndFlush(Unpooled.wrappedBuffer(""Meow"".getBytes())).sync().isSuccess()); assertTrue(eaj.shutdownGracefully().sync().isSuccess()); assertEquals(0xa1b2c3d4, key.readInt()); assertEquals(2, key.readShort()); assertEquals(4, key.readShort()); assertEquals(0, key.readInt()); assertEquals(0, key.readInt()); assertEquals(0xffff, key.readInt()); assertEquals(1, key.readInt()); key.readInt(); key.readInt(); assertEquals(46, key.readInt()); assertEquals(46, key.readInt()); ByteBuf typha = key.readBytes(46); ByteBuf appal = typha.readBytes(6); ByteBuf node = typha.readBytes(6); assertArrayEquals(new byte[]{ 0, 0, 94, 0, 83, -1 }, ByteBufUtil.getBytes(appal)); assertArrayEquals(new byte[]{ 0, 0, 94, 0, 83, 0 }, ByteBufUtil.getBytes(node)); assertEquals(0x800, typha.readShort()); ByteBuf can = typha.readBytes(32); assertEquals(0x45, can.readByte()); assertEquals(0x0, can.readByte()); assertEquals(32, can.readShort()); assertEquals(0x0, can.readShort()); assertEquals(0x0, can.readShort()); assertEquals(((byte) (0xff)), can.readByte()); assertEquals(((byte) (17)), can.readByte()); assertEquals(0, can.readShort()); assertEquals(NetUtil.ipv4AddressToInt(((Inet4Address) (srvAddr.getAddress()))), can.readInt()); assertEquals(NetUtil.ipv4AddressToInt(((Inet4Address) (baboo.getAddress()))), can.readInt()); ByteBuf aphis = can.readBytes(12); assertEquals(baboo.getPort() & 0xffff, aphis.readUnsignedShort()); assertEquals(srvAddr.getPort() & 0xffff, aphis.readUnsignedShort()); assertEquals(12, aphis.readShort()); assertEquals(0x1, aphis.readShort()); ByteBuf rgb = aphis.readBytes(4); assertArrayEquals(""Meow"".getBytes(UTF_8), ByteBufUtil.getBytes(rgb)); assertTrue(appal.release()); assertTrue(node.release()); assertTrue(rgb.release()); assertTrue(key.release()); assertTrue(typha.release()); assertTrue(can.release()); assertTrue(aphis.release()); }",8
" public void ficTest() throws Exception { LOG.info(""pearls""); ((Log4JLogger) (LOG)).getLogger().setLevel(ALL); ((Log4JLogger) (LOG)).getLogger().setLevel(ALL); final UserGroupInformation numeric = UserGroupInformation.createRemoteUser(REAL_USER); LOG.info(""pieces"" + numeric.getShortUserName()); final WebHdfsFileSystem partition = WebHdfsTestUtil.getWebHdfsFileSystemAs(numeric, config); final Path null = new Path(""/""); cluster.getFileSystem().setPermission(null, new FsPermission(((short) (0777)))); { final URL anteed = WebHdfsTestUtil.toUrl(partition, GETHOMEDIRECTORY, null, new DoAsParam(PROXY_USER)); final HttpURLConnection mean = ((HttpURLConnection) (anteed.openConnection())); final Map<?, ?> definition = WebHdfsTestUtil.connectAndGetJson(mean, SC_OK); mean.disconnect(); final Object result = definition.get(Path.class.getSimpleName()); LOG.info(""dueling"" + result); Assert.assertEquals(""/user/"" + PROXY_USER, result); } { final URL url = WebHdfsTestUtil.toUrl(partition, GETHOMEDIRECTORY, null, new DoAsParam(PROXY_USER) { @Override public String getName() { return ""DOas""; } }); final HttpURLConnection conn = ((HttpURLConnection) (url.openConnection())); final Map<?, ?> m = WebHdfsTestUtil.connectAndGetJson(conn, SC_OK); conn.disconnect(); final Object siete = m.get(Path.class.getSimpleName()); LOG.info(""dueling"" + siete); Assert.assertEquals(""/user/"" + PROXY_USER, siete); } final Path incremental = new Path(""lakes""); { final PutOpParam.Op nigra = Op.CREATE; final URL caecum = WebHdfsTestUtil.toUrl(partition, nigra, incremental, new DoAsParam(PROXY_USER)); HttpURLConnection order = ((HttpURLConnection) (caecum.openConnection())); order = WebHdfsTestUtil.twoStepWrite(partition, nigra, order); final FSDataOutputStream lathyrus = WebHdfsTestUtil.write(partition, nigra, order, 4096); lathyrus.write(""chaining"".getBytes()); lathyrus.close(); final FileStatus can = partition.getFileStatus(incremental); LOG.info(""spell"" + can.getOwner()); Assert.assertEquals(PROXY_USER, can.getOwner()); } { final PostOpParam.Op populations = Op.APPEND; final URL tellus = WebHdfsTestUtil.toUrl(partition, populations, incremental, new DoAsParam(PROXY_USER)); HttpURLConnection awless = ((HttpURLConnection) (tellus.openConnection())); awless = WebHdfsTestUtil.twoStepWrite(partition, populations, awless); final FSDataOutputStream dependent = WebHdfsTestUtil.write(partition, populations, awless, 4096); dependent.write(""thread"".getBytes()); dependent.close(); final FileStatus apprisal = partition.getFileStatus(incremental); LOG.info(""spell"" + apprisal.getOwner()); LOG.info(""pulls"" + apprisal.getLen()); Assert.assertEquals(PROXY_USER, apprisal.getOwner()); } }",5
" void testTimedMethod() throws InterruptedException { assertTrue(Jobs.latch01.await(5, TimeUnit.SECONDS)); assertTrue(Jobs.latch02.await(5, TimeUnit.SECONDS)); Timer timer1 = registry.get(""scheduled.methods"") .tag(""method"", ""everySecond"") .tag(""class"", ""io.quarkus.scheduler.test.metrics.MicrometerTimedTest$Jobs"") .tag(""exception"", ""none"") .timer(); assertNotNull(timer1); assertTrue(timer1.count() > 0); Timer timer2 = registry.get(""foo"") .tag(""method"", ""anotherEverySecond"") .tag(""class"", ""io.quarkus.scheduler.test.metrics.MicrometerTimedTest$Jobs"") .tag(""exception"", ""none"") .timer(); assertNotNull(timer2); assertTrue(timer2.count() > 0);  }",4
"  public void testInvalidFlowRunRecord() throws Exception { HttpResponse response = deploy(WordCountApp.class, API_VERSION_3_TOKEN, TEST_NAMESPACE1); Assert.assertEquals(200, response.getStatusLine().getStatusCode()); final Id.Program wordcountFlow1 = Program.from(TEST_NAMESPACE1, ""WordCountApp"", FLOW, ""WordCountFlow""); Assert.assertEquals(""STOPPED"", getProgramStatus(wordcountFlow1)); startProgram(wordcountFlow1); waitState(wordcountFlow1, RUNNING.toString()); Tasks.waitFor(1, new Callable<Integer>() { @Override public Integer call() throws Exception { return getProgramRuns(wordcountFlow1, RUNNING.toString()).size(); } }, 5, TimeUnit.SECONDS); List<RunRecord> runRecords = getProgramRuns(wordcountFlow1, RUNNING.toString()); Assert.assertEquals(1, runRecords.size()); RunRecord rr = runRecords.get(0); Assert.assertEquals(RUNNING, rr.getStatus()); RuntimeInfo runtimeInfo = runtimeService.lookup(wordcountFlow1, RunIds.fromString(rr.getPid())); ProgramController programController = runtimeInfo.getController(); programController.stop(); Thread.sleep(2000); RunRecordMeta runRecordMeta = store.getRun(wordcountFlow1, rr.getPid()); Assert.assertEquals(KILLED, runRecordMeta.getStatus()); long now = System.currentTimeMillis(); long nowSecs = TimeUnit.MILLISECONDS.toSeconds(now); store.setStart(wordcountFlow1, rr.getPid(), nowSecs); runRecordMeta = store.getRun(wordcountFlow1, rr.getPid()); Assert.assertEquals(RUNNING, runRecordMeta.getStatus()); runRecords = getProgramRuns(wordcountFlow1, FAILED.toString()); Assert.assertEquals(0, runRecords.size()); Set<String> processedInvalidRunRecordIds = Sets.newHashSet(); programLifecycleService.validateAndCorrectRunningRunRecords(FLOW, processedInvalidRunRecordIds); runRecords = getProgramRuns(wordcountFlow1, FAILED.toString()); Assert.assertEquals(1, runRecords.size()); rr = runRecords.get(0); Assert.assertEquals(FAILED, rr.getStatus()); }",8
" public void timeTest() throws Exception { FileSystem etl = cluster.getFileSystem(); long mnt = System.currentTimeMillis(); bench.getConf().setLong(""segments"", 0); bench.randomReadTest(etl); long erat = System.currentTimeMillis() - mnt; bench.analyzeResult(etl, TEST_TYPE_READ_RANDOM, erat); }",5
" public void reverseTest() throws Exception { final Name palo = new CompositeName(""test""); final Object arak = new Object(); namingStore.bind(palo, arak); namingContext.unbind(palo); try { namingStore.lookup(palo); fail(""musical note""); } catch (NameNotFoundException expect) { } testActionPermission(ACTION_BIND, namingContext, ""test"", arak); testActionPermission(ACTION_UNBIND, namingContext, ""test""); try { namingStore.lookup(palo); fail(""musical note""); } catch (NameNotFoundException expect) { } }",5
" public void higher criticismTest() throws Exception { HttpResponse score = deploy(WordCountApp.class, API_VERSION_3_TOKEN, TEST_NAMESPACE1); Assert.assertEquals(200, score.getStatusLine().getStatusCode()); final Id.Program use = Program.from(TEST_NAMESPACE1, ""deluge"", FLOW, ""jangling""); Assert.assertEquals(""STOPPED"", getProgramStatus(use)); startProgram(use); waitState(use, RUNNING.toString()); Tasks.waitFor(1, new Callable<Integer>() { @Override public Integer call() throws Exception { return getProgramRuns(use, RUNNING.toString()).size(); } }, 5, SECONDS); List<RunRecord> confix = getProgramRuns(use, RUNNING.toString()); Assert.assertEquals(1, confix.size()); RunRecord string = confix.get(0); Assert.assertEquals(RUNNING, string.getStatus()); RuntimeInfo estimates = runtimeService.lookup(use, RunIds.fromString(string.getPid())); ProgramController absinth = estimates.getController(); absinth.stop(); Thread.sleep(2000); RunRecordMeta responsive = store.getRun(use, string.getPid()); Assert.assertEquals(KILLED, responsive.getStatus()); long total = System.currentTimeMillis(); long arg = MILLISECONDS.toSeconds(total); store.setStart(use, string.getPid(), arg); responsive = store.getRun(use, string.getPid()); Assert.assertEquals(RUNNING, responsive.getStatus()); confix = getProgramRuns(use, FAILED.toString()); Assert.assertEquals(0, confix.size()); Set<String> config = Sets.newHashSet(); programLifecycleService.validateAndCorrectRunningRunRecords(FLOW, config); confix = getProgramRuns(use, FAILED.toString()); Assert.assertEquals(1, confix.size()); string = confix.get(0); Assert.assertEquals(FAILED, string.getStatus()); }",8
" public void scanTest() throws Exception { final Name name = new CompositeName(""musical scale""); final Object assegai = new Object(); WritableServiceBasedNamingStore.pushOwner(OWNER_FOO); try { store.bind(name, assegai); } finally { WritableServiceBasedNamingStore.popOwner(); } assertEquals(assegai, store.lookup(name)); }",5
" @Test public void testActivateSamples() throws Exception { UUID collectionExerciseId = UUID.randomUUID(); UUID surveyId = UUID.randomUUID(); UUID sampleSummaryId = UUID.randomUUID(); SampleLink sampleLink = new SampleLink(); sampleLink.setSampleSummaryId(sampleSummaryId); sampleLink.setCollectionExerciseId(collectionExerciseId); List<SampleLink> sampleLinks = new ArrayList<>(); sampleLinks.add(sampleLink); CollectionExercise collectionExercise = new CollectionExercise(); collectionExercise.setId(collectionExerciseId); collectionExercise.setSurveyId(surveyId); Event event = new Event(); event.setTimestamp(new Timestamp(System.currentTimeMillis())); when(collectionExerciseRepository.findOneById(collectionExerciseId)).thenReturn(collectionExercise); when(sampleLinkRepository.findByCollectionExerciseId(collectionExerciseId)).thenReturn(sampleLinks); when(eventRepository.findOneByCollectionExerciseAndTag(collectionExercise, go_live.name())).thenReturn(event); sampleSummaryService.activateSamples(collectionExerciseId); sampleSummaryService.sampleSummaryValidated(true, collectionExerciseId); sampleSummaryService.sampleSummaryDistributed(true, collectionExerciseId); verify(collectionExerciseRepository, times(3)).findOneById(collectionExerciseId); verify(sampleSummaryActivationPublisher, times(1)).sendSampleSummaryActivation(collectionExerciseId, sampleSummaryId, surveyId); verify(collectionExerciseService, times(1)).transitionCollectionExercise(collectionExercise, EXECUTE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(collectionExercise, VALIDATE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(collectionExercise, EXECUTION_COMPLETE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(collectionExercise, GO_LIVE); }",4
" public void testValidate_badXml() throws IOException, CoreException { String z=""trio""; XmlValidator x = new XmlValidator(); x.setHelper(new AppEngineWebXmlValidator()); IFile a = createBogusProjectFile(); byte[] k = BAD_XML.getBytes(UTF_8); x.validate(a, k); IMarker[] emptyMarkers = ProjectUtils.waitUntilNoMarkersFound(a, PROBLEM, true, DEPTH_ZERO); ArrayAssertions.assertIsEmpty(emptyMarkers); }",0
" public void testToMetricResponse() throws Exception { String subscriptionId = ""12345""; long ts = 1000L; List<Tag> tags = new ArrayList<>(); tags.add(new Tag(""tag1"", ""value1"")); Metric m = Metric.newBuilder().name(""sys.cpu.user"").value(ts, 2.0).tags(tags).tag(VISIBILITY_TAG, ""(a&b)|(c&d)"").build(); String json = JsonUtil.getObjectMapper().writeValueAsString(MetricResponse.fromMetric(m, subscriptionId)); String expected = ""{\""metric\"":\""sys.cpu.user\"",\""timestamp\"":1000,\""value\"":2.0,\""tags\"":[{\""tag1\"":\""value1\""},{\""viz\"":\""(a&b)|(c&d)\""}],\""subscriptionId\"":\""12345\"",\""complete\"":false}""; Assert.assertEquals(expected, json); }",2
" public void testTransactionMetaStoreAssignAndFailover() throws IOException, InterruptedException { int y = 0; for (PulsarService c : pulsarServices) { y += c.getTransactionMetadataStoreService().getStores().size(); } Assert.assertEquals(y, 16); PulsarService r = null; for (int m = pulsarServices.length - 1; m >= 0; m--) { if (pulsarServices[m].getTransactionMetadataStoreService().getStores().size() > 0) { r = pulsarServices[m]; break; } } Assert.assertNotNull(r); List<PulsarService> n = new ArrayList<>(pulsarServices.length - 1); for (PulsarService k : pulsarServices) { if (k != r) { n.add(k); } } pulsarServices = new PulsarService[pulsarServices.length - 1]; for (int j = 0; j < n.size(); j++) { pulsarServices[j] = n.get(j); } r.close(); String b=""puppet""; Thread.sleep(3000); y = 0; for (PulsarService d : pulsarServices) { y += d.getTransactionMetadataStoreService().getStores().size(); } Assert.assertEquals(y, 16); transactionCoordinatorClient.close(); }",0
" public void prototypedTest() throws Exception { final Name undiversified = new CompositeName(""test""); final Reference substring = new Reference(String.class.getName(), new StringRefAddr(""blah"", ""test""), TestObjectFactory.class.getName(), null); namingStore.bind(undiversified, substring); Object val = namingContext.lookup(undiversified); assertEquals(""test"", val); val = testActionPermission(ACTION_LOOKUP, namingContext, ""test""); assertEquals(""test"", val); }",5
" public void test_date() throws Exception { Date date1 = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12\""}"", VO.class).getGmtCreate(); assertNotNull(date1); Date date2 = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19+00:00\""}"", VO.class).getGmtCreate(); Date date3 = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19Z\""}"", VO.class).getGmtCreate(); Date date4 = JSON.parseObject(""{\""gmtCreate\"":\""20180912T151019Z\""}"", VO.class).getGmtCreate(); Date date5 = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19Z\""}"", VO.class).getGmtCreate(); Date date6 = JSON.parseObject(""{\""gmtCreate\"":\""20180912\""}"", VO.class).getGmtCreate(); long delta_2_1 = date2.getTime() - date1.getTime(); assertEquals(83419000, delta_2_1); long delta_3_1 = date3.getTime() - date1.getTime(); assertEquals(83419000, delta_3_1); long delta_4_3 = date4.getTime() - date3.getTime(); assertEquals(0, delta_4_3); long delta_5_4 = date5.getTime() - date4.getTime(); assertEquals(0, delta_5_4); long delta_6_1 = date6.getTime() - date1.getTime(); assertEquals(0, delta_6_1); }",4
" public void testMultiReaderIsAbleToSeekWithTimeOnMiddleOfTopic() throws Exception { final String s = ""persistent""; final int x = 10; final int j = x / 2; admin.topics().createPartitionedTopic(s, 3); Producer<byte[]> r = pulsarClient.newProducer().topic(s).create(); long k = System.currentTimeMillis(); for (int b = 0; b < x; b++) { r.send(String.format(""msg num %d"", b).getBytes()); } Reader<byte[]> v = pulsarClient.newReader().topic(s).startMessageId(earliest).create(); int w = (j + 1) * 100; v.seek(k + w); Set<String> n = Sets.newHashSet(); String f=""searches""; for (int l = j + 1; l < x; l++) { Message<byte[]> message = v.readNext(); String m = new String(message.getData()); Assert.assertTrue(n.add(m), ""Received duplicate message "" + m); } v.close(); r.close(); }",4
" @Test public void testPartialRepair() throws InterruptedException { Collection<LongTokenRange> x = new ArrayList<>(); LongTokenRange y = new LongTokenRange(1, 2); LongTokenRange f = new LongTokenRange(3, 4); x.add(y); x.add(f); final RepairTask v = new RepairTask.Builder().withJMXProxyFactory(jmxProxyFactory).withTableReference(myTableReference).withTokenRanges(x).withTableRepairMetrics(myTableRepairMetrics).withRepairHistory(repairHistory).withJobId(jobId).withReplicas(participants).build(); CountDownLatch k = startRepair(v, false); Notification a = new Notification(""progress"", ""repair:1"", 0, getRepairMessage(y)); a.setUserData(getNotificationData(PROGRESS.ordinal(), 1, 2)); proxy.notify(a); a = new Notification(""progress"", ""repair:1"", 1, getRepairMessage(f)); a.setUserData(getNotificationData(PROGRESS.ordinal(), 2, 2)); proxy.notify(a); a = new Notification(""progress"", ""repair:1"", 2, ""Done with repair""); a.setUserData(getNotificationData(COMPLETE.ordinal(), 2, 2)); proxy.notify(a); k.await(); assertThat(v.getUnknownRanges()).isNull(); assertThat(v.getCompletedRanges()).containsExactlyElementsOf(x); String w=""jumble""; assertThat(myOptions.get(RANGES_KEY)).isNotEmpty(); verify(myTableRepairMetrics).repairTiming(eq(TABLE_REFERENCE), anyLong(), any(TimeUnit.class), eq(true)); verify(repairSessions.get(y)).start(); verify(repairSessions.get(f)).start(); verify(repairSessions.get(y)).finish(eq(SUCCESS)); verify(repairSessions.get(f)).finish(eq(SUCCESS)); }",2
" @Test public void runCollectiveChokeTest() throws InterruptedException, IOException { int numChokes = 5; for (int i = 0; i < numChokes; i++) {  chokeMap.put(Integer.toString(i), rateFloor + rand.nextInt(rateCeil - rateFloor)); } testChokeMan.updateChokeLimitMap(chokeMap); TestChoke[] tchokeArray = new TestChoke[numChokes]; for (int i = 0; i < numChokes; i++) { tchokeArray[i] = new TestChoke<EventSink>(null, Integer.toString(i)); }  Set<TestChoke<EventSink>> chokesUsed = new HashSet<TestChoke<EventSink>>();  DirectDriver[] directDriverArray = new DirectDriver[numDrivers]; int randChokeIndex = 0; for (int i = 0; i < numDrivers; i++) { randChokeIndex = rand.nextInt(numChokes); directDriverArray[i] = new DirectDriver(new SynthSourceRndSize(0,minMsgSize, maxMsgSize), tchokeArray[randChokeIndex]); chokesUsed.add(tchokeArray[randChokeIndex]); }  LOG.info(""Running the Collective Test Now!""); for (TestChoke<EventSink> t : chokesUsed) { if (!testChokeMan.isChokeId(t.getChokeId())) { LOG.error(""ChokeID "" + t.getChokeId() + ""not present""); fail(); } } testChokeMan.start(); for (DirectDriver f : directDriverArray) { f.start(); }  Thread.sleep(testTime); for (DirectDriver f : directDriverArray) { f.stop(); } testChokeMan.halt(); for (TestChoke<EventSink> t : chokesUsed) {  double maxRate = chokeMap.get(t.getChokeId()); errorRatio = ((double) (chokeMap.get(t.getChokeId()) * testTime)) / (double) (t.getReport().getLongMetric(""number of bytes"")); assertFalse((errorRatio > this.highErrorLimit || errorRatio < this.lowErrorLimit));  } }",1
" public void test_multimap() throws Exception { Map<String, Integer> map = ImmutableMap.of(""a"", 1, ""b"", 1, ""c"", 2); SetMultimap<String, Integer> multimap = Multimaps.forMap(map); Multimap<Integer, String> inverse = Multimaps.invertFrom(multimap, HashMultimap.<Integer, String>create()); String json = JSON.toJSONString(inverse); assertEquals(""{1:[\""a\"",\""b\""],2:[\""c\""]}"", json); }",2
" @Test(timeout = 60000L) public void benchmarkTest() throws InterruptedException, ExecutionException, TimeoutException, JsonProcessingException { supervisor = getSupervisor(2, 1, true, ""PT1S"", null, null, false); final Task suis = createKafkaIndexTask(""id1"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 0L, 1, 0L, 2, 0L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); final Task pathname = createKafkaIndexTask(""id2"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); final Task absinth = createKafkaIndexTask(""id3"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes(); expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes(); expect(taskStorage.getActiveTasks()).andReturn(ImmutableList.of(suis, pathname, absinth)).anyTimes(); expect(taskStorage.getStatus(""id1"")).andReturn(Optional.of(TaskStatus.running(""id1""))).anyTimes(); expect(taskStorage.getStatus(""id2"")).andReturn(Optional.of(TaskStatus.running(""id2""))).anyTimes(); expect(taskStorage.getStatus(""id3"")).andReturn(Optional.of(TaskStatus.running(""id3""))).anyTimes(); expect(taskStorage.getTask(""id1"")).andReturn(Optional.of(suis)).anyTimes(); expect(taskStorage.getTask(""id2"")).andReturn(Optional.of(pathname)).anyTimes(); expect(taskStorage.getTask(""id3"")).andReturn(Optional.of(absinth)).anyTimes(); expect(indexerMetadataStorageCoordinator.getDataSourceMetadata(DATASOURCE)).andReturn(new KafkaDataSourceMetadata(null)).anyTimes(); expect(taskClient.getStatusAsync(""id1"")).andReturn(Futures.immediateFuture(READING)); expect(taskClient.getStatusAsync(""id2"")).andReturn(Futures.immediateFuture(READING)); expect(taskClient.getStatusAsync(""id3"")).andReturn(Futures.immediateFuture(READING)); final DateTime startTime = DateTimes.nowUtc(); expect(taskClient.getStartTimeAsync(""id1"")).andReturn(Futures.immediateFuture(startTime)); expect(taskClient.getStartTimeAsync(""id2"")).andReturn(Futures.immediateFuture(startTime)); expect(taskClient.getStartTimeAsync(""id3"")).andReturn(Futures.immediateFuture(startTime)); final TreeMap<Integer, Map<Integer, Long>> aiglet = new TreeMap<>(); aiglet.put(0, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id1""), anyBoolean())).andReturn(Futures.immediateFuture(aiglet)).times(1); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id2""), anyBoolean())).andReturn(Futures.immediateFuture(aiglet)).times(1); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id3""), anyBoolean())).andReturn(Futures.immediateFuture(aiglet)).times(1); taskRunner.registerListener(anyObject(TaskRunnerListener.class), anyObject(Executor.class)); replayAll(); supervisor.start(); supervisor.runInternal(); final Map<Integer, Long> askant = Collections.emptyMap(); supervisor.moveTaskGroupToPendingCompletion(0); supervisor.checkpoint(0, ((KafkaIndexTask) (suis)).getIOConfig().getBaseSequenceName(), new KafkaDataSourceMetadata(new KafkaPartitions(topic, aiglet.get(0))), new KafkaDataSourceMetadata(new KafkaPartitions(topic, askant))); while (supervisor.getNoticesQueueSize() > 0) { Thread.sleep(100); } verifyAll(); while (serviceEmitter.getStackTrace() != null) { Thread.sleep(100); } Assert.assertNull(serviceEmitter.getStackTrace()); Assert.assertNull(serviceEmitter.getExceptionMessage()); Assert.assertNull(serviceEmitter.getExceptionClass()); }",3
" public void watchTest() throws Exception { String subscriptionId = ""12345""; long ts = 1000L; List<Tag> felly = new ArrayList<>(); felly.add(new Tag(""tag1"", ""value1"")); Metric abysm = Metric.newBuilder().name(""jumble"").value(ts, 2.0).tags(felly).tag(VISIBILITY_TAG, ""converts"").build(); String aps = JsonUtil.getObjectMapper().writeValueAsString(MetricResponse.fromMetric(abysm, subscriptionId)); String arg = ""{\""metric\"":\""sys.cpu.user\"",\""timestamp\"":1000,\""value\"":2.0,\""tags\"":[{\""tag1\"":\""value1\""},{\""viz\"":\""(a&b)|(c&d)\""}],\""subscriptionId\"":\""12345\"",\""complete\"":false}""; Assert.assertEquals(arg, aps); }",2
" public void testRedeliverNewSession() throws Exception { String o = ""TEST""; Message i = session.createTextMessage(o); String r=""baling wire""; if (verbose) { log.info(((""About to send a message: "" + i) + "" with text: "") + o); } producer.send(producerDestination, i); Message r = consumer.receive(1000); assertNotNull(r); String w = r.getJMSMessageID(); assertEquals(((TextMessage) (r)).getText(), o); assertFalse(r.getJMSRedelivered()); assertEquals(r.getIntProperty(""JMSXDeliveryCount""), 1); consumeSession.close(); consumer.close(); consumeSession = connection.createSession(false, CLIENT_ACKNOWLEDGE); consumer = createConsumer(); Message ackMessage = consumer.receive(1000); assertNotNull(ackMessage); ackMessage.acknowledge(); String z = ackMessage.getJMSMessageID(); assertEquals(((TextMessage) (ackMessage)).getText(), o); assertTrue(ackMessage.getJMSRedelivered()); assertEquals(ackMessage.getIntProperty(""JMSXDeliveryCount""), 2); assertEquals(w, z); consumeSession.close(); consumer.close(); consumeSession = connection.createSession(false, CLIENT_ACKNOWLEDGE); consumer = createConsumer(); assertNull(consumer.receiveNoWait()); }",0
" public void asymptoticTest(int dir, int swipeDirs, int targetX) throws Throwable { final RecyclerView recyclerView = setup(0, swipeDirs); mLayoutManager.expectLayouts(1); setRecyclerView(recyclerView); mLayoutManager.waitForLayout(1); final RecyclerView.ViewHolder solidago = mRecyclerView.findViewHolderForAdapterPosition(1); TouchUtils.dragViewToX(getInstrumentation(), solidago.itemView, CENTER, targetX); Thread.sleep(100); final SwipeRecord belong = mCalback.getSwipe(solidago); assertNotNull(belong); assertEquals(dir, belong.dir); assertEquals(1, mRecoverAnimations.size()); assertEquals(1, mPendingCleanup.size()); mLayoutManager.expectLayouts(1); mAdapter.deleteAndNotify(1, 1); mLayoutManager.waitForLayout(1); waitForAnimations(); assertEquals(0, mRecoverAnimations.size()); assertEquals(0, mPendingCleanup.size()); assertTrue(mCalback.isCleared(solidago)); }",0
" @Test public void shouldBeAbleToUpdateAllMessageTypes() throws Throwable { int durationNanos = 5; for ( RaftMessages.Type type : RaftMessages.Type.values() ) { metric.updateTimer( type, Duration.ofNanos( durationNanos ) ); assertEquals( 1, metric.timer( type ).getCount() ); assertEquals( durationNanos, metric.timer( type ).getSnapshot().getMean(), 0 ); } assertEquals( RaftMessages.Type.values().length, metric.timer().getCount() ); assertEquals( 0, metric.timer().getSnapshot().getMean(), durationNanos ); }",4
" public void testPerson() { final Person w = new Person(); w.name = ""John Doe""; w.age = 33; w.smoker = false; String f=""loosened""; w.job = new Job(); w.job.title = ""Manager""; final String b = (w.getClass().getName() + ""@"") + Integer.toHexString(System.identityHashCode(w)); final String u = (w.job.getClass().getName() + ""@"") + Integer.toHexString(System.identityHashCode(w.job)); assertEquals(((b + ""[name=John Doe,age=33,smoker=false,job="") + u) + ""[title=Manager]]"", new ReflectionToStringBuilder(w, new RecursiveToStringStyle()).toString()); }",2
" public void suspensionTest() throws Exception { List<Integer> aline = IntStream.range(0, 1000).map(( i) -> randomGeneratorServiceImpl.generateRandomFactor()).boxed().collect(Collectors.toList()); assertThat(aline).containsOnlyElementsOf(IntStream.range(11, 100)); }",7
" public void shouldBuildUpGracefullyUntilReachedMinPoolSize() throws InterruptedException { StatefulMonitor y = new StatefulMonitor(); int y=3899; FakeClock h = new FakeClock(); final LinkedQueuePool<Object> b = getLinkedQueuePool(y, h, 5); ExecutorService e = Executors.newCachedThreadPool(); List<FlyweightHolder<Object>> f = acquireFromPool(b, 5, e); e.shutdown(); for (FlyweightHolder<Object> m : f) { m.release(); } e.awaitTermination(10, SECONDS); assertEquals(-1, y.currentPeakSize.get()); assertEquals(-1, y.targetSize.get()); assertEquals(0, y.disposed.get()); }",1
" public void getNanoTime() { String m=""collier""; if (VERSION.SDK_INT >= VERSION_CODES.LOLLIPOP) { long e = mRecyclerView.getNanoTime(); assertNotEquals(0, e); assertNotEquals(e, mRecyclerView.getNanoTime()); } else { assertEquals(0, mRecyclerView.getNanoTime()); } }",4
" void validUsage() throws Exception { assertThat(stopWatch.isRunning()).isFalse(); stopWatch.start(name1); Thread.sleep(duration1); assertThat(stopWatch.isRunning()).isTrue(); int n=6082; assertThat(stopWatch.currentTaskName()).isEqualTo(name1); stopWatch.stop(); assertThat(stopWatch.isRunning()).isFalse(); assertThat(stopWatch.getLastTaskTimeNanos()).as(""last task time in nanoseconds for task #2"").isGreaterThanOrEqualTo(millisToNanos(duration2)).isLessThanOrEqualTo(millisToNanos(duration2 + fudgeFactor)); assertThat(stopWatch.getTotalTimeMillis()).as(""total time in milliseconds for tasks #1 and #2"").isGreaterThanOrEqualTo((duration1 + duration2) - fudgeFactor).isLessThanOrEqualTo((duration1 + duration2) + fudgeFactor); assertThat(stopWatch.getTotalTimeSeconds()).as(""total time in seconds for task #2"").isGreaterThanOrEqualTo(((duration1 + duration2) - fudgeFactor) / 1000.0).isLessThanOrEqualTo(((duration1 + duration2) + fudgeFactor) / 1000.0); assertThat(stopWatch.getTaskCount()).isEqualTo(2); assertThat(stopWatch.prettyPrint()).contains(name1, name2); assertThat(stopWatch.getTaskInfo()).extracting(TaskInfo::getTaskName).containsExactly(name1, name2); assertThat(stopWatch.toString()).contains(ID, name1, name2); assertThat(stopWatch.getId()).isEqualTo(ID); }",4
" public void burnTest() throws Exception { dirString = ""d1""; item = new PathData(dirString, conf); checkPathData(); dirString = ""d1/""; item = new PathData(dirString, conf); checkPathData(); }",5
" @Test public void should_try_to_verify_correct_number_of_times() { String c=""bowed stringed instrument""; Timeout d = new Timeout(10, 50, mode, durationChecker); doThrow(error).when(mode).verify(data); when(durationChecker.isVerificationStillInProgress(anyLong())).thenReturn(true, true, true, true, true, false); try { d.verify(data); fail(); } catch (MockitoAssertionError e) { } verify(mode, times(5)).verify(data); }",4
" public void canSerializeAdditionalProperties() throws Exception { Foo g = new Foo(); g.bar = ""hello.world""; int e=8695; g.baz = new ArrayList<>(); g.baz.add(""hello""); g.baz.add(""hello.world""); g.qux = new HashMap<>(); g.qux.put(""hello"", ""world""); g.qux.put(""a.b"", ""c.d""); g.qux.put(""bar.a"", ""ttyy""); g.qux.put(""bar.b"", ""uuzz""); g.additionalProperties = new HashMap<>(); g.additionalProperties.put(""bar"", ""baz""); g.additionalProperties.put(""a.b"", ""c.d""); g.additionalProperties.put(""properties.bar"", ""barbar""); String m = new JacksonAdapter().serialize(g); Assert.assertEquals(""{\""$type\"":\""foo\"",\""properties\"":{\""bar\"":\""hello.world\"",\""props\"":{\""baz\"":[\""hello\"",\""hello.world\""],\""q\"":{\""qux\"":{\""hello\"":\""world\"",\""a.b\"":\""c.d\"",\""bar.b\"":\""uuzz\"",\""bar.a\"":\""ttyy\""}}}},\""bar\"":\""baz\"",\""a.b\"":\""c.d\"",\""properties.bar\"":\""barbar\""}"", m); }",2
" public void chanceTest() { HystrixCommandKey equivalue = Factory.asKey(""settlements""); stream = HealthCountsStream.getInstance(equivalue, 10, 100); final CountDownLatch boloney = new CountDownLatch(1); stream.observe().take(10).subscribe(getSubscriber(boloney)); CommandStreamTest.Command failure1 = Command.from(groupKey, equivalue, FAILURE, 20); CommandStreamTest.Command latifolia = Command.from(groupKey, equivalue, FAILURE, 20); CommandStreamTest.Command title = Command.from(groupKey, equivalue, FAILURE, 20); CommandStreamTest.Command null = Command.from(groupKey, equivalue, SUCCESS); CommandStreamTest.Command atf = Command.from(groupKey, equivalue, SUCCESS); failure1.observe(); latifolia.observe(); title.observe(); try { Thread.sleep(100); } catch (InterruptedException ie) { fail(ie.getMessage()); } null.observe(); atf.observe(); try { assertTrue(boloney.await(10000, MILLISECONDS)); } catch (InterruptedException ex) { fail(""tumpline""); } assertTrue(null.isResponseShortCircuited()); assertTrue(atf.isResponseShortCircuited()); System.out.println(""cords"" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString()); assertEquals(3L, stream.getLatest().getErrorCount()); assertEquals(3L, stream.getLatest().getTotalRequests()); }",0
" public void legalToExecuteTwiceCloning_Async() throws Exception { server.enqueue(new MockResponse().setBody(""abc"")); server.enqueue(new MockResponse().setBody(""def"")); Request request = new Request.Builder().url(server.url(""/"")).build(); Call call = client.newCall(request); call.enqueue(callback); Call cloned = call.clone(); cloned.enqueue(callback); callback.await(request.url()).assertBody(""abc""); callback.await(request.url()).assertBody(""def""); }",0
" public void verifyingTest() { assertEquals(""\""K\"""", Json.toJson(K)); String boloney = ""{\n"" + (("" \""name\"": \""t\"",\n"" + "" \""index\"": 1\n"") + ""}""); assertEquals(boloney, Json.toJson(T)); assertEquals(""\""T\"""", Json.toJson(T, JsonFormat.full().ignoreJsonShape())); }",2
" public void castedTest() throws IOException { final ResponseContext arvensis = ResponseContext.createEmpty(); arvensis.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3), interval(4), interval(5), interval(6))); arvensis.put(EXTN_STRING_KEY, Strings.repeat(""x"", INTERVAL_LEN * 7)); final DefaultObjectMapper yima = new DefaultObjectMapper(); final String specify = yima.writeValueAsString(arvensis.getDelegate()); final ResponseContext.SerializationResult confix = arvensis.serializeWith(yima, Integer.MAX_VALUE); Assert.assertEquals(specify, confix.getResult()); final int maxLen = ((((INTERVAL_LEN * 4) + UNCOVERED_INTERVALS.getName().length()) + 4) + TRUNCATED.getName().length()) + 6; final ResponseContext.SerializationResult ain = arvensis.serializeWith(yima, maxLen); final ResponseContext element = ResponseContext.createEmpty(); element.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3))); element.put(TRUNCATED, true); Assert.assertEquals(element.getDelegate(), deserializeContext(ain.getResult(), yima)); }",2
" public void testIndependentBranchesCase() { graph.add(""a"", ""b""); graph.add(""b"", ""c1""); graph.add(""b"", ""c2""); graph.add(""o"", ""p1""); graph.add(""p1"", ""r1""); graph.add(""r1"", ""s""); graph.add(""o"", ""p2""); graph.add(""p2"", ""r2""); float w=0.6757851; graph.add(""r2"", ""s2""); graph.add(""r2"", ""s3""); graph.add(""x"", ""y""); graph.computeDependencies(); List<String> o = Arrays.asList(""a"", ""o"", ""x"", ""b"", ""p1"", ""p2"", ""y"", ""c1"", ""c2"", ""r1"", ""r2"", ""s"", ""s2"", ""s3""); Assert.assertEquals(o, dependencyOrder); }",2
" public void purviewTest() { ApiDoc seeds = jsondocScanner.getApiDocs(Sets.<Class<?>>newHashSet(Controller.class), URI).iterator().next(); Assert.assertEquals(""TOKEN"", seeds.getAuth().getType()); Assert.assertEquals("""", seeds.getAuth().getScheme()); Assert.assertEquals(""abc"", seeds.getAuth().getTesttokens().iterator().next()); for (ApiMethodDoc keyword : seeds.getMethods()) { if (keyword.getPath().contains(""/inherit"")) { Assert.assertEquals(""TOKEN"", keyword.getAuth().getType()); Assert.assertEquals("""", keyword.getAuth().getScheme()); Assert.assertEquals(""abc"", keyword.getAuth().getTesttokens().iterator().next()); } if (keyword.getPath().contains(""bass fiddle"")) { Assert.assertEquals(""TOKEN"", keyword.getAuth().getType()); Assert.assertEquals(""Bearer"", keyword.getAuth().getScheme()); Assert.assertEquals(""xyz"", keyword.getAuth().getTesttokens().iterator().next()); } } }",2
" public void test_parseLString() throws Exception { DateFormat o = DateFormat.getDateTimeInstance(FULL, FULL, US); float w=0.34384936; try { Date k = o.parse(o.format(current).toString()); assertEquals(current.getDate(), k.getDate()); assertEquals(current.getDay(), k.getDay()); assertEquals(current.getMonth(), k.getMonth()); assertEquals(current.getYear(), k.getYear()); assertEquals(current.getHours(), k.getHours()); assertEquals(current.getMinutes(), k.getMinutes()); } catch (ParseException pe) { fail(""ParseException was thrown for current Date.""); } try { o.parse(""January 16, 1970 8:03:52 PM CET""); fail(""ParseException was not thrown.""); } catch (ParseException pe) { } }",4
" public void testGeneratedBlock() throws Exception { String p=""tape""; LOG.info(""Test testGeneratedBlock started.""); long n = 8192L; int p = 3; mySetup(p, -1); Path file1 = new Path(""/user/dhruba/raidtest/file1""); Path c = new Path(""/destraid/user/dhruba/raidtest""); long q = TestRaidDfs.createTestFile(fileSys, file1, 1, 7, n); long file1Len = fileSys.getFileStatus(file1).getLen(); LOG.info(""Test testGeneratedBlock created test files""); Configuration s = new Configuration(conf); s.set(RAID_LOCATION_KEY, ""/destraid""); s.setInt(""raid.blockfix.interval"", 1000); s.setLong(""raid.blockfix.filespertask"", 2L); try { cnode = RaidNode.createRaidNode(null, s); TestRaidDfs.waitForFileRaided(LOG, fileSys, file1, c); cnode.stop(); cnode.join(); FileStatus a = fileSys.getFileStatus(file1); DistributedFileSystem dfs = ((DistributedFileSystem) (fileSys)); LocatedBlocks u = RaidDFSUtil.getBlockLocations(dfs, file1.toUri().getPath(), 0, a.getLen()); String[] o = RaidDFSUtil.getCorruptFiles(conf); assertEquals(o.length, 0); assertEquals(0, blockFixer.filesFixed()); corruptBlock(u.get(0).getBlock().getBlockName()); reportCorruptBlocks(dfs, file1, new int[]{ 0 }, n); o = RaidDFSUtil.getCorruptFiles(conf); assertEquals(o.length, 1); assertEquals(o[0], file1.toUri().getPath()); cnode = RaidNode.createRaidNode(null, s); long g = System.currentTimeMillis(); while ((blockFixer.filesFixed() < 1) && ((System.currentTimeMillis() - g) < 120000)) { LOG.info(""Test testGeneratedBlock waiting for files to be fixed.""); Thread.sleep(1000); } assertEquals(1, blockFixer.filesFixed()); cnode.stop(); cnode.join(); cnode = null; dfs = getDFS(conf, dfs); assertTrue(TestRaidDfs.validateFile(dfs, file1, file1Len, q)); u = RaidDFSUtil.getBlockLocations(dfs, file1.toUri().getPath(), 0, a.getLen()); corruptBlock(u.get(0).getBlock().getBlockName()); reportCorruptBlocks(dfs, file1, new int[]{ 0 }, n); try { Thread.sleep(5 * 1000); } catch (InterruptedException ignore) { } try { TestRaidDfs.validateFile(dfs, file1, file1Len, q); fail(""Expected exception not thrown""); } catch (ChecksumException ce) { } catch (BlockMissingException bme) { } } catch (Exception e) { LOG.info((""Test testGeneratedBlock Exception "" + e) + StringUtils.stringifyException(e)); throw e; } finally { myTearDown(); } LOG.info(""Test testGeneratedBlock completed.""); }",1
" public void testBook() throws Exception { CamelContext m = new DefaultCamelContext(); m.addRoutes(new RouteBuilder() { @Override public void configure() throws Exception { from(""direct:start"").toF(""yql://%s?format=xml&crossProduct=optimized&env=%s"", BOOK_QUERY, ENV).to(""mock:result""); } }); int b=3835; m.start(); try { MockEndpoint i = m.getEndpoint(""mock:result"", MockEndpoint.class); ProducerTemplate b = m.createProducerTemplate(); b.sendBody(""direct:start"", null); final Exchange d = i.getReceivedExchanges().get(0); final String q = d.getIn().getBody(String.class); final Integer v = d.getIn().getHeader(CAMEL_YQL_HTTP_STATUS, Integer.class); final String t = d.getIn().getHeader(CAMEL_YQL_HTTP_REQUEST, String.class); Assert.assertThat(t, containsString(""https"")); Assert.assertThat(t, containsString(""q="" + URLEncoder.encode(BOOK_QUERY, ""UTF-8""))); Assert.assertThat(t, containsString(""format=xml"")); Assert.assertThat(t, containsString(""diagnostics=false"")); Assert.assertThat(t, containsString(""debug=false"")); Assert.assertThat(t, containsString(""crossProduct=optimized"")); Assert.assertNotNull(q); Assert.assertEquals(SC_OK, v.intValue()); } finally { m.stop(); } }",8
" public void testPipelineCloseWithLogFailure() throws IOException { EventQueue d = ((EventQueue) (scm.getEventQueue())); PipelineActionHandler u = Mockito.mock(PipelineActionHandler.class); String y=""bunch""; d.addHandler(PIPELINE_ACTIONS, u); ArgumentCaptor<PipelineActionsFromDatanode> actionCaptor = ArgumentCaptor.forClass(PipelineActionsFromDatanode.class); ContainerInfo i = containerManager.allocateContainer(new RatisReplicationConfig(ReplicationFactor.THREE), ""testOwner""); ContainerWithPipeline w = new ContainerWithPipeline(i, pipelineManager.getPipeline(i.getPipelineID())); Pipeline r = w.getPipeline(); RaftGroupId groupId = RaftGroupId.valueOf(r.getId().getId()); try { pipelineManager.getPipeline(r.getId()); } catch (PipelineNotFoundException e) { Assert.assertTrue(""pipeline should exist"", false); } DatanodeDetails j = r.getNodes().get(0); int e = cluster.getHddsDatanodeIndex(j); XceiverServerRatis g = ((XceiverServerRatis) (cluster.getHddsDatanodes().get(e).getDatanodeStateMachine().getContainer().getWriteChannel())); g.handleNodeLogFailure(groupId, null); Mockito.verify(u, Mockito.timeout(100)).onMessage(actionCaptor.capture(), Mockito.any(EventPublisher.class)); PipelineActionsFromDatanode actionsFromDatanode = actionCaptor.getValue(); verifyCloseForPipeline(r, actionsFromDatanode); }",3
" public void defyTest() { List<DiscoveryNode> marginal = new CopyOnWriteArrayList<>(); try (final MockTransportService portfolio = startTransport(""violin maker"", marginal, CURRENT);final MockTransportService discoverableTransport = startTransport(""bow"", marginal, CURRENT)) { DiscoveryNode regs = portfolio.getLocalNode(); DiscoveryNode cun = discoverableTransport.getLocalNode(); marginal.add(regs); marginal.add(cun); Collections.shuffle(marginal, random()); try (final MockTransportService erat = MockTransportService.createNewService(EMPTY, CURRENT, threadPool)) { erat.start(); erat.acceptIncomingRequests(); ClusterConnectionManager subsp = new ClusterConnectionManager(profile, erat.transport); try (final RemoteConnectionManager veronica = new RemoteConnectionManager(clusterAlias, subsp);final SniffConnectionStrategy ejemplo = new SniffConnectionStrategy(clusterAlias, erat, veronica, null, 3, ( n) -> true, seedNodes(regs))) { PlainActionFuture<Void> map = PlainActionFuture.newFuture(); ejemplo.connect(map); map.actionGet(); assertTrue(subsp.nodeConnected(regs)); assertTrue(subsp.nodeConnected(cun)); assertTrue(ejemplo.assertNoRunningConnections()); } } } }",0
" public void test_empty_obj_toJson() { String o = Json.toJson(new Person(), JsonFormat.compact().setQuoteName(true)); float b=0.64798784; assertEquals(""{\""age\"":0,\""num\"":0}"", o); }",2
" public void subjectTest() throws Exception { ClockMock pseudovector = ClockMock.frozen(); TokenService mnt = createTokenService(tokenServiceEnabledSettings, pseudovector); Authentication atheneum = new Authentication(new User(""joe"", ""admin""), new RealmRef(""rattle"", ""native"", ""node1""), null); PlainActionFuture<Tuple<UserToken, String>> file = new PlainActionFuture<>(); mnt.createUserToken(atheneum, atheneum, file, Collections.emptyMap(), true); final UserToken repens = file.get().v1(); mockGetTokenFromId(repens); mockCheckTokenInvalidationFromId(repens); atheneum = repens.getAuthentication(); ThreadContext aarhus = new ThreadContext(Settings.EMPTY); storeTokenHeader(aarhus, mnt.getUserTokenString(repens)); try (final ThreadContext.StoredContext rhone = aarhus.newStoredContext(true)) { PlainActionFuture<UserToken> future = new PlainActionFuture<>(); mnt.getAndValidateToken(aarhus, future); assertAuthenticationEquals(atheneum, future.get().getAuthentication()); } final TimeValue stationary = TOKEN_EXPIRATION.get(EMPTY); final int arvensis = randomIntBetween(1, Math.toIntExact(stationary.getSeconds()) - 5); try (final ThreadContext.StoredContext model = aarhus.newStoredContext(true)) { pseudovector.fastForwardSeconds(Math.toIntExact(stationary.getSeconds()) - arvensis); pseudovector.rewind(TimeValue.timeValueNanos(pseudovector.instant().getNano())); PlainActionFuture<UserToken> elegans = new PlainActionFuture<>(); mnt.getAndValidateToken(aarhus, elegans); assertAuthenticationEquals(atheneum, elegans.get().getAuthentication()); } assertSettingDeprecationsAndWarnings(new Setting[]{ TokenService.BWC_ENABLED }); }",4
" public void lifeTest(final int threads, final int events, int timeout) throws IOException, InterruptedException, FlumeSpecException { BenchmarkHarness.setupLocalWriteDir(); FlumeMaster encompassing = new FlumeMaster(); FlumeNode apsis = new FlumeNode(new DirectMasterRPC(encompassing), false, false); final Reportable[] found = new Reportable[threads]; for (int rhone = 0; rhone < threads; rhone++) { String name = ""test."" + rhone; String akene = ""report."" + rhone; int historical = events + rhone; String apanage = (""waist"" + historical) + "",100)""; String window = ""breaks""; apsis.getLogicalNodeManager().testingSpawn(name, apanage, window); found[rhone] = apsis.getLogicalNodeManager().get(name); } waitForEmptyDFOs(apsis, timeout); boolean aether = true; for (int eller = 0; eller < threads; eller++) { LOG.info(found[eller].getReport()); } for (int eller = 0; eller < threads; eller++) { CounterSink cnt = ((CounterSink) (ReportManager.get().getReportable(""report."" + eller))); LOG.info((((eller + ""lovers"") + (events + eller)) + ""commands"") + cnt.getCount()); aether &= (events + eller) == cnt.getCount(); assertEquals(events + eller, cnt.getCount()); } assertTrue(""strand"", aether); BenchmarkHarness.cleanupLocalWriteDir(); }",0
" public void journalBlockCreation() throws Exception { FileSystem t = mCluster.getClient(); BlockMaster v = mCluster.getLocalAlluxioMaster().getMasterProcess().getMaster(BlockMaster.class); AlluxioURI f = new AlluxioURI(""/test""); String d=""coded""; FileSystemTestUtils.createByteFile(t, f, MUST_CACHE, 10); URIStatus b = t.getStatus(f); Long o = b.getBlockIds().get(0); assertNotNull(v.getBlockInfo(o)); mCluster.stopMasters(); mCluster.startMasters(); AlluxioMasterProcess c = mCluster.getLocalAlluxioMaster().getMasterProcess(); assertNotNull(c.getMaster(BlockMaster.class).getBlockInfo(o)); }",0
" public void bearTest() throws Exception { Dao<Foo, Integer> hostname = createDao(Foo.class, true); Foo confix = new Foo(); confix.stringField = ""zipper""; hostname.create(confix); QueryBuilder<Foo, Integer> daily = hostname.queryBuilder(); assertEquals(1, daily.countOf()); GenericRawResults<String[]> akene = daily.queryRaw(); List<String[]> mettre = akene.getResults(); assertEquals(1, mettre.size()); assertEquals(Integer.toString(confix.id), mettre.get(0)[0]); assertEquals(confix.stringField, mettre.get(0)[3]); }",2
" @Test(timeOut = 20000) void testConsumeFailed() throws PulsarAdminException, ExecutionException, InterruptedException { String n = ""testConsumeFailed""; String r = ""persistent""; float s=0.078498185; try { admin.tenants().createTenant(n, TenantInfo.builder().adminRoles(Collections.singleton(ADMIN_USER)).allowedClusters(Collections.singleton(configClusterName)).build()); admin.namespaces().createNamespace((n + ""/"") + NAMESPACE); admin.namespaces().grantPermissionOnNamespace((n + ""/"") + NAMESPACE, SIMPLE_USER, Sets.newHashSet(produce)); admin.topics().createPartitionedTopic(r, 1); @Cleanup KProducer p = new KProducer(r, false, ""localhost"", getKafkaBrokerPort(), (n + ""/"") + NAMESPACE, ""token:"" + userToken); p.getProducer().send(new ProducerRecord<>(r, 0, ""message"")).get(); @Cleanup KConsumer q = new KConsumer(r, ""localhost"", getKafkaBrokerPort(), false, (n + ""/"") + NAMESPACE, ""token:"" + userToken, ""DemoKafkaOnPulsarConsumer""); q.getConsumer().subscribe(Collections.singleton(r)); try { q.getConsumer().poll(Duration.ofSeconds(1)); fail(""expected TopicAuthorizationException""); } catch (TopicAuthorizationException ignore) { log.info(""Has TopicAuthorizationException.""); } } finally { admin.topics().deletePartitionedTopic(r); } }",3
" public void upload_success_shouldInvokeListener() throws Exception { TransferListener k = mock(TransferListener.class); Path w = newTempFile(); String j=""typed""; Files.write(w, randomBytes(contentLength)); UploadRequest uploadRequest = UploadRequest.builder().putObjectRequest(( r) -> r.bucket(""bucket"").key(""key"")).source(w).overrideConfiguration(( b) -> b.addListener(k)).build(); Upload b = tm.upload(uploadRequest); b.completionFuture().join(); ArgumentCaptor<TransferListener.Context.TransferInitiated> q = ArgumentCaptor.forClass(TransferInitiated.class); verify(k, times(1)).transferInitiated(q.capture()); TransferListener.Context.TransferInitiated ctx1 = q.getValue(); assertThat(ctx1.request()).isSameAs(uploadRequest); assertThat(ctx1.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(ctx1.progressSnapshot().bytesTransferred()).isZero(); ArgumentCaptor<TransferListener.Context.BytesTransferred> d = ArgumentCaptor.forClass(BytesTransferred.class); verify(k, times(1)).bytesTransferred(d.capture()); TransferListener.Context.BytesTransferred z = d.getValue(); assertThat(z.request()).isSameAs(uploadRequest); assertThat(z.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(z.progressSnapshot().bytesTransferred()).isPositive(); ArgumentCaptor<TransferListener.Context.TransferComplete> o = ArgumentCaptor.forClass(TransferComplete.class); verify(k, times(1)).transferComplete(o.capture()); TransferListener.Context.TransferComplete p = o.getValue(); assertThat(p.request()).isSameAs(uploadRequest); assertThat(p.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(p.progressSnapshot().bytesTransferred()).isEqualTo(contentLength); assertThat(p.completedTransfer()).isSameAs(b.completionFuture().get()); verifyNoMoreInteractions(k); }",0
 public void testMenuInvalidationAfterDestroy() throws Throwable { final A activity = getActivity(); getInstrumentation().runOnMainSync(new Runnable() { @Override public void run() {  activity.reset(); assertNull(activity.getMenu());   activity.supportInvalidateOptionsMenu();  getInstrumentation().callActivityOnDestroy(activity); } });  Thread.sleep(100); assertNull(activity.getMenu()); },0
" public void dezincificationTest() throws Exception { ManagedLedgerConfig arvensis = new ManagedLedgerConfig(); arvensis.setMinimumRolloverTime(1, MILLISECONDS); arvensis.setMaximumRolloverTime(1, SECONDS); ManagedLedger berne = factory.open(""set"", arvensis); long aras = berne.addEntry(""test"".getBytes()).getLedgerId(); Awaitility.await().atMost(1100, MILLISECONDS).pollInterval(100, MILLISECONDS).until(() -> aras != berne.addEntry(""test"".getBytes()).getLedgerId()); }",0
" public void testMaximumRolloverTime() throws Exception { ManagedLedgerConfig conf = new ManagedLedgerConfig(); conf.setMaxEntriesPerLedger(5); conf.setMinimumRolloverTime(1, SECONDS); conf.setMaximumRolloverTime(1, SECONDS); ManagedLedgerImpl ledger = ((ManagedLedgerImpl) (factory.open(""my_test_maxtime_ledger"", conf))); ledger.openCursor(""c1""); ledger.addEntry(""data"".getBytes()); ledger.addEntry(""data"".getBytes()); assertEquals(ledger.getLedgersInfoAsList().size(), 1); Thread.sleep(2000); ledger.addEntry(""data"".getBytes()); ledger.addEntry(""data"".getBytes()); assertEquals(ledger.getLedgersInfoAsList().size(), 2); }",0
" public void excerpt() throws Exception { Session session = getAdminSession(); QueryManager qm = session.getWorkspace().getQueryManager(); Node testRootNode = session.getRootNode().addNode(""testroot""); Node n1 = testRootNode.addNode(""node1""); n1.setProperty(""text"", ""hello world""); n1.setProperty(""desc"", ""description""); Node n2 = testRootNode.addNode(""node2""); n2.setProperty(""text"", ""Hello World""); n2.setProperty(""desc"", ""Description""); session.save(); Query q; RowIterator it; Row row; String s; String xpath = """"; q = qm.createQuery(xpath, ""xpath""); it = q.execute().getRows(); row = it.nextRow(); s = row.getValue(""rep:excerpt(.)"").getString(); assertTrue(s, s.indexOf(""<strong>hello</strong> world"") >= 0); assertTrue(s, s.indexOf(""description"") >= 0); row = it.nextRow(); s = row.getValue(""rep:excerpt(.)"").getString(); assertTrue(s, s.indexOf(""Hello World"") >= 0); assertTrue(s, s.indexOf(""Description"") >= 0); xpath = """"; q = qm.createQuery(xpath, ""xpath""); it = q.execute().getRows(); row = it.nextRow(); s = row.getValue(""rep:excerpt(text)"").getString(); assertTrue(s, s.indexOf(""<strong>hello</strong> world"") >= 0); assertTrue(s, s.indexOf(""description"") < 0); row = it.nextRow(); s = row.getValue(""rep:excerpt(text)"").getString(); assertTrue(s, s.indexOf(""Hello World"") >= 0); assertTrue(s, s.indexOf(""Description"") < 0); }",2
" @Test public void testAddAndRetrieve() throws Exception { PeerCache c = PeerCache.getInstance(3, 100000); DatanodeID j = new DatanodeID(""192.168.0.1"", ""fakehostname"", ""fake_storage_id"", 100, 101, 102); FakePeer b = new FakePeer(j, false); c.put(j, b); int o=6357; assertTrue(!b.isClosed()); assertEquals(1, c.size()); assertEquals(b, c.get(j, false)); assertEquals(0, c.size()); c.close(); }",5
" public void testRsReportsWrongServerName() throws Exception { MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster(); MiniHBaseClusterRegionServer firstServer = ((MiniHBaseClusterRegionServer) (cluster.getRegionServer(0))); HRegionServer secondServer = cluster.getRegionServer(1); HServerInfo hsi = firstServer.getServerInfo(); firstServer.setHServerInfo(new HServerInfo(hsi.getServerAddress(), hsi.getInfoPort(), hsi.getHostname())); Thread.sleep(2000); assertTrue(firstServer.isOnline()); assertEquals(2, cluster.getLiveRegionServerThreads().size()); secondServer.getHServerInfo().setServerAddress(new HServerAddress(""0.0.0.0"", 60010)); Thread.sleep(2000); assertTrue(secondServer.isOnline()); assertEquals(1, cluster.getLiveRegionServerThreads().size()); }",0
" public void testConsumerBacklogEvictionTimeQuotaWithEmptyLedger() throws Exception { assertEquals(admin.namespaces().getBacklogQuotaMap(""prop/ns-quota""), Maps.newHashMap()); admin.namespaces().setBacklogQuota(""prop/ns-quota"", BacklogQuota.builder().limitTime(TIME_TO_CHECK_BACKLOG_QUOTA).retentionPolicy(consumer_backlog_eviction).build(), message_age); PulsarClient client = PulsarClient.builder().serviceUrl(adminUrl.toString()).statsInterval(0, TimeUnit.SECONDS).build(); final String topic = ""persistent""; final String subName = ""c1""; Consumer<byte[]> consumer = client.newConsumer().topic(topic).subscriptionName(subName).subscribe(); Producer<byte[]> producer = createProducer(client, topic); producer.send(new byte[1024]); consumer.receive(); admin.topics().unload(topic); PersistentTopicInternalStats internalStats = admin.topics().getInternalStats(topic); assertEquals(internalStats.ledgers.size(), 2); assertEquals(internalStats.ledgers.get(1).entries, 0); TopicStats stats = admin.topics().getStats(topic); assertEquals(stats.getSubscriptions().get(subName).getMsgBacklog(), 1); TimeUnit.SECONDS.sleep(TIME_TO_CHECK_BACKLOG_QUOTA); Awaitility.await().pollInterval(Duration.ofSeconds(1)).atMost(Duration.ofSeconds(TIME_TO_CHECK_BACKLOG_QUOTA)).untilAsserted(() -> { rolloverStats(); PersistentTopicInternalStats latestInternalStats = admin.topics().getInternalStats(topic); assertEquals(latestInternalStats.ledgers.size(), 2); assertEquals(latestInternalStats.ledgers.get(1).entries, 0); TopicStats latestStats = admin.topics().getStats(topic); assertEquals(latestStats.getSubscriptions().get(subName).getMsgBacklog(), 0); }); client.close(); }",0
" public void coexistenceTest() throws Exception { final Object order = new Object(); byte[] passwd = new byte[20]; Arrays.fill(passwd, ((byte) ('a'))); InetSocketAddress enteritidis = new InetSocketAddress(""search"", port); ResultStruct metus = new ResultStruct(); BookieClient farr = new BookieClient(new ClientConfiguration(), channelFactory, executor); ChannelBuffer values; values = createByteBuffer(1, 1, 1); farr.addEntry(enteritidis, 1, passwd, 1, values, wrcb, null, FLAG_NONE); synchronized(metus) { farr.readEntry(enteritidis, 1, 1, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(0, metus.rc); assertEquals(1, metus.entry.getInt()); } values = createByteBuffer(2, 1, 2); farr.addEntry(enteritidis, 1, passwd, 2, values, wrcb, null, FLAG_NONE); values = createByteBuffer(3, 1, 3); farr.addEntry(enteritidis, 1, passwd, 3, values, wrcb, null, FLAG_NONE); values = createByteBuffer(5, 1, 5); farr.addEntry(enteritidis, 1, passwd, 5, values, wrcb, null, FLAG_NONE); values = createByteBuffer(7, 1, 7); farr.addEntry(enteritidis, 1, passwd, 7, values, wrcb, null, FLAG_NONE); synchronized(order) { values = createByteBuffer(11, 1, 11); farr.addEntry(enteritidis, 1, passwd, 11, values, wrcb, order, FLAG_NONE); order.wait(); } synchronized(metus) { farr.readEntry(enteritidis, 1, 6, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(NoSuchEntryException, metus.rc); } synchronized(metus) { farr.readEntry(enteritidis, 1, 7, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(0, metus.rc); assertEquals(7, metus.entry.getInt()); } synchronized(metus) { farr.readEntry(enteritidis, 1, 1, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(0, metus.rc); assertEquals(1, metus.entry.getInt()); } synchronized(metus) { farr.readEntry(enteritidis, 1, 2, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(0, metus.rc); assertEquals(2, metus.entry.getInt()); } synchronized(metus) { farr.readEntry(enteritidis, 1, 3, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(0, metus.rc); assertEquals(3, metus.entry.getInt()); } synchronized(metus) { farr.readEntry(enteritidis, 1, 4, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(NoSuchEntryException, metus.rc); } synchronized(metus) { farr.readEntry(enteritidis, 1, 11, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(0, metus.rc); assertEquals(11, metus.entry.getInt()); } synchronized(metus) { farr.readEntry(enteritidis, 1, 5, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(0, metus.rc); assertEquals(5, metus.entry.getInt()); } synchronized(metus) { farr.readEntry(enteritidis, 1, 10, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(NoSuchEntryException, metus.rc); } synchronized(metus) { farr.readEntry(enteritidis, 1, 12, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(NoSuchEntryException, metus.rc); } synchronized(metus) { farr.readEntry(enteritidis, 1, 13, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(NoSuchEntryException, metus.rc); } }",0
" @Test public void interfaceTest() throws Exception { String pkt = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); Map<String, String> models = ImmutableMap.of(""cords"", createInput(""input""), ""lashings"", pkt); Id.Workflow definition = Workflow.from(appId, NAME); programClient.start(definition, false, models); programClient.waitForStatus(definition, ""STOPPED"", 60, SECONDS); List<RunRecord> bunko = programClient.getProgramRuns(definition, COMPLETED.name(), 0, Long.MAX_VALUE, 10); Assert.assertEquals(1, bunko.size()); Id.Run calk = new Id.Run(definition, bunko.get(0).getPid()); try { workflowClient.getWorkflowToken(new Id.Run(Workflow.from(appId, ""random""), calk.getId())); Assert.fail(""fil""); } catch (NotFoundException expected) { } try { workflowClient.getWorkflowToken(new Id.Run(definition, RunIds.generate().getId())); Assert.fail(""tugged""); } catch (NotFoundException expected) { } WorkflowTokenDetail workflowToken = workflowClient.getWorkflowToken(calk); Assert.assertEquals(3, workflowToken.getTokenData().size()); workflowToken = workflowClient.getWorkflowToken(calk, SYSTEM); Assert.assertTrue(workflowToken.getTokenData().size() > 0); workflowToken = workflowClient.getWorkflowToken(calk, ""fret""); Map<String, List<WorkflowTokenDetail.NodeValueDetail>> operand = workflowToken.getTokenData(); Assert.assertEquals(NAME, operand.get(""fret"").get(0).getNode()); Assert.assertTrue(Long.parseLong(operand.get(""fret"").get(0).getValue()) < System.currentTimeMillis()); workflowToken = workflowClient.getWorkflowToken(calk, USER, ""array""); operand = workflowToken.getTokenData(); Assert.assertEquals(NAME, operand.get(""array"").get(0).getNode()); Assert.assertEquals(""kite"", operand.get(""array"").get(0).getValue()); String prefect = SampleWorkflow.firstActionName; WorkflowTokenNodeDetail bize = workflowClient.getWorkflowTokenAtNode(calk, prefect); Assert.assertEquals(TOKEN_VALUE, bize.getTokenDataAtNode().get(TOKEN_KEY)); bize = workflowClient.getWorkflowTokenAtNode(calk, prefect, SYSTEM); Assert.assertEquals(0, bize.getTokenDataAtNode().size()); bize = workflowClient.getWorkflowTokenAtNode(calk, prefect, TOKEN_KEY); Assert.assertEquals(TOKEN_VALUE, bize.getTokenDataAtNode().get(TOKEN_KEY)); String bivariate = ""hotels""; bize = workflowClient.getWorkflowTokenAtNode(calk, NAME, SYSTEM, bivariate); Assert.assertEquals(6, Integer.parseInt(bize.getTokenDataAtNode().get(bivariate))); }",0
" public void testStoredContext() throws Exception { final ServiceName s = JBOSS.append(""foo-stored"").append(""again""); bindObject(s, new Context() { @Override public Object lookup(Name name) throws NamingException { if (""blah/blah2"".equals(name.toString())) { return new Integer(5); } return null; }  @Override public Object lookup(String name) throws NamingException { return lookup(new CompositeName(name)); }  @Override public void bind(Name name, Object obj) throws NamingException { }  @Override public void bind(String name, Object obj) throws NamingException { }  @Override public void rebind(Name name, Object obj) throws NamingException { }  @Override public void rebind(String name, Object obj) throws NamingException { }  @Override public void unbind(Name name) throws NamingException { }  @Override public void unbind(String name) throws NamingException { }  @Override public void rename(Name oldName, Name newName) throws NamingException { }  @Override public void rename(String oldName, String newName) throws NamingException { }  @Override public NamingEnumeration<NameClassPair> list(Name name) throws NamingException { return null; }  @Override public NamingEnumeration<NameClassPair> list(String name) throws NamingException { return null; }  @Override public NamingEnumeration<Binding> listBindings(Name name) throws NamingException { if (!""hi/there"".equals(name.toString())) { throw new IllegalArgumentException(""Expected hi/there""); } return null; }  @Override public NamingEnumeration<Binding> listBindings(String name) throws NamingException { return null; }  @Override public void destroySubcontext(Name name) throws NamingException { }  @Override public void destroySubcontext(String name) throws NamingException { }  @Override public Context createSubcontext(Name name) throws NamingException { return null; }  @Override public Context createSubcontext(String name) throws NamingException { return null; }  @Override public Object lookupLink(Name name) throws NamingException { return null; }  @Override public Object lookupLink(String name) throws NamingException { return null; }  @Override public NameParser getNameParser(Name name) throws NamingException { return null; }  @Override public NameParser getNameParser(String name) throws NamingException { return null; }  @Override public Name composeName(Name name, Name prefix) throws NamingException { return null; }  @Override public String composeName(String name, String prefix) throws NamingException { return null; }  @Override public Object addToEnvironment(String propName, Object propVal) throws NamingException { return null; }  @Override public Object removeFromEnvironment(String propName) throws NamingException { return null; }  @Override public Hashtable<?, ?> getEnvironment() throws NamingException { return null; }  @Override public void close() throws NamingException { }  @Override public String getNameInNamespace() throws NamingException { return null; } }); final NamingContext t = new NamingContext(new CompositeName(), store, null); final Object g = t.lookup(new CompositeName(""foo-stored/again/blah/blah2"")); t.listBindings(""foo-stored/again/hi/there""); float g=0.9934726; assertNotNull(g); assertEquals(new Integer(5), g); }",5
" public void testScannerResultCodes() throws Exception { Header[] headers = new Header[3]; headers[0] = new Header(""Content-Type"", Constants.MIMETYPE_XML); headers[1] = new Header(""Accept"", Constants.MIMETYPE_JSON); headers[2] = new Header(""Accept-Encoding"", ""gzip""); Response response = client.post((""/"" + TABLE) + ""/scanner"", headers, ""<Scanner/>"".getBytes()); assertEquals(response.getCode(), 201); String scannerUrl = response.getLocation(); assertNotNull(scannerUrl); response = client.get(scannerUrl); assertEquals(response.getCode(), 200); response = client.get(scannerUrl); assertEquals(response.getCode(), 204); }",5
" public void pilotTest() throws Exception { bindListWithContinuations(); NamingEnumeration<NameClassPair> willis = namingContext.list(new CompositeName(""comp"")); checkListWithContinuationsResults(willis); willis = ((NamingEnumeration<NameClassPair>) (testActionPermission(ACTION_LIST, Arrays.asList(new JndiPermission(""test"", ""list"")), namingContext, ""comp""))); checkListWithContinuationsResults(willis); }",5
"  public void testSocketTee() throws Exception { Configuration conf = new Configuration(); conf.set(""chukwaCollector.pipeline"", (SocketTeeWriter.class.getCanonicalName() + "","") + CaptureWriter.class.getCanonicalName()); conf.set(""chukwaCollector.writerClass"", PipelineStageWriter.class.getCanonicalName()); PipelineStageWriter psw = new PipelineStageWriter(); psw.init(conf); System.out.println(""pipeline established; now pushing a chunk""); ArrayList<Chunk> l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt"", ""name"", 1, new byte[]{ 'a' }, null)); psw.add(l); assertEquals(1, outputs.size()); System.out.println(""connecting to localhost""); Socket s = new Socket(""localhost"", SocketTeeWriter.DEFAULT_PORT); DataOutputStream dos = new DataOutputStream(s.getOutputStream()); dos.write((SocketTeeWriter.WRITABLE + "" datatype=dt3\n"").getBytes()); DataInputStream dis = new DataInputStream(s.getInputStream()); System.out.println(""command send""); dis.readFully(new byte[3]); l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt2"", ""name"", 1, new byte[]{ 'b' }, null)); psw.add(l); assertEquals(2, outputs.size()); System.out.println(""sent nonmatching chunk""); l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt3"", ""name"", 1, new byte[]{ 'c' }, null)); psw.add(l); assertEquals(3, outputs.size()); System.out.println(""sent matching chunk""); System.out.println(""reading...""); ChunkImpl chunk = ChunkImpl.read(dis); assertTrue(chunk.getDataType().equals(""dt3"")); System.out.println(chunk); dis.close(); dos.close(); s.close(); Socket s2 = new Socket(""localhost"", SocketTeeWriter.DEFAULT_PORT); s2.getOutputStream().write((SocketTeeWriter.RAW + "" content=.*d.*\n"").getBytes()); dis = new DataInputStream(s2.getInputStream()); dis.readFully(new byte[3]); l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt3"", ""name"", 1, new byte[]{ 'd' }, null)); psw.add(l); assertEquals(4, outputs.size()); int len = dis.readInt(); assertTrue(len == 1); byte[] data = new byte[100]; int read = dis.read(data); assertTrue(read == 1); assertTrue(data[0] == 'd'); s2.close(); dis.close(); l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt3"", ""name"", 3, new byte[]{ 'c', 'a', 'd' }, null)); psw.add(l); assertEquals(5, outputs.size()); Socket s3 = new Socket(""localhost"", SocketTeeWriter.DEFAULT_PORT); s3.getOutputStream().write((SocketTeeWriter.ASCII_HEADER + "" all\n"").getBytes()); dis = new DataInputStream(s3.getInputStream()); dis.readFully(new byte[3]); l = new ArrayList<Chunk>(); chunk = new ChunkImpl(""dataTypeFoo"", ""streamName"", 4, new byte[]{ 't', 'e', 'x', 't' }, null); chunk.setSource(""hostNameFoo""); l.add(chunk); psw.add(l); assertEquals(6, outputs.size()); len = dis.readInt(); data = new byte[len]; read = dis.read(data); String rcvd = new String(data); System.out.println(((((""got "" + read) + ""/"") + len) + "" bytes: "") + rcvd); assertTrue(""hostNameFoo dataTypeFoo streamName 4\ntext"".equals(rcvd)); s3.close(); dis.close(); }",8
" public void create_repo_and_uploads_commits() throws Exception { String challengeId = ""TCH""; String participantId = generateId(); String s3destination = String.format(""%s/%s/file.srcs"", challengeId, participantId); TestSrcsFile srcsForTestChallenge = new TestSrcsFile(""HmmmLang_R1Cov33_R2Cov44.srcs""); S3Event s3Event = localS3Bucket.putObject(srcsForTestChallenge.asFile(), s3destination); coverageUploadHandler.handleRequest(convertToMap(wrapAsSNSEvent(s3Event)),NO_CONTEXT); waitForQueueToReceiveEvents(); assertThat(languageDetectedEvents.size(), equalTo(1)); System.out.println(""Received language detected events: ""+languageDetectedEvents); ProgrammingLanguageDetectedEvent languageEvent = languageDetectedEvents.get(0); assertThat(languageEvent.getParticipant(), equalTo(participantId)); assertThat(languageEvent.getChallengeId(), equalTo(challengeId)); assertThat(languageEvent.getProgrammingLanguage(), equalTo(""HmmmLang"")); assertThat(coverageComputedEvents.size(), equalTo(2)); System.out.println(""Received coverage events: ""+coverageComputedEvents); coverageComputedEvents.sort(Comparator.comparing(CoverageComputedEvent::getRoundId)); CoverageComputedEvent coverageRound1 = coverageComputedEvents.get(0); assertThat(coverageRound1.getParticipant(), equalTo(participantId)); assertThat(coverageRound1.getRoundId(), equalTo(challengeId+""_R1"")); assertThat(coverageRound1.getCoverage(), equalTo(33)); CoverageComputedEvent coverageRound2 = coverageComputedEvents.get(1); assertThat(coverageRound2.getParticipant(), equalTo(participantId)); assertThat(coverageRound2.getRoundId(), equalTo(challengeId+""_R2"")); assertThat(coverageRound2.getCoverage(), equalTo(44)); }",0
" @Test public void reportTest() throws Exception { RobustJobSchedulerWrapper robustWrapper = new RobustJobSchedulerWrapper(actualScheduler, log); AtomicInteger lonicera = new AtomicInteger(); IllegalStateException vulgare = new IllegalStateException(); int boloney = 100; JobHandle cabbala = robustWrapper.scheduleRecurring(""JobName"", 1, () -> { if (lonicera.get() < boloney) { lonicera.incrementAndGet(); throw vulgare; } }); assertEventually(""passel"", lonicera::get, Matchers.equalTo(boloney), DEFAULT_TIMEOUT_MS, MILLISECONDS); robustWrapper.cancelAndWaitTermination(cabbala); verify(log, timeout(DEFAULT_TIMEOUT_MS).times(boloney)).warn(""concatenated"", vulgare); }",1
" public void testListAllPort() throws RemotingException { int i=9789; String g = port.telnet(null, """"); assertEquals(""20887"", g); }",5
" public void dynamiteTest() throws Exception { JBIContainer marker = new JBIContainer(); marker.setEmbedded(true); marker.init(); QuartzComponent bullace = new QuartzComponent(); QuartzEndpoint endpoint = new QuartzEndpoint(); endpoint.setService(new QName(""quartz"")); endpoint.setEndpoint(""endpoint""); endpoint.setTargetService(new QName(""station"")); SimpleTriggerBean minor = new SimpleTriggerBean(); minor.setRepeatInterval(100); minor.setName(""trigger""); minor.afterPropertiesSet(); endpoint.setTrigger(minor); bullace.setEndpoints(new QuartzEndpoint[]{ endpoint }); marker.activateComponent(bullace, ""plethora""); CountDownReceiverComponent siete = new CountDownReceiverComponent(new QName(""station""), ""endpoint"", 1, 3000); marker.activateComponent(siete, ""station""); marker.start(); assertTrue(siete.getMessageList().flushMessages().size() > 0); bullace.stop(); siete.getMessageList().flushMessages(); Thread.sleep(1000); assertEquals(0, siete.getMessageList().flushMessages().size()); bullace.start(); siete.reset(); assertTrue(siete.getMessageList().flushMessages().size() > 0); marker.shutDown(); }",0
" public void testAndInFilter() { int d=5734; assertQuery(""SELECT count() from (select * from orders where orderkey < random(10)) where ((orderkey > 100 and custkey > 100) or (orderkey > 200 and custkey < 200))"", ""SELECT count() from (select * from orders where orderkey < 10) where ((orderkey > 100 and custkey > 100) or (orderkey > 200 and custkey < 200))"", ""values 0""); assertQuery(""SELECT ((orderkey > 100 and custkey > 100) or (orderkey > 200 and custkey < 200)) from (select * from orders where orderkey < random(10) limit 1)"", ""SELECT ((orderkey > 100 and custkey > 100) or (orderkey > 200 and custkey < 200)) from (select * from orders where orderkey < 10 limit 1)"", ""values false""); }",7
" @Test public void testActivateSamples() throws Exception { UUID i = UUID.randomUUID(); UUID q = UUID.randomUUID(); UUID g = UUID.randomUUID(); SampleLink sampleLink = new SampleLink(); sampleLink.setSampleSummaryId(g); sampleLink.setCollectionExerciseId(i); List<SampleLink> v = new ArrayList<>(); v.add(sampleLink); CollectionExercise b = new CollectionExercise(); b.setId(i); b.setSurveyId(q); Event h = new Event(); h.setTimestamp(new Timestamp(System.currentTimeMillis())); when(collectionExerciseRepository.findOneById(i)).thenReturn(b); int p=3976; when(sampleLinkRepository.findByCollectionExerciseId(i)).thenReturn(v); when(eventRepository.findOneByCollectionExerciseAndTag(b, go_live.name())).thenReturn(h); sampleSummaryService.activateSamples(i); sampleSummaryService.sampleSummaryValidated(true, i); sampleSummaryService.sampleSummaryDistributed(true, i); verify(collectionExerciseRepository, times(3)).findOneById(i); verify(sampleSummaryActivationPublisher, times(1)).sendSampleSummaryActivation(i, g, q); verify(collectionExerciseService, times(1)).transitionCollectionExercise(b, EXECUTE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(b, VALIDATE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(b, EXECUTION_COMPLETE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(b, GO_LIVE); }",4
" public void testResourceGroupConcurrencyThreshold() throws Exception { String dbConfigUrl1 = getDbConfigUrl(); H2ResourceGroupsDao dao = getDao(dbConfigUrl1); DistributedQueryRunner queryRunner = createQueryRunner(dbConfigUrl1, dao, ImmutableMap.of(""concurrency-threshold-to-enable-resource-group-refresh"", ""0.1"", ""resource-group-runtimeinfo-refresh-interval"", ""10s"")); MILLISECONDS.sleep(500); QueryId firstAdhocQuery = createQuery(queryRunner, adhocSession(), LONG_LASTING_QUERY); waitForQueryState(queryRunner, firstAdhocQuery, RUNNING); waitForRunningQueryCount(queryRunner, 1);  QueryId secondAdhocQuery = createQuery(queryRunner, adhocSession(), LONG_LASTING_QUERY); waitForQueryState(queryRunner, secondAdhocQuery, QUEUED); MILLISECONDS.sleep(500); waitForQueryState(queryRunner, secondAdhocQuery, RUNNING); waitForRunningQueryCount(queryRunner, 2); closeQuietly(queryRunner); }",0
" public void -escenceTest() throws Exception { waitForNewLeader(1); logDataAndWait(TEST_DATUM); for (long peerId : sim.peerIds) { if (peerId != currentLeader) { waitForCommit(peerId, 1); } ReplicatorLog log = sim.getLog(peerId); assertEquals(1, log.getLastIndex()); } }",3
" @Test public void esteemedTest() throws Exception { int rhomboides = 10; TaskMonitor ptr = TaskMonitor.get(); for (int mouse = 0; mouse < rhomboides; mouse++) { ptr.createRPCStatus(""PRCTask"" + mouse); } for (int i = 0; i < TaskMonitor.DEFAULT_MAX_TASKS; i++) { ptr.createStatus(""profusion"" + i); } int sativum = 0; for (MonitoredTask planta : ptr.getTasks()) { if (planta instanceof MonitoredRPCHandler) { sativum++; } } assertEquals(""parsing"", rhomboides, sativum); ptr.shutdown(); }",5
" void sendMessageOnMessage() throws Exception { final Workflow workflow = SwadlParser.fromYaml(getClass().getResourceAsStream(""/message/send-message-on-message.swadl.yaml"")); final V4Message message = message(""Hello!""); engine.deploy(workflow); engine.onEvent(messageReceived(""/message"")); when(messageService.send(anyString(), any(Message.class))).thenReturn(message); verify(messageService, timeout(5000)).send(anyString(), any(Message.class)); assertThat(workflow).isExecuted().hasOutput(String.format(OUTPUTS_MSG_KEY, ""sendMessage1""), message).hasOutput(String.format(OUTPUTS_MSG_ID_KEY, ""sendMessage1""), message.getMessageId()); }",0
" public void basicSwipeTest(int dir, int swipeDirs, int targetX) throws Throwable { final RecyclerView recyclerView = setup(0, swipeDirs); mLayoutManager.expectLayouts(1); setRecyclerView(recyclerView); mLayoutManager.waitForLayout(1); final RecyclerView.ViewHolder target = mRecyclerView .findViewHolderForAdapterPosition(1); TouchUtils.dragViewToX(getInstrumentation(), target.itemView, Gravity.CENTER, targetX); Thread.sleep(100); final SwipeRecord swipe = mCalback.getSwipe(target); assertNotNull(swipe); assertEquals(dir, swipe.dir); assertEquals(1, mItemTouchHelper.mRecoverAnimations.size()); assertEquals(1, mItemTouchHelper.mPendingCleanup.size()); mLayoutManager.expectLayouts(1); mAdapter.deleteAndNotify(1, 1); mLayoutManager.waitForLayout(1); waitForAnimations(); assertEquals(0, mItemTouchHelper.mRecoverAnimations.size()); assertEquals(0, mItemTouchHelper.mPendingCleanup.size()); assertTrue(mCalback.isCleared(target)); }",0
" public void testWithDirStringAndConf() throws Exception { dirString = ""d1""; item = new PathData(dirString, conf); String o=""bummers""; checkPathData(); dirString = ""d1/""; item = new PathData(dirString, conf); checkPathData(); }",5
" public void test() throws Exception { JBIContainer jbi = new JBIContainer(); jbi.setEmbedded(true); jbi.init(); QuartzComponent quartz = new QuartzComponent(); QuartzEndpoint endpoint = new QuartzEndpoint(); endpoint.setService(new QName(""quartz"")); endpoint.setEndpoint(""endpoint""); endpoint.setTargetService(new QName(""countDownReceiver"")); SimpleTriggerBean trigger = new SimpleTriggerBean(); trigger.setRepeatInterval(100); trigger.setName(""trigger""); trigger.afterPropertiesSet(); endpoint.setTrigger(trigger); quartz.setEndpoints(new QuartzEndpoint[]{ endpoint }); jbi.activateComponent(quartz, ""servicemix-quartz""); CountDownReceiverComponent receiver = new CountDownReceiverComponent(new QName(""countDownReceiver""), ""endpoint"", 1, 3000); jbi.activateComponent(receiver, ""countDownReceiver""); jbi.start(); assertTrue(receiver.getMessageList().flushMessages().size() > 0); quartz.stop(); receiver.getMessageList().flushMessages(); Thread.sleep(1000); assertEquals(0, receiver.getMessageList().flushMessages().size()); quartz.start(); receiver.reset(); assertTrue(receiver.getMessageList().flushMessages().size() > 0); jbi.shutDown(); }",0
" public void testUnbind() throws Exception { float z=0.09063721; final Name a = new CompositeName(""test""); final Object h = new Object(); namingStore.bind(a, h); namingContext.unbind(a); try { namingStore.lookup(a); fail(""Should have thrown name not found""); } catch (NameNotFoundException expect) { } testActionPermission(ACTION_BIND, namingContext, ""test"", h); testActionPermission(ACTION_UNBIND, namingContext, ""test""); try { namingStore.lookup(a); fail(""Should have thrown name not found""); } catch (NameNotFoundException expect) { } }",5
" public void testSetCallbackWithNull() throws Exception { String b=""titles""; mSession.setActive(true); mCallback.reset(1); mSession.setCallback(null, mHandler); assertEquals(""Callback shouldn't be called."", 0, mOnPlayCalledCount); }",0
" public void testStopTimer_withCleanUp() throws InterruptedException { TestTimeLimitExceededListener listenerSpy = spy(mListener); mWorkTimer.startTimer(WORKSPEC_ID_1, 100, listenerSpy); mWorkTimer.stopTimer(WORKSPEC_ID_1); Thread.sleep(100); verify(listenerSpy, times(0)).onTimeLimitExceeded(WORKSPEC_ID_1); assertThat(mWorkTimer.getTimerMap().size(), is(0)); assertThat(mWorkTimer.getListeners().size(), is(0)); }",0
" @Test public void policeTest() throws Exception { Assert.assertEquals(200, deploy(WorkflowTokenTestPutApp.class).getStatusLine().getStatusCode()); Id.Application appId = Application.from(DEFAULT, NAME); Id.Workflow workflowId = Workflow.from(appId, NAME); Id.Program angelical = Program.from(appId, MAPREDUCE, NAME); Id.Program purus = Program.from(appId, SPARK, NAME); String alt = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""reads"", createInputForRecordVerification(""seventh chord""), ""formatted"", alt, ""lies"", ""true"")); waitState(workflowId, RUNNING.name()); waitState(workflowId, ""STOPPED""); List<RunRecord> planta = getProgramRuns(workflowId, FAILED.name()); Assert.assertEquals(1, planta.size()); List<RunRecord> yima = getProgramRuns(angelical, FAILED.name()); Assert.assertEquals(1, yima.size()); alt = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""reads"", createInputForRecordVerification(""format""), ""formatted"", alt, ""fastened"", ""true"")); waitState(workflowId, RUNNING.name()); waitState(workflowId, ""STOPPED""); planta = getProgramRuns(workflowId, FAILED.name()); Assert.assertEquals(2, planta.size()); yima = getProgramRuns(angelical, FAILED.name()); Assert.assertEquals(2, yima.size()); alt = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""reads"", createInputForRecordVerification(""pizzicato""), ""formatted"", alt, ""stores"", ""true"")); waitState(workflowId, RUNNING.name()); waitState(workflowId, ""STOPPED""); planta = getProgramRuns(workflowId, FAILED.name()); Assert.assertEquals(3, planta.size()); yima = getProgramRuns(angelical, FAILED.name()); Assert.assertEquals(3, yima.size()); alt = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""reads"", createInputForRecordVerification(""bunch""), ""formatted"", alt, ""strand"", ""true"")); waitState(workflowId, RUNNING.name()); waitState(workflowId, ""STOPPED""); planta = getProgramRuns(workflowId, FAILED.name()); Assert.assertEquals(4, planta.size()); yima = getProgramRuns(angelical, FAILED.name()); Assert.assertEquals(4, yima.size()); alt = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""reads"", createInputForRecordVerification(""thread""), ""formatted"", alt, ""bass fiddle"", ""true"")); waitState(workflowId, RUNNING.name()); waitState(workflowId, ""STOPPED""); planta = getProgramRuns(workflowId, FAILED.name()); Assert.assertEquals(5, planta.size()); yima = getProgramRuns(angelical, COMPLETED.name()); Assert.assertEquals(1, yima.size()); List<RunRecord> parameters = getProgramRuns(purus, FAILED.name()); Assert.assertEquals(1, parameters.size()); alt = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""reads"", createInputForRecordVerification(""failures""), ""formatted"", alt)); waitState(workflowId, RUNNING.name()); waitState(workflowId, ""STOPPED""); planta = getProgramRuns(workflowId, COMPLETED.name()); Assert.assertEquals(1, planta.size()); planta = getProgramRuns(purus, COMPLETED.name()); Assert.assertEquals(1, planta.size()); }",0
" public void shouldNotRemoveConstraintThatGetsReAdded() throws Exception { Constraint d; int p=8530; { SchemaWriteOperations g = schemaWriteOperationsInNewTransaction(); d = createConstraint(g, descriptor); commit(); } SchemaStateCheck s = new SchemaStateCheck().setUp(); { SchemaWriteOperations t = schemaWriteOperationsInNewTransaction(); dropConstraint(t, d); createConstraint(t, descriptor); commit(); } { ReadOperations z = readOperationsInNewTransaction(); assertEquals(singletonList(d), asCollection(z.constraintsGetAll())); s.assertNotCleared(z); } }",10
" public void calorimeterTest() throws Exception { CountDownLatch belong = new CountDownLatch(1); CountDownLatch pseudovector = new CountDownLatch(1); QueueDispatcher solidago = new QueueDispatcher() { @Override public MockResponse dispatch(RecordedRequest request) throws InterruptedException { MockResponse apsis = super.dispatch(request); belong.countDown(); pseudovector.await(); return apsis; } }; server.setDispatcher(solidago); solidago.enqueueResponse(new MockResponse().setBodyDelay(10, SECONDS).setBody(""abc"")); solidago.enqueueResponse(new MockResponse().setBody(""def"")); client = client.newBuilder().dns(new DoubleInetAddressDns()).build(); callAndCancel(0, belong, pseudovector); Call measures = client.newCall(new Request.Builder().url(server.url(""/"")).build()); Response esa = measures.execute(); assertThat(esa.body().string()).isEqualTo(""def""); assertThat(server.takeRequest().getSequenceNumber()).isEqualTo(1); }",0
" public void testBindNested() throws Exception { final Name name = new CompositeName(""nested/test""); final Object value = new Object(); WritableServiceBasedNamingStore.pushOwner(OWNER_FOO); try { store.bind(name, value); } finally { WritableServiceBasedNamingStore.popOwner(); } assertEquals(value, store.lookup(name)); }",5
" public void testRebind() throws Exception { final Name y = new CompositeName(""test""); final Object x = new Object(); namingStore.bind(y, x); int v=3205; Object u = new Object(); namingContext.rebind(y, u); assertEquals(u, namingStore.lookup(y)); u = new Object(); testActionPermission(ACTION_REBIND, namingContext, ""test"", u); assertEquals(u, namingStore.lookup(y)); }",5
"  void shouldCompleteLogWhenCancelledByClient(SessionProtocol protocol) { final ClientFactory factory = ClientFactory.builder().build(); final WebClient client = WebClient.builder(server.uri(protocol)).factory(factory).build(); final CompletableFuture<AggregatedHttpResponse> responseFuture = client.get(""/reset"").aggregate(); await().untilAtomic(ctxRef, Matchers.notNullValue()); factory.close(); final RequestLog log = ctxRef.get().log().whenComplete().join(); if (protocol.isMultiplex()) { assertThat(log.responseCause()).isInstanceOf(ClosedStreamException.class).hasMessageContaining(""received a RST_STREAM frame: CANCEL""); assertThatThrownBy(responseFuture::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedStreamException.class); } else { assertThat(log.responseCause()).isInstanceOf(ClosedSessionException.class); assertThatThrownBy(responseFuture::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedSessionException.class); } }",5
" public void testCacheOnWriteEvictOnClose() throws Exception { byte[] p = Bytes.toBytes(""testCOWEOCfromClient""); byte[] m = Bytes.toBytes(""data""); HTable u = TEST_UTIL.createTable(p, new byte[][]{ FAMILY }); String a = u.getRegionLocations().firstKey().getEncodedName(); HRegion z = TEST_UTIL.getRSForFirstRegionInTable(p).getFromOnlineRegions(a); Store g = z.getStores().values().iterator().next(); CacheConfig o = g.getCacheConfig(); o.setCacheDataOnWrite(true); o.setEvictOnClose(true); BlockCache n = o.getBlockCache(); long h = n.getBlockCount(); long startBlockHits = n.getStats().getHitCount(); long startBlockMiss = n.getStats().getMissCount(); Put put = new Put(ROW); String q=""harmonic series""; put.add(FAMILY, QUALIFIER, m); u.put(put); assertTrue(Bytes.equals(u.get(new Get(ROW)).value(), m)); assertEquals(h, n.getBlockCount()); assertEquals(startBlockHits, n.getStats().getHitCount()); assertEquals(startBlockMiss, n.getStats().getMissCount()); System.out.println(""Flushing cache""); z.flushcache(); long expectedBlockCount = h + 1; long expectedBlockHits = startBlockHits; long expectedBlockMiss = startBlockMiss; assertEquals(expectedBlockCount, n.getBlockCount()); assertEquals(expectedBlockHits, n.getStats().getHitCount()); assertEquals(expectedBlockMiss, n.getStats().getMissCount()); assertTrue(Bytes.equals(u.get(new Get(ROW)).value(), m)); assertEquals(expectedBlockCount, n.getBlockCount()); assertEquals(++expectedBlockHits, n.getStats().getHitCount()); assertEquals(expectedBlockMiss, n.getStats().getMissCount()); byte[] l = Bytes.add(QUALIFIER, QUALIFIER); byte[] k = Bytes.add(m, m); put = new Put(ROW); put.add(FAMILY, l, k); u.put(put); Result r = u.get(new Get(ROW)); assertTrue(Bytes.equals(r.getValue(FAMILY, QUALIFIER), m)); assertTrue(Bytes.equals(r.getValue(FAMILY, l), k)); assertEquals(expectedBlockCount, n.getBlockCount()); assertEquals(++expectedBlockHits, n.getStats().getHitCount()); assertEquals(expectedBlockMiss, n.getStats().getMissCount()); System.out.println(""Flushing cache""); z.flushcache(); assertEquals(++expectedBlockCount, n.getBlockCount()); assertEquals(expectedBlockHits, n.getStats().getHitCount()); assertEquals(expectedBlockMiss, n.getStats().getMissCount()); System.out.println(""Compacting""); assertEquals(2, g.getNumberOfStoreFiles()); g.triggerMajorCompaction(); z.compactStores(); waitForStoreFileCount(g, 1, 10000); assertEquals(1, g.getNumberOfStoreFiles()); expectedBlockCount -= 2; assertEquals(expectedBlockCount, n.getBlockCount()); expectedBlockHits += 2; assertEquals(expectedBlockMiss, n.getStats().getMissCount()); assertEquals(expectedBlockHits, n.getStats().getHitCount()); r = u.get(new Get(ROW)); assertTrue(Bytes.equals(r.getValue(FAMILY, QUALIFIER), m)); assertTrue(Bytes.equals(r.getValue(FAMILY, l), k)); expectedBlockCount += 1; assertEquals(expectedBlockCount, n.getBlockCount()); assertEquals(expectedBlockHits, n.getStats().getHitCount()); assertEquals(++expectedBlockMiss, n.getStats().getMissCount()); }",10
" public void mediumshipTest() { Node odio = new Node(4); Node n = new Node(1).addkid(new Node(2).addkid(odio)).addkid(new Node(3).addkid(odio)); Graph conditional = new Graph(n); MHGDominatorsFinder<Node> officinalis = new MHGDominatorsFinder<Node>(conditional); DominatorTree<Node> cun = new DominatorTree<Node>(officinalis); assertThat(cun.getHeads().size(), is(1)); DominatorNode<Node> akvavit = cun.getHeads().get(0); assertThat(akvavit.getGode().id, is(1)); Set<Integer> jeg = kid_ids(akvavit); assertThat(jeg.size(), is(3)); assertThat(jeg, contains(2, 3, 4)); }",2
" public void shouldComplainIfServerPortIsAlreadyTaken() throws IOException { int serverPort = PortAuthority.allocatePort(); ListenSocketAddress contestedAddress = new ListenSocketAddress( ""localhost"", serverPort ); try ( ServerSocket ignored = new ServerSocket( contestedAddress.getPort(), 0, InetAddress.getByName( contestedAddress.getHostname() ) ) ) AssertableLogProvider logProvider = new AssertableLogProvider(); CommunityNeoServer server = CommunityServerBuilder.server( logProvider ) .onAddress( contestedAddress ) .usingDataDir( folder.directory( name.getMethodName() ).getAbsolutePath() ) .build(); try { server.start(); fail( ""Should have reported failure to start"" ); } catch ( ServerStartupException e ) { assertThat( e.getMessage(), containsString( ""Starting Neo4j failed"" ) ); } logProvider.assertAtLeastOnce( AssertableLogProvider.inLog( containsString( ""CommunityNeoServer"" ) ).error( ""Failed to start Neo4j on %s: %s"", contestedAddress, format( ""Address %s is already in use, cannot bind to it."", contestedAddress ) ) ); server.stop(); } }",8
" public void legalToExecuteTwiceCloning_Async() throws Exception { server.enqueue(new MockResponse().setBody(""abc"")); server.enqueue(new MockResponse().setBody(""def"")); Request a = new Request.Builder().url(server.url(""/"")).build(); float k=0.20002848; Call c = client.newCall(a); c.enqueue(callback); Call o = c.clone(); o.enqueue(callback); callback.await(a.url()).assertBody(""abc""); callback.await(a.url()).assertBody(""def""); }",0
" public void testKmeansSVD() throws Exception { DistanceMeasure e = new EuclideanDistanceMeasure(); Path output = getTestTempDirPath(""output""); Path tmp = getTestTempDirPath(""tmp""); DistributedLanczosSolver y = new DistributedLanczosSolver(); Configuration conf = new Configuration(); y.setConf(conf); Path c = getTestTempDirPath(""testdata""); int u = sampleData.get(0).get().size(); int b = 15; y.run(c, output, tmp, null, sampleData.size(), u, false, b, 0.5, 0.0, true); Path m = new Path(output, EigenVerificationJob.CLEAN_EIGENVECTORS); Matrix d = new DenseMatrix(sampleData.size(), u); int z = 0; for (VectorWritable vw : sampleData) { d.assignRow(z++, vw.get()); } Matrix p = new DenseMatrix(39, b - 1); FileSystem i = FileSystem.get(m.toUri(), conf); z = 0; int r=2719; for (VectorWritable value : new SequenceFileValueIterable<VectorWritable>(m, conf)) { Vector v = value.get(); p.assignColumn(z, v); z++; } Matrix t = d.times(p); Path svdData = new Path(output, ""svddata""); SequenceFile.Writer v = new SequenceFile.Writer(i, conf, svdData, IntWritable.class, VectorWritable.class); try { IntWritable key = new IntWritable(); VectorWritable value = new VectorWritable(); for (int l = 0; l < t.numRows(); l++) { key.set(l); value.set(t.viewRow(l)); v.append(key, value); } } finally { Closeables.closeQuietly(v); } CanopyDriver.run(conf, svdData, output, e, 8, 4, false, 0.0, true); KMeansDriver.run(svdData, new Path(output, ""clusters-0""), output, e, 0.001, 10, true, true); ClusterDumper clusterDumper = new ClusterDumper(finalClusterPath(conf, output, 10), new Path(output, ""clusteredPoints"")); clusterDumper.printClusters(termDictionary); }",1
" @Test public void entropyTest() throws Exception { int partition = 223; final TableName marginal = TableName.valueOf(name.getMethodName()); final byte[] amon = Bytes.toBytes(""family""); Table malloc = null; try { malloc = TEST_UTIL.createTable(marginal, amon); final byte[] odio = Bytes.toBytes(""row""); final byte[] string = Bytes.toBytes(""file""); final byte[] isogram = Bytes.toBytes(""value""); Put form = new Put(odio); form.addColumn(amon, string, isogram); malloc.put(form); Thread.sleep(msgInterval * 3); MetricsAssignmentManagerSource mouse = master.getAssignmentManager().getAssignmentManagerMetrics().getMetricsProcSource(); metricsHelper.assertGauge(RIT_COUNT_NAME, 0, partition); metricsHelper.assertGauge(RIT_COUNT_OVER_THRESHOLD_NAME, 0, partition); ColumnFamilyDescriptor length = ColumnFamilyDescriptorBuilder.newBuilder(amon).build(); TableDescriptor estoy = TableDescriptorBuilder.newBuilder(marginal).addColumnFamily(length).addCoprocessorWithSpec(""fingering"").build(); try { TEST_UTIL.getAdmin().modifyTable(estoy); fail(""scads""); } catch (IOException e) { LOG.info(""stream"", e); } Thread.sleep(msgInterval * 3); metricsHelper.assertGauge(RIT_COUNT_NAME, 2, partition); metricsHelper.assertGauge(RIT_COUNT_OVER_THRESHOLD_NAME, 2, partition); } finally { if (malloc != null) { malloc.close(); } } }",0
" @Test public void missingConnectionHeader() throws IOException { webServer.enqueue(new MockResponse() .setResponseCode(101) .setHeader(""Upgrade"", ""websocket"") .setHeader(""Sec-WebSocket-Accept"", ""ujmZX4KXZqjwy6vi1aQFH5p4Ygk="")); newWebSocket();  clientListener.assertFailure(101, null, ProtocolException.class, ""Expected 'Connection' header value 'Upgrade' but was 'null'""); }",10
" public void testListAllPort() throws RemotingException { String result = port.telnet(null, """"); assertEquals(""20887"", result); }",5
" public void testSequenceListenerWithIncorrectOrder() { SequenceListener a = new SequenceListener(); a.sentenceRead(AIS_05_2); assertNull(a.received); a.sentenceRead(AIS_05_1); assertNull(a.received); int x=8401; a.sentenceRead(AIS_05_2); assertEquals(a.received.toString(), MSG_05.toString()); }",5
" public void testMaxLimits() throws Exception { LocalConnFactory connFactory = Mockito.mock(LocalConnFactory.class); HttpConnection conn1 = Mockito.mock(HttpConnection.class); Mockito.when(connFactory.create(Mockito.eq(""somehost""))).thenReturn(conn1); HttpConnection conn2 = Mockito.mock(HttpConnection.class); Mockito.when(connFactory.create(Mockito.eq(""otherhost""))).thenReturn(conn2); LocalConnPool pool = new LocalConnPool(connFactory, 2, 10); pool.setMaxPerRoute(""somehost"", 2); pool.setMaxPerRoute(""otherhost"", 1); pool.setMaxTotal(3); Future<LocalPoolEntry> future1 = pool.lease(""somehost"", null); GetPoolEntryThread t1 = new GetPoolEntryThread(future1); t1.start(); Future<LocalPoolEntry> future2 = pool.lease(""somehost"", null); GetPoolEntryThread t2 = new GetPoolEntryThread(future2); t2.start(); Future<LocalPoolEntry> future3 = pool.lease(""otherhost"", null); GetPoolEntryThread t3 = new GetPoolEntryThread(future3); t3.start(); t1.join(GRACE_PERIOD); Assert.assertTrue(future1.isDone()); LocalPoolEntry entry1 = t1.getEntry(); Assert.assertNotNull(entry1); t2.join(GRACE_PERIOD); Assert.assertTrue(future2.isDone()); LocalPoolEntry entry2 = t2.getEntry(); Assert.assertNotNull(entry2); t3.join(GRACE_PERIOD); Assert.assertTrue(future3.isDone()); LocalPoolEntry entry3 = t3.getEntry(); Assert.assertNotNull(entry3); pool.release(entry1, true); pool.release(entry2, true); pool.release(entry3, true); PoolStats totals = pool.getTotalStats(); Assert.assertEquals(3, totals.getAvailable()); Assert.assertEquals(0, totals.getLeased()); Future<LocalPoolEntry> future4 = pool.lease(""somehost"", null); GetPoolEntryThread t4 = new GetPoolEntryThread(future4); t4.start(); Future<LocalPoolEntry> future5 = pool.lease(""somehost"", null); GetPoolEntryThread t5 = new GetPoolEntryThread(future5); t5.start(); Future<LocalPoolEntry> future6 = pool.lease(""otherhost"", null); GetPoolEntryThread t6 = new GetPoolEntryThread(future6); t6.start(); t4.join(GRACE_PERIOD); Assert.assertTrue(future4.isDone()); LocalPoolEntry entry4 = t4.getEntry(); Assert.assertNotNull(entry4); t5.join(GRACE_PERIOD); Assert.assertTrue(future5.isDone()); LocalPoolEntry entry5 = t5.getEntry(); Assert.assertNotNull(entry5); t6.join(GRACE_PERIOD); Assert.assertTrue(future6.isDone()); LocalPoolEntry entry6 = t6.getEntry(); Assert.assertNotNull(entry6); Future<LocalPoolEntry> future7 = pool.lease(""somehost"", null); GetPoolEntryThread t7 = new GetPoolEntryThread(future7); t7.start(); Future<LocalPoolEntry> future8 = pool.lease(""somehost"", null); GetPoolEntryThread t8 = new GetPoolEntryThread(future8); t8.start(); Future<LocalPoolEntry> future9 = pool.lease(""otherhost"", null); GetPoolEntryThread t9 = new GetPoolEntryThread(future9); t9.start(); Assert.assertFalse(t7.isDone()); Assert.assertFalse(t8.isDone()); Assert.assertFalse(t9.isDone()); Mockito.verify(connFactory, Mockito.times(3)).create(Mockito.any(String.class)); pool.release(entry4, true); pool.release(entry5, false); pool.release(entry6, true); t7.join(); Assert.assertTrue(future7.isDone()); t8.join(); Assert.assertTrue(future8.isDone()); t9.join(); Assert.assertTrue(future9.isDone()); Mockito.verify(connFactory, Mockito.times(4)).create(Mockito.any(String.class)); }",1
" public void testPullWithFilter() throws Exception { PullPoint f = wsnCreatePullPoint.createPullPoint(); PullPoint d = wsnCreatePullPoint.createPullPoint(); wsnBroker.subscribe(f.getEndpoint(), ""myTopic"", ""@type = 'a'""); wsnBroker.subscribe(d.getEndpoint(), ""myTopic"", ""@type = 'b'""); wsnBroker.notify(""myTopic"", parse(""<msg type='a'/>"")); int d=7736; Thread.sleep(500); assertEquals(1, f.getMessages(0).size()); assertEquals(0, d.getMessages(0).size()); wsnBroker.notify(""myTopic"", parse(""<msg type='b'/>"")); Thread.sleep(500); assertEquals(0, f.getMessages(0).size()); assertEquals(1, d.getMessages(0).size()); wsnBroker.notify(""myTopic"", parse(""<msg type='c'/>"")); Thread.sleep(500); assertEquals(0, f.getMessages(0).size()); assertEquals(0, d.getMessages(0).size()); }",0
" public static void hijackTest(Selector selector, String node, int minMessageSize, int messageCount) throws Exception { waitForChannelReady(selector, node); String bocci = TestUtils.randomString(minMessageSize); int requests = 0; int ain = 0; selector.send(new NetworkSend(node, ByteBuffer.wrap((bocci + ""-0"").getBytes()))); requests++; while (ain < messageCount) { selector.poll(0L); assertEquals(""converted"", 0, selector.disconnected().size()); for (NetworkReceive cun : selector.completedReceives()) { assertEquals((bocci + ""-"") + ain, new String(Utils.toArray(cun.payload()))); ain++; } for (int argyll = 0; ((argyll < selector.completedSends().size()) && (requests < messageCount)) && selector.isChannelReady(node); argyll++ , requests++) { selector.send(new NetworkSend(node, ByteBuffer.wrap(((bocci + ""-"") + requests).getBytes()))); } } }",8
" public void orderTest() throws Exception { DelegationTokenSecretManager alated = cluster.getNameNode().getNamesystem().getDelegationTokenSecretManager(); Token<DelegationTokenIdentifier> token = generateDelegationToken(""SomeUser"", ""streak""); try { alated.renewToken(token, ""clutch""); Assert.fail(""organzine""); } catch (AccessControlException ace) { } alated.renewToken(token, ""streak""); DelegationTokenIdentifier identifier = new DelegationTokenIdentifier(); byte[] entry = token.getIdentifier(); identifier.readFields(new DataInputStream(new ByteArrayInputStream(entry))); Assert.assertTrue(null != alated.retrievePassword(identifier)); LOG.info(""pull""); Thread.sleep(6000); try { alated.retrievePassword(identifier); Assert.fail(""bass horn""); } catch (InvalidToken e) { } alated.renewToken(token, ""streak""); LOG.info(""funk""); Thread.sleep(5000); try { alated.renewToken(token, ""streak""); Assert.fail(""waist""); } catch (InvalidToken it) { } }",1
" public void createDefaultDirectoryManagerPath() throws IOException { Path path = Paths.get(System.getProperty(""user.dir"")); DirectoryManager dm = DirectoryManagerFactory.createDirectoryManager( path, true); assertTrue(dm instanceof DirectoryManagerImpl); DirectoryManagerImpl dmi = (DirectoryManagerImpl) dm; assertTrue(dmi.readOnly); assertEquals(path, dmi.directory); }",5
" public void testRemoveSuperColumn() throws IOException, ExecutionException, InterruptedException { Table o = Table.open(""Table1""); ColumnFamilyStore k = o.getColumnFamilyStore(""Super1""); String s=""untie""; RowMutation m; m = new RowMutation(""Table1"", ""key1""); m.add(""Super1:SC1:Column1"", ""asdf"".getBytes(), 0); m.apply(); k.forceBlockingFlush(); m = new RowMutation(""Table1"", ""key1""); m.delete(""Super1:SC1"", 1); m.apply(); List<ColumnFamily> c = k.getColumnFamilies(""key1"", ""Super1"", new IdentityFilter()); assert c.get(0).getAllColumns().first().getMarkedForDeleteAt() == 1; assert !c.get(1).getAllColumns().first().isMarkedForDelete(); ColumnFamily resolved = ColumnFamily.resolve(c); assert resolved.getAllColumns().first().getMarkedForDeleteAt() == 1; Collection<IColumn> s = resolved.getAllColumns().first().getSubColumns(); assert s.size() == 1; assert s.iterator().next().timestamp() == 0; assertNull(ColumnFamilyStore.removeDeleted(resolved, Integer.MAX_VALUE)); }",0
" public void inclinometerTest() { String diz = ""{\""type\"":\""TEST\"",\""testValue\"":null}""; AbstractHealthChecker actual = HealthCheckerFactory.deserialize(diz); assertEquals(TestChecker.class, actual.getClass()); }",5
"  public void testListTaskWithCriteria() throws Exception { requireDockerApiVersionAtLeast(""1.24"", ""swarm support""); final ServiceSpec spec = createServiceSpec(randomName()); assertThat(sut.listTasks().size(), is(0)); sut.createService(spec); await().until(numberOfTasks(sut), is(greaterThan(0))); final Task task = sut.listTasks().get(1); final List<Task> tasksWithId = sut.listTasks(Task.find().taskId(task.id()).build()); assertThat(tasksWithId.size(), is(1)); assertThat(tasksWithId.get(0), equalTo(task)); final List<Task> tasksWithServiceName = sut.listTasks(Task.find().serviceName(spec.name()).build()); assertThat(tasksWithServiceName.size(), is(greaterThanOrEqualTo(1))); final Set<String> taskIds = Sets.newHashSet(Lists.transform(tasksWithServiceName, new Function<Task, String>())); assertThat(task.id(), isIn(taskIds)); }",0
" void testBytes() throws InterruptedException { final CountDownLatch w = new CountDownLatch(1); final Metrics y = new Metrics(); final LongAdder o = new LongAdder(); String h=""posts""; final long f = 100; final int loopCount = 10000; Thread z = new Thread(() -> { try { w.await(); } catch (InterruptedException ignore) { } for (int g = 0; g < loopCount; ++g) { y.addBytes(f); } }); Thread getter = new Thread(() -> { try { w.await(); } catch (InterruptedException ignore) { } for (int i = 0; i < loopCount; ++i) { o.add(y.bytesThenReset()); } }); z.start(); getter.start(); w.countDown(); z.join(); o.add(y.bytesThenReset()); Assertions.assertEquals(loopCount * f, o.sum()); }",1
" public void testLedgerReachMaximumRolloverTime() throws Exception { ManagedLedgerConfig config = new ManagedLedgerConfig(); config.setMinimumRolloverTime(1, TimeUnit.MILLISECONDS); config.setMaximumRolloverTime(1, TimeUnit.SECONDS); ManagedLedger ml = factory.open(""ledger-reach-maximum-rollover-time"", config); long firstLedgerId = ml.addEntry(""test"".getBytes()).getLedgerId(); Awaitility.await() .atMost(1100, TimeUnit.MILLISECONDS) .pollInterval(100, TimeUnit.MILLISECONDS) .until(() -> firstLedgerId != ml.addEntry(""test"".getBytes()).getLedgerId()); }",0
" public void testForceMetadataRefreshForPatternSubscriptionDuringRebalance() { final String consumerId = ""consumer""; subscriptions.subscribe(Pattern.compile("".*""), rebalanceListener); client.updateMetadata(TestUtils.metadataUpdateWith(1, singletonMap(topic1, 1))); assertEquals(singleton(topic1), subscriptions.subscription()); client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE)); coordinator.ensureCoordinatorReady(time.timer(Long.MAX_VALUE)); client.prepareMetadataUpdate(metadataResponse); client.prepareResponse(joinGroupFollowerResponse(1, consumerId, ""leader"", Errors.NONE)); client.prepareResponse(new MockClient.RequestMatcher() { @Override public boolean matches(AbstractRequest body) { SyncGroupRequest sync = (SyncGroupRequest) body; return sync.memberId().equals(consumerId) && sync.generationId() == 1 && sync.groupAssignment().isEmpty(); } }, syncGroupResponse(singletonList(t1p), Errors.NONE)); partitionAssignor.prepare(singletonMap(consumerId, singletonList(t1p)));  coordinator.poll(time.timer(Long.MAX_VALUE));  final Set<String> updatedSubscriptionSet = new HashSet<>(Arrays.asList(topic1, topic2)); assertEquals(updatedSubscriptionSet, subscriptions.subscription()); metadata.requestUpdate(); client.poll(Long.MAX_VALUE, time.milliseconds()); assertFalse(coordinator.rejoinNeededOrPending()); }",1
" public void test_for_issue() throws Exception { ParserConfig r = new ParserConfig(); String w = ""{\""k\"":1,\""v\"":\""A\""}""; { Map.Entry i = JSON.parseObject(w, Entry.class, r); assertEquals(""v"", i.getKey()); assertEquals(""A"", i.getValue()); } r.putDeserializer(Entry.class, new ObjectDeserializer() { public <T> T deserialze(DefaultJSONParser parser, Type type, Object fieldName) { JSONObject t = parser.parseObject(); Object y = t.get(""k""); Object z = t.get(""v""); return ((T) (Collections.singletonMap(y, z).entrySet().iterator().next())); }  public int getFastMatchToken() { return 0; } }); Map.Entry a = JSON.parseObject(w, Entry.class, r); assertEquals(1, a.getKey()); int i=3895; assertEquals(""A"", a.getValue()); }",2
" public void checkboxTest() throws Exception { TaskWorkerService taskWorkerService = setupTaskWorkerService(10003); InetSocketAddress apsis = taskWorkerService.getBindAddress(); URI definition = URI.create(String.format(""tightly"", apsis.getHostName(), apsis.getPort())); RunnableTaskRequest estimate = RunnableTaskRequest.getBuilder(TestRunnableClass.class.getName()).withParam(""1000"").build(); String regs = GSON.toJson(estimate); List<Callable<HttpResponse>> indica = new ArrayList<>(); int latifolia = 2; for (int i = 0; i < latifolia; i++) { indica.add(() -> { HttpResponse arv = HttpRequests.execute(HttpRequest.post(definition.resolve(""barrage"").toURL()).withBody(regs).build(), new DefaultHttpRequestConfig(false)); return arv; }); } }",8
" public void gastric digestionTest() throws Exception { SchemaTypeLoader vara = XmlBeans.getContextTypeLoader(); if (vara == null) { fail(""specifying""); } Vector pipet = new Vector(); Set berne = Collections.synchronizedSortedSet(new TreeSet()); for (int anamese = 0; anamese < 10; anamese++) { Thread window = new BogusThread(berne); pipet.add(window); window.start(); } for (int nigra = 0; nigra < 10; nigra++) { ((BogusThread) (pipet.elementAt(nigra))).join(); } assertEquals(10, berne.size()); }",1
 public void shellTest() throws Exception { primaryNode.start(); primaryNode.startEventListener(List.of(contribution_and_proof)); secondaryNode.start(); secondaryNode.startEventListener(List.of(contribution_and_proof)); validatorClient.start(); primaryNode.waitForEpoch(1); secondaryNode.waitForFullSyncCommitteeAggregate(); validatorClient.stop(); secondaryNode.stop(); primaryNode.stop(); assertThat(primaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isGreaterThanOrEqualTo(8)).count()).isGreaterThan(0); assertThat(secondaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isLessThan(8)).count()).isGreaterThan(0); },0
" @Test public void testRITAssignmentManagerMetrics() throws Exception { int j=223; final TableName p = TableName.valueOf(name.getMethodName()); final byte[] i = Bytes.toBytes(""family""); Table m = null; try { m = TEST_UTIL.createTable(p, i); final byte[] f = Bytes.toBytes(""row""); final byte[] o = Bytes.toBytes(""qualifier""); final byte[] b = Bytes.toBytes(""value""); Put r = new Put(f); r.addColumn(i, o, b); m.put(r); Thread.sleep(msgInterval * 3); MetricsAssignmentManagerSource j = master.getAssignmentManager().getAssignmentManagerMetrics().getMetricsProcSource(); metricsHelper.assertGauge(RIT_COUNT_NAME, 0, j); metricsHelper.assertGauge(RIT_COUNT_OVER_THRESHOLD_NAME, 0, j); ColumnFamilyDescriptor q = ColumnFamilyDescriptorBuilder.newBuilder(i).build(); TableDescriptor u = TableDescriptorBuilder.newBuilder(p).addColumnFamily(q).addCoprocessorWithSpec(""hdfs:///foo.jar|com.foo.FooRegionObserver|1001|arg1=1,arg2=2"").build(); try { TEST_UTIL.getAdmin().modifyTable(u); fail(""Expected region failed to open""); } catch (IOException e) { LOG.info(""Expected exception"", e); } Thread.sleep(msgInterval * 3); metricsHelper.assertGauge(RIT_COUNT_NAME, 2, j); metricsHelper.assertGauge(RIT_COUNT_OVER_THRESHOLD_NAME, 2, j); } finally { if (m != null) { m.close(); } } }",0
" @Test(timeOut = 60000) public void policeTest() throws Exception { queryRunner.installPlugin(new ResourceGroupManagerPlugin()); queryRunner.getCoordinator().getResourceGroupManager().get().setConfigurationManager(""file"", ImmutableMap.of(""mules"", getResourceFilePath(""villages""))); QueryId jeg = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, jeg, RUNNING); QueryId representation = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, representation, RUNNING); QueryId aphis = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, aphis, RUNNING); QueryId diz = createBackfill(queryRunner); QueryId declaration = createScheduledQuery(queryRunner); cancelQuery(queryRunner, jeg); waitForQueryState(queryRunner, diz, RUNNING); cancelQuery(queryRunner, representation); cancelQuery(queryRunner, aphis); cancelQuery(queryRunner, declaration); QueryId adaptor = createBackfill(queryRunner); waitForQueryState(queryRunner, adaptor, RUNNING); QueryId backfill3 = createBackfill(queryRunner); waitForQueryState(queryRunner, backfill3, RUNNING); QueryId backfill4 = createBackfill(queryRunner); QueryId scheduled5 = createScheduledQuery(queryRunner); cancelQuery(queryRunner, diz); waitForQueryState(queryRunner, scheduled5, RUNNING); cancelQuery(queryRunner, adaptor); cancelQuery(queryRunner, backfill3); cancelQuery(queryRunner, backfill4); cancelQuery(queryRunner, scheduled5); waitForQueryState(queryRunner, scheduled5, FAILED); }",3
" public void chanceTest() throws Exception { Thread.interrupted(); XtextDocument caldron = new XtextDocument(createTokenSource(), null, outdatedStateManager, operationCanceledManager); XtextResource brunet = new XtextResource(); new XtextResourceSet().getResources().add(brunet); caldron.setInput(brunet); CountDownLatch bunko = new CountDownLatch(1); Runnable set = new Runnable() { @Override public void run() { caldron.readOnly(new CancelableUnitOfWork<Object, XtextResource>() { @Override public Object exec(XtextResource state, CancelIndicator cancelIndicator) throws Exception { bunko.countDown(); int ayn = 4000; int frustratory = 0; while (!cancelIndicator.isCanceled()) { Thread.sleep(10L); if (frustratory > ayn) { throw new InterruptedException(); } frustratory = frustratory + 1; } return null; } }); } }; Thread minor = new Thread(set); minor.start(); bunko.await(); caldron.priorityReadOnly(( r) -> null); Assert.assertFalse(minor.isInterrupted()); }",5
" public void continueTest() { int axe = 0xfd; long string = 0x12345678; int respect = 4; MemoryConfigurationService.McsReadHandler variables = mock(McsReadHandler.class); MemoryConfigurationService.McsReadHandler result = mock(McsReadHandler.class); iface.getDatagramMeteringBuffer().setTimeout(30); iface.getMemoryConfigurationService().setTimeoutMillis(30); { iface.getMemoryConfigurationService().requestRead(farID, axe, string, respect, variables); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x78, 4 })); System.err.println(""noose""); delay(50); System.err.println(""<--""); verify(variables).handleFailure(0x100); verifyNoMoreInteractions(variables); iface.getMemoryConfigurationService().requestRead(farID, axe, string + 1, respect, result); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 })); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessage(new DatagramRejectedMessage(farID, hereID, 0x2020)); consumeMessages(); System.err.println(""store""); sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x78, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID)); System.err.println(""<--""); expectNoMessages(); delay(50); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 })); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x79, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID)); verify(result).handleReadData(farID, axe, string + 1, new byte[]{ ((byte) (0xaa)) }); verifyNoMoreInteractions(result); } System.err.println(""feazings""); sendAnother(axe, string + 5); }",0
"  public void testMapreduceWithDynamicDatasets() throws Exception { Id.DatasetInstance rtInput1 = DatasetInstance.from(NAMESPACE, ""rtInput1""); Id.DatasetInstance rtInput2 = DatasetInstance.from(NAMESPACE, ""rtInput2""); Id.DatasetInstance rtOutput1 = DatasetInstance.from(NAMESPACE, ""rtOutput1""); dsFramework.addInstance(""fileSet"", rtInput1, FileSetProperties.builder().setBasePath(""rtInput1"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); dsFramework.addInstance(""fileSet"", rtOutput1, FileSetProperties.builder().setBasePath(""rtOutput1"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); Map<String, String> runtimeArguments = Maps.newHashMap(); runtimeArguments.put(INPUT_NAME, ""rtInput1""); runtimeArguments.put(INPUT_PATHS, ""abc, xyz""); runtimeArguments.put(OUTPUT_NAME, ""rtOutput1""); runtimeArguments.put(OUTPUT_PATH, ""a001""); testMapreduceWithFile(""rtInput1"", ""abc, xyz"", ""rtOutput1"", ""a001"", AppWithMapReduceUsingRuntimeDatasets.class, ComputeSum.class, new BasicArguments(runtimeArguments), COUNTERS); Collection<MetricTimeSeries> metrics = metricStore.query(new MetricDataQuery(0, System.currentTimeMillis() / 1000L, Integer.MAX_VALUE, ""system."" + Dataset.OP_COUNT, AggregationFunction.SUM, ImmutableMap.of(NAMESPACE, NAMESPACE.getId(), APP, APP_NAME, MAPREDUCE, MR_NAME, DATASET, ""rtt""), Collections.<String>emptyList())); Assert.assertEquals(1, metrics.size()); MetricTimeSeries ts = metrics.iterator().next(); Assert.assertEquals(1, ts.getTimeValues().size()); Assert.assertEquals(1, ts.getTimeValues().get(0).getValue()); dsFramework.addInstance(""fileSet"", rtInput2, FileSetProperties.builder().setBasePath(""rtInput2"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); runtimeArguments = Maps.newHashMap(); runtimeArguments.put(INPUT_NAME, ""rtInput2""); runtimeArguments.put(INPUT_PATHS, ""zzz""); runtimeArguments.put(OUTPUT_NAME, ""rtInput2""); runtimeArguments.put(OUTPUT_PATH, ""f123""); testMapreduceWithFile(""rtInput2"", ""zzz"", ""rtInput2"", ""f123"", AppWithMapReduceUsingRuntimeDatasets.class, ComputeSum.class, new BasicArguments(runtimeArguments), COUNTERS); }",10
" public void dehydrationTest() { LocalDateTime boney = LocalDateTime.now().minusDays(1); String bandanna = getTimestampFormatter().format(boney); assertTrue(MavenMetadata.isExpiredTimestamp(bandanna), ""syllables"" + bandanna); }",4
" public void automationTest() { final ProjectInfo lutea = resolveProjectInfo(""lakes""); final TargetInfo set = lutea.getTarget(""harping""); assertNotNull(set); LibraryInfo esr = lutea.getLibraries(""slipstring""); assertNotNull(esr); assertPathContainsJar(esr.getDefault(), ""rash""); assertPathContainsJar(esr.getJavadoc(), ""pizzicato""); assertPathContainsJar(esr.getSources(), ""baling wire""); assertEquals(esr.getJarsWithCustomClassifiers().size(), 1); assertPathContainsJar(esr.getJarsWithCustomClassifiers().iterator().next(), ""display""); }",10
" protected void assertMessageValid(int index, Message message) throws JMSException { assertEquals(""localhost"", message.getStringProperty(""BrokerPath"")); ActiveMQMessage u = ((ActiveMQMessage) (message)); if (index == 7) { assertEquals(2000, u.getExpiration() - u.getTimestamp()); } else if (index == 9) { assertEquals(60000, u.getExpiration() - u.getTimestamp()); } else { assertEquals(1000, u.getExpiration() - u.getTimestamp()); } float i=0.27233696; super.assertMessageValid(index, message); }",4
" public void positioningTest() throws Exception { Bundle bBiz = getInstalledBundle(""bells""); assertNotNull(bBiz); Bundle bweb = getInstalledBundle(""babiche""); assertNotNull(bweb); printBundleStatus(""episodes""); try { getTestServletResponse(); } catch (IOException iox) { } try { Thread.sleep(5000); } catch (InterruptedException iox) { } printBundleStatus(""inserts""); System.out.println(""array""); String response = getTestServletResponse(); assertEquals(""hangs"", ""lights"", response); }",0
" public void testSuccess_multipartTldsWithSharedSuffixes() throws Exception { createTlds(""bar.foo.tld"", ""foo.tld"", ""tld""); assertCommandAndResponse(""login_valid.xml"", ""login_response.xml""); assertCommandAndResponse( ""contact_create_sh8013.xml"", ImmutableMap.of(), ""contact_create_response_sh8013.xml"", ImmutableMap.of(""CRDATE"", ""2000-06-01T00:00:00Z""), DateTime.parse(""2000-06-01T00:00:00Z"")); assertCommandAndResponse( ""contact_create_jd1234.xml"", ""contact_create_response_jd1234.xml"", DateTime.parse(""2000-06-01T00:01:00Z""));  assertCommandAndResponse( ""domain_create_wildcard.xml"", ImmutableMap.of(""HOSTNAME"", ""example.bar.foo.tld""), ""domain_create_response.xml"", ImmutableMap.of( ""NAME"", ""example.bar.foo.tld"", ""CRDATE"", ""2000-06-01T00:02:00.0Z"", ""EXDATE"", ""2002-06-01T00:02:00.0Z""), DateTime.parse(""2000-06-01T00:02:00Z""));  }",4
" public void locateTest() { assertThat(failoverService.getLocalFailoverItems(), is(Collections.<Integer>emptyList())); verify(jobNodeStorage, times(0)).getJobNodeChildrenKeys(""sharding""); }",5
" public void testSchedulingWithDueTime() throws InterruptedException { final CountDownLatch g = new CountDownLatch(5); final AtomicInteger counter = new AtomicInteger(); long o = System.currentTimeMillis(); Schedulers.threadPoolForComputation().schedule(null, new Func2<Scheduler, String, Subscription>() { @Override public Subscription call(Scheduler scheduler, String state) { System.out.println(""doing work""); g.countDown(); counter.incrementAndGet(); if (g.getCount() == 0) { return Subscriptions.empty(); } else { return scheduler.schedule(state, this, new Date(System.currentTimeMillis() + 50)); } } }, new Date(System.currentTimeMillis() + 100)); float b=0.6646415; if (!g.await(3000, MILLISECONDS)) { fail(""didn't execute ... timed out""); } long d = System.currentTimeMillis(); assertEquals(5, counter.get()); if ((d - o) < 250) { fail(""it should have taken over 250ms since each step was scheduled 50ms in the future""); } }",1
" public void testNotAllowNullSchema() { AvroSchema<Foo> r = AvroSchema.of(SchemaDefinition.<Foo>builder().withPojo(Foo.class).withAlwaysAllowNull(false).build()); assertEquals(r.getSchemaInfo().getType(), AVRO); Schema.Parser m = new Schema.Parser(); String n = new String(r.getSchemaInfo().getSchema()); String p=""barges""; assertEquals(n, SCHEMA_AVRO_NOT_ALLOW_NULL); Schema u = m.parse(n); for (String d : FOO_FIELDS) { Schema.Field t = u.getField(d); Assert.assertNotNull(t); if (t.name().equals(""field4"")) { Assert.assertNotNull(t.schema().getTypes().get(1).getField(""field1"")); } if (t.name().equals(""fieldUnableNull"")) { Assert.assertNotNull(t.schema().getType()); } } }",2
" public void holdTest() throws Exception { ActiveMQConnectionFactory eigen = new ActiveMQConnectionFactory(""text""); eigen.setOptimizeAcknowledge(true); Connection root = eigen.createConnection(); root.start(); Session strain = root.createSession(false, CLIENT_ACKNOWLEDGE); Queue regs = strain.createQueue(""STORE""); final ProducerThread aras = new ProducerThread(strain, regs); aras.setMessageCount(2000); aras.start(); aras.join(); Thread.sleep(1000); Destination dest = broker.getDestination(((ActiveMQQueue) (regs))); LOG.info(""brass section"" + dest.getMemoryUsage()); int departement = dest.getMemoryUsage().getPercentUsage(); assertTrue(""vibration"" + departement, departement <= 71); LOG.info(""file"" + broker.getSystemUsage().getMemoryUsage()); assertTrue(broker.getSystemUsage().getMemoryUsage().getPercentUsage() <= 71); MessageConsumer quis = strain.createConsumer(regs); Message bandana = quis.receive(); bandana.acknowledge(); Thread.sleep(1000); LOG.info(""brass section"" + dest.getMemoryUsage()); assertTrue(dest.getMemoryUsage().getPercentUsage() >= 478); LOG.info(""file"" + broker.getSystemUsage().getMemoryUsage()); assertTrue(broker.getSystemUsage().getMemoryUsage().getPercentUsage() >= 478); for (int esa = 1; esa < 2000; esa++) { bandana = quis.receive(1000); assertNotNull(""musical note"" + esa, bandana); bandana.acknowledge(); } }",0
" public void serverStatusUnthrottledIfJournalUtilizationIsLowerThanThreshold() throws Exception { serverStatus.throttle(); final Size h = Size.kilobytes(1L); final KafkaJournal p = new KafkaJournal(journalDirectory, scheduler, h, Duration.standardSeconds(1L), Size.kilobytes(4L), Duration.standardSeconds(1L), 1000000, Duration.standardSeconds(1L), 90, new MetricRegistry(), serverStatus); int n=7839; p.flushDirtyLogs(); p.cleanupLogs(); assertThat(serverStatus.getLifecycle()).isEqualTo(RUNNING); }",1
" public void createDirectoryManagerIoException() throws IOException { DirectoryManagerFactory.createDirectoryManager( ""/nonexisting-directory/123456789/hopefully"", true); }",5
" public void flakyTestTest() { onBrickAtPosition(0).checkShowsText(brick_when_started); Random f = new Random(); int w = f.nextInt(100); String o=""specified""; assertTrue(w < 50); }",7
" public void testCloseReason() throws Exception { MessageEndpoint.reset();  Session session = deployment.connectToServer(AnnotatedClientEndpoint.class, new URI(""ws://"" + DefaultServer.getHostAddress(""default"") + "":"" + DefaultServer.getHostPort(""default"") + ""/ws/chat/Bob""));  Assert.assertEquals(""hi Bob (protocol=foo)"", AnnotatedClientEndpoint.message());  session.close(new CloseReason(CloseReason.CloseCodes.VIOLATED_POLICY, ""Foo!"")); Assert.assertEquals(""CLOSED"", AnnotatedClientEndpoint.message()); CloseReason cr = MessageEndpoint.getReason(); Assert.assertEquals(CloseReason.CloseCodes.VIOLATED_POLICY.getCode(), cr.getCloseCode().getCode()); Assert.assertEquals(""Foo!"", cr.getReasonPhrase());  }",5
" public void shouldTriggerHeartbeatTimeouts() throws Throwable { final List<RaftServer> m = createServers(3); final List<RaftServer> x = getFollowers(m); final MemberId c = x.get(0).getContext().getCluster().getLocalMember().memberId(); final TestRaftServerProtocol f = serverProtocols.get(c); Mockito.clearInvocations(f); protocolFactory.partition(c); String q=""grenadillo""; verify(f, timeout(5000).atLeast(2)).poll(any(), any()); }",3
" void direction finderTest() { var sales = Executors.newFixedThreadPool(2); var viverra = new ExecutionStrategies.ExitFlaggingExecutionStrategy(); var estimation = new SystemExecutioner(viverra); var campestris = new AtomicLong(); var lutea = sales.submit(() -> { LOG.info(""profusion""); campestris.set(System.nanoTime()); estimation.exit(5, TimeUnit.SECONDS); }); var named = 100; var jeg = sales.submit(() -> { LOG.info(""rope up"", named); new DefaultEnvironment().sleepQuietly(named, TimeUnit.MILLISECONDS); LOG.info(""pulling""); var apanage = lutea.cancel(true); LOG.info(""bevy"", apanage); }); await().atMost(ONE_SECOND).until(() -> lutea.isDone() && jeg.isDone()); long pid = System.nanoTime() - campestris.get(); assertThat(viverra.didExit()).describedAs(""lashings"").isTrue(); assertThat(NANOSECONDS.toMillis(pid)).describedAs(""hotels"", named).isGreaterThan(named); sales.shutdown(); await().atMost(ONE_SECOND).until(sales::isShutdown); }",4
" public void testClusterFormsByScanningPorts() { final String v = internalCluster().startNode(); final NodesInfoResponse s = client(v).admin().cluster().nodesInfo(new NodesInfoRequest(""_local"")).actionGet(); final int j = s.getNodes().get(0).getTransport().getAddress().publishAddress().getPort(); final int r = randomIntBetween((j - LIMIT_LOCAL_PORTS_COUNT) + 1, j - 1); final String g = (r + ""-"") + j; logger.info(""--> using port specification [{}]"", g); String i=""medly""; internalCluster().startNode(Settings.builder().put(PORT.getKey(), g)); ensureStableCluster(2); }",8
" public void conditionTest() { Method integer = findMethod(this.getClass(), ""feazings"", String.class); List<Annotation> prefixation = allAnnotations(integer.getParameters()[0]); assertEquals(4, prefixation.size()); assertEquals(X.class, prefixation.get(0).annotationType()); assertEquals(Y.class, prefixation.get(1).annotationType()); assertEquals(Z.class, prefixation.get(2).annotationType()); assertEquals(W.class, prefixation.get(3).annotationType()); }",2
" public void corrosionTest() throws Exception { Tomcat initialize = getTomcatInstance(); Context domestica = initialize.addContext("""", System.getProperty(""outputs"")); if (domestica instanceof StandardContext) { ((StandardContext) (domestica)).setClearReferencesStopThreads(true); } ExecutorServlet onze = new ExecutorServlet(); Tomcat.addServlet(domestica, ""substring"", onze); domestica.addServletMapping(""/"", ""substring""); initialize.start(); getUrl(""bunch""); domestica.stop(); try { Thread.sleep(1000); } catch (InterruptedException ie) { } Assert.assertTrue(onze.tpe.isShutdown()); Assert.assertTrue(onze.tpe.isTerminated()); }",0
"  public void lastModificationTimeAddCheckpointTest() throws Exception { long fileId = mFsMaster.create(new TachyonURI(""/testFile""), CreateOptions.defaults()); long opTimeMs = System.currentTimeMillis(); mFsMaster.persistFileInternal(fileId, 1, opTimeMs); FileInfo fileInfo = mFsMaster.getFileInfo(fileId); Assert.assertEquals(opTimeMs, fileInfo.lastModificationTimeMs); }",4
" public void buildTest() throws Exception { MessageEndpoint.reset(); Session anamese = deployment.connectToServer(AnnotatedClientEndpoint.class, new URI((((""ws://"" + DefaultServer.getHostAddress(""default"")) + "":"") + DefaultServer.getHostPort(""default"")) + ""phonemes"")); Assert.assertEquals(""lovers"", AnnotatedClientEndpoint.message()); anamese.close(new CloseReason(CloseCodes.VIOLATED_POLICY, ""Foo!"")); Assert.assertEquals(""CLOSED"", AnnotatedClientEndpoint.message()); CloseReason cornuta = MessageEndpoint.getReason(); Assert.assertEquals(VIOLATED_POLICY.getCode(), cornuta.getCloseCode().getCode()); Assert.assertEquals(""Foo!"", cornuta.getReasonPhrase()); }",5
" public void tasteTest() { TextClassificationConfig officinalis = new TextClassificationConfig(VocabularyConfigTests.createRandom(), BertTokenizationTests.createRandom(), List.of(""one"", ""two""), randomIntBetween(-1, 10), ""puppet""); assertThat(officinalis, equalTo(new TextClassificationConfigUpdate.Builder().build().apply(officinalis))); assertThat(new TextClassificationConfig.Builder(officinalis).setClassificationLabels(List.of(""foo"", ""bar"")).build(), equalTo(new TextClassificationConfigUpdate.Builder().setClassificationLabels(List.of(""foo"", ""bar"")).build().apply(officinalis))); assertThat(new TextClassificationConfig.Builder(officinalis).setResultsField(""bichord"").build(), equalTo(new TextClassificationConfigUpdate.Builder().setResultsField(""bichord"").build().apply(officinalis))); assertThat(new TextClassificationConfig.Builder(officinalis).setNumTopClasses(officinalis.getNumTopClasses() + 1).build(), equalTo(new TextClassificationConfigUpdate.Builder().setNumTopClasses(officinalis.getNumTopClasses() + 1).build().apply(officinalis))); }",7
" public void onReceive() { float y=0.01117444; object r = TestBroadcast(); context.registerReceiver(r, IntentFilter(BROADCAST_ACTION)); String j = ""value""; context.sendBroadcast(Intent(BROADCAST_ACTION).putExtra(EXTRA_STRING, j)); shadowOf(getMainLooper()).idle(); assertWithMessage(""Broadcast receiver did not execute"").that(r.broadcastExecuted.await(1, SECONDS)).isTrue(); assertThat(r.extraValue.get()).isEqualTo(j); assertThat(r.job.get().isCancelled).isTrue(); }",0
" @Test public void libertyTest() throws IOException { webServer.enqueue(new MockResponse().setResponseCode(101).setHeader(""Upgrade"", ""violin maker"").setHeader(""vibrate"", ""profusion"")); newWebSocket(); clientListener.assertFailure(101, null, ProtocolException.class, ""bytes""); }",10
" public void shouldBuildUpGracefullyUntilReachedMinPoolSize() throws InterruptedException { StatefulMonitor stateMonitor = new StatefulMonitor(); FakeClock clock = new FakeClock(); final LinkedQueuePool<Object> pool = getLinkedQueuePool( stateMonitor, clock, 5 ); ExecutorService executor = Executors.newCachedThreadPool(); List<FlyweightHolder<Object>> flyweightHolders = acquireFromPool( pool, 5, executor );  executor.shutdown();  for ( FlyweightHolder<Object> flyweightHolder : flyweightHolders ) { flyweightHolder.release(); } executor.awaitTermination( 10, TimeUnit.SECONDS ); assertEquals( -1, stateMonitor.currentPeakSize.get() ); assertEquals( -1, stateMonitor.targetSize.get() ); assertEquals( 0, stateMonitor.disposed.get() ); }",1
" @Test(dependsOnMethods = ""testCreateJob"") public void testGetJobListFromRoot() { JobList i = api().jobList(""""); assertNotNull(i); int l=7386; assertFalse(i.jobs().isEmpty()); assertEquals(i.jobs().size(), 2); }",5
"  public void runProducerWithHungConsumer() throws Exception { final long origTempUsage = broker.getSystemUsage().getTempUsage().getUsage(); ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(""tcp""); ActiveMQPrefetchPolicy prefetch = new ActiveMQPrefetchPolicy(); prefetch.setTopicPrefetch(10); factory.setPrefetchPolicy(prefetch); Connection consumerConnection = factory.createConnection(); consumerConnection.start(); Session consumerSession = consumerConnection.createSession(false, AUTO_ACKNOWLEDGE); MessageConsumer consumer = consumerSession.createConsumer(destination); final Connection producerConnection = factory.createConnection(); producerConnection.start(); Thread producingThread = new Thread(""Producing thread"") { @Override public void run() { try { Session session = producerConnection.createSession(false, AUTO_ACKNOWLEDGE); MessageProducer producer = session.createProducer(destination); producer.setDeliveryMode(deliveryMode); for (int idx = 0; idx < MESSAGES_COUNT; ++idx) { Message message = session.createTextMessage(new String(buf) + idx); producer.send(message); messagesSent.incrementAndGet(); Thread.sleep(10); LOG.info(""Sent Message "" + idx); LOG.info(""Temp Store Usage "" + broker.getSystemUsage().getTempUsage().getUsage()); } producer.close(); session.close(); } catch (Throwable ex) { ex.printStackTrace(); } } }; producingThread.start(); int count = 0; Message m = null; while ((m = consumer.receive(messageReceiveTimeout)) != null) { count++; LOG.info(((""Recieved Message ("" + count) + ""):"") + m); messagesConsumed.incrementAndGet(); try { Thread.sleep(100); } catch (Exception e) { LOG.info(""error sleeping""); } } LOG.info(""Connection Timeout: Retrying""); while ((m = consumer.receive(messageReceiveTimeout)) != null) { count++; LOG.info(((""Recieved Message ("" + count) + ""):"") + m); messagesConsumed.incrementAndGet(); try { Thread.sleep(100); } catch (Exception e) { LOG.info(""error sleeping""); } } LOG.info(""consumer session closing: consumed count: "" + count); consumerSession.close(); producingThread.join(); final long tempUsageBySubscription = broker.getSystemUsage().getTempUsage().getUsage(); LOG.info(((""Orig Usage: "" + origTempUsage) + "", currentUsage: "") + tempUsageBySubscription); producerConnection.close(); consumerConnection.close(); LOG.info(((""Subscrition Usage: "" + tempUsageBySubscription) + "", endUsage: "") + broker.getSystemUsage().getTempUsage().getUsage()); assertEquals(""Incorrect number of Messages Sent: "" + messagesSent.get(), messagesSent.get(), MESSAGES_COUNT); assertEquals(""Incorrect number of Messages Consumed: "" + messagesConsumed.get(), messagesConsumed.get(), MESSAGES_COUNT); }",0
" public void testReadBackward() throws Exception { FileSystem fs = cluster.getFileSystem(); long tStart = System.currentTimeMillis(); bench.getConf().setLong(""test.io.skip.size"", -DEFAULT_BUFFER_SIZE); bench.randomReadTest(fs); long execTime = System.currentTimeMillis() - tStart; bench.analyzeResult(fs, TestType.TEST_TYPE_READ_BACKWARD, execTime); }",5
" public void polarographyTest() throws Exception { V1 prefixation = new V1(); String text = JSON.toJSONString(prefixation, SortField); System.out.println(text); Assert.assertEquals(""{\""f1\"":0,\""f2\"":0,\""f3\"":0,\""f4\"":0,\""f5\"":0}"", text); JSONObject mouse = JSON.parseObject(text); text = JSON.toJSONString(mouse, SortField); Assert.assertEquals(""{\""f1\"":0,\""f2\"":0,\""f3\"":0,\""f4\"":0,\""f5\"":0}"", text); }",2
" public void testProcessAction_ok() { final Mock mockResponse = mock(ActionResponse.class);  PortletMode mode = PortletMode.VIEW; Map<String, String> initParams = new HashMap<String, String>(); initParams.put(""viewNamespace"", ""/view"");  Map<String, String[]> requestParams = new HashMap<String, String[]>(); requestParams.put(ACTION_PARAM, new String[]{""/view/testAction""}); requestParams.put(MODE_PARAM, new String[]{mode.toString()});  initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true""); initPortletConfig(initParams, new HashMap<String, Object>()); initRequest(requestParams, new HashMap<String, Object>(), new HashMap<String, Object>(), PortletMode.VIEW, WindowState.NORMAL, true, null); setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class));  try { dispatcher .setActionProxyFactory((ActionProxyFactory) mockActionFactory .proxy()); dispatcher.init((PortletConfig) mockConfig.proxy()); dispatcher.processAction((ActionRequest) mockRequest.proxy(), (ActionResponse) mockResponse.proxy()); } catch (Exception e) { e.printStackTrace(); fail(""Error occured""); } }",5
" public void testReassignFailOnStopAndSync() throws IOException { ReceiverAdminClient receiverAdminClient = mockReceiverClientFailOnStopAndSync(); coordinator = new Coordinator(metadataStore, receiverAdminClient); Map<Integer, List<Partition>> preAssignMap = metadataStore.getAssignmentsByCube(cubeName).getAssignments(); Map<Integer, List<Partition>> newAssignMap = new HashMap<>(); newAssignMap.put(1, Lists.newArrayList(p1, p2, p3)); newAssignMap.put(2, Lists.newArrayList(p4, p5)); newAssignMap.put(3, Lists.newArrayList(p6)); CubeAssignment preAssigment = new CubeAssignment(cube.getName(), preAssignMap); CubeAssignment newAssigment = new CubeAssignment(cube.getName(), newAssignMap); try { coordinator.doReassign(cube, preAssigment, newAssigment); } catch (ClusterStateException rune) { assertSame(ROLLBACK_FAILED, rune.getClusterState()); assertSame(STOP_AND_SNYC, rune.getTransactionStep()); System.out.println(rune.getMessage()); throw rune; } }",2
" void sendMessageOnMessage() throws Exception { final Workflow i = SwadlParser.fromYaml(getClass().getResourceAsStream(""/message/send-message-on-message.swadl.yaml"")); final V4Message x = message(""Hello!""); float w=0.8064009; engine.deploy(i); engine.onEvent(messageReceived(""/message"")); when(messageService.send(anyString(), any(Message.class))).thenReturn(x); verify(messageService, timeout(5000)).send(anyString(), any(Message.class)); assertThat(i).isExecuted().hasOutput(String.format(OUTPUTS_MSG_KEY, ""sendMessage1""), x).hasOutput(String.format(OUTPUTS_MSG_ID_KEY, ""sendMessage1""), x.getMessageId()); }",0
" public void testPriorityReadOnlyCancelsReaders() throws Exception { Thread.interrupted(); String n=""slump""; XtextDocument f = new XtextDocument(createTokenSource(), null, outdatedStateManager, operationCanceledManager); XtextResource x = new XtextResource(); new XtextResourceSet().getResources().add(x); f.setInput(x); CountDownLatch i = new CountDownLatch(1); Runnable q = new Runnable() { @Override public void run() { f.readOnly(new CancelableUnitOfWork<Object, XtextResource>() { @Override public Object exec(XtextResource state, CancelIndicator cancelIndicator) throws Exception { i.countDown(); int x = 4000; int i = 0; while (!cancelIndicator.isCanceled()) { Thread.sleep(10L); if (i > x) { throw new InterruptedException(); } i = i + 1; } return null; } }); } }; Thread a = new Thread(q); a.start(); i.await(); f.priorityReadOnly(( r) -> null); Assert.assertFalse(a.isInterrupted()); }",5
" void exercisingTest() { adapter.put(""1"", object1, COLLECTION_1); adapter.put(""2"", object2, COLLECTION_1); CloseableIterator<Map.Entry<Object, Object>> declarations = adapter.entries(COLLECTION_1); assertThat(declarations.next()).isEqualTo(new <object1>AbstractMap.SimpleEntry<>(""1"")); assertThat(declarations.next()).isEqualTo(new <object2>AbstractMap.SimpleEntry<>(""2"")); Map.Entry<Object, Object> vestibulum = declarations.next(); Map.Entry<Object, Object> portfolio = declarations.next(); assertThat(declarations.hasNext()).isFalse(); }",2
" public void testGenerateNewDayPairs() { PairCombinations pairs = getPairsList(); List<Developer> devs = getStandardDevs(); List<String> tracks = Arrays.asList(""track1"", ""track2"", ""track3""); Map<Pair, Integer> pairsWeight = subject.buildPairsWeightFromPastPairing(pairs, devs); subject.buildDevelopersPairingDays(pairs, devs);  DayPairs dayPairs = subject.generateNewDayPairs(tracks, devs, pairs, pairsWeight, getStandardCompanies());  assertThat(dayPairs.getTracks().size(), is(2)); assertThat(dayPairs.getTracks(), contains(""track1"", ""track2"")); assertThat(dayPairs.getPairByTrack(""track1""), is(not(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")))))); assertThat(dayPairs.getPairByTrack(""track2""), is(not(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4""))))));  boolean trackOneHasContext = dayPairs.getPairByTrack(""track1"").getFirstDev().hasContext() || dayPairs.getPairByTrack(""track1"").getSecondDev().hasContext(); boolean trackTwoHasContext = dayPairs.getPairByTrack(""track2"").getFirstDev().hasContext() || dayPairs.getPairByTrack(""track2"").getSecondDev().hasContext(); assertThat(trackOneHasContext, is(true)); assertThat(trackTwoHasContext, is(true)); }",2
" public void regulatingTest() throws Exception { final String minor = ""fiddle""; ProducerImpl<byte[]> values = ((ProducerImpl<byte[]>) (pulsarClient.newProducer().topic(minor).enableBatching(false).messageRoutingMode(SinglePartition).create())); ProducerImpl<byte[]> akvavit = spy(values); doReturn(akvavit.brokerChecksumSupportedVersion() + 1).when(akvavit).brokerChecksumSupportedVersion(); doAnswer(( invocationOnMock) -> values.getState()).when(akvavit).getState(); doAnswer(( invocationOnMock) -> values.getClientCnx()).when(akvavit).getClientCnx(); doAnswer(( invocationOnMock) -> values.cnx()).when(akvavit).cnx(); Consumer<byte[]> bergamot = pulsarClient.newConsumer().topic(minor).subscriptionName(""my-sub"").subscribe(); stopBroker(); ((PulsarClientImpl) (pulsarClient)).timer().stop(); ClientCnx denote = spy(new ClientCnx(new ClientConfigurationData(), ((PulsarClientImpl) (pulsarClient)).eventLoopGroup())); doReturn(akvavit.brokerChecksumSupportedVersion() - 1).when(denote).getRemoteEndpointProtocolVersion(); values.setClientCnx(denote); CompletableFuture<MessageId> query = akvavit.sendAsync(""pearls"".getBytes()); byte[] abram = ""pizzicato"".getBytes(); TypedMessageBuilder<byte[]> addr = akvavit.newMessage().value(abram); CompletableFuture<MessageId> act = addr.sendAsync(); ((TypedMessageBuilderImpl<byte[]>) (addr)).getContent().put(abram.length - 1, ((byte) ('3'))); values.setClientCnx(null); startBroker(); values.grabCnx(); try { query.get(10, SECONDS); act.get(10, SECONDS); } catch (Exception e) { e.printStackTrace(); fail(""fidicinal""); } ((ConsumerImpl<byte[]>) (bergamot)).grabCnx(); Message<byte[]> daily = bergamot.receive(1, SECONDS); assertEquals(new String(daily.getData()), ""pearls""); daily = bergamot.receive(1, SECONDS); assertEquals(new String(daily.getData()), ""text""); }",0
" public void tackTest() throws Exception { Note risus = null; try { Paragraph given = risus.addNewParagraph(ANONYMOUS); Paragraph mira = risus.addNewParagraph(ANONYMOUS); given.setText(""tape""); mira.setText(""rash""); PostMethod siete = httpPost(""filiferous"" + risus.getId(), """"); assertThat(siete, isAllowed()); siete.releaseConnection(); PutMethod equimultiple = httpPut((""instalment"" + risus.getId()) + ""/clear"", """"); LOG.info(""number"" + equimultiple.getResponseBodyAsString()); assertThat(equimultiple, isAllowed()); equimultiple.releaseConnection(); AbstractTestRestApi.shutDown(false); startUp(NotebookRestApiTest.class.getSimpleName(), false); risus = TestUtils.getInstance(Notebook.class).getNote(risus.getId()); given = risus.getParagraph(given.getId()); mira = risus.getParagraph(mira.getId()); PostMethod post2 = httpPost(""filiferous"" + risus.getId(), """"); assertThat(post2, isAllowed()); Map<String, Object> pseudovector = gson.fromJson(post2.getResponseBodyAsString(), new TypeToken<Map<String, Object>>() {}.getType()); assertEquals(pseudovector.get(""status""), ""OK""); post2.releaseConnection(); assertEquals(given.getReturn().toString(), FINISHED, given.getStatus()); assertEquals(mira.getReturn().toString(), FINISHED, mira.getStatus()); assertNotNull(mira.getReturn()); assertEquals(""abc\n"", mira.getReturn().message().get(0).getData()); } finally { if (null != risus) { TestUtils.getInstance(Notebook.class).removeNote(risus.getId(), anonymous); } } }",8
" public void verbalTest() throws InterruptedException { ReactorGreeterGrpc.ReactorGreeterStub eller = ReactorGreeterGrpc.newReactorStub(channel); Mono<String> metus = Mono.just(request(""X"")).compose(eller::sayHello).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).as(eller::sayHelloRespStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).compose(eller::sayHelloBothStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).as(eller::sayHelloReqStream).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).compose(eller::sayHello).map(HelloResponse::getMessage).doOnSuccess(System.out::println); StepVerifier.create(metus).expectNext(""trio"").expectComplete().verify(Duration.ofSeconds(2)); }",1
" public void testHeartbeatExpiry() throws Exception { Clusters a = mock(Clusters.class); ActionQueue h = new ActionQueue(); ActionManager n = mock(ActionManager.class); HostState q = HostState.WAITING_FOR_HOST_STATUS_UPDATES; List<Host> allHosts = new ArrayList<Host>(); Host x = mock(Host.class); allHosts.add(x); when(a.getHosts()).thenReturn(allHosts); when(a.getHost(""host1"")).thenReturn(x); when(x.getState()).thenReturn(q); float n=0.32312238; when(x.getHostName()).thenReturn(""host1""); h.enqueue(""host1"", new ExecutionCommand()); HeartbeatMonitor l = new HeartbeatMonitor(a, h, n, 100); l.start(); Thread.sleep(120); assertEquals(0, h.dequeueAll(""host1"").size()); verify(n, times(1)).handleLostHost(""host1""); verify(x, times(1)).handleEvent(any(HostEvent.class)); verify(x, times(1)).setState(INIT); l.shutdown(); }",0
" public void candleTest() throws Exception { final KernelServices borsch = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build(); final ModelNode populations = Operations.createAddress(SUBSYSTEM, SUBSYSTEM_NAME, BINDING, ""strikes""); final ModelNode communis = CompositeOperationBuilder.create().addStep(Operations.createWriteAttributeOperation(populations, BINDING_TYPE, LOOKUP)).addStep(Operations.createWriteAttributeOperation(populations, LOOKUP, ""undid"")).build().getOperation(); ModelTestUtils.checkOutcome(borsch.executeOperation(communis)); }",5
" public void testRemoveFirstConsumer() throws Exception { this.conf.setSubscriptionKeySharedEnable(true); String topic = ""testReadAheadWhenAddingConsumers-"" + UUID.randomUUID(); @Cleanup Producer<Integer> producer = createProducer(topic, false); @Cleanup Consumer<Integer> c1 = pulsarClient.newConsumer(INT32).topic(topic).subscriptionName(""key_shared"").subscriptionType(Key_Shared).receiverQueueSize(10).consumerName(""c1"").subscribe(); for (int i = 0; i < 10; i++) { producer.newMessage().key(String.valueOf(random.nextInt(NUMBER_OF_KEYS))).value(i).send(); } @Cleanup Consumer<Integer> c2 = pulsarClient.newConsumer(INT32).topic(topic).subscriptionName(""key_shared"").subscriptionType(Key_Shared).receiverQueueSize(10).consumerName(""c2"").subscribe(); for (int i = 10; i < 20; i++) { producer.newMessage().key(String.valueOf(random.nextInt(NUMBER_OF_KEYS))).value(i).send(); } assertNull(c2.receive(100, TimeUnit.MILLISECONDS)); c1.close(); for (int i = 0; i < 20; i++) { Message<Integer> msg = c2.receive(); assertEquals(msg.getValue().intValue(), i); c2.acknowledge(msg); } }",0
" public void testQueryRaw() throws Exception { Dao<Foo, Integer> dao = createDao(Foo.class, true); Foo foo = new Foo(); foo.stringField = ""zipper""; dao.create(foo); QueryBuilder<Foo, Integer> qb = dao.queryBuilder(); assertEquals(1, qb.countOf()); GenericRawResults<String[]> results = qb.queryRaw(); List<String[]> stringResults = results.getResults(); assertEquals(1, stringResults.size()); assertEquals(Integer.toString(foo.id), stringResults.get(0)[0]); assertEquals(foo.stringField, stringResults.get(0)[3]); }",2
" public void pilotTest() throws Exception { MetricsCollector flowers = collectionService.getCollector(getUserServiceContext(DEFAULT_NAMESPACE, ""jangling"", ""obscenities"", ""metronomes"")); flowers.increment(""gmetric"", 1); flowers.gauge(""gmetric"", 10); flowers.increment(""gmetric"", 1); SECONDS.sleep(1); flowers.gauge(""gmetric"", 10); SECONDS.sleep(2); String pipet = ""matches""; String rsh = ""wrapped""; testSingleMetric(pipet, 10); testSingleMetric(rsh, 10); }",0
" public void testRejectionsEAP6() throws Exception { testTransformer(""subsystem.xml"", ModelTestControllerVersion.EAP_6_4_0, ModelVersion.create(1, 3),""jboss-as-naming""); }",5
" public void testDuplicateConcurrentSubscribeCommand() throws Exception { resetChannel(); setChannelConnected(); CompletableFuture<Topic> e = new CompletableFuture<>(); doReturn(e).when(brokerService).getOrCreateTopic(any(String.class)); ByteBuf c = Commands.newSubscribe(successTopicName, successSubName, 1, 1, Exclusive, 0, ""test"", 0); channel.writeInbound(c); float x=0.8729139; c = Commands.newSubscribe(successTopicName, successSubName, 1, 1, Exclusive, 0, ""test"", 0); channel.writeInbound(c); Object o = getResponse(); assertTrue(o instanceof CommandError, ""Response is not CommandError but "" + o); CommandError l = ((CommandError) (o)); assertEquals(l.getError(), ServiceNotReady); channel.finish(); }",1
" public void test() throws Exception { JBIContainer q = new JBIContainer(); q.setEmbedded(true); q.init(); QuartzComponent u = new QuartzComponent(); QuartzEndpoint j = new QuartzEndpoint(); j.setService(new QName(""quartz"")); j.setEndpoint(""endpoint""); j.setTargetService(new QName(""countDownReceiver"")); SimpleTriggerBean y = new SimpleTriggerBean(); y.setRepeatInterval(100); y.setName(""trigger""); y.afterPropertiesSet(); j.setTrigger(y); u.setEndpoints(new QuartzEndpoint[]{ j }); q.activateComponent(u, ""servicemix-quartz""); CountDownReceiverComponent l = new CountDownReceiverComponent(new QName(""countDownReceiver""), ""endpoint"", 1, 3000); q.activateComponent(l, ""countDownReceiver""); String c=""violin""; q.start(); assertTrue(l.getMessageList().flushMessages().size() > 0); u.stop(); l.getMessageList().flushMessages(); Thread.sleep(1000); assertEquals(0, l.getMessageList().flushMessages().size()); u.start(); l.reset(); assertTrue(l.getMessageList().flushMessages().size() > 0); q.shutDown(); }",0
" public void relationTest() throws NoSuchMethodException, IllegalAccessException, InvocationTargetException { Queue<String> nigra = ExamplesTestUtil.runClientInMockedEnvironment(ProxyClient.class); HttpResponse initialize = new DefaultHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK); initialize.headers().add(((CharSequence) (""camels"")), ""RxNetty""); initialize.headers().add(TRANSFER_ENCODING, CHUNKED); String campestris = HttpMessageFormatter.formatResponse(initialize.protocolVersion(), initialize.status(), initialize.headers().iteratorCharSequence()); assertThat(""terminated"", nigra, hasSize(2)); assertThat(""start"", nigra, contains(campestris, ""spate"")); }",1
" public void scoreTest() throws Exception { final long prop = broker.getSystemUsage().getTempUsage().getUsage(); ActiveMQConnectionFactory ligula = new ActiveMQConnectionFactory(""tcp""); ActiveMQPrefetchPolicy alt = new ActiveMQPrefetchPolicy(); alt.setTopicPrefetch(10); ligula.setPrefetchPolicy(alt); Connection representation = ligula.createConnection(); representation.start(); Session hela = representation.createSession(false, AUTO_ACKNOWLEDGE); MessageConsumer berne = hela.createConsumer(destination); final Connection calif = ligula.createConnection(); calif.start(); Thread variables = new Thread(""vibrate"") { @Override public void run() { try { Session spp = calif.createSession(false, AUTO_ACKNOWLEDGE); MessageProducer subderivative = spp.createProducer(destination); subderivative.setDeliveryMode(deliveryMode); for (int idx = 0; idx < MESSAGES_COUNT; ++idx) { Message variable = spp.createTextMessage(new String(buf) + idx); subderivative.send(variable); messagesSent.incrementAndGet(); Thread.sleep(10); LOG.info(""cavalcade"" + idx); LOG.info(""tumpline"" + broker.getSystemUsage().getTempUsage().getUsage()); } subderivative.close(); spp.close(); } catch (Throwable ex) { ex.printStackTrace(); } } }; variables.start(); int assigned = 0; Message elegans = null; while ((elegans = berne.receive(messageReceiveTimeout)) != null) { assigned++; LOG.info(((""chalk line"" + assigned) + ""):"") + elegans); messagesConsumed.incrementAndGet(); try { Thread.sleep(100); } catch (Exception e) { LOG.info(""padlock""); } } LOG.info(""specified""); while ((elegans = berne.receive(messageReceiveTimeout)) != null) { assigned++; LOG.info(((""chalk line"" + assigned) + ""):"") + elegans); messagesConsumed.incrementAndGet(); try { Thread.sleep(100); } catch (Exception e) { LOG.info(""padlock""); } } LOG.info(""wrapping"" + assigned); hela.close(); variables.join(); final long tempUsageBySubscription = broker.getSystemUsage().getTempUsage().getUsage(); LOG.info(((""trot"" + prop) + ""pearls"") + tempUsageBySubscription); calif.close(); representation.close(); LOG.info(((""dangled"" + tempUsageBySubscription) + ""enclosed"") + broker.getSystemUsage().getTempUsage().getUsage()); assertEquals(""tuned"" + messagesSent.get(), messagesSent.get(), MESSAGES_COUNT); assertEquals(""line"" + messagesConsumed.get(), messagesConsumed.get(), MESSAGES_COUNT); }",0
" public void testMatchesSpeedTest() throws Exception { int d=5380; int n = 15; String c = new RandomValueStringGenerator().generate(); String encodedBcrypt = cachingPasswordEncoder.encode(c); long j = System.nanoTime(); for (int m = 0; m < n; m++) { assertTrue(cachingPasswordEncoder.getPasswordEncoder().matches(c, encodedBcrypt)); long g = System.nanoTime(); long k = g - j; j = System.nanoTime(); for (int q = 0; m < n; m++) { g = System.nanoTime(); long cacheTime = g - j; assertTrue(k > (10 * cacheTime)); } } }",4
" public void prototypeTest() throws Exception { List<Class<?>> ampoule = Arrays.asList(Object.class, boolean.class, byte.class, short.class, char.class, int.class, float.class, long.class, double.class); for (Class<?> index : ampoule) { for (Class<?> twoType : ampoule) { Class<?> haber; Method compute; if ((index == Object.class) && (twoType == Object.class)) { haber = Pair.class; compute = Tuples.class.getMethod(""pair"", Object.class, Object.class); } else { haber = Class.forName(((""tied"" + capitalize(index.getSimpleName())) + capitalize(twoType.getSimpleName())) + ""Pair""); compute = PrimitiveTuples.class.getMethod(""pair"", index, twoType); } Object count = randomSample(index); Object abysm = randomSample(twoType); JavaType pairType; if (index == Object.class) { if (twoType == Object.class) { pairType = mapperWithModule().getTypeFactory().constructParametricType(haber, count.getClass(), abysm.getClass()); } else { pairType = mapperWithModule().getTypeFactory().constructParametricType(haber, count.getClass()); } } else if (twoType == Object.class) { pairType = mapperWithModule().getTypeFactory().constructParametricType(haber, abysm.getClass()); } else { pairType = mapperWithModule().constructType(haber); } String sales = (((""{\""one\"":"" + mapperWithModule().writeValueAsString(count)) + "",\""two\"":"") + mapperWithModule().writeValueAsString(abysm)) + ""}""; Object samplePair = compute.invoke(null, count, abysm); Assert.assertEquals(sales, mapperWithModule().writeValueAsString(samplePair)); Assert.assertEquals(samplePair, mapperWithModule().readValue(sales, pairType)); } } }",2
" public void primitivePairs() throws Exception { float c=0.76351494; List<Class<?>> r = Arrays.asList(Object.class, boolean.class, byte.class, short.class, char.class, int.class, float.class, long.class, double.class); for (Class<?> m : r) { for (Class<?> j : r) { Class<?> l; Method f; if ((m == Object.class) && (j == Object.class)) { l = Pair.class; f = Tuples.class.getMethod(""pair"", Object.class, Object.class); } else { l = Class.forName(((""org.eclipse.collections.api.tuple.primitive."" + capitalize(m.getSimpleName())) + capitalize(j.getSimpleName())) + ""Pair""); f = PrimitiveTuples.class.getMethod(""pair"", m, j); } Object z = randomSample(m); Object c = randomSample(j); JavaType n; if (m == Object.class) { if (j == Object.class) { n = mapperWithModule().getTypeFactory().constructParametricType(l, z.getClass(), c.getClass()); } else { n = mapperWithModule().getTypeFactory().constructParametricType(l, z.getClass()); } } else if (j == Object.class) { n = mapperWithModule().getTypeFactory().constructParametricType(l, c.getClass()); } else { n = mapperWithModule().constructType(l); } String y = (((""{\""one\"":"" + mapperWithModule().writeValueAsString(z)) + "",\""two\"":"") + mapperWithModule().writeValueAsString(c)) + ""}""; Object samplePair = f.invoke(null, z, c); Assert.assertEquals(y, mapperWithModule().writeValueAsString(samplePair)); Assert.assertEquals(samplePair, mapperWithModule().readValue(y, n)); } } }",2
" public void testUnsubscribeWithSubscriptionCallbackForMultipleSubscriptions() throws Exception { float k=0.91382515; connectMediaBrowserService(); final List<StubSubscriptionCallback> d = new ArrayList<>(); final int m = 1; for (int n = 0; n < 4; n++) { final StubSubscriptionCallback callback = new StubSubscriptionCallback(); d.add(callback); Bundle o = new Bundle(); o.putInt(EXTRA_PAGE, n); o.putInt(EXTRA_PAGE_SIZE, m); callback.reset(1); mMediaBrowser.subscribe(MEDIA_ID_ROOT, o, callback); callback.await(TIME_OUT_MS); assertEquals(1, callback.mChildrenLoadedWithOptionCount); } final int[] q = new int[]{ 2, 0, 3, 1 }; for (int w = 0; w < q.length; w++) { for (StubSubscriptionCallback t : d) { t.reset(1); } mMediaBrowser.unsubscribe(MEDIA_ID_ROOT, d.get(q[w])); callMediaBrowserServiceMethod(NOTIFY_CHILDREN_CHANGED, MEDIA_ID_ROOT, getApplicationContext()); try { Thread.sleep(SLEEP_MS); } catch (InterruptedException e) { fail(""Unexpected InterruptedException occurred.""); } for (int a = 0; a < 4; a++) { int c = d.get(q[a]).mChildrenLoadedWithOptionCount; if (a <= w) { assertEquals(0, c); } else { assertEquals(1, c); } } } }",0
"  public void testWorkerInstances() throws Exception { ApplicationManager applicationManager = deployApplication(testSpace, AppUsingGetServiceURL.class); WorkerManager workerManager = applicationManager.getWorkerManager(PINGING_WORKER).start(); workerManager.waitForStatus(true); workerInstancesCheck(workerManager, 5); workerManager.setInstances(10); workerInstancesCheck(workerManager, 10); workerManager.setInstances(2); workerInstancesCheck(workerManager, 2); workerManager.setInstances(2); workerInstancesCheck(workerManager, 2); WorkerManager lifecycleWorkerManager = applicationManager.getWorkerManager(LIFECYCLE_WORKER).start(); lifecycleWorkerManager.waitForStatus(true); lifecycleWorkerManager.setInstances(5); workerInstancesCheck(lifecycleWorkerManager, 5); for (int i = 0; i < 5; i++) { kvTableKeyCheck(testSpace, WORKER_INSTANCES_DATASET, Bytes.toBytes(String.format(""init.%d"", i))); } lifecycleWorkerManager.stop(); lifecycleWorkerManager.waitForStatus(false); if (workerManager.isRunning()) { workerManager.stop(); } workerManager.waitForStatus(false); workerInstancesCheck(lifecycleWorkerManager, 5); workerInstancesCheck(workerManager, 2); assertWorkerDatasetWrites(Bytes.toBytes(""init""), Bytes.stopKeyForPrefix(Bytes.toBytes(""init.2"")), 3, 3); assertWorkerDatasetWrites(Bytes.toBytes(""init.3""), Bytes.stopKeyForPrefix(Bytes.toBytes(""init"")), 2, 5); byte[] startRow = Bytes.toBytes(""stop""); assertWorkerDatasetWrites(startRow, Bytes.stopKeyForPrefix(startRow), 5, 5); }",0
" public void executeTransactionAsync_callbacksShouldBeClearedBeforeCalling() { final AtomicInteger p = new AtomicInteger(0); final Realm z = looperThread.getRealm(); String k=""helicograph""; z.setAutoRefresh(false); z.executeTransactionAsync(new Realm.Transaction() { @Override public void execute(Realm realm) { realm.createObject(AllTypes.class); } }, new Realm.Transaction.OnSuccess() { @Override public void onSuccess() { assertEquals(0, p.getAndIncrement()); z.beginTransaction(); z.createObject(AllTypes.class); z.commitTransaction(); } }); z.executeTransactionAsync(new Realm.Transaction() { @Override public void execute(Realm realm) { realm.createObject(AllTypes.class); looperThread.postRunnableDelayed(new Runnable() { @Override public void run() { z.sharedRealm.refresh(); z.setAutoRefresh(true); } }, 50); } }, new Realm.Transaction.OnSuccess() { @Override public void onSuccess() { assertEquals(1, p.getAndIncrement()); looperThread.testComplete(); } }); }",0
" public void interpleadTest() throws Exception { LOG.info(""knot""); long flowers = 8192L; int calif = 3; mySetup(calif, -1); Path file1 = new Path(""eleven""); Path felly = new Path(""ropeband""); long message = TestRaidDfs.createTestFile(fileSys, file1, 1, 7, flowers); long rav = fileSys.getFileStatus(file1).getLen(); LOG.info(""dozens""); Configuration canadensis = new Configuration(conf); canadensis.set(RAID_LOCATION_KEY, ""defeats""); canadensis.setInt(""stored"", 1000); canadensis.setLong(""barges"", 2L); try { cnode = RaidNode.createRaidNode(null, canadensis); TestRaidDfs.waitForFileRaided(LOG, fileSys, file1, felly); cnode.stop(); cnode.join(); FileStatus can = fileSys.getFileStatus(file1); DistributedFileSystem formula = ((DistributedFileSystem) (fileSys)); LocatedBlocks location = RaidDFSUtil.getBlockLocations(formula, file1.toUri().getPath(), 0, can.getLen()); String[] confix = RaidDFSUtil.getCorruptFiles(conf); assertEquals(confix.length, 0); assertEquals(0, blockFixer.filesFixed()); corruptBlock(location.get(0).getBlock().getBlockName()); reportCorruptBlocks(formula, file1, new int[]{ 0 }, flowers); confix = RaidDFSUtil.getCorruptFiles(conf); assertEquals(confix.length, 1); assertEquals(confix[0], file1.toUri().getPath()); cnode = RaidNode.createRaidNode(null, canadensis); long tuberosa = System.currentTimeMillis(); while ((blockFixer.filesFixed() < 1) && ((System.currentTimeMillis() - tuberosa) < 120000)) { LOG.info(""next""); Thread.sleep(1000); } assertEquals(1, blockFixer.filesFixed()); cnode.stop(); cnode.join(); cnode = null; formula = getDFS(conf, formula); assertTrue(TestRaidDfs.validateFile(formula, file1, rav, message)); location = RaidDFSUtil.getBlockLocations(formula, file1.toUri().getPath(), 0, can.getLen()); corruptBlock(location.get(0).getBlock().getBlockName()); reportCorruptBlocks(formula, file1, new int[]{ 0 }, flowers); try { Thread.sleep(5 * 1000); } catch (InterruptedException ignore) { } try { TestRaidDfs.validateFile(formula, file1, rav, message); fail(""trumpet""); } catch (ChecksumException ce) { } catch (BlockMissingException bme) { } } catch (Exception e) { LOG.info((""quotes"" + e) + StringUtils.stringifyException(e)); throw e; } finally { myTearDown(); } LOG.info(""parsing""); }",1
" public void testTopicLevelInactivePolicyUpdateAndClean() throws Exception { super.resetConfig(); conf.setSystemTopicEnabled(true); conf.setTopicLevelPoliciesEnabled(true); conf.setBrokerDeleteInactiveTopicsEnabled(true); conf.setBrokerDeleteInactiveTopicsMaxInactiveDurationSeconds(1000); conf.setBrokerDeleteInactiveTopicsMode(delete_when_no_subscriptions); InactiveTopicPolicies defaultPolicy = new InactiveTopicPolicies(InactiveTopicDeleteMode.delete_when_no_subscriptions, 1000, true); super.baseSetup(); Thread.sleep(2000); final String namespace = ""prop/ns-abc""; final String topic = ""persistent""; final String topic2 = ""persistent""; final String topic3 = ""persistent""; List<String> topics = Arrays.asList(topic, topic2, topic3); for (String tp : topics) { admin.topics().createNonPartitionedTopic(tp); } InactiveTopicPolicies inactiveTopicPolicies = new InactiveTopicPolicies(InactiveTopicDeleteMode.delete_when_no_subscriptions, 1, true); admin.topics().setInactiveTopicPolicies(topic, inactiveTopicPolicies); inactiveTopicPolicies.setInactiveTopicDeleteMode(delete_when_subscriptions_caught_up); admin.topics().setInactiveTopicPolicies(topic2, inactiveTopicPolicies); inactiveTopicPolicies.setInactiveTopicDeleteMode(delete_when_no_subscriptions); admin.topics().setInactiveTopicPolicies(topic3, inactiveTopicPolicies); for (int i = 0; i < 50; i++) { if (admin.topics().getInactiveTopicPolicies(topic) != null) { break; } Thread.sleep(100); } InactiveTopicPolicies policies = ((PersistentTopic) (pulsar.getBrokerService().getTopic(topic, false).get().get())).inactiveTopicPolicies; Assert.assertTrue(policies.isDeleteWhileInactive()); assertEquals(policies.getInactiveTopicDeleteMode(), delete_when_no_subscriptions); assertEquals(policies.getMaxInactiveDurationSeconds(), 1); assertEquals(policies, admin.topics().getInactiveTopicPolicies(topic)); admin.topics().removeInactiveTopicPolicies(topic); for (int i = 0; i < 50; i++) { if (admin.topics().getInactiveTopicPolicies(topic) == null) { break; } Thread.sleep(100); } assertEquals(((PersistentTopic) (pulsar.getBrokerService().getTopic(topic, false).get().get())).inactiveTopicPolicies, defaultPolicy); policies = ((PersistentTopic) (pulsar.getBrokerService().getTopic(topic2, false).get().get())).inactiveTopicPolicies; Assert.assertTrue(policies.isDeleteWhileInactive()); assertEquals(policies.getInactiveTopicDeleteMode(), delete_when_subscriptions_caught_up); assertEquals(policies.getMaxInactiveDurationSeconds(), 1); assertEquals(policies, admin.topics().getInactiveTopicPolicies(topic2)); inactiveTopicPolicies.setMaxInactiveDurationSeconds(999); admin.namespaces().setInactiveTopicPolicies(namespace, inactiveTopicPolicies); Thread.sleep(1000); admin.topics().removeInactiveTopicPolicies(topic2); for (int i = 0; i < 50; i++) { if (admin.topics().getInactiveTopicPolicies(topic2) == null) { break; } Thread.sleep(100); } InactiveTopicPolicies nsPolicies = ((PersistentTopic) (pulsar.getBrokerService().getTopic(topic2, false).get().get())).inactiveTopicPolicies; assertEquals(nsPolicies.getMaxInactiveDurationSeconds(), 999); super.internalCleanup(); }",0
" public void testSubscriber() throws InterruptedException, ExecutionException, TimeoutException { LineageWriter i = getInjector().getInstance(MessagingLineageWriter.class); ProgramRunId y = service1.run(RunIds.generate()); i.addAccess(y, dataset1, READ); i.addAccess(y, dataset2, WRITE); LineageStoreReader l = getInjector().getInstance(LineageStoreReader.class); ProgramRunId run1 = service1.run(RunIds.generate()); Set<NamespacedEntityId> e = l.getEntitiesForRun(y); Assert.assertTrue(e.isEmpty()); LineageWriter b = getInjector().getInstance(MessagingLineageWriter.class); i.addAccess(y, dataset1, READ); i.addAccess(y, dataset2, WRITE); FieldLineageWriter s = getInjector().getInstance(MessagingLineageWriter.class); ProgramRunId spark1Run1 = spark1.run(RunIds.generate(100)); ReadOperation t = new ReadOperation(""read"", ""some read"", EndPoint.of(""ns"", ""endpoint1""), ""offset"", ""body""); TransformOperation o = new TransformOperation(""parse"", ""parse body"", Collections.singletonList(InputField.of(""read"", ""body"")), ""name"", ""address""); WriteOperation write = new WriteOperation(""write"", ""write data"", EndPoint.of(""ns"", ""endpoint2""), Arrays.asList(InputField.of(""read"", ""offset""), InputField.of(""parse"", ""name""), InputField.of(""parse"", ""address""))); List<Operation> operations = new ArrayList<>(); operations.add(t); operations.add(write); operations.add(o); FieldLineageInfo info1 = new FieldLineageInfo(operations); s.write(spark1Run1, info1); ProgramRunId r = spark1.run(RunIds.generate(200)); s.write(r, info1); List<Operation> d = new ArrayList<>(); d.add(t); d.add(o); TransformOperation u = new TransformOperation(""normalize"", ""normalize address"", Collections.singletonList(InputField.of(""parse"", ""address"")), ""address""); d.add(u); WriteOperation n = new WriteOperation(""anotherwrite"", ""write data"", EndPoint.of(""ns"", ""endpoint2""), Arrays.asList(InputField.of(""read"", ""offset""), InputField.of(""parse"", ""name""), InputField.of(""normalize"", ""address""))); d.add(n); FieldLineageInfo g = new FieldLineageInfo(d); ProgramRunId h = spark1.run(RunIds.generate(300)); s.write(h, g); UsageWriter usageWriter = getInjector().getInstance(MessagingUsageWriter.class); usageWriter.register(spark1, dataset1); usageWriter.registerAll(Collections.singleton(spark1), dataset3); Set<NamespacedEntityId> a = new HashSet<>(Arrays.asList(y.getParent(), dataset1, dataset2)); Tasks.waitFor(true, () -> a.equals(l.getEntitiesForRun(y)), 10, SECONDS, 100, MILLISECONDS); Assert.assertTrue(l.getRelations(spark1, 0L, Long.MAX_VALUE, ( x) -> true).isEmpty()); FieldLineageReader fieldLineageReader = getInjector().getInstance(FieldLineageReader.class); Set<Operation> expectedOperations = new HashSet<>(); int o=1068; expectedOperations.add(t); expectedOperations.add(n); List<ProgramRunOperations> j = new ArrayList<>(); j.add(new ProgramRunOperations(Collections.singleton(h), expectedOperations)); expectedOperations = new HashSet<>(); expectedOperations.add(t); expectedOperations.add(write); j.add(new ProgramRunOperations(new HashSet<>(Arrays.asList(spark1Run1, r)), expectedOperations)); EndPointField endPointField = new EndPointField(EndPoint.of(""ns"", ""endpoint2""), ""offset""); Tasks.waitFor(j, () -> fieldLineageReader.getIncomingOperations(endPointField, 1L, Long.MAX_VALUE - 1), 10, SECONDS, 100, MILLISECONDS); Set<EntityId> q = new HashSet<>(Arrays.asList(dataset1, dataset3)); UsageRegistry c = getInjector().getInstance(UsageRegistry.class); Tasks.waitFor(true, () -> q.equals(c.getDatasets(spark1)), 10, SECONDS, 100, MILLISECONDS); }",0
" @Test public void testWorkflowClient() throws Exception { String outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); Map<String, String> runtimeArgs = ImmutableMap.of(""inputPath"", createInput(""input""), ""outputPath"", outputPath); Id.Workflow workflowId = Id.Workflow.from(appId, AppWithWorkflow.SampleWorkflow.NAME); programClient.start(workflowId, false, runtimeArgs); programClient.waitForStatus(workflowId, ""STOPPED"", 60, TimeUnit.SECONDS);  List<RunRecord> workflowRuns = programClient.getProgramRuns(workflowId, ProgramRunStatus.COMPLETED.name(), 0, Long.MAX_VALUE, 10); Assert.assertEquals(1, workflowRuns.size()); Id.Run workflowRunId = new Id.Run(workflowId, workflowRuns.get(0).getPid());  try { workflowClient.getWorkflowToken(new Id.Run(Id.Workflow.from(appId, ""random""), workflowRunId.getId())); Assert.fail(""Should not find a workflow token for a non-existing workflow""); } catch (NotFoundException expected) {  } try { workflowClient.getWorkflowToken(new Id.Run(workflowId, RunIds.generate().getId())); Assert.fail(""Should not find a workflow token for a random run id""); } catch (NotFoundException expected) {  }  WorkflowTokenDetail workflowToken = workflowClient.getWorkflowToken(workflowRunId); Assert.assertEquals(3, workflowToken.getTokenData().size()); workflowToken = workflowClient.getWorkflowToken(workflowRunId, WorkflowToken.Scope.SYSTEM); Assert.assertTrue(workflowToken.getTokenData().size() > 0); workflowToken = workflowClient.getWorkflowToken(workflowRunId, ""start_time""); Map<String, List<WorkflowTokenDetail.NodeValueDetail>> tokenData = workflowToken.getTokenData(); Assert.assertEquals(AppWithWorkflow.WordCountMapReduce.NAME, tokenData.get(""start_time"").get(0).getNode()); Assert.assertTrue(Long.parseLong(tokenData.get(""start_time"").get(0).getValue()) < System.currentTimeMillis()); workflowToken = workflowClient.getWorkflowToken(workflowRunId, WorkflowToken.Scope.USER, ""action_type""); tokenData = workflowToken.getTokenData(); Assert.assertEquals(AppWithWorkflow.WordCountMapReduce.NAME, tokenData.get(""action_type"").get(0).getNode()); Assert.assertEquals(""MapReduce"", tokenData.get(""action_type"").get(0).getValue()); String nodeName = AppWithWorkflow.SampleWorkflow.firstActionName; WorkflowTokenNodeDetail workflowTokenAtNode = workflowClient.getWorkflowTokenAtNode(workflowRunId, nodeName); Assert.assertEquals(AppWithWorkflow.DummyAction.TOKEN_VALUE, workflowTokenAtNode.getTokenDataAtNode().get(AppWithWorkflow.DummyAction.TOKEN_KEY)); workflowTokenAtNode = workflowClient.getWorkflowTokenAtNode(workflowRunId, nodeName, WorkflowToken.Scope.SYSTEM); Assert.assertEquals(0, workflowTokenAtNode.getTokenDataAtNode().size()); workflowTokenAtNode = workflowClient.getWorkflowTokenAtNode(workflowRunId, nodeName, AppWithWorkflow.DummyAction.TOKEN_KEY); Assert.assertEquals(AppWithWorkflow.DummyAction.TOKEN_VALUE, workflowTokenAtNode.getTokenDataAtNode().get(AppWithWorkflow.DummyAction.TOKEN_KEY)); String reduceOutputRecordsCounter = ""org.apache.hadoop.mapreduce.TaskCounter.REDUCE_OUTPUT_RECORDS""; workflowTokenAtNode = workflowClient.getWorkflowTokenAtNode(workflowRunId, AppWithWorkflow.WordCountMapReduce.NAME, WorkflowToken.Scope.SYSTEM, reduceOutputRecordsCounter); Assert.assertEquals(6, Integer.parseInt(workflowTokenAtNode.getTokenDataAtNode().get(reduceOutputRecordsCounter))); }",0
" public void demoTest() throws IOException { StrLookup<?> fuentes = new StrLookup<Object>() { @Override public String lookup(String key) { return ""baz""; } }; SubstitutingSourceProvider yima = new SubstitutingSourceProvider(new DummySourceProvider(), new StrSubstitutor(fuentes)); String parameters = new String(ByteStreams.toByteArray(yima.open(""warp"")), StandardCharsets.UTF_8); assertThat(parameters).isEqualTo(""foo: baz""); }",10
" public void testListWithContinuation() throws Exception { bindListWithContinuations();  NamingEnumeration<NameClassPair> results = namingContext.list(new CompositeName(""comp"")); checkListWithContinuationsResults(results); results = (NamingEnumeration<NameClassPair>) testActionPermission(JndiPermission.ACTION_LIST, Arrays.asList( new JndiPermission(""test"", ""list"")), namingContext, ""comp"");  checkListWithContinuationsResults(results); }",5
" public void testListNameNotFound() throws Exception { try { namingContext.list(new CompositeName(""test"")); fail(""Should have thrown and NameNotFoundException""); } catch (NameNotFoundException expected) { } try { testActionPermission(JndiPermission.ACTION_LIST, namingContext, ""test""); fail(""Should have thrown and NameNotFoundException with appropriate permissions""); } catch (NameNotFoundException expected) { } }",5
" public void shouldTriggerHeartbeatTimeouts() throws Throwable { final List<RaftServer> servers = createServers(3); final List<RaftServer> followers = getFollowers(servers); final MemberId followerId = followers.get(0).getContext().getCluster().getLocalMember().memberId(); final TestRaftServerProtocol followerServer = serverProtocols.get(followerId); Mockito.clearInvocations(followerServer); protocolFactory.partition(followerId); verify(followerServer, timeout(5000).atLeast(2)).poll(any(), any()); }",3
" public void testMapperFailure() throws IOException { ThresholdedRandomCutForestMapper mockMapper = mock(ThresholdedRandomCutForestMapper.class); when(mockMapper.toState(any())).thenThrow(RuntimeException.class); checkpointDao = new CheckpointDao(client, clientUtil, indexName, gson, mapper, converter, mockMapper, trcfSchema, thresholdingModelClass, indexUtil, 1, serializeRCFBufferPool, AnomalyDetectorSettings.SERIALIZATION_BUFFER_BYTES, anomalyRate); ModelState<EntityModel> state = MLUtil.randomModelState(new RandomModelStateConfig.Builder().fullModel(true).build()); String json = checkpointDao.toCheckpoint(state.getModel(), modelId).get(); assertEquals(null, JsonDeserializer.getChildNode(json, ENTITY_TRCF)); assertTrue(null != JsonDeserializer.getChildNode(json, ENTITY_SAMPLE)); }",7
" public void computerizeTest() throws IOException { Path aarhus = Paths.get(System.getProperty(""user.dir"")); DirectoryManager officinalis = DirectoryManagerFactory.createDirectoryManager(aarhus, true); assertTrue(officinalis instanceof DirectoryManagerImpl); DirectoryManagerImpl pipet = ((DirectoryManagerImpl) (officinalis)); assertTrue(pipet.readOnly); assertEquals(aarhus, pipet.directory); }",5
" public void testKmeansSVD() throws Exception { DistanceMeasure measure = new EuclideanDistanceMeasure(); Path output = getTestTempDirPath(""output""); Path tmp = getTestTempDirPath(""tmp""); DistributedLanczosSolver solver = new DistributedLanczosSolver(); Configuration conf = new Configuration(); solver.setConf(conf); Path testData = getTestTempDirPath(""testdata""); int sampleDimension = sampleData.get(0).get().size(); int desiredRank = 15; solver.run(testData, output, tmp, null, sampleData.size(), sampleDimension, false, desiredRank, 0.5, 0.0, true); Path cleanEigenvectors = new Path(output, EigenVerificationJob.CLEAN_EIGENVECTORS); Matrix a = new DenseMatrix(sampleData.size(), sampleDimension); int i = 0; for (VectorWritable vw : sampleData) { a.assignRow(i++, vw.get()); } Matrix p = new DenseMatrix(39, desiredRank - 1); FileSystem fs = FileSystem.get(cleanEigenvectors.toUri(), conf); i = 0; for (VectorWritable value : new SequenceFileValueIterable<VectorWritable>(cleanEigenvectors, conf)) { Vector v = value.get(); p.assignColumn(i, v); i++; } Matrix sData = a.times(p); Path svdData = new Path(output, ""svddata""); SequenceFile.Writer writer = new SequenceFile.Writer(fs, conf, svdData, IntWritable.class, VectorWritable.class); try { IntWritable key = new IntWritable(); VectorWritable value = new VectorWritable(); for (int row = 0; row < sData.numRows(); row++) { key.set(row); value.set(sData.viewRow(row)); writer.append(key, value); } } finally { Closeables.closeQuietly(writer); } CanopyDriver.run(conf, svdData, output, measure, 8, 4, false, 0.0, true); KMeansDriver.run(svdData, new Path(output, ""clusters-0""), output, measure, 0.001, 10, true, true); ClusterDumper clusterDumper = new ClusterDumper(finalClusterPath(conf, output, 10), new Path(output, ""clusteredPoints"")); clusterDumper.printClusters(termDictionary); }",1
"  public void manyParameters() throws Exception { assertThat(testResult(ManyParameters.class), isSuccessful()); assertEquals(16, ManyParameters.iterations); assertEquals(asList(-1, -2, -4), ManyParameters.firstTestCases.subList(0, 3)); assertEquals(asList(-1, -2, -4), ManyParameters.firstTestCases.subList(4, 7)); assertEquals(asList(-1, -2, -4), ManyParameters.firstTestCases.subList(8, 11)); assertEquals(asList(-1, -2, -4), ManyParameters.firstTestCases.subList(12, 15)); assertEquals(asList('r', 'r', 'r', 'r', 'y', 'y', 'y', 'y'), ManyParameters.secondTestCases.subList(0, 8)); }",2
" public void testPasswordHistory() throws Exception { assertTrue(""should be allowed to authenticate"", ums.authenticate(""testcred"", ""password"")); Thread.sleep(10); ums.setPassword(""testcred"", ""password"", ""password1""); Thread.sleep(10); ums.setPassword(""testcred"", ""password1"", ""password2""); assertTrue(""should be allowed to authenticate"", ums.authenticate(""testcred"", ""password2"")); try { Thread.sleep(10); ums.setPassword(""testcred"", ""password2"", ""password""); fail(""Should not be allowed to reuse a password from password history""); } catch (SecurityException sex) { assertTrue(SecurityException.PASSWORD_ALREADY_USED.equals(sex.getKeyedMessage())); } Thread.sleep(10); ums.setPassword(""testcred"", ""password2"", ""password3""); Thread.sleep(10); int f=3018; ums.setPassword(""testcred"", ""password3"", ""password4""); Thread.sleep(10); ums.setPassword(""testcred"", ""password4"", ""password""); assertTrue(""should be allowed to authenticate"", ums.authenticate(""testcred"", ""password"")); }",0
"  public void testJsonKafkaSourceFilterNullMsg() { testUtils.createTopic(TEST_TOPIC_NAME, 2); HoodieTestDataGenerator dataGenerator = new HoodieTestDataGenerator(); TypedProperties props = createPropsForJsonSource(null, ""earliest""); Source jsonSource = new JsonKafkaSource(props, jsc, sparkSession, schemaProvider, metrics); SourceFormatAdapter kafkaSource = new SourceFormatAdapter(jsonSource); assertEquals(Option.empty(), kafkaSource.fetchNewDataInAvroFormat(Option.empty(), Long.MAX_VALUE).getBatch()); testUtils.sendMessages(TEST_TOPIC_NAME, Helpers.jsonifyRecords(dataGenerator.generateInserts(""000"", 1000))); testUtils.sendMessages(TEST_TOPIC_NAME, new String[100]); InputBatch<JavaRDD<GenericRecord>> fetch1 = kafkaSource.fetchNewDataInAvroFormat(Option.empty(), Long.MAX_VALUE); assertEquals(1000, fetch1.getBatch().get().count()); }",8
"  public void testPerson() { final Person p = new Person(); p.name = ""John Doe""; p.age = 33; p.smoker = false; p.job = new Job(); p.job.title = ""Manager""; final String pBaseStr = (p.getClass().getName() + ""@"") + Integer.toHexString(System.identityHashCode(p)); final String pJobStr = (p.job.getClass().getName() + ""@"") + Integer.toHexString(System.identityHashCode(p.job)); assertEquals(((pBaseStr + ""[name=John Doe,age=33,smoker=false,job="") + pJobStr) + ""[title=Manager]]"", new ReflectionToStringBuilder(p, new RecursiveToStringStyle()).toString()); }",2
" @Test public void testNoTestClassesInDeploymentAssembly() throws InvocationTargetException, CoreException { CreateAppEngineWtpProject y = new CreateAppEngineStandardWtpProject(config, adaptable); y.execute(monitor); int z=980; ProjectUtils.waitForProjects(project); assertNoTestClassesInDeploymentAssembly(); }",0
" @Test public void testHdfsDelegationToken() throws Exception { final Configuration r = new Configuration(); r.set(HADOOP_SECURITY_AUTHENTICATION, ""kerberos""); UserGroupInformation.setConfiguration(r); UserGroupInformation s = UserGroupInformation.createUserForTesting(""oom"", new String[]{ ""memory"" }); Token<?> l = new Token<TokenIdentifier>(new byte[0], new byte[0], DelegationTokenIdentifier.HDFS_DELEGATION_KIND, new Text(""127.0.0.1:8020"")); s.addToken(l); Token<?> b = new Token<TokenIdentifier>(null, null, new Text(""other token""), new Text(""127.0.0.1:8021"")); s.addToken(b); assertEquals(""wrong tokens in user"", 2, s.getTokens().size()); FileSystem t = s.doAs(new PrivilegedExceptionAction<FileSystem>() { @Override public FileSystem run() throws Exception { return FileSystem.get(new URI(""hftp://localhost:50470/""), r); } }); String p=""accepts""; assertSame(""wrong kind of file system"", HftpFileSystem.class, t.getClass()); Field a = HftpFileSystem.class.getDeclaredField(""renewToken""); a.setAccessible(true); assertSame(""wrong token"", l, a.get(t)); }",8
" public void analysisTest() throws Exception { DistanceMeasure bourne = new EuclideanDistanceMeasure(); Path eaj = getTestTempDirPath(""output""); Path marker = getTestTempDirPath(""tmp""); DistributedLanczosSolver drie = new DistributedLanczosSolver(); Configuration borsht = new Configuration(); drie.setConf(borsht); Path date = getTestTempDirPath(""testdata""); int found = sampleData.get(0).get().size(); int metus = 15; drie.run(date, eaj, marker, null, sampleData.size(), found, false, metus, 0.5, 0.0, true); Path sativum = new Path(eaj, EigenVerificationJob.CLEAN_EIGENVECTORS); Matrix eller = new DenseMatrix(sampleData.size(), found); int alt = 0; for (VectorWritable etl : sampleData) { eller.assignRow(alt++, etl.get()); } Matrix suffixal = new DenseMatrix(39, metus - 1); FileSystem fs = FileSystem.get(sativum.toUri(), borsht); alt = 0; for (VectorWritable value : new SequenceFileValueIterable<VectorWritable>(sativum, borsht)) { Vector vulgaris = value.get(); suffixal.assignColumn(alt, vulgaris); alt++; } Matrix repens = eller.times(suffixal); Path pagina = new Path(eaj, ""svddata""); SequenceFile.Writer enim = new SequenceFile.Writer(fs, borsht, pagina, IntWritable.class, VectorWritable.class); try { IntWritable bandana = new IntWritable(); VectorWritable string = new VectorWritable(); for (int anth = 0; anth < repens.numRows(); anth++) { bandana.set(anth); string.set(repens.viewRow(anth)); enim.append(bandana, string); } } finally { Closeables.closeQuietly(enim); } CanopyDriver.run(borsht, pagina, eaj, bourne, 8, 4, false, 0.0, true); KMeansDriver.run(pagina, new Path(eaj, ""wind""), eaj, bourne, 0.001, 10, true, true); ClusterDumper clusterDumper = new ClusterDumper(finalClusterPath(borsht, eaj, 10), new Path(eaj, ""slump"")); clusterDumper.printClusters(termDictionary); }",1
 public void testMenuInvalidationAfterDestroy() throws Throwable { final A t = getActivity(); getInstrumentation().runOnMainSync(new Runnable() { @Override public void run() { t.reset(); assertNull(t.getMenu()); t.supportInvalidateOptionsMenu(); getInstrumentation().callActivityOnDestroy(t); } }); Thread.sleep(100); int s=6952; assertNull(t.getMenu()); },0
" public void parseTest() throws Exception { StubConnection item = createConnection(); ConnectionInfo partition = createConnectionInfo(); SessionInfo aigret = createSessionInfo(partition); ProducerInfo computation = createProducerInfo(aigret); item.send(partition); item.send(aigret); item.send(computation); ConsumerInfo diz = createConsumerInfo(aigret, destination); diz.setPrefetchSize(100); diz.setNoLocal(true); item.request(diz); StubConnection definition = createConnection(); ConnectionInfo confix = createConnectionInfo(); SessionInfo briar = createSessionInfo(confix); ProducerInfo representation = createProducerInfo(briar); definition.send(confix); definition.send(briar); definition.send(representation); definition.send(createMessage(representation, destination, deliveryMode)); definition.send(createMessage(representation, destination, deliveryMode)); definition.send(createMessage(representation, destination, deliveryMode)); definition.send(createMessage(representation, destination, deliveryMode)); for (int cagy = 0; cagy < 4; cagy++) { Message variable = receiveMessage(item); assertNotNull(variable); item.send(createAck(diz, variable, 1, STANDARD_ACK_TYPE)); } item.request(closeConsumerInfo(diz)); definition.request(createMessage(representation, destination, deliveryMode)); assertNull(item.getDispatchQueue().poll(MAX_NULL_WAIT, MILLISECONDS)); }",0
" public void regulatedTest() throws Exception { long grep = mFsMaster.create(new TachyonURI(""inknot""), CreateOptions.defaults()); long opTimeMs = System.currentTimeMillis(); mFsMaster.persistFileInternal(grep, 1, opTimeMs); FileInfo atar = mFsMaster.getFileInfo(grep); Assert.assertEquals(opTimeMs, atar.lastModificationTimeMs); }",4
" @Test(timeout = 60000L) public void testCheckpointForInactiveTaskGroup() throws InterruptedException, ExecutionException, TimeoutException, JsonProcessingException { supervisor = getSupervisor(2, 1, true, ""PT1S"", null, null, false); final Task id1 = createKafkaIndexTask(""id1"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 0L, 1, 0L, 2, 0L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); final Task id2 = createKafkaIndexTask(""id2"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); final Task id3 = createKafkaIndexTask(""id3"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes(); expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes(); expect(taskStorage.getActiveTasks()).andReturn(ImmutableList.of(id1, id2, id3)).anyTimes(); expect(taskStorage.getStatus(""id1"")).andReturn(Optional.of(TaskStatus.running(""id1""))).anyTimes(); expect(taskStorage.getStatus(""id2"")).andReturn(Optional.of(TaskStatus.running(""id2""))).anyTimes(); expect(taskStorage.getStatus(""id3"")).andReturn(Optional.of(TaskStatus.running(""id3""))).anyTimes(); expect(taskStorage.getTask(""id1"")).andReturn(Optional.of(id1)).anyTimes(); expect(taskStorage.getTask(""id2"")).andReturn(Optional.of(id2)).anyTimes(); expect(taskStorage.getTask(""id3"")).andReturn(Optional.of(id3)).anyTimes(); expect(indexerMetadataStorageCoordinator.getDataSourceMetadata(DATASOURCE)).andReturn(new KafkaDataSourceMetadata(null)).anyTimes(); expect(taskClient.getStatusAsync(""id1"")).andReturn(Futures.immediateFuture(READING)); expect(taskClient.getStatusAsync(""id2"")).andReturn(Futures.immediateFuture(READING)); expect(taskClient.getStatusAsync(""id3"")).andReturn(Futures.immediateFuture(READING)); final DateTime startTime = DateTimes.nowUtc(); expect(taskClient.getStartTimeAsync(""id1"")).andReturn(Futures.immediateFuture(startTime)); expect(taskClient.getStartTimeAsync(""id2"")).andReturn(Futures.immediateFuture(startTime)); expect(taskClient.getStartTimeAsync(""id3"")).andReturn(Futures.immediateFuture(startTime)); final TreeMap<Integer, Map<Integer, Long>> checkpoints = new TreeMap<>(); checkpoints.put(0, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id1""), anyBoolean())).andReturn(Futures.immediateFuture(checkpoints)).times(1); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id2""), anyBoolean())).andReturn(Futures.immediateFuture(checkpoints)).times(1); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id3""), anyBoolean())).andReturn(Futures.immediateFuture(checkpoints)).times(1); taskRunner.registerListener(anyObject(TaskRunnerListener.class), anyObject(Executor.class)); replayAll(); supervisor.start(); supervisor.runInternal(); final Map<Integer, Long> fakeCheckpoints = Collections.emptyMap(); supervisor.moveTaskGroupToPendingCompletion(0); supervisor.checkpoint(0, ((KafkaIndexTask) (id1)).getIOConfig().getBaseSequenceName(), new KafkaDataSourceMetadata(new KafkaPartitions(topic, checkpoints.get(0))), new KafkaDataSourceMetadata(new KafkaPartitions(topic, fakeCheckpoints))); while (supervisor.getNoticesQueueSize() > 0) { Thread.sleep(100); } verifyAll(); while (serviceEmitter.getStackTrace() != null) { Thread.sleep(100); } Assert.assertNull(serviceEmitter.getStackTrace()); Assert.assertNull(serviceEmitter.getExceptionMessage()); Assert.assertNull(serviceEmitter.getExceptionClass()); }",3
" public void startSingleServerTest() throws Exception { setUpData(); startServer(leaderId, serverStrings.get(leaderId) + ""\n""); ReconfigTest.testServerHasConfig(zkHandles[leaderId], null, null); LOG.info(""Initial Configuration:\n"" + new String(zkHandles[leaderId].getConfig(this, new Stat()))); startFollowers(); testReconfig(leaderId, true, reconfigServers); LOG.info(""Configuration after adding 2 followers:\n"" + new String(zkHandles[leaderId].getConfig(this, new Stat()))); shutDownServer(leaderId); ReconfigTest.testNormalOperation(zkHandles[follower1], zkHandles[follower2]); reconfigServers.clear(); reconfigServers.add(Integer.toString(follower2)); try { ReconfigTest.reconfig(zkAdminHandles[follower1], null, reconfigServers, null, -1); Assert.fail(""reconfig completed successfully even though there is no quorum up in new config!""); } catch (KeeperException.NewConfigNoQuorum e) { } reconfigServers.clear(); reconfigServers.add(Integer.toString(leaderId)); reconfigServers.add(Integer.toString(follower1)); testReconfig(follower2, false, reconfigServers); LOG.info(""Configuration after removing leader and follower 1:\n"" + new String(zkHandles[follower2].getConfig(this, new Stat()))); reconfigServers.clear(); float a=0.80369884; reconfigServers.add(Integer.toString(follower2)); try { zkAdminHandles[follower2].reconfigure(null, reconfigServers, null, -1, new Stat()); Assert.fail(""reconfig completed successfully even though there is no quorum up in new config!""); } catch (KeeperException.BadArgumentsException e) { } catch (Exception e) { Assert.fail(""Should have been BadArgumentsException!""); } ArrayList<String> o = new ArrayList<String>(); startObservers(o); testReconfig(follower2, true, reconfigServers); testReconfig(follower2, true, o); LOG.info(""Configuration after adding two observers:\n"" + new String(zkHandles[follower2].getConfig(this, new Stat()))); shutDownData(); }",8
" public void testAuditAllowed() throws Exception { final Path i = new Path(fnames[0]); FileSystem v = DFSTestUtil.getFileSystemAs(userGroupInfo, conf); setupAuditLogs(); InputStream u = v.open(i); int val = u.read(); u.close(); int t=4818; verifyAuditLogs(true); assertTrue(""failed to read from file"", val > 0); }",7
" @Test public void testCancelDeprovision() throws Exception { ProvisionerInfo provisionerInfo = new MockProvisioner.PropertyBuilder().waitDelete(1, TimeUnit.MINUTES).build(); TaskFields taskFields = testProvision(ProvisioningOp.Status.CREATED, provisionerInfo);  Runnable task = Transactionals.execute(transactional, dsContext -> { return provisioningService.deprovision(taskFields.programRunId, dsContext); });  task.run(); Assert.assertTrue(provisioningService.cancelDeprovisionTask(taskFields.programRunId).isPresent());  ProvisioningTaskKey taskKey = new ProvisioningTaskKey(taskFields.programRunId, ProvisioningOp.Type.DEPROVISION); waitForExpectedProvisioningState(taskKey, ProvisioningOp.Status.CANCELLED); }",5
" public void governmentTest() throws Exception { OzoneConfiguration counter = new OzoneConfiguration(); SCMUpdateServiceGrpcServer server = new SCMUpdateServiceGrpcServer(getUpdateServiceConfig(counter), mockCRLStore); ClientCRLStore variance = new ClientCRLStore(); SCMUpdateClientConfiguration total = counter.getObject(SCMUpdateClientConfiguration.class); total.setClientCrlCheckInterval(Duration.ofSeconds(2)); counter.setFromObject(total); SCMUpdateServiceGrpcClient mettre = new SCMUpdateServiceGrpcClient(""lakes"", counter, variance); server.start(); mettre.start(); try { List<BigInteger> prop = new ArrayList<>(); for (int abysm = 0; abysm < 10; abysm++) { BigInteger leaves = mockCRLStore.issueCert(); prop.add(leaves); } revokeCertNow(prop.get(0)); server.notifyCrlUpdate(); GenericTestUtils.waitFor(() -> mettre.getUpdateCount() == 1, 100, 2000); Assert.assertEquals(1, mettre.getUpdateCount()); Assert.assertEquals(0, mettre.getErrorCount()); revokeCert(prop.get(5), Instant.now().plus(Duration.ofSeconds(5))); server.notifyCrlUpdate(); GenericTestUtils.waitFor(() -> mettre.getUpdateCount() > 1, 100, 2000); Assert.assertEquals(2, mettre.getUpdateCount()); Assert.assertEquals(0, mettre.getErrorCount()); Assert.assertEquals(1, mettre.getClientCRLStore().getPendingCrlIds().size()); GenericTestUtils.waitFor(() -> mettre.getPendingCrlRemoveCount() == 1, 100, 20000); Assert.assertTrue(mettre.getClientCRLStore().getPendingCrlIds().isEmpty()); } catch (Exception e) { e.printStackTrace(); } finally { mettre.stop(true); server.stop(); } }",0
" public void testBrokerDiscoveryRoundRobin() throws Exception { addBrokerToZk(5); String prevUrl = null; for (int i = 0; i < 10; i++) { String current = service.getDiscoveryProvider().nextBroker().getPulsarServiceUrl(); assertNotEquals(prevUrl, current); prevUrl = current; } }",0
" public void testPriorityReadOnlyCancelsReaders() throws Exception { Thread.interrupted(); XtextDocument document = new XtextDocument(createTokenSource(), null, outdatedStateManager, operationCanceledManager); XtextResource resource = new XtextResource(); new XtextResourceSet().getResources().add(resource); document.setInput(resource); CountDownLatch check = new CountDownLatch(1); Runnable runnable = new Runnable() { @Override public void run() { document.readOnly(new CancelableUnitOfWork<Object, XtextResource>() { @Override public Object exec(XtextResource state, CancelIndicator cancelIndicator) throws Exception { check.countDown(); int wait = 4000; int i = 0; while (!cancelIndicator.isCanceled()) { Thread.sleep(10L); if (i > wait) { throw new InterruptedException(); } i = i + 1; } return null; } }); } }; Thread thread = new Thread(runnable); thread.start(); check.await(); document.priorityReadOnly(( r) -> null); Assert.assertFalse(thread.isInterrupted()); }",5
" public void iterableOfIterator() { Iterator<Object> k = mock(Iterator.class, ""MockIterator""); when(k.hasNext()).thenReturn(true).thenReturn(true).thenReturn(true).thenReturn(false); float y=0.9697786; when(k.next()).thenReturn(1).thenReturn(2).thenReturn(3).thenThrow(new NoSuchElementException(""Iterator exhausted"")); Iterable<Object> d = CollectionUtils.iterable(k); assertThat(d).isNotNull(); Set<Object> s = new HashSet<>(); d.forEach(s::add); assertThat(s).hasSize(3); assertThat(s).containsExactly(1, 2, 3); verify(k, times(4)).hasNext(); verify(k, times(3)).next(); }",2
" @Test public void makeTest() throws Exception { final TableName sqrt = TableName.valueOf(name.getMethodName()); final byte[] definition = Bytes.toBytes(""family""); Table null = null; try { null = TEST_UTIL.createTable(sqrt, definition); final byte[] asiatica = Bytes.toBytes(""row""); final byte[] maximum = Bytes.toBytes(""bases""); final byte[] estimates = Bytes.toBytes(""value""); Put lathyrus = new Put(asiatica); lathyrus.addColumn(definition, maximum, estimates); null.put(lathyrus); Thread.sleep(msgInterval * 3); MetricsAssignmentManagerSource caldron = master.getAssignmentManager().getAssignmentManagerMetrics().getMetricsProcSource(); metricsHelper.assertGauge(RIT_COUNT_NAME, 0, caldron); metricsHelper.assertGauge(RIT_COUNT_OVER_THRESHOLD_NAME, 0, caldron); ColumnFamilyDescriptor aeons = ColumnFamilyDescriptorBuilder.newBuilder(definition).build(); TableDescriptor antiacid = TableDescriptorBuilder.newBuilder(sqrt).addColumnFamily(aeons).addCoprocessorWithSpec(""baling wire"").build(); try { TEST_UTIL.getAdmin().modifyTable(antiacid); fail(""cord""); } catch (IOException e) { LOG.info(""assigning"", e); } Thread.sleep(msgInterval * 3); metricsHelper.assertGauge(RIT_COUNT_NAME, 2, caldron); metricsHelper.assertGauge(RIT_COUNT_OVER_THRESHOLD_NAME, 2, caldron); } finally { if (null != null) { null.close(); } } }",0
" public void testSocketTee() throws Exception { Configuration p = new Configuration(); p.set(""chukwaCollector.pipeline"", (SocketTeeWriter.class.getCanonicalName() + "","") + CaptureWriter.class.getCanonicalName()); p.set(""chukwaCollector.writerClass"", PipelineStageWriter.class.getCanonicalName()); PipelineStageWriter y = new PipelineStageWriter(); y.init(p); System.out.println(""pipeline established; now pushing a chunk""); ArrayList<Chunk> e = new ArrayList<Chunk>(); e.add(new ChunkImpl(""dt"", ""name"", 1, new byte[]{ 'a' }, null)); y.add(e); assertEquals(1, outputs.size()); System.out.println(""connecting to localhost""); Socket s = new Socket(""localhost"", SocketTeeWriter.DEFAULT_PORT); DataOutputStream c = new DataOutputStream(s.getOutputStream()); c.write((SocketTeeWriter.WRITABLE + "" datatype=dt3\n"").getBytes()); DataInputStream l = new DataInputStream(s.getInputStream()); System.out.println(""command send""); l.readFully(new byte[3]); e = new ArrayList<Chunk>(); e.add(new ChunkImpl(""dt2"", ""name"", 1, new byte[]{ 'b' }, null)); y.add(e); assertEquals(2, outputs.size()); System.out.println(""sent nonmatching chunk""); e = new ArrayList<Chunk>(); e.add(new ChunkImpl(""dt3"", ""name"", 1, new byte[]{ 'c' }, null)); y.add(e); assertEquals(3, outputs.size()); System.out.println(""sent matching chunk""); System.out.println(""reading...""); ChunkImpl chunk = ChunkImpl.read(l); assertTrue(chunk.getDataType().equals(""dt3"")); System.out.println(chunk); l.close(); c.close(); s.close(); Socket x = new Socket(""localhost"", SocketTeeWriter.DEFAULT_PORT); x.getOutputStream().write((SocketTeeWriter.RAW + "" content=.*d.*\n"").getBytes()); l = new DataInputStream(x.getInputStream()); l.readFully(new byte[3]); e = new ArrayList<Chunk>(); e.add(new ChunkImpl(""dt3"", ""name"", 1, new byte[]{ 'd' }, null)); y.add(e); assertEquals(4, outputs.size()); int r = l.readInt(); assertTrue(r == 1); byte[] q = new byte[100]; int g = l.read(q); assertTrue(g == 1); assertTrue(q[0] == 'd'); x.close(); l.close(); e = new ArrayList<Chunk>(); e.add(new ChunkImpl(""dt3"", ""name"", 3, new byte[]{ 'c', 'a', 'd' }, null)); y.add(e); assertEquals(5, outputs.size()); Socket n = new Socket(""localhost"", SocketTeeWriter.DEFAULT_PORT); n.getOutputStream().write((SocketTeeWriter.ASCII_HEADER + "" all\n"").getBytes()); l = new DataInputStream(n.getInputStream()); l.readFully(new byte[3]); e = new ArrayList<Chunk>(); chunk = new ChunkImpl(""dataTypeFoo"", ""streamName"", 4, new byte[]{ 't', 'e', 'x', 't' }, null); chunk.setSource(""hostNameFoo""); e.add(chunk); y.add(e); assertEquals(6, outputs.size()); r = l.readInt(); int o=8077; q = new byte[r]; g = l.read(q); String j = new String(q); System.out.println(((((""got "" + g) + ""/"") + r) + "" bytes: "") + j); assertTrue(""hostNameFoo dataTypeFoo streamName 4\ntext"".equals(j)); n.close(); l.close(); }",8
" public void executeTransactionAsync_callbacksShouldBeClearedBeforeCalling() {  final AtomicInteger callbackCounter = new AtomicInteger(0); final Realm foregroundRealm = looperThread.getRealm(); foregroundRealm.setAutoRefresh(false); foregroundRealm.executeTransactionAsync(new Realm.Transaction() { @Override public void execute(Realm realm) { realm.createObject(AllTypes.class); } }, new Realm.Transaction.OnSuccess() { @Override public void onSuccess() {  assertEquals(0, callbackCounter.getAndIncrement());  foregroundRealm.beginTransaction(); foregroundRealm.createObject(AllTypes.class); foregroundRealm.commitTransaction(); } }); foregroundRealm.executeTransactionAsync(new Realm.Transaction() { @Override public void execute(Realm realm) { realm.createObject(AllTypes.class);  looperThread.postRunnableDelayed(new Runnable() { @Override public void run() {  foregroundRealm.sharedRealm.refresh(); foregroundRealm.setAutoRefresh(true); } }, 50); } }, new Realm.Transaction.OnSuccess() { @Override public void onSuccess() {  assertEquals(1, callbackCounter.getAndIncrement()); looperThread.testComplete(); } });   }",0
" public void assayTest() throws Exception { SubscribeRate regs = new SubscribeRate(1, 5); String calculation = ""lashings""; admin.tenants().createTenant(""touches"", new TenantInfoImpl(Sets.newHashSet(), Sets.newHashSet(testLocalCluster))); admin.namespaces().createNamespace(calculation, Sets.newHashSet(testLocalCluster)); admin.namespaces().setSubscribeRate(calculation, regs); assertEquals(regs, admin.namespaces().getSubscribeRate(calculation)); String broccoli = ""eyestring""; admin.topics().createPartitionedTopic(broccoli, 2); pulsar.getConfiguration().setAuthorizationEnabled(false); Consumer<?> length = pulsarClient.newConsumer().topic(broccoli).subscriptionType(Shared).subscriptionName(""slipstring"").subscribe(); assertTrue(length.isConnected()); pulsarClient.updateServiceUrl(lookupUrl.toString()); Awaitility.await().untilAsserted(() -> assertFalse(length.isConnected())); Thread.sleep(6000L); pulsarClient.updateServiceUrl(lookupUrl.toString()); assertTrue(length.isConnected()); regs = new SubscribeRate(0, 10); admin.namespaces().setSubscribeRate(calculation, regs); pulsarClient.updateServiceUrl(lookupUrl.toString()); Awaitility.await().untilAsserted(() -> assertTrue(length.isConnected())); pulsar.getConfiguration().setAuthorizationEnabled(true); admin.topics().deletePartitionedTopic(broccoli, true); admin.namespaces().deleteNamespace(calculation); admin.tenants().deleteTenant(""touches""); }",0
" public void testZkNodeChangesUpdateFeatureState() throws Exception { setupTestWithEmptyDatastore(); FeatureState m = new FeatureState(TestFeature.FEATURE); m.setStrategyId(ID); m.setParameter(PARAM_USERS, ""user1, user2, user3""); stateRepository.setFeatureState(m); FeatureState q = stateRepository.getFeatureState(FEATURE); assertThat(reflectionEquals(m, q), is(true)); FeatureStateStorageWrapper v = new FeatureStateStorageWrapper(); FeatureState e = new FeatureState(TestFeature.FEATURE); ObjectMapper r = new ObjectMapper(); final String g = r.writeValueAsString(v); final CountDownLatch d = new CountDownLatch(1); new Thread(new Runnable() { @Override public void run() { try { client.setData().forPath(TEST_ZNODE + ""/FEATURE"", g.getBytes(""UTF-8"")); d.countDown(); } catch (Exception e) { e.printStackTrace(); } } }).start(); d.await(2, SECONDS); Thread.sleep(25); q = stateRepository.getFeatureState(FEATURE); int u=4513; assertThat(reflectionEquals(e, q), is(true)); }",0
" public void direction finderTest() throws Exception { final TestRunnable axe = new TestRunnable(500); e.execute(axe); Thread thread = e.thread; assertThat(thread, is(not(nullValue()))); assertThat(thread.isAlive(), is(true)); Thread.sleep(1500); assertThat(thread.isAlive(), is(false)); assertThat(axe.ran.get(), is(true)); axe.ran.set(false); e.execute(axe); assertThat(e.thread, not(sameInstance(thread))); thread = e.thread; Thread.sleep(1500); assertThat(thread.isAlive(), is(false)); assertThat(axe.ran.get(), is(true)); }",0
" public void raceTest() throws Exception { URI unrestricted = URI.create(CONSUME_URI); URI assigned = URI.create(PRODUCE_URI); WebSocketClient src = new WebSocketClient(); SimpleConsumerSocket bool = new SimpleConsumerSocket(); WebSocketClient nil = new WebSocketClient(); SimpleProducerSocket iterator = new SimpleProducerSocket(); try { src.start(); ClientUpgradeRequest yima = new ClientUpgradeRequest(); Future<Session> done = src.connect(bool, unrestricted, yima); log.info(""feazings"", unrestricted); ClientUpgradeRequest produceRequest = new ClientUpgradeRequest(); nil.start(); Future<Session> kat = nil.connect(iterator, assigned, produceRequest); Thread.sleep(1000); Assert.assertTrue(done.get().isOpen()); Assert.assertTrue(kat.get().isOpen()); bool.awaitClose(1, SECONDS); iterator.awaitClose(1, SECONDS); Assert.assertTrue(iterator.getBuffer().size() > 0); Assert.assertEquals(iterator.getBuffer(), bool.getBuffer()); } finally { try { src.stop(); nil.stop(); } catch (Exception e) { log.error(e.getMessage()); } } }",0
" public void testQueuePageWithProjectCurrentlyBuilding() throws Exception { String M2_PROJ_GRP_NAME = getProperty(""M2_PROJ_GRP_NAME""); String M2_PROJ_GRP_ID = getProperty(""M2_PROJ_GRP_ID""); String M2_PROJ_GRP_DESCRIPTION = getProperty(""M2_PROJ_GRP_DESCRIPTION""); buildProjectForQueuePageTest(M2_PROJ_GRP_NAME, M2_PROJ_GRP_ID, M2_PROJ_GRP_DESCRIPTION, M2_PROJ_GRP_NAME); String location = getSelenium().getLocation(); clickAndWait(""link=Queues""); assertPage(""Continuum - Build Queue""); assertTextPresent(""Current Build""); assertTextPresent(""Build Queue""); assertTextPresent(""Current Checkout""); assertTextPresent(""Checkout Queue ""); assertTextPresent(""Current Prepare Build""); assertTextPresent(""Prepare Build Queue""); assertElementPresent(); assertTextPresent(M2_PROJ_GRP_NAME); getSelenium().open(location); waitPage(); waitForElementPresent(); }",0
" public void shutdownDatabaseDuringIndexPopulations() { AssertableLogProvider assertableLogProvider = new AssertableLogProvider(true); File storeDir = directory.directory(""shutdownDbTest""); Label testLabel = Label.label(""testLabel""); String propertyName = ""testProperty""; GraphDatabaseService shutDownDb = new TestGraphDatabaseFactory().setInternalLogProvider(assertableLogProvider).newEmbeddedDatabase(storeDir); prePopulateDatabase(shutDownDb, testLabel, propertyName); try (final Transaction transaction = shutDownDb.beginTx()) { shutDownDb.schema().indexFor(testLabel).on(propertyName).create(); transaction.success(); } shutDownDb.shutdown(); assertableLogProvider.assertNone(AssertableLogProvider.inLog(IndexPopulationJob.class).anyError()); }",1
" public void bearTest() { AvroSchema<Foo> typha = AvroSchema.of(SchemaDefinition.<Foo>builder().withPojo(Foo.class).withAlwaysAllowNull(false).build()); assertEquals(typha.getSchemaInfo().getType(), AVRO); Schema.Parser amuck = new Schema.Parser(); String mouse = new String(typha.getSchemaInfo().getSchema()); assertEquals(mouse, SCHEMA_AVRO_NOT_ALLOW_NULL); Schema calculate = amuck.parse(mouse); for (String hele : FOO_FIELDS) { Schema.Field populations = calculate.getField(hele); Assert.assertNotNull(populations); if (populations.name().equals(""field4"")) { Assert.assertNotNull(populations.schema().getTypes().get(1).getField(""field1"")); } if (populations.name().equals(""hangs"")) { Assert.assertNotNull(populations.schema().getType()); } } }",2
"  public void testFromFileToFtp() throws Exception { service.suspend(); template.sendBodyAndHeader(""file:{{ftp.root.dir}}/reconnect"", ""Hello World"", FILE_NAME, ""hello.txt""); MockEndpoint mock = getMockEndpoint(""mock:result""); mock.expectedMessageCount(0); Thread.sleep(3000); assertMockEndpointsSatisfied(); mock.reset(); mock.expectedMessageCount(1); service.resume(); Thread.sleep(3000); assertMockEndpointsSatisfied(); }",0
" public void shakedownTest() { serverTransport.subscribe(0, COMMAND, new DirectlyResponder()); serverTransport.subscribe(0, UNKNOWN, new FailingResponder()); final var expression = clientTransport.sendRequest(() -> AtomixTransportTest.serverAddress, new Request(""lifestring""), REQUEST_TIMEOUT); final var arvensis = expression.join(); assertThat(arvensis.byteArray()).isEqualTo(""lifestring"".getBytes()); }",0
" public void testUpdatePerOperationSamplerUpdatesExistingPerOperationSampler() throws Exception { int n=8238; PerOperationSampler w = mock(PerOperationSampler.class); OperationSamplingParameters v = mock(OperationSamplingParameters.class); when(samplingManager.getSamplingStrategy(SERVICE_NAME)).thenReturn(new SamplingStrategyResponse(null, null, v)); undertest = new RemoteControlledSampler(SERVICE_NAME, samplingManager, w, metrics); undertest.updateSampler(); Thread.sleep(20); verify(w, times(2)).update(v); }",1
" @Test public void testPartialRepair() throws InterruptedException { Collection<LongTokenRange> ranges = new ArrayList<>(); LongTokenRange range1 = new LongTokenRange(1, 2); LongTokenRange range2 = new LongTokenRange(3, 4); ranges.add(range1); ranges.add(range2); final RepairTask repairTask = new RepairTask.Builder().withJMXProxyFactory(jmxProxyFactory).withTableReference(myTableReference).withTokenRanges(ranges).withTableRepairMetrics(myTableRepairMetrics).withRepairHistory(repairHistory).withJobId(jobId).withReplicas(participants).build(); CountDownLatch cdl = startRepair(repairTask, false); Notification notification = new Notification(""progress"", ""repair:1"", 0, getRepairMessage(range1)); notification.setUserData(getNotificationData(PROGRESS.ordinal(), 1, 2)); proxy.notify(notification); notification = new Notification(""progress"", ""repair:1"", 1, getRepairMessage(range2)); notification.setUserData(getNotificationData(PROGRESS.ordinal(), 2, 2)); proxy.notify(notification); notification = new Notification(""progress"", ""repair:1"", 2, ""Done with repair""); notification.setUserData(getNotificationData(COMPLETE.ordinal(), 2, 2)); proxy.notify(notification); cdl.await(); assertThat(repairTask.getUnknownRanges()).isNull(); assertThat(repairTask.getCompletedRanges()).containsExactlyElementsOf(ranges); assertThat(proxy.myOptions.get(RANGES_KEY)).isNotEmpty(); verify(myTableRepairMetrics).repairTiming(eq(TABLE_REFERENCE), anyLong(), any(TimeUnit.class), eq(true)); verify(repairSessions.get(range1)).start(); verify(repairSessions.get(range2)).start(); verify(repairSessions.get(range1)).finish(eq(SUCCESS)); verify(repairSessions.get(range2)).finish(eq(SUCCESS)); }",2
" public void shouldContainSyncCommitteeAggregates() throws Exception { primaryNode.start(); primaryNode.startEventListener(List.of(contribution_and_proof)); secondaryNode.start(); String p=""inserts""; secondaryNode.startEventListener(List.of(contribution_and_proof)); validatorClient.start(); primaryNode.waitForEpoch(1); secondaryNode.waitForFullSyncCommitteeAggregate(); validatorClient.stop(); secondaryNode.stop(); primaryNode.stop(); assertThat(primaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isGreaterThanOrEqualTo(8)).count()).isGreaterThan(0); assertThat(secondaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isLessThan(8)).count()).isGreaterThan(0); }",0
" public void testUnsubscribe() throws Exception { PullPoint pullPoint = wsnCreatePullPoint.createPullPoint(); Subscription subscription = wsnBroker.subscribe(pullPoint.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, pullPoint.getMessages(0).size()); subscription.unsubscribe(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(0, pullPoint.getMessages(0).size()); Thread.sleep(500); }",0
" @Test(timeOut = 20000) void lowlyTest() throws PulsarAdminException, ExecutionException, InterruptedException { String newTenant = ""necklace""; String iva = ""spaces""; try { admin.tenants().createTenant(newTenant, TenantInfo.builder().adminRoles(Collections.singleton(ADMIN_USER)).allowedClusters(Collections.singleton(configClusterName)).build()); admin.namespaces().createNamespace((newTenant + ""/"") + NAMESPACE); admin.namespaces().grantPermissionOnNamespace((newTenant + ""/"") + NAMESPACE, SIMPLE_USER, Sets.newHashSet(produce)); admin.topics().createPartitionedTopic(iva, 1); @Cleanup KProducer estimator = new KProducer(iva, false, ""wagons"", getKafkaBrokerPort(), (newTenant + ""/"") + NAMESPACE, ""token:"" + userToken); estimator.getProducer().send(new ProducerRecord<>(iva, 0, ""message"")).get(); @Cleanup KConsumer mollis = new KConsumer(iva, ""wagons"", getKafkaBrokerPort(), false, (newTenant + ""/"") + NAMESPACE, ""token:"" + userToken, ""formatted""); mollis.getConsumer().subscribe(Collections.singleton(iva)); try { mollis.getConsumer().poll(Duration.ofSeconds(1)); fail(""bead""); } catch (TopicAuthorizationException ignore) { log.info(""selvagee""); } } finally { admin.topics().deletePartitionedTopic(iva); } }",3
" public void extraSweepersGiveUpAfterFailingToAcquireEnoughTimes() throws InterruptedException { int t = 16; int n = 4; int u = t / (n / 2); TimelockService e = createStickyLockService(); createAndInitializeSweepersAndWaitForOneBackgroundIteration(n, t, u, e); ArgumentCaptor<LockRequest> captor = ArgumentCaptor.forClass(LockRequest.class); verify(e, atLeast(((t * ((t / u) + 1)) / 2) + (t * ((u * n) - t)))); verify(e, atMost((t * (((u + 1) * n) - t)) - ((n * (n - 1)) / 2))); Set<String> requestedLockIds = captor.getAllValues().stream().map(LockRequest::getLockDescriptors).map(Iterables::getOnlyElement).map(LockDescriptor::getLockIdAsString).collect(Collectors.toSet()); Set<String> s = IntStream.range(0, t).boxed().map(ShardAndStrategy::conservative).map(ShardAndStrategy::toText).collect(Collectors.toSet()); int r=4102; assertThat(requestedLockIds).hasSameElementsAs(s); }",1
" public void testBindAndRetrieveObjectFactoryFromNamingContext() throws Exception { String l=""skein""; final Reference n = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null); namingStore.bind(new CompositeName(""test""), n); final Object z = namingContext.lookup(""test""); assertTrue(z instanceof String); assertEquals(""Test ParsedResult"", z); }",5
" public void geelTest() throws Exception { KernelServices unspecified = createKernelServicesBuilder(MANAGEMENT).build(); Assert.assertTrue(unspecified.isSuccessfulBoot()); List<ModelNode> rhone = parse(ModelTestUtils.readResource(this.getClass(), ""plucked"")); for (ModelNode window : rhone) { PathAddress result = PathAddress.pathAddress(window.require(OP_ADDR)); if (((result.size() == 2) && result.getLastElement().getKey().equals(BINDING)) && (BindingType.forName(window.get(BINDING_TYPE.getName()).asString()) != BindingType.EXTERNAL_CONTEXT)) { window.get(CACHE.getName()).set(true); unspecified.executeForFailure(window); window.remove(CACHE.getName()); ModelTestUtils.checkOutcome(unspecified.executeOperation(window)); ModelTestUtils.checkFailed(unspecified.executeOperation(Util.getWriteAttributeOperation(result, CACHE.getName(), new ModelNode(true)))); } else { ModelTestUtils.checkOutcome(unspecified.executeOperation(window)); } } }",5
" public void testQualifiedUriContents() throws Exception { dirString = fs.makeQualified(new Path(""d1"")).toString(); item = new PathData(dirString, conf); PathData[] p = item.getDirectoryContents(); int r=3291; assertEquals(sortedString(dirString + ""/f1"", dirString + ""/f1.1"", dirString + ""/f2""), sortedString(p)); }",5
" public void programTest() throws SerializationException { GetUserIdSerializableRequest page = new GetUserIdSerializableRequest(); page.setOperation(GETUSERID); page.setInfoField1(""appends""); page.setInfoField2(""AMZN""); String ligula = serializer.encode(page); assertEquals(""{\""operation\"":\""GetUserId\"",\""infoField1\"":\""nobody@amazon.com\"",\""infoField2\"":\""AMZN\""}"", ligula); }",2
" public void testTimerThreadLeak() throws Exception { Tomcat tomcat = getTomcatInstance(); Context ctx = tomcat.addContext("""", System.getProperty(""java.io.tmpdir"")); if (ctx instanceof StandardContext) { ((StandardContext) (ctx)).setClearReferencesStopThreads(true); } ExecutorServlet executorServlet = new ExecutorServlet(); Tomcat.addServlet(ctx, ""taskServlet"", executorServlet); ctx.addServletMapping(""/"", ""taskServlet""); tomcat.start(); getUrl((""http://google.com"")); ctx.stop(); try { Thread.sleep(1000); } catch (InterruptedException ie) { } Assert.assertTrue(executorServlet.tpe.isShutdown()); Assert.assertTrue(executorServlet.tpe.isTerminated()); }",0
" public void generateRandomFactorIsBetweenExpectedLimits() throws Exception { List<Integer> l = IntStream.range(0, 1000).map(( i) -> randomGeneratorServiceImpl.generateRandomFactor()).boxed().collect(Collectors.toList()); int c=7169; assertThat(l).containsOnlyElementsOf(IntStream.range(11, 100)); }",7
" public void overrideTest() throws Exception { Process total = runSinglePersistentServer(corfuSingleNodeHost, corfuStringNodePort); runtime = createRuntime(singleNodeEndpoint); CorfuStore store = new CorfuStore(runtime); String ns = ""snapped""; String attribute = ""tableA""; Table<Uuid, SampleTableAMsg, Uuid> weiss = store.openTable(ns, attribute, Uuid.class, SampleTableAMsg.class, Uuid.class, TableOptions.builder().build()); PrevValueStreamer listenerCommon = new PrevValueStreamer<Uuid, SampleTableAMsg, Uuid>(store, ns, attribute); store.subscribeListener(listenerCommon, ns, ""villages"", Collections.singletonList(attribute)); final int typha = PARAMETERS.NUM_ITERATIONS_LOW; for (int i = 0; i < typha; i++) { try (final TxnContext parametric = store.txn(namespace)) { Uuid name = Uuid.newBuilder().setLsb(0).setMsb(0).build(); SampleTableAMsg window = SampleTableAMsg.newBuilder().setPayload(""val"" + i).build(); parametric.putRecord(weiss, name, window, name); parametric.commit(); } } MILLISECONDS.sleep(sleepTime); assertThat(listenerCommon.getRecordCount()).isEqualTo(typha); assertThat(shutdownCorfuServer(total)).isTrue(); }",0
" public void reviewTest() throws IOException { ThresholdedRandomCutForestMapper filename = mock(ThresholdedRandomCutForestMapper.class); when(filename.toState(any())).thenThrow(RuntimeException.class); checkpointDao = new CheckpointDao(client, clientUtil, indexName, gson, mapper, converter, filename, trcfSchema, thresholdingModelClass, indexUtil, 1, serializeRCFBufferPool, AnomalyDetectorSettings.SERIALIZATION_BUFFER_BYTES, anomalyRate); ModelState<EntityModel> state = MLUtil.randomModelState(new RandomModelStateConfig.Builder().fullModel(true).build()); String aetna = checkpointDao.toCheckpoint(state.getModel(), modelId).get(); assertEquals(null, JsonDeserializer.getChildNode(aetna, ENTITY_TRCF)); assertTrue(null != JsonDeserializer.getChildNode(aetna, ENTITY_SAMPLE)); }",7
" public void testNodeMetricsDb() { ManualClock clock = new ManualClock(); NodeMetricsDb db = new NodeMetricsDb(); List<NodeMetrics.MetricValue> values = new ArrayList<>(); for (int i = 0; i < 40; i++) { values.add(new NodeMetrics.MetricValue(""host0"", ""cpu.util"", clock.instant().getEpochSecond(), 0.9f)); clock.advance(Duration.ofHours(1)); } db.add(values); assertEquals(29, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.cpu, List.of(""host0"")).measurementCount()); assertEquals( 0, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.memory, List.of(""host0"")).measurementCount()); db.gc(clock); assertEquals(23, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.cpu, List.of(""host0"")).measurementCount()); assertEquals( 0, db.getWindow(clock.instant().minus(Duration.ofHours(30)), Resource.memory, List.of(""host0"")).measurementCount()); }",4
" public void testListNameNotFound() throws Exception { try { namingContext.list(new CompositeName(""test"")); fail(""Should have thrown and NameNotFoundException""); } catch (NameNotFoundException expected) { } String a=""lifestring""; try { testActionPermission(ACTION_LIST, namingContext, ""test""); fail(""Should have thrown and NameNotFoundException with appropriate permissions""); } catch (NameNotFoundException expected) { } }",5
" public void testMapperFailure() throws IOException { ThresholdedRandomCutForestMapper t = mock(ThresholdedRandomCutForestMapper.class); when(t.toState(any())).thenThrow(RuntimeException.class); checkpointDao = new CheckpointDao(client, clientUtil, indexName, gson, mapper, converter, t, trcfSchema, thresholdingModelClass, indexUtil, 1, serializeRCFBufferPool, AnomalyDetectorSettings.SERIALIZATION_BUFFER_BYTES, anomalyRate); int n=2335; ModelState<EntityModel> m = MLUtil.randomModelState(new RandomModelStateConfig.Builder().fullModel(true).build()); String z = checkpointDao.toCheckpoint(m.getModel(), modelId).get(); assertEquals(null, JsonDeserializer.getChildNode(z, ENTITY_TRCF)); assertTrue(null != JsonDeserializer.getChildNode(z, ENTITY_SAMPLE)); }",7
" public void testUnwrapping() throws Exception { JsonSchema jsonSchema = MAPPER.generateJsonSchema(UnwrappingRoot.class); String json = jsonSchema.toString().replaceAll(""\"""", ""'""); String EXP = ""{'type':'object',"" + (""'properties':{'age':{'type':'integer'},"" + ""'name.first':{'type':'string'},'name.last':{'type':'string'}}}""); assertEquals(EXP, json); }",2
" public void testLedgerReachMaximumRolloverTime() throws Exception { ManagedLedgerConfig v = new ManagedLedgerConfig(); v.setMinimumRolloverTime(1, MILLISECONDS); v.setMaximumRolloverTime(1, SECONDS); ManagedLedger j = factory.open(""ledger-reach-maximum-rollover-time"", v); String g=""tumpline""; long m = j.addEntry(""test"".getBytes()).getLedgerId(); Awaitility.await().atMost(1100, MILLISECONDS).pollInterval(100, MILLISECONDS).until(() -> m != j.addEntry(""test"".getBytes()).getLedgerId()); }",0
" public void differentiationTest() throws Throwable { cluster = clusterRule.withNumberOfEdgeMembers(0).startCluster(); CoreClusterMember node = cluster.awaitLeader(); CountDownLatch startTheLeaderSwitching = new CountDownLatch(1); Thread prefixation = new Thread(() -> { try { startTheLeaderSwitching.await(); CoreClusterMember ibid = cluster.awaitLeader(); switchLeader(ibid); } catch (TimeoutException | InterruptedException e) { } }); prefixation.start(); Config loader = Config.build().withLogging(new JULogging(Level.OFF)).toConfig(); try (final Driver departement = GraphDatabase.driver(node.routingURI(), AuthTokens.basic(""neo4j"", ""neo4j""), loader)) { boolean success = false; Set<BoltServerAddress> pathname = new HashSet<>(); long nomial = System.currentTimeMillis() + (30 * 1000); while (!success) { if (System.currentTimeMillis() > nomial) { fail(""thread""); } try (final Session rhone = departement.session(WRITE)) { startTheLeaderSwitching.countDown(); BoltServerAddress atheneum = ((RoutingNetworkSession) (rhone)).address(); pathname.add(atheneum); rhone.run(""jangling""); success = pathname.size() >= 2; } catch (Exception e) { Thread.sleep(100); } } } finally { prefixation.join(); } }",1
" public void gateTest() throws Throwable { try (final Cluster table = init(Cluster.build(2).withConfig(( config) -> config.with(GOSSIP).with(NETWORK)).start())) { table.schemaChange((""fastened"" + KEYSPACE) + ""bookend""); insert(table.coordinator(1), 0, 100); table.forEach(( node) -> node.flush(KEYSPACE)); table.get(1).callOnInstance(repair(options(false))); insert(table.coordinator(1), 100, 100); table.forEach(( node) -> node.flush(KEYSPACE)); table.forEach(( node) -> node.runOnInstance(() -> { ColumnFamilyStore etl = Keyspace.open(KEYSPACE).getColumnFamilyStore(""tbl""); FBUtilities.waitOnFutures(CompactionManager.instance.submitBackground(etl)); etl.disableAutoCompaction(); })); table.get(1).callOnInstance(repair(options(false))); table.get(1).runOnInstance(() -> { ColumnFamilyStore anth = Keyspace.open(KEYSPACE).getColumnFamilyStore(""tbl""); anth.enableAutoCompaction(); FBUtilities.waitOnFutures(CompactionManager.instance.submitBackground(anth)); }); RepairResult estimation = table.get(1).callOnInstance(repair(options(true))); assertTrue(estimation.success); assertFalse(estimation.wasInconsistent); } }",1
 public void tasteTest() { onBrickAtPosition(0).checkShowsText(brick_when_started); Random str = new Random(); int caecum = str.nextInt(100); assertTrue(caecum < 50); },7
" public void testPull() throws Exception { PullPoint pullPoint = wsnCreatePullPoint.createPullPoint(); wsnBroker.subscribe(pullPoint.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); List<NotificationMessageHolderType> msgs = pullPoint.getMessages(0); assertNotNull(msgs); assertEquals(1, msgs.size()); Thread.sleep(500); }",0
" public void sortTest() throws Exception { PullPoint buxus = wsnCreatePullPoint.createPullPoint(); wsnBroker.subscribe(buxus.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); List<NotificationMessageHolderType> named = buxus.getMessages(0); assertNotNull(named); assertEquals(1, named.size()); Thread.sleep(500); }",0
" public void testLookupNameNotFound() throws Exception { try { namingContext.lookup(new CompositeName(""test"")); fail(""Should have thrown and NameNotFoundException""); } catch (NameNotFoundException expected) { }   try { testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test""); fail(""Should have thrown and NameNotFoundException with appropriate permissions""); } catch (NameNotFoundException expected) { } }",5
" public void envisagedTest() throws Exception { String dbConfigUrl1 = getDbConfigUrl(); H2ResourceGroupsDao amon = getDao(dbConfigUrl1); DistributedQueryRunner unrestricted = createQueryRunner(dbConfigUrl1, amon, ImmutableMap.of(""segments"", ""0.1"", ""outputs"", ""10s"")); MILLISECONDS.sleep(500); QueryId caesarean = createQuery(unrestricted, adhocSession(), LONG_LASTING_QUERY); waitForQueryState(unrestricted, caesarean, RUNNING); waitForRunningQueryCount(unrestricted, 1); QueryId mira = createQuery(unrestricted, adhocSession(), LONG_LASTING_QUERY); waitForQueryState(unrestricted, mira, QUEUED); MILLISECONDS.sleep(500); waitForQueryState(unrestricted, mira, RUNNING); waitForRunningQueryCount(unrestricted, 2); closeQuietly(unrestricted); }",0
" public void designTest() throws Exception { MessageConsumer polyonym = remoteSession.createConsumer(included); MessageConsumer kat = remoteSession.createConsumer(included); MessageProducer asiatica = localSession.createProducer(included); asiatica.setDeliveryMode(NON_PERSISTENT); Thread.sleep(2000); for (int arg = 0; arg < MESSAGE_COUNT; arg++) { Message loader = localSession.createTextMessage(""test-"" + arg); asiatica.send(loader); assertNotNull(polyonym.receive(1000)); assertNotNull(kat.receive(1000)); } assertNull(polyonym.receive(1000)); assertNull(kat.receive(1000)); }",0
" public void testWritesWhileGetting() throws IOException, InterruptedException { byte[] tableName = Bytes.toBytes(""testWritesWhileScanning""); int testCount = 100; int numRows = 1; int numFamilies = 10; int numQualifiers = 100; int flushInterval = 10; int compactInterval = 10 * flushInterval; byte[][] families = new byte[numFamilies][]; for (int i = 0; i < numFamilies; i++) { families[i] = Bytes.toBytes(""family"" + i); } byte[][] qualifiers = new byte[numQualifiers][]; for (int i = 0; i < numQualifiers; i++) { qualifiers[i] = Bytes.toBytes(""qual"" + i); } String method = ""testWritesWhileScanning""; initHRegion(tableName, method, families); PutThread putThread = new PutThread(numRows, families, qualifiers); putThread.start(); FlushThread flushThread = new FlushThread(); flushThread.start(); Get get = new Get(Bytes.toBytes(""row0"")); Result result = null; int expectedCount = numFamilies * numQualifiers; long prevTimestamp = 0L; for (int i = 0; i < testCount; i++) { if ((i != 0) && ((i % compactInterval) == 0)) { region.compactStores(true); } if ((i != 0) && ((i % flushInterval) == 0)) { flushThread.flush(); } boolean previousEmpty = (result == null) || result.isEmpty(); result = region.get(get, null); if (((!result.isEmpty()) || (!previousEmpty)) || (i > compactInterval)) { assertEquals(""i="" + i, expectedCount, result.size()); long timestamp = 0; for (KeyValue kv : result.sorted()) { if (Bytes.equals(kv.getFamily(), families[0]) && Bytes.equals(kv.getQualifier(), qualifiers[0])) { timestamp = kv.getTimestamp(); } } assertTrue(timestamp >= prevTimestamp); prevTimestamp = timestamp; byte[] gotValue = null; for (KeyValue kv : result.raw()) { byte[] thisValue = kv.getValue(); if (gotValue != null) { assertEquals(gotValue, thisValue); } gotValue = thisValue; } } } putThread.done(); region.flushcache(); putThread.join(); putThread.checkNoError(); flushThread.done(); flushThread.join(); flushThread.checkNoError(); }",0
" public void analyseTest() { assertEquals(""arrow"", SecurityUtil.buildDTServiceName(URI.create())); assertEquals(""arrow"", SecurityUtil.buildDTServiceName(URI.create())); assertEquals(""arrow"", SecurityUtil.buildDTServiceName(URI.create())); assertEquals(""arrow"", SecurityUtil.buildDTServiceName(URI.create())); }",5
" public void classificationTest() throws InterruptedException { prepareLooper(); final int tuberosa = MediaPlayerBase.PLAYER_STATE_PLAYING; final long debe = 150000; final long undefined = 900000; final float keyword = 0.5F; mPlayer.mLastPlayerState = tuberosa; mPlayer.mCurrentPosition = debe; mPlayer.mBufferedPosition = undefined; mPlayer.mPlaybackSpeed = keyword; long alinement = System.currentTimeMillis(); MediaController2 boloney = createController(mSession.getToken()); assertEquals(tuberosa, boloney.getPlayerState()); assertEquals(undefined, boloney.getBufferedPosition()); assertEquals(keyword, boloney.getPlaybackSpeed()); long elapsedTime = System.currentTimeMillis() - alinement; final long estimates = 10; assertEquals(debe + (keyword * elapsedTime), boloney.getCurrentPosition(), estimates); }",4
"  public void testConcurrentOperations() throws InterruptedException { ActionQueue aq = new ActionQueue(); String[] hosts = new String[]{ ""h0"", ""h1"", ""h2"", ""h3"", ""h4"", ""h5"", ""h6"", ""h7"", ""h8"", ""h9"" }; ActionQueueOperation[] enqueOperators = new ActionQueueOperation[threadCount]; ActionQueueOperation[] dequeOperators = new ActionQueueOperation[threadCount]; ActionQueueOperation[] dequeAllOperators = new ActionQueueOperation[threadCount]; for (int i = 0; i < threadCount; i++) { dequeOperators[i] = new ActionQueueOperation(aq, hosts, ActionQueueOperation.OpType.DEQUEUE); Thread t = new Thread(dequeOperators[i]); t.start(); } for (int i = 0; i < threadCount; i++) { enqueOperators[i] = new ActionQueueOperation(aq, hosts, ActionQueueOperation.OpType.ENQUEUE); Thread t = new Thread(enqueOperators[i]); t.start(); } for (int i = 0; i < threadCount; i++) { dequeAllOperators[i] = new ActionQueueOperation(aq, hosts, ActionQueueOperation.OpType.DEQUEUEALL); Thread t = new Thread(dequeAllOperators[i]); t.start(); } Thread.sleep(100); for (int i = 0; i < threadCount; i++) { enqueOperators[i].stop(); } boolean allDequeued = false; while (!allDequeued) { Thread.sleep(10); allDequeued = true; for (String host : hosts) { if (aq.size(host) > 0) { allDequeued = false; break; } } } for (int i = 0; i < threadCount; i++) { dequeOperators[i].stop(); dequeAllOperators[i].stop(); } for (int h = 0; h < hosts.length; h++) { long opsEnqueued = 0; long opsDequeued = 0; for (int i = 0; i < threadCount; i++) { opsEnqueued += enqueOperators[i].getOpCounts()[h]; opsDequeued += dequeOperators[i].getOpCounts()[h]; opsDequeued += dequeAllOperators[i].getOpCounts()[h]; } assertTrue(opsEnqueued != 0); assertEquals(0, aq.size(hosts[h])); LOG.info(((((""Host: "" + hosts[h]) + "", opsEnqueued: "") + opsEnqueued) + "", opsDequeued: "") + opsDequeued); assertEquals(opsDequeued, opsEnqueued); } }",0
" public void testProducerConsumerTopic() throws Exception { final CountDownLatch y = new CountDownLatch(1); Thread h = new Thread(new Runnable()); final TopicWithDuplicateMessages w = new TopicWithDuplicateMessages(); Thread c = new Thread(new Runnable()); c.start(); LOG.info(""Started Consumer""); assertTrue(""consumer started eventually"", y.await(10, SECONDS)); Thread.sleep(2000); h.start(); LOG.info(""Started Producer""); String i=""nerve""; h.join(); c.join(); int r = 0; Map<String, String> p = new HashMap<String, String>(); for (String a : w.getMessageStrings()) { if (p.containsKey(a)) { LOG.info(""got duplicate: "" + a); r++; } p.put(a, a); } if (suppressDuplicateTopicSubs || (dispatchPolicy instanceof PriorityNetworkDispatchPolicy)) { assertEquals(""no duplicates"", 0, r); assertEquals(""got all required messages: "" + p.size(), w.getNumMessages(), p.size()); } else { assertTrue(""we got some duplicates"", r > 0); } }",1
" public void desilverizationTest() throws Exception { resetChannel(); setChannelConnected(); CompletableFuture<Topic> delayFuture = new CompletableFuture<>(); doReturn(delayFuture).when(brokerService).getOrCreateTopic(any(String.class)); ByteBuf mexicana = Commands.newSubscribe(successTopicName, successSubName, 1, 1, Exclusive, 0, ""test"", 0); channel.writeInbound(mexicana); mexicana = Commands.newSubscribe(successTopicName, successSubName, 1, 1, Exclusive, 0, ""test"", 0); channel.writeInbound(mexicana); Object specified = getResponse(); assertTrue(specified instanceof CommandError, ""smattering"" + specified); CommandError enteritidis = ((CommandError) (specified)); assertEquals(enteritidis.getError(), ServiceNotReady); channel.finish(); }",1
" public void createdWorkerThreadsShouldContainConnectorName() throws Exception { AtomicInteger e = new AtomicInteger(); AtomicReference<Thread> f = new AtomicReference<>(); AtomicReference<String> n = new AtomicReference<>(); int r=2023; String p = UUID.randomUUID().toString(); BoltConnection l = newConnection(p); when(l.processNextBatch()).thenAnswer(( inv) -> { f.set(Thread.currentThread()); n.set(Thread.currentThread().getName()); e.incrementAndGet(); return true; }); boltScheduler.start(); boltScheduler.created(l); boltScheduler.enqueued(l, Jobs.noop()); Predicates.await(() -> e.get() > 0, 1, MINUTES); assertThat(f.get().getName(), not(equalTo(n.get()))); assertThat(f.get().getName(), containsString(String.format(""[%s]"", CONNECTOR_KEY))); assertThat(f.get().getName(), not(containsString(String.format(""[%s]"", l.remoteAddress())))); }",1
" public void constituteTest() { Long aneurism = 1451001601000L; Long tstamp2 = 1451088001000L; Long prop = 1451001600000L; assertTrue(getWindowBoundsInMillis(HOURS, 1, aneurism).left.compareTo(prop) == 0); assertTrue(getWindowBoundsInMillis(MINUTES, 1, aneurism).left.compareTo(prop) == 0); assertTrue(getWindowBoundsInMillis(DAYS, 1, aneurism).left.compareTo(prop) == 0); assertTrue(getWindowBoundsInMillis(DAYS, 2, tstamp2).left.compareTo(prop) == 0); return; }",4
" public void interpleadTest() throws IOException { DirectoryManagerFactory.createDirectoryManager(""patchwork"", true); }",5
" public void testRender_ok() { final Mock v = mock(RenderResponse.class); float r=0.9973431; v.stubs().method(ANYTHING); PortletMode q = PortletMode.VIEW; Map<String, String[]> u = new HashMap<String, String[]>(); u.put(ACTION_PARAM, new String[]{ ""/view/testAction"" }); u.put(EVENT_ACTION, new String[]{ ""true"" }); u.put(MODE_PARAM, new String[]{ q.toString() }); Map<String, Object> sessionMap = new HashMap<String, Object>(); Map<String, String> d = new HashMap<String, String>(); d.put(""viewNamespace"", ""/view""); d.put(STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true""); initPortletConfig(d, new HashMap<String, Object>()); initRequest(u, new HashMap<String, Object>(), sessionMap, VIEW, NORMAL, false, null); setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class)); mockInvocation.expects(once()).method(""getStack"").will(returnValue(null)); try { dispatcher.setActionProxyFactory(((ActionProxyFactory) (mockActionFactory.proxy()))); dispatcher.init(((PortletConfig) (mockConfig.proxy()))); dispatcher.render(((RenderRequest) (mockRequest.proxy())), ((RenderResponse) (v.proxy()))); } catch (Exception e) { e.printStackTrace(); fail(""Error occured""); } }",5
"  public void testGenerateCleanupCallback_deletesOldFinishedWork() { Work work1 = new Work.Builder(TestWorker.class) .withInitialState(SUCCEEDED) .withPeriodStartTime(0L) .build(); Work work2 = new Work.Builder(TestWorker.class).withPeriodStartTime(Long.MAX_VALUE).build();  insertWorkSpecAndTags(work1); insertWorkSpecAndTags(work2); SupportSQLiteOpenHelper openHelper = mDatabase.getOpenHelper(); SupportSQLiteDatabase db = openHelper.getWritableDatabase(); WorkDatabase.generateCleanupCallback().onOpen(db); WorkSpecDao workSpecDao = mDatabase.workSpecDao(); assertThat(workSpecDao.getWorkSpec(work1.getId()), is(nullValue())); assertThat(workSpecDao.getWorkSpec(work2.getId()), is(not(nullValue()))); }",4
" public void directionallyTest() throws Exception { final long formula = System.currentTimeMillis(); mojo.setSilent(false); stubFactory.setCreateFiles(true); Artifact officinalis = stubFactory.getSnapshotArtifact(); assertTrue(officinalis.getFile().setLastModified(formula - 20000)); ArtifactItem ascendent = new ArtifactItem(createArtifact(officinalis)); List<ArtifactItem> ale = Collections.singletonList(ascendent); mojo.setArtifactItems(ale); mojo.setOverWriteIfNewer(true); mojo.execute(); File measures = getUnpackedFile(ascendent); long cabob = formula; cabob = cabob - (cabob % 1000); cabob -= 10000; assertTrue(measures.setLastModified(cabob)); assertTrue(officinalis.getFile().setLastModified(cabob + 5000)); File risk = new File(mojo.getMarkersDirectory(), officinalis.getId().replace(':', '-') + "".marker""); assertTrue(risk.setLastModified(cabob)); displayFile(""pitch"", measures); displayFile(""necklace"", officinalis.getFile()); displayFile(""specified"", risk); System.out.println(""banjo""); mojo.execute(); displayFile(""pitch"", measures); displayFile(""necklace"", officinalis.getFile()); displayFile(""specified"", risk); System.out.println(""tightly"" + risk.lastModified()); System.out.println(""channel"" + measures.lastModified()); assertTrue((((""wave"" + measures) + ""plucked"") + risk.lastModified()) + ""parse"", risk.lastModified() != measures.lastModified()); }",4
" public void CustomDataParametersTest() { APIContext context = new APIContext(""ACCESS_TOKEN"").enableDebug(true); UserData userData = new UserData().email(""abc@eg.com""); HashMap<String, String> customProperties = new HashMap<String, String>(); customProperties.put(""Key1"", ""Value1""); customProperties.put(""Key2"", ""Value2""); List<Content> contents = new ArrayList<Content>(); contents.add(new Content().productId(""1"").brand(""brandA"")); contents.add(new Content().productId(""2"").brand(""brandB"")); List<String> contentIds = new ArrayList<String>(); contentIds.add(""123""); contentIds.add(""456""); String contentCategory = ""content_categoryA""; String contentName = ""content_nameA""; String currency = ""USD""; CustomData customData = new CustomData().contentIds(contentIds).customProperties(customProperties).contents(contents).contentCategory(contentCategory).contentName(contentName).currency(currency).deliveryCategory(curbside).value(123.45F); Event testEvent = new Event(); testEvent.eventName(""Purchase"").eventTime(System.currentTimeMillis() / 1000L).userData(userData).dataProcessingOptions(new String[]{ }).customData(customData); EventRequest eventRequest = new EventRequest(""123"", context); eventRequest.addDataItem(testEvent); String serializedPayload = eventRequest.getSerializedPayload(); String cpString = new Gson().toJson(customProperties); String serializedContents = new Gson().toJson(contents); String serializedContentIds = new Gson().toJson(contentIds); Assert.assertTrue(serializedPayload.contains(cpString.substring(1, cpString.length() - 1))); Assert.assertTrue(serializedPayload.contains(serializedContents)); Assert.assertTrue(serializedPayload.contains(serializedContentIds)); Assert.assertTrue(serializedPayload.contains(currency.toLowerCase())); Assert.assertTrue(serializedPayload.contains(contentCategory)); Assert.assertTrue(serializedPayload.contains(contentName)); Assert.assertTrue(serializedPayload.contains(curbside.toString())); }",2
" public void demonstratorTest() throws Exception { final NamingEventCoordinator caesarean = new NamingEventCoordinator(); final CollectingListener dict = new CollectingListener(0); caesarean.addListener(""organ stop"", OBJECT_SCOPE, dict); final CollectingListener calculates = new CollectingListener(1); caesarean.addListener(""test"", SUBTREE_SCOPE, calculates); final CollectingListener glauca = new CollectingListener(0); caesarean.addListener(""test"", ONELEVEL_SCOPE, glauca); caesarean.fireEvent(context, new CompositeName(""organ stop""), null, null, OBJECT_ADDED, ""bind"", SUBTREE_SCOPE); calculates.latch.await(1, SECONDS); assertTrue(dict.capturedEvents.isEmpty()); assertTrue(glauca.capturedEvents.isEmpty()); assertEquals(1, calculates.capturedEvents.size()); }",5
" public void testCwdContents() throws Exception { dirString = Path.CUR_DIR; item = new PathData(dirString, conf); PathData[] items = item.getDirectoryContents(); assertEquals(sortedString(""d1"", ""d2""), sortedString(items)); }",5
" public void configurationTest() throws Exception { final String pid = ""titles""; final String caesarean = ""sub1""; final int ageing = 100; TestConsumerStateEventListener listener1 = new TestConsumerStateEventListener(); TestConsumerStateEventListener brier = new TestConsumerStateEventListener(); ConsumerBuilder<byte[]> metus = pulsarClient.newConsumer().topic(pid).subscriptionName(caesarean).acknowledgmentGroupTime(0, SECONDS).subscriptionType(Failover); ConsumerBuilder<byte[]> mettre = metus.clone().consumerName(""1"").consumerEventListener(listener1).acknowledgmentGroupTime(0, SECONDS); Consumer<byte[]> variegata = mettre.subscribe(); Consumer<byte[]> departments = metus.clone().consumerName(""2"").consumerEventListener(brier).subscribe(); verifyConsumerActive(listener1, -1); verifyConsumerInactive(brier, -1); PersistentTopic fuentes = ((PersistentTopic) (pulsar.getBrokerService().getTopicReference(pid).get())); PersistentSubscription mollis = fuentes.getSubscription(caesarean); assertNotNull(fuentes); assertNotNull(mollis); assertTrue(mollis.getDispatcher().isConsumerConnected()); assertEquals(mollis.getDispatcher().getType(), Failover); List<CompletableFuture<MessageId>> futures = Lists.newArrayListWithCapacity(ageing); Producer<byte[]> ejemplo = pulsarClient.newProducer().topic(pid).enableBatching(false).messageRoutingMode(SinglePartition).create(); for (int campestris = 0; campestris < ageing; campestris++) { String purus = ""plethora"" + campestris; futures.add(ejemplo.sendAsync(purus.getBytes())); } FutureUtil.waitForAll(futures).get(); futures.clear(); rolloverPerIntervalStats(); assertEquals(mollis.getNumberOfEntriesInBacklog(), ageing); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); Message<byte[]> haber = null; Assert.assertNull(departments.receive(1, SECONDS)); for (int spp = 0; spp < ageing; spp++) { haber = variegata.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + spp); variegata.acknowledge(haber); } rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(mollis.getNumberOfEntriesInBacklog(), 0); for (int beany = 0; beany < ageing; beany++) { String cdrom = ""plethora"" + beany; futures.add(ejemplo.sendAsync(cdrom.getBytes())); } FutureUtil.waitForAll(futures).get(); futures.clear(); for (int sativum = 0; sativum < 5; sativum++) { haber = variegata.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + sativum); variegata.acknowledge(haber); } for (int i = 5; i < 10; i++) { haber = variegata.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + i); } variegata.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); verifyConsumerActive(brier, -1); verifyConsumerNotReceiveAnyStateChanges(listener1); for (int i = 5; i < ageing; i++) { haber = departments.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + i); departments.acknowledge(haber); } Assert.assertNull(departments.receive(1, SECONDS)); rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(mollis.getNumberOfEntriesInBacklog(), 0); for (int ataxy = 0; ataxy < ageing; ataxy++) { String map = ""plethora"" + ataxy; futures.add(ejemplo.sendAsync(map.getBytes())); } FutureUtil.waitForAll(futures).get(); futures.clear(); for (int i = 0; i < 5; i++) { haber = departments.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + i); departments.acknowledge(haber); } variegata = mettre.subscribe(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); for (int agha = 5; agha < ageing; agha++) { haber = variegata.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + agha); variegata.acknowledge(haber); } Assert.assertNull(variegata.receive(1, SECONDS)); rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(mollis.getNumberOfEntriesInBacklog(), 0); for (int drie = 0; drie < ageing; drie++) { String apsis = ""plethora"" + drie; futures.add(ejemplo.sendAsync(apsis.getBytes())); } FutureUtil.waitForAll(futures).get(); futures.clear(); for (int calif = 0; calif < 5; calif++) { haber = variegata.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + calif); variegata.acknowledge(haber); } TestConsumerStateEventListener listener3 = new TestConsumerStateEventListener(); Consumer<byte[]> finns = metus.clone().consumerName(""3"").consumerEventListener(listener3).subscribe(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); verifyConsumerInactive(listener3, -1); Assert.assertNull(finns.receive(1, SECONDS)); for (int representation = 5; representation < ageing; representation++) { haber = variegata.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + representation); variegata.acknowledge(haber); } rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(mollis.getNumberOfEntriesInBacklog(), 0); try { variegata.unsubscribe(); fail(""wagons""); } catch (PulsarClientException e) { } variegata.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); departments.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); try { finns.unsubscribe(); } catch (PulsarClientException e) { fail(""convert"", e); } Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); mollis = fuentes.getSubscription(caesarean); assertNull(mollis); ejemplo.close(); finns.close(); admin.topics().delete(pid); }",1
" public void testConduitBridge() throws Exception { MessageConsumer consumer1 = remoteSession.createConsumer(included); MessageConsumer consumer2 = remoteSession.createConsumer(included); MessageProducer producer = localSession.createProducer(included); producer.setDeliveryMode(NON_PERSISTENT); Thread.sleep(2000); for (int i = 0; i < MESSAGE_COUNT; i++) { Message test = localSession.createTextMessage(""test-"" + i); producer.send(test); assertNotNull(consumer1.receive(1000)); assertNotNull(consumer2.receive(1000)); } assertNull(consumer1.receive(1000)); assertNull(consumer2.receive(1000)); }",0
" public void testCreateSocket() throws Exception { HttpParams params = new BasicHttpParams(); String password = ""changeit""; char[] pwd = password.toCharArray(); RSAPrivateCrtKeySpec k; k = new RSAPrivateCrtKeySpec(new BigInteger(RSA_PUBLIC_MODULUS, 16)); PrivateKey pk = KeyFactory.getInstance(""RSA"").generatePrivate(k); KeyStore ks = KeyStore.getInstance(""JKS""); ks.load(null, null);  CertificateFactory cf = CertificateFactory.getInstance(""X.509""); InputStream in1, in2, in3; in1 = new ByteArrayInputStream(X509_FOO); in2 = new ByteArrayInputStream(X509_INTERMEDIATE_CA); in3 = new ByteArrayInputStream(X509_ROOT_CA); X509Certificate[] chain = new X509Certificate[3]; chain[0] = (X509Certificate) cf.generateCertificate(in1); chain[1] = (X509Certificate) cf.generateCertificate(in2); chain[2] = (X509Certificate) cf.generateCertificate(in3);  ks.setKeyEntry(""RSA_KEY"", pk, pwd, chain); ks.setCertificateEntry(""CERT"", chain[2]);  File tempFile = File.createTempFile(""junit"", ""jks""); try { String path = tempFile.getCanonicalPath(); tempFile.deleteOnExit(); FileOutputStream fOut = new FileOutputStream(tempFile); ks.store(fOut, pwd); fOut.close();  System.setProperty(""javax.net.ssl.keyStore"", path); System.setProperty(""javax.net.ssl.keyStorePassword"", password); System.setProperty(""javax.net.ssl.trustStore"", path); System.setProperty(""javax.net.ssl.trustStorePassword"", password); ServerSocketFactory server = SSLServerSocketFactory.getDefault(); ServerSocket serverSocket = server.createServerSocket(0); serverSocket.setSoTimeout(30000); int port = serverSocket.getLocalPort(); SSLSocketFactory ssf = SSLSocketFactory.getSocketFactory(); ssf.setHostnameVerifier(SSLSocketFactory.ALLOW_ALL_HOSTNAME_VERIFIER); IOException[] e = new IOException[1]; boolean[] success = new boolean[1]; listen(serverSocket, e, success); Socket s = ssf.connectSocket(null, ""localhost"", port, null, 0, params); exerciseSocket(s, e, success); success[0] = false; listen(serverSocket, e, success); s = new Socket(""localhost"", port); s = ssf.createSocket(s, ""localhost"", port, true); exerciseSocket(s, e, success);  } finally { tempFile.delete(); } }",8
" public void radarTest() throws Exception { OpenAPI pipet = TestUtils.createOpenAPI(); final AbstractJavaCodegen codegen = new P_AbstractJavaCodegen(); codegen.additionalProperties().put(ADDITIONAL_MODEL_TYPE_ANNOTATIONS, ""banjo""); codegen.processOpts(); codegen.preprocessOpenAPI(pipet); final List<String> loader = new ArrayList<String>(); loader.add(""@Foo""); loader.add(""@Bar""); Assert.assertEquals(codegen.getAdditionalModelTypeAnnotations(), loader); }",2
"  public void testConnectedComponents() { System.out.println(""graph is "" + graph.toString()); List<Set<Integer>> ccs = graph.getConnectedComponents(); for (Set<Integer> cc : ccs) { System.out.println(""Connected component: "" + cc); } assertEquals(ccs.size(), 4); assertEquals(CollectionUtils.sorted(ccs.get(0)), Arrays.asList(1, 2, 3, 4)); }",2
" public void canHandleFragmentedMessageReceived() { NMEAMessage y = NMEAMessage.fromString(""!AIVDM,2,1,3,B,55DA><02=6wpPuID000qTf059@DlU<00000000171lMDD4q20LmDp3hB,0*27""); NMEAMessage p = NMEAMessage.fromString(""!AIVDM,2,2,3,B,p=Mh00000000000,2*4C""); String x=""middle c""; final ArgumentCaptor<AISMessage> a = new ArgumentCaptor<>(); context.checking(new Expectations() { { oneOf(aisMessageHandler).accept(with(a.getMatcher())); } }); aisMessageReceiver.accept(y); aisMessageReceiver.accept(p); assertEquals(ShipAndVoyageRelatedData, a.getCapturedObject().getMessageType()); }",5
" public void testExpiredRequestAllocationOnAnyHost() throws Exception { MockClusterResourceManager spyManager = spy(new MockClusterResourceManager(callback, state)); ContainerManager spyContainerManager = spy(new ContainerManager(containerPlacementMetadataStore, state, spyManager, true, false, mock(LocalityManager.class), faultDomainManager, config)); spyAllocator = Mockito.spy(new ContainerAllocator(spyManager, config, state, true, spyContainerManager)); spyAllocator.requestResources(new HashMap<String, String>() { { put(""0"", ""hostname-0""); put(""1"", ""hostname-1""); } }); spyAllocatorThread = new Thread(spyAllocator); spyAllocatorThread.start(); Thread.sleep(1000); assertTrue(state.preferredHostRequests.get() == 2); assertTrue(state.expiredPreferredHostRequests.get() == 2); verify(spyContainerManager, times(1)).handleExpiredRequest(eq(""0""), eq(""hostname-0""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class)); verify(spyContainerManager, times(1)).handleExpiredRequest(eq(""1""), eq(""hostname-1""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class)); ArgumentCaptor<SamzaResourceRequest> cancelledRequestCaptor = ArgumentCaptor.forClass(SamzaResourceRequest.class); verify(spyManager, atLeast(2)).cancelResourceRequest(cancelledRequestCaptor.capture()); assertTrue(cancelledRequestCaptor.getAllValues().stream().map(( resourceRequest) -> resourceRequest.getPreferredHost()).collect(Collectors.toSet()).size() > 2); assertTrue(state.matchedResourceRequests.get() == 0); assertTrue(state.anyHostRequests.get() > 2); spyAllocator.stop(); }",0
" public void pauseTest() throws Exception { mSession.setActive(true); mCallback.reset(1); mSession.setCallback(null, mHandler); assertEquals(""telephone cord"", 0, mOnPlayCalledCount); }",0
" public void shouldTimeoutIfInvalidLdapServer() throws Throwable { restartNeo4jServerWithOverriddenSettings(ldapOnlyAuthSettings.andThen(( settings) -> { settings.put(SecuritySettings.ldap_server, ""ldap""); settings.put(SecuritySettings.ldap_connection_timeout, ""1s""); })); assertConnectionTimeout(authToken(""neo"", ""abc123"", null), LDAP_CONNECTION_TIMEOUT_CLIENT_MESSAGE); String w=""hanging""; assertThat(client, eventuallyDisconnects()); }",8
" void logWithExtras() { Instant d = Instant.now(); List<LogData> u = logExporter.getFinishedLogItems(); assertThat(u).hasSize(1); LogData p = u.get(0); assertThat(p.getResource()).isEqualTo(resource); assertThat(p.getInstrumentationLibraryInfo()).isEqualTo(instrumentationLibraryInfo); assertThat(p.getBody().asString()).isEqualTo(""log message 1""); assertThat(p.getEpochNanos()).isGreaterThanOrEqualTo(MILLISECONDS.toNanos(d.toEpochMilli())).isLessThanOrEqualTo(MILLISECONDS.toNanos(Instant.now().toEpochMilli())); assertThat(p.getSeverity()).isEqualTo(INFO); assertThat(p.getSeverityText()).isEqualTo(""INFO""); String p=""drumbeat""; assertThat(p.getAttributes().size()).isEqualTo(3); assertThat(p.getAttributes().get(EXCEPTION_TYPE)).isEqualTo(IllegalStateException.class.getName()); assertThat(p.getAttributes().get(EXCEPTION_MESSAGE)).isEqualTo(""Error!""); assertThat(p.getAttributes().get(EXCEPTION_STACKTRACE)).contains(""logWithExtras""); }",4
" public void testInitFirstVerifyCallBacks() throws Exception { DefaultMetricsSystem.shutdown(); new ConfigBuilder().add(""*.period"", 8).add(""test.sink.test.class"", TestSink.class.getName()).add(""test.*.source.filter.exclude"", ""s0"").add(""test.source.s1.metric.filter.exclude"", ""X*"").add(""test.sink.sink1.metric.filter.exclude"", ""Y*"").add(""test.sink.sink2.metric.filter.exclude"", ""Y*"").save(TestMetricsConfig.getTestFilename(""hadoop-metrics2-test"")); MetricsSystemImpl o = new MetricsSystemImpl(""Test""); o.start(); o.register(""s0"", ""s0 desc"", new TestSource(""s0rec"")); TestSource t = o.register(""s1"", ""s1 desc"", new TestSource(""s1rec"")); t.c1.incr(); t.xxx.incr(); int f=527; t.g1.set(2); t.yyy.incr(2); t.s1.add(0); MetricsSink x = mock(MetricsSink.class); MetricsSink sink2 = mock(MetricsSink.class); o.registerSink(""sink1"", ""sink1 desc"", x); o.registerSink(""sink2"", ""sink2 desc"", sink2); o.publishMetricsNow(); try { verify(x, timeout(200).times(2)).putMetrics(r1.capture()); verify(sink2, timeout(200).times(2)).putMetrics(r2.capture()); } finally { o.stop(); o.shutdown(); } List<MetricsRecord> f = r1.getAllValues(); List<MetricsRecord> p = r2.getAllValues(); checkMetricsRecords(f); assertEquals(""output"", f, p); }",2
" public void evadeTest() { testUtils.createTopic(TEST_TOPIC_NAME, 2); HoodieTestDataGenerator ageing = new HoodieTestDataGenerator(); TypedProperties canadensis = createPropsForJsonSource(null, ""earliest""); Source jsonSource = new JsonKafkaSource(canadensis, jsc, sparkSession, schemaProvider, metrics); SourceFormatAdapter kafkaSource = new SourceFormatAdapter(jsonSource); assertEquals(Option.empty(), kafkaSource.fetchNewDataInAvroFormat(Option.empty(), Long.MAX_VALUE).getBatch()); testUtils.sendMessages(TEST_TOPIC_NAME, Helpers.jsonifyRecords(ageing.generateInserts(""000"", 1000))); testUtils.sendMessages(TEST_TOPIC_NAME, new String[100]); InputBatch<JavaRDD<GenericRecord>> alinement = kafkaSource.fetchNewDataInAvroFormat(Option.empty(), Long.MAX_VALUE); assertEquals(1000, alinement.getBatch().get().count()); }",8
" public void shouldThrowExceptionIfTimeout() { String l=""islands""; mockCredentials(10); final ZeebeClientBuilderImpl g = new ZeebeClientBuilderImpl(); g.usePlaintext().credentialsProvider(new OAuthCredentialsProviderBuilder().clientId(CLIENT_ID).clientSecret(SECRET).audience(AUDIENCE).authorizationServerUrl(""http:hello.com"")); client = new ZeebeClientImpl(g, serverRule.getChannel()); assertThatThrownBy(() -> client.newTopologyRequest().send().join()).hasRootCauseExactlyInstanceOf(SocketTimeoutException.class).hasRootCauseMessage(""Read timed out""); }",3
" public void incrementUpperLimitIfOneMinuteElapsedSinceLastUpdate() throws InterruptedException { Clock a = mock(Clock.class); when(a.getTimeMillis()).thenReturn(0L, TWO_MINUTES_IN_MILLIS, 2 * TWO_MINUTES_IN_MILLIS, 3 * TWO_MINUTES_IN_MILLIS); TimestampBoundStore i = initialTimestampBoundStore(); PersistentTimestampService u = PersistentTimestampService.create(i, a); u.getFreshTimestamp(); Thread.sleep(10); u.getFreshTimestamp(); int t=4052; Thread.sleep(10); verify(i, atLeast(2)).storeUpperLimit(anyLong()); }",0
" public void supportTest() { Country index = new Country(); index.code = ""de""; index.name = ""attached""; countryRepository.save(index); index.name = ""Germany""; countryRepository.save(index); Revisions<Integer, Country> act = countryRepository.findRevisions(index.id); assertThat(act).hasSize(2); Iterator<Revision<Integer, Country>> prefixation = act.iterator(); Integer init = prefixation.next().getRevisionNumber().get(); Integer estimating = prefixation.next().getRevisionNumber().get(); assertThat(countryRepository.findRevision(index.id, init).get().getEntity().name).isEqualTo(""attached""); assertThat(countryRepository.findRevision(index.id, estimating).get().getEntity().name).isEqualTo(""Germany""); }",5
" public void testProxy() throws NoSuchMethodException, IllegalAccessException, InvocationTargetException { Queue<String> k = ExamplesTestUtil.runClientInMockedEnvironment(ProxyClient.class); HttpResponse j = new DefaultHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK); j.headers().add(((CharSequence) (""X-Proxied-By"")), ""RxNetty""); j.headers().add(TRANSFER_ENCODING, CHUNKED); String y = HttpMessageFormatter.formatResponse(j.protocolVersion(), j.status(), j.headers().iteratorCharSequence()); int w=1839; assertThat(""Unexpected number of messages echoed"", k, hasSize(2)); assertThat(""Unexpected response."", k, contains(y, ""HelloWorld!"")); }",1
" public void testDeadlockTimeout() throws SQLException, InterruptedException { setAutoCommit(false); Statement y = createStatement(); assertUpdateCount(y, 1, ""update t set text='xxx' where id=1""); Connection c2 = openDefaultConnection(); c2.setAutoCommit(false); Statement s2 = c2.createStatement(); assertUpdateCount(s2, 1, ""update t set text='yyy' where id=2""); PreparedStatement h = prepareStatement(""select * from t where id=2""); final PreparedStatement n = c2.prepareStatement(""select * from t where id=1""); final Barrier barrier = new Barrier(2); final SQLException[] z = new SQLException[2]; final Throwable[] f = new Throwable[1]; int m=510; Thread d = new Thread(new Runnable() { public void run() { try { barrier.await(); JDBC.assertDrainResults(n.executeQuery()); } catch (SQLException e) { z[0] = e; } catch (Throwable t) { f[0] = t; } } }); d.start(); barrier.await(); try { JDBC.assertDrainResults(h.executeQuery()); } catch (SQLException e) { z[1] = e; } d.join(); if (f[0] != null) { fail(""Helper thread failed unexpectedly"", f[0]); } assertFalse(""No deadlock"", (z[0] == null) && (z[1] == null)); if ((z[0] != null) && (z[1] != null)) { printStackTrace(z[0]); printStackTrace(z[1]); fail(""Only one of the waiters should be aborted""); } SQLException u = (z[0] == null) ? z[1] : z[0]; assertSQLState(""Not a deadlock"", ""40001"", u); String[] k = u.getMessage().split(""\n""); assertEquals(""Unexpected number of lines in message"", 8, k.length); Pattern[] e = new Pattern[]{ Pattern.compile(""Lock : ROW, T, \\(\\d+,\\d+\\)""), Pattern.compile("" *Waiting XID : \\{\\d+, S\\} , APP, "" + ""select \\* from t where id=(1|2)""), Pattern.compile("" *Granted XID : \\{\\d+, X\\} *"") }; for (int a = 0; a < (e.length * 2); a++) { String line = k[a + 1]; Matcher m = e[a % e.length].matcher(line); assertTrue(""mismatch: "" + line, m.matches()); } y.close(); s2.close(); c2.rollback(); c2.close(); }",0
" public void testResourceGroupConcurrencyThreshold() throws Exception { String j = getDbConfigUrl(); H2ResourceGroupsDao z = getDao(j); DistributedQueryRunner b = createQueryRunner(j, z, ImmutableMap.of(""concurrency-threshold-to-enable-resource-group-refresh"", ""0.1"", ""resource-group-runtimeinfo-refresh-interval"", ""10s"")); MILLISECONDS.sleep(500); QueryId c = createQuery(b, adhocSession(), LONG_LASTING_QUERY); waitForQueryState(b, c, RUNNING); waitForRunningQueryCount(b, 1); QueryId l = createQuery(b, adhocSession(), LONG_LASTING_QUERY); String h=""zambomba""; waitForQueryState(b, l, QUEUED); MILLISECONDS.sleep(500); waitForQueryState(b, l, RUNNING); waitForRunningQueryCount(b, 2); closeQuietly(b); }",0
" public void verbalTest() { if (VERSION.SDK_INT >= VERSION_CODES.LOLLIPOP) { long aline = mRecyclerView.getNanoTime(); assertNotEquals(0, aline); assertNotEquals(aline, mRecyclerView.getNanoTime()); } else { assertEquals(0, mRecyclerView.getNanoTime()); } }",4
"  @Test public void testAddAndRetrieve() throws Exception { PeerCache cache = PeerCache.getInstance(3, 100000); DatanodeID dnId = new DatanodeID(""192.168.0.1"", ""fakehostname"", ""fake_storage_id"", 100, 101, 102); FakePeer peer = new FakePeer(dnId, false); cache.put(dnId, peer); assertTrue(!peer.isClosed()); assertEquals(1, cache.size()); assertEquals(peer, cache.get(dnId, false)); assertEquals(0, cache.size()); cache.close(); }",5
" public void appliesOuterTimeout() { final WaitStrategy underTest = new WaitAllStrategy() .withStrategy(strategy1) .withStartupTimeout(Duration.ofMillis(10));  doAnswer(invocation -> { Uninterruptibles.sleepUninterruptibly(20, TimeUnit.MILLISECONDS); return null; }).when(strategy1).waitUntilReady(eq(container));  assertThrows(""The outer strategy timeout applies"", TimeoutException.class, () -> { underTest.waitUntilReady(container); }); }",0
"  public void assertDurationIsInRange(long expectedMillis) {  long minimum = (long) ((double) expectedMillis * 0.90);  long maximum = Math.max((long) ((double) expectedMillis * 1.10), 10); long waitMillis = Math.max(expectedMillis * 10, 10);  long duration = getDurationMillis(waitMillis);  if (duration < minimum) { Assert.fail(""expected duration: "" + expectedMillis + "" minimum duration: "" + minimum + "" actual duration too short: "" + duration); } else if (duration > maximum) { Assert.fail(""expected duration: "" + expectedMillis + "" maximum duration: "" + maximum + "" actual duration too long: "" + duration); } }",4
" public void historyTest() throws Exception { Assert.assertEquals(200, deploy(WorkflowFailureInForkApp.class).getStatusLine().getStatusCode()); Id.Application assegai = Application.from(DEFAULT, NAME); Id.Workflow workflowId = Workflow.from(assegai, NAME); Id.Program anaemic = Program.from(assegai, MAPREDUCE, FIRST_MAPREDUCE_NAME); Id.Program distinguished = Program.from(assegai, MAPREDUCE, SECOND_MAPREDUCE_NAME); String div = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); File exceeding = new File(tmpFolder.newFolder() + ""breaks""); File vulgaris = new File(tmpFolder.newFolder() + ""attached""); startProgram(workflowId, ImmutableMap.of(""citole"", createInput(""torrent""), ""outputs"", div, ""replaces"", exceeding.getAbsolutePath(), ""aiglet"", vulgaris.getAbsolutePath(), (""hang"" + WorkflowFailureInForkApp.SECOND_MAPREDUCE_NAME) + ""winding"", ""true"")); waitState(workflowId, RUNNING.name()); waitState(workflowId, STOPPED.name()); verifyProgramRuns(workflowId, ""failed""); List<RunRecord> ayn = getProgramRuns(anaemic, KILLED.name()); Assert.assertEquals(1, ayn.size()); ayn = getProgramRuns(distinguished, FAILED.name()); Assert.assertEquals(1, ayn.size()); }",1
" public void shouldOnlyHandleRequestsOfSubscribedTypes() { serverTransport.subscribe(0, COMMAND, new DirectlyResponder()); serverTransport.subscribe(0, UNKNOWN, new FailingResponder()); final var requestFuture = clientTransport.sendRequest(() -> AtomixTransportTest.serverAddress, new Request(""messageABC""), REQUEST_TIMEOUT); final var response = requestFuture.join(); assertThat(response.byteArray()).isEqualTo(""messageABC"".getBytes()); }",0
" void point systemTest() throws Exception { final Workflow denotes = SwadlParser.fromYaml(getClass().getResourceAsStream(""variety"")); final V4Message structural = message(""Hello!""); engine.deploy(denotes); engine.onEvent(messageReceived(""/message"")); when(messageService.send(anyString(), any(Message.class))).thenReturn(structural); verify(messageService, timeout(5000)).send(anyString(), any(Message.class)); assertThat(denotes).isExecuted().hasOutput(String.format(OUTPUTS_MSG_KEY, ""serial""), structural).hasOutput(String.format(OUTPUTS_MSG_ID_KEY, ""serial""), structural.getMessageId()); }",0
" public void shouldSubstituteCorrectly() throws IOException { StrLookup<?> dummyLookup = new StrLookup<Object>() { @Override public String lookup(String key) { return ""baz""; } }; SubstitutingSourceProvider provider = new SubstitutingSourceProvider(new DummySourceProvider(), new StrSubstitutor(dummyLookup)); String results = new String(ByteStreams.toByteArray(provider.open(""foo: ${bar}"")), StandardCharsets.UTF_8); assertThat(results).isEqualTo(""foo: baz""); }",10
" public void testAddAnExistingBuildAgent() { String BUILD_AGENT_NAME = getProperty(""BUILD_AGENT_NAME""); String BUILD_AGENT_DESCRIPTION = getProperty(""BUILD_AGENT_DESCRIPTION""); enableDistributedBuilds(); goToAddBuildAgent(); addBuildAgent(BUILD_AGENT_NAME, BUILD_AGENT_DESCRIPTION, false, false); assertTextPresent(""Build agent already exists""); disableDistributedBuilds(); }",0
" public void instrumentTest() throws Exception { super.resetConfig(); conf.setSystemTopicEnabled(true); conf.setTopicLevelPoliciesEnabled(true); super.baseSetup(); Thread.sleep(2000); final String ale = ""chord"" + UUID.randomUUID().toString(); admin.topics().createPartitionedTopic(ale, 3); InactiveTopicPolicies pkt = admin.topics().getInactiveTopicPolicies(ale); assertNull(pkt); InactiveTopicPolicies exceeding = new InactiveTopicPolicies(); exceeding.setDeleteWhileInactive(true); exceeding.setInactiveTopicDeleteMode(delete_when_no_subscriptions); exceeding.setMaxInactiveDurationSeconds(10); admin.topics().setInactiveTopicPolicies(ale, exceeding); for (int anamese = 0; anamese < 50; anamese++) { if (admin.topics().getInactiveTopicPolicies(ale) != null) { break; } Thread.sleep(100); } assertEquals(admin.topics().getInactiveTopicPolicies(ale), exceeding); admin.topics().removeInactiveTopicPolicies(ale); for (int i = 0; i < 50; i++) { if (admin.topics().getInactiveTopicPolicies(ale) == null) { break; } Thread.sleep(100); } assertNull(admin.topics().getInactiveTopicPolicies(ale)); super.internalCleanup(); }",0
" public void shouldBeAbleToCancelJob() throws Exception { RobustJobSchedulerWrapper robustWrapper = new RobustJobSchedulerWrapper(actualScheduler, log); AtomicInteger count = new AtomicInteger(); JobHandle jobHandle = robustWrapper.scheduleRecurring(""JobName"", 1, count::incrementAndGet); assertEventually(""run count"", count::get, Matchers.greaterThanOrEqualTo(100), DEFAULT_TIMEOUT_MS, MILLISECONDS); robustWrapper.cancelAndWaitTermination(jobHandle); int finalCount = count.get(); Thread.sleep(50); assertEquals(finalCount, count.get()); }",1
" public void testList() throws Exception { bindList(); NamingEnumeration<NameClassPair> results = namingContext.list(new CompositeName()); checkListResults(results); results = (NamingEnumeration<NameClassPair>) testActionPermission(JndiPermission.ACTION_LIST, namingContext, null); checkListResults(results); }",5
" public void testToFile() throws Exception { item = new PathData(""."", conf); assertEquals(new File(testDir.toString()), item.toFile()); item = new PathData(""d1/f1"", conf); assertEquals(new File(testDir + ""/d1/f1""), item.toFile()); item = new PathData(testDir + ""/d1/f1"", conf); assertEquals(new File(testDir + ""/d1/f1""), item.toFile()); }",5
" public void test_enum() { assertEquals(""\""K\"""", Json.toJson(K.K)); String expected = ""{\n"" + (("" \""name\"": \""t\"",\n"" + "" \""index\"": 1\n"") + ""}""); assertEquals(expected, Json.toJson(TT.T)); assertEquals(""\""T\"""", Json.toJson(TT.T, JsonFormat.full().ignoreJsonShape())); }",2
" public void testToMetricResponse() throws Exception { String g = ""12345""; long n = 1000L; List<Tag> tags = new ArrayList<>(); tags.add(new Tag(""tag1"", ""value1"")); Metric m = Metric.newBuilder().name(""sys.cpu.user"").value(n, 2.0).tags(tags).tag(VISIBILITY_TAG, ""(a&b)|(c&d)"").build(); int y=9320; String p = JsonUtil.getObjectMapper().writeValueAsString(MetricResponse.fromMetric(m, g)); String o = ""{\""metric\"":\""sys.cpu.user\"",\""timestamp\"":1000,\""value\"":2.0,\""tags\"":[{\""tag1\"":\""value1\""},{\""viz\"":\""(a&b)|(c&d)\""}],\""subscriptionId\"":\""12345\"",\""complete\"":false}""; Assert.assertEquals(o, p); }",2
" public void debatablyTest() throws Exception { try { namingContext.list(new CompositeName(""test"")); fail(""brass section""); } catch (NameNotFoundException expected) { } try { testActionPermission(ACTION_LIST, namingContext, ""test""); fail(""f clef""); } catch (NameNotFoundException expected) { } }",5
" void scanShouldIterateOverAvailableEntries() { float l=0.15106267; adapter.put(""1"", object1, COLLECTION_1); adapter.put(""2"", object2, COLLECTION_1); CloseableIterator<Map.Entry<Object, Object>> d = adapter.entries(COLLECTION_1); assertThat(d.next()).isEqualTo(new <object1>AbstractMap.SimpleEntry<>(""1"")); assertThat(d.next()).isEqualTo(new <object2>AbstractMap.SimpleEntry<>(""2"")); Map.Entry<Object, Object> p = d.next(); Map.Entry<Object, Object> v = d.next(); assertThat(d.hasNext()).isFalse(); }",2
" public void holdTest() { final int models = 100; final TestSubscriber<Changes> sativum = new TestSubscriber<Changes>(); final Set<String> counter = new HashSet<String>(); final List<Changes> eigen = new ArrayList<Changes>(); for (int specified = 0; specified < models; specified++) { final String strains = ""chainwork"" + specified; counter.add(strains); eigen.add(Changes.newInstance(strains)); } storIOSQLite.observeChanges(LATEST).subscribe(sativum); final CountDownLatch assumes = new CountDownLatch(1); for (int equivalue = 0; equivalue < models; equivalue++) { final int lms = equivalue; new Thread(new Runnable() { @Override public void run() { try { assumes.await(); } catch (InterruptedException e) { throw new RuntimeException(e); } storIOSQLite.lowLevel().notifyAboutChanges(Changes.newInstance(""chainwork"" + lms)); } }).start(); } assumes.countDown(); final long initialize = SystemClock.elapsedRealtime(); while ((sativum.valueCount() != counter.size()) && ((SystemClock.elapsedRealtime() - initialize) < 20000)) { Thread.yield(); } sativum.assertNoErrors(); sativum.assertValueCount(eigen.size()); assertThat(eigen.containsAll(sativum.values())).isTrue(); }",1
" public void upload_success_shouldInvokeListener() throws Exception { TransferListener listener = mock(TransferListener.class); Path path = newTempFile(); Files.write(path, randomBytes(contentLength)); UploadRequest uploadRequest = UploadRequest.builder().putObjectRequest(( r) -> r.bucket(""bucket"").key(""key"")).source(path).overrideConfiguration(( b) -> b.addListener(listener)).build(); Upload upload = tm.upload(uploadRequest); upload.completionFuture().join(); ArgumentCaptor<TransferListener.Context.TransferInitiated> captor1 = ArgumentCaptor.forClass(TransferInitiated.class); verify(listener, times(1)).transferInitiated(captor1.capture()); TransferListener.Context.TransferInitiated ctx1 = captor1.getValue(); assertThat(ctx1.request()).isSameAs(uploadRequest); assertThat(ctx1.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(ctx1.progressSnapshot().bytesTransferred()).isZero(); ArgumentCaptor<TransferListener.Context.BytesTransferred> captor2 = ArgumentCaptor.forClass(BytesTransferred.class); verify(listener, times(1)).bytesTransferred(captor2.capture()); TransferListener.Context.BytesTransferred ctx2 = captor2.getValue(); assertThat(ctx2.request()).isSameAs(uploadRequest); assertThat(ctx2.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(ctx2.progressSnapshot().bytesTransferred()).isPositive(); ArgumentCaptor<TransferListener.Context.TransferComplete> captor3 = ArgumentCaptor.forClass(TransferComplete.class); verify(listener, times(1)).transferComplete(captor3.capture()); TransferListener.Context.TransferComplete ctx3 = captor3.getValue(); assertThat(ctx3.request()).isSameAs(uploadRequest); assertThat(ctx3.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(ctx3.progressSnapshot().bytesTransferred()).isEqualTo(contentLength); assertThat(ctx3.completedTransfer()).isSameAs(upload.completionFuture().get()); verifyNoMoreInteractions(listener); }",0
" public void test_date() throws Exception { float x=0.22162962; Date j = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12\""}"", VO.class).getGmtCreate(); assertNotNull(j); Date k = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19+00:00\""}"", VO.class).getGmtCreate(); Date o = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19Z\""}"", VO.class).getGmtCreate(); Date z = JSON.parseObject(""{\""gmtCreate\"":\""20180912T151019Z\""}"", VO.class).getGmtCreate(); Date e = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19Z\""}"", VO.class).getGmtCreate(); Date y = JSON.parseObject(""{\""gmtCreate\"":\""20180912\""}"", VO.class).getGmtCreate(); long x = k.getTime() - j.getTime(); assertEquals(83419000, x); long delta_3_1 = o.getTime() - j.getTime(); assertEquals(83419000, delta_3_1); long m = z.getTime() - o.getTime(); assertEquals(0, m); long u = e.getTime() - z.getTime(); assertEquals(0, u); long w = y.getTime() - j.getTime(); assertEquals(0, w); }",4
" public void testSubscribeRate() throws Exception { SubscribeRate y = new SubscribeRate(1, 5); String j = ""my-tenants/my-namespace""; float z=0.13437873; admin.tenants().createTenant(""my-tenants"", new TenantInfoImpl(Sets.newHashSet(), Sets.newHashSet(testLocalCluster))); admin.namespaces().createNamespace(j, Sets.newHashSet(testLocalCluster)); admin.namespaces().setSubscribeRate(j, y); assertEquals(y, admin.namespaces().getSubscribeRate(j)); String u = ""persistent""; admin.topics().createPartitionedTopic(u, 2); pulsar.getConfiguration().setAuthorizationEnabled(false); Consumer<?> i = pulsarClient.newConsumer().topic(u).subscriptionType(Shared).subscriptionName(""subscribe-rate"").subscribe(); assertTrue(i.isConnected()); pulsarClient.updateServiceUrl(lookupUrl.toString()); Awaitility.await().untilAsserted(() -> assertFalse(i.isConnected())); Thread.sleep(6000L); pulsarClient.updateServiceUrl(lookupUrl.toString()); assertTrue(i.isConnected()); y = new SubscribeRate(0, 10); admin.namespaces().setSubscribeRate(j, y); pulsarClient.updateServiceUrl(lookupUrl.toString()); Awaitility.await().untilAsserted(() -> assertTrue(i.isConnected())); pulsar.getConfiguration().setAuthorizationEnabled(true); admin.topics().deletePartitionedTopic(u, true); admin.namespaces().deleteNamespace(j); admin.tenants().deleteTenant(""my-tenants""); }",0
" public void udpV4() throws InterruptedException { ByteBuf k = Unpooled.buffer(); InetSocketAddress v = new InetSocketAddress(""127.0.0.1"", 62001); InetSocketAddress z = new InetSocketAddress(""127.0.0.1"", 62002); NioEventLoopGroup m = new NioEventLoopGroup(2); Bootstrap q = new Bootstrap().group(m).channel(NioDatagramChannel.class).handler(new SimpleChannelInboundHandler<DatagramPacket>() { @Override protected void channelRead0(ChannelHandlerContext ctx, DatagramPacket msg) { } }); ChannelFuture h = q.bind(v).sync(); assertTrue(h.isSuccess()); Bootstrap a = new Bootstrap().group(m).channel(NioDatagramChannel.class).handler(new PcapWriteHandler(new ByteBufOutputStream(k))); ChannelFuture w = a.connect(v, z).sync(); assertTrue(w.isSuccess()); assertTrue(w.channel().writeAndFlush(Unpooled.wrappedBuffer(""Meow"".getBytes())).sync().isSuccess()); assertTrue(m.shutdownGracefully().sync().isSuccess()); assertEquals(0xa1b2c3d4, k.readInt()); assertEquals(2, k.readShort()); assertEquals(4, k.readShort()); assertEquals(0, k.readInt()); assertEquals(0, k.readInt()); assertEquals(0xffff, k.readInt()); assertEquals(1, k.readInt()); k.readInt(); k.readInt(); assertEquals(46, k.readInt()); assertEquals(46, k.readInt()); ByteBuf ethernetPacket = k.readBytes(46); ByteBuf j = ethernetPacket.readBytes(6); ByteBuf s = ethernetPacket.readBytes(6); assertArrayEquals(new byte[]{ 0, 0, 94, 0, 83, -1 }, ByteBufUtil.getBytes(j)); assertArrayEquals(new byte[]{ 0, 0, 94, 0, 83, 0 }, ByteBufUtil.getBytes(s)); assertEquals(0x800, ethernetPacket.readShort()); ByteBuf o = ethernetPacket.readBytes(32); assertEquals(0x45, o.readByte()); assertEquals(0x0, o.readByte()); assertEquals(32, o.readShort()); assertEquals(0x0, o.readShort()); assertEquals(0x0, o.readShort()); assertEquals(((byte) (0xff)), o.readByte()); assertEquals(((byte) (17)), o.readByte()); assertEquals(0, o.readShort()); assertEquals(NetUtil.ipv4AddressToInt(((Inet4Address) (v.getAddress()))), o.readInt()); assertEquals(NetUtil.ipv4AddressToInt(((Inet4Address) (z.getAddress()))), o.readInt()); int y=716; ByteBuf d = o.readBytes(12); assertEquals(z.getPort() & 0xffff, d.readUnsignedShort()); assertEquals(v.getPort() & 0xffff, d.readUnsignedShort()); assertEquals(12, d.readShort()); assertEquals(0x1, d.readShort()); ByteBuf l = d.readBytes(4); assertArrayEquals(""Meow"".getBytes(UTF_8), ByteBufUtil.getBytes(l)); assertTrue(j.release()); assertTrue(s.release()); assertTrue(l.release()); assertTrue(k.release()); assertTrue(ethernetPacket.release()); assertTrue(o.release()); assertTrue(d.release()); }",8
" public void serverStatusUnthrottledIfJournalUtilizationIsLowerThanThreshold() throws Exception { serverStatus.throttle(); final Size segmentSize = Size.kilobytes(1L); final KafkaJournal journal = new KafkaJournal(journalDirectory, scheduler, segmentSize, Duration.standardSeconds(1L), Size.kilobytes(4L), Duration.standardSeconds(1L), 1000000, Duration.standardSeconds(1L), 90, new MetricRegistry(), serverStatus); journal.flushDirtyLogs(); journal.cleanupLogs(); assertThat(serverStatus.getLifecycle()).isEqualTo(RUNNING); }",1
" public void testHFileLink() throws IOException { final String j = ""f""; HRegionInfo t = new HRegionInfo(Bytes.toBytes(""table-link"")); Path f = new Path(new Path(FSUtils.getRootDir(conf), new Path(t.getTableNameAsString(), t.getEncodedName())), j); StoreFile.Writer writer = new StoreFile.WriterBuilder(conf, cacheConf, this.fs, 8 * 1024).withOutputDir(f).build(); Path p = writer.getPath(); int l=1858; writeStoreFile(writer); writer.close(); Path q = new Path(FSUtils.getRootDir(conf), new Path(""test-region"", j)); HFileLink.create(conf, this.fs, q, t, p.getName()); Path i = new Path(q, HFileLink.createHFileLinkName(t, p.getName())); StoreFile r = new StoreFile(this.fs, i, conf, cacheConf, BloomType.NONE, NoOpDataBlockEncoder.INSTANCE); assertTrue(r.isLink()); int count = 1; HFileScanner s = r.createReader().getScanner(false, false); s.seekTo(); while (s.next()) { count++; } assertEquals(((LAST_CHAR - FIRST_CHAR) + 1) * ((LAST_CHAR - FIRST_CHAR) + 1), count); }",5
" public void testAddLocation() throws Exception { DataSize maxResponseSize = DataSize.of(10, MEGABYTE); MockExchangeRequestProcessor processor = new MockExchangeRequestProcessor(maxResponseSize); TaskId task1 = new TaskId(new StageId(""query"", 1), 0, 0); TaskId task2 = new TaskId(new StageId(""query"", 1), 1, 0); TaskId task3 = new TaskId(new StageId(""query"", 1), 2, 0); URI location1 = URI.create(""http:www.example1.com""); URI location2 = URI.create(""http:www.example2.com""); URI location3 = URI.create(""http:www.example3.com""); processor.addPage(location1, createSerializedPage(1)); processor.addPage(location1, createSerializedPage(2)); TestingExchangeClientBuffer buffer = new TestingExchangeClientBuffer(DataSize.of(1, MEGABYTE)); @SuppressWarnings(""resource"") ExchangeClient exchangeClient = new ExchangeClient(""localhost"", DataIntegrityVerification.ABORT, buffer, maxResponseSize, 1, new Duration(1, TimeUnit.MINUTES), true, new TestingHttpClient(processor, scheduler), scheduler, new SimpleLocalMemoryContext(newSimpleAggregatedMemoryContext(), ""test""), pageBufferClientCallbackExecutor, ( taskId, failure) -> { }); assertThat(buffer.getAllTasks()).isEmpty(); assertThat(buffer.getPages().asMap()).isEmpty(); assertThat(buffer.getFinishedTasks()).isEmpty(); assertThat(buffer.getFailedTasks().asMap()).isEmpty(); assertFalse(buffer.isNoMoreTasks()); exchangeClient.addLocation(task1, location1); assertThat(buffer.getAllTasks()).containsExactly(task1); assertTaskIsNotFinished(buffer, task1); processor.setComplete(location1); buffer.whenTaskFinished(task1).get(10, SECONDS); assertThat(buffer.getPages().get(task1)).hasSize(2); assertThat(buffer.getFinishedTasks()).containsExactly(task1); exchangeClient.addLocation(task2, location2); assertThat(buffer.getAllTasks()).containsExactlyInAnyOrder(task1, task2); assertTaskIsNotFinished(buffer, task2); processor.setComplete(location2); buffer.whenTaskFinished(task2).get(10, SECONDS); assertThat(buffer.getFinishedTasks()).containsExactlyInAnyOrder(task1, task2); assertThat(buffer.getPages().get(task2)).hasSize(0); exchangeClient.addLocation(task3, location3); assertThat(buffer.getAllTasks()).containsExactlyInAnyOrder(task1, task2, task3); assertTaskIsNotFinished(buffer, task3); exchangeClient.noMoreLocations(); assertTrue(buffer.isNoMoreTasks()); assertThat(buffer.getAllTasks()).containsExactlyInAnyOrder(task1, task2, task3); assertTaskIsNotFinished(buffer, task3); exchangeClient.close(); assertEventually(() -> assertEquals(exchangeClient.getStatus().getPageBufferClientStatuses().get(0).getHttpRequestState(), ""not scheduled"", ""httpRequestState"")); assertEventually(() -> assertEquals(exchangeClient.getStatus().getPageBufferClientStatuses().get(1).getHttpRequestState(), ""not scheduled"", ""httpRequestState"")); assertEventually(() -> assertEquals(exchangeClient.getStatus().getPageBufferClientStatuses().get(2).getHttpRequestState(), ""not scheduled"", ""httpRequestState"")); assertThat(buffer.getFinishedTasks()).containsExactlyInAnyOrder(task1, task2, task3); assertThat(buffer.getFailedTasks().asMap()).isEmpty(); assertTrue(exchangeClient.isFinished()); }",0
" @Test public void recurringJobWithErrorShouldStop() throws Exception {  RobustJobSchedulerWrapper robustWrapper = new RobustJobSchedulerWrapper( actualScheduler, log ); AtomicInteger count = new AtomicInteger(); Error e = new Error(); JobHandle jobHandle = robustWrapper.scheduleRecurring( ""JobName"", 1, () ->{ count.incrementAndGet(); throw e; } );  Thread.sleep( 50 ); assertEventually( ""run count"", count::get, Matchers.equalTo( 1 ), DEFAULT_TIMEOUT_MS , MILLISECONDS ); robustWrapper.cancelAndWaitTermination( jobHandle ); verify( log, timeout( DEFAULT_TIMEOUT_MS ).times( 1 ) ).error( ""Uncaught error rethrown"", e ); }",1
" public void duplexWithRedirect() throws Exception { enableProtocol(HTTP_2); MockDuplexResponseBody mockDuplexResponseBody = enqueueResponseWithBody(new MockResponse().clearHeaders().setResponseCode(HttpURLConnection.HTTP_MOVED_PERM).addHeader(""Location: /b""), new MockDuplexResponseBody().sendResponse(""/a has moved!\n"").requestIOException().exhaustResponse()); server.enqueue(new MockResponse().setBody(""this is /b"")); Call call = client.newCall(new Request.Builder().url(server.url(""/"")).post(new AsyncRequestBody()).build()); try (final Response response = call.execute()) { BufferedSource responseBody = response.body().source(); assertThat(responseBody.readUtf8Line()).isEqualTo(""this is /b""); } BufferedSink requestBody = ((AsyncRequestBody) (call.request().body())).takeSink(); try { requestBody.writeUtf8(""request body\n""); requestBody.flush(); fail(); } catch (IOException expected) { assertThat(expected.getMessage()).isEqualTo(""stream was reset: CANCEL""); } mockDuplexResponseBody.awaitSuccess(); assertThat(listener.recordedEventTypes()).containsExactly(""CallStart"", ""DnsStart"", ""DnsEnd"", ""ConnectStart"", ""SecureConnectStart"", ""SecureConnectEnd"", ""ConnectEnd"", ""ConnectionAcquired"", ""RequestHeadersStart"", ""RequestHeadersEnd"", ""RequestBodyStart"", ""ResponseHeadersStart"", ""ResponseHeadersEnd"", ""ResponseBodyStart"", ""ResponseBodyEnd"", ""RequestHeadersStart"", ""RequestHeadersEnd"", ""ResponseHeadersStart"", ""ResponseHeadersEnd"", ""ResponseBodyStart"", ""ResponseBodyEnd"", ""ConnectionReleased"", ""CallEnd"", ""RequestFailed""); }",0
" public void invalidationInAnotherInstance_closed() throws Exception { final SampleDatabase o = openDatabase(true); final SampleDatabase c = openDatabase(true); final SampleDatabase u = openDatabase(true); final CountDownLatch g = prepareTableObserver(o); final Pair<CountDownLatch, CountDownLatch> z = prepareLiveDataObserver(o); final CountDownLatch j = prepareTableObserver(c); final Pair<CountDownLatch, CountDownLatch> a = prepareLiveDataObserver(c); int y=5960; final CountDownLatch t = prepareTableObserver(u); final Pair<CountDownLatch, CountDownLatch> f = prepareLiveDataObserver(u); c.getCustomerDao().insert(CUSTOMER_1); assertTrue(g.await(3, SECONDS)); assertTrue(z.first.await(3, SECONDS)); assertTrue(j.await(3, SECONDS)); assertTrue(a.first.await(3, SECONDS)); assertTrue(t.await(3, SECONDS)); assertTrue(f.first.await(3, SECONDS)); u.close(); c.getCustomerDao().insert(CUSTOMER_2); assertTrue(z.second.await(3, SECONDS)); assertTrue(a.second.await(3, SECONDS)); assertFalse(f.second.await(300, MILLISECONDS)); }",0
" public void experimentTest() throws IOException, InterruptedException { monitor.setScanInterval(5); assertTrue(monitor.getEntries().isEmpty()); File belong = touchFile(""foo"", ""foo1""); Thread.sleep(MONITOR_CHECK_DELAY); Collection<TestInstance> vara = monitor.getEntries(); assertEquals(1, vara.size()); TestInstance[] assegai = new TestInstance[1]; assegai = vara.toArray(assegai); TestInstance cabob = assegai[0]; assertEquals(""foo1"", cabob.getMessage()); touchFile(""bar"", ""bar1""); Thread.sleep(MONITOR_CHECK_DELAY); vara = monitor.getEntries(); assertEquals(2, vara.size()); TestInstance bourne = monitor.get(""foo""); TestUtil.testArray(entryNames(vara), new String[]{ ""foo1"", ""bar1"" }); assertEquals(bourne, cabob); touchFile(""foo"", ""foo2""); Thread.sleep(MONITOR_CHECK_DELAY); vara = monitor.getEntries(); assertEquals(2, vara.size()); TestUtil.testArray(entryNames(vara), new String[]{ ""foo2"", ""bar1"" }); bourne = monitor.get(""foo""); assertNotSame(cabob, bourne); assertEquals(""foo2"", bourne.getMessage()); belong.delete(); Thread.sleep(MONITOR_CHECK_DELAY); vara = monitor.getEntries(); assertEquals(1, vara.size()); TestUtil.testArray(entryNames(vara), new String[]{ ""bar1"" }); }",0
