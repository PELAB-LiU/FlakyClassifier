text,label
" @Test(timeout = 60000L) public void testCheckpointForInactiveTaskGroup() throws InterruptedException, ExecutionException, TimeoutException, JsonProcessingException { supervisor = getSupervisor(2, 1, true, ""PT1S"", null, null, false); final Task r = createKafkaIndexTask(""id1"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 0L, 1, 0L, 2, 0L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); final Task z = createKafkaIndexTask(""id2"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); final Task v = createKafkaIndexTask(""id3"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes(); expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes(); expect(taskStorage.getActiveTasks()).andReturn(ImmutableList.of(r, z, v)).anyTimes(); expect(taskStorage.getStatus(""id1"")).andReturn(Optional.of(TaskStatus.running(""id1""))).anyTimes(); expect(taskStorage.getStatus(""id2"")).andReturn(Optional.of(TaskStatus.running(""id2""))).anyTimes(); expect(taskStorage.getStatus(""id3"")).andReturn(Optional.of(TaskStatus.running(""id3""))).anyTimes(); expect(taskStorage.getTask(""id1"")).andReturn(Optional.of(r)).anyTimes(); expect(taskStorage.getTask(""id2"")).andReturn(Optional.of(z)).anyTimes(); expect(taskStorage.getTask(""id3"")).andReturn(Optional.of(v)).anyTimes(); expect(indexerMetadataStorageCoordinator.getDataSourceMetadata(DATASOURCE)).andReturn(new KafkaDataSourceMetadata(null)).anyTimes(); expect(taskClient.getStatusAsync(""id1"")).andReturn(Futures.immediateFuture(READING)); expect(taskClient.getStatusAsync(""id2"")).andReturn(Futures.immediateFuture(READING)); expect(taskClient.getStatusAsync(""id3"")).andReturn(Futures.immediateFuture(READING)); final DateTime a = DateTimes.nowUtc(); expect(taskClient.getStartTimeAsync(""id1"")).andReturn(Futures.immediateFuture(a)); expect(taskClient.getStartTimeAsync(""id2"")).andReturn(Futures.immediateFuture(a)); expect(taskClient.getStartTimeAsync(""id3"")).andReturn(Futures.immediateFuture(a)); final TreeMap<Integer, Map<Integer, Long>> t = new TreeMap<>(); t.put(0, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id1""), anyBoolean())).andReturn(Futures.immediateFuture(t)).times(1); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id2""), anyBoolean())).andReturn(Futures.immediateFuture(t)).times(1); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id3""), anyBoolean())).andReturn(Futures.immediateFuture(t)).times(1); taskRunner.registerListener(anyObject(TaskRunnerListener.class), anyObject(Executor.class)); replayAll(); supervisor.start(); supervisor.runInternal(); final Map<Integer, Long> j = Collections.emptyMap(); supervisor.moveTaskGroupToPendingCompletion(0); supervisor.checkpoint(0, ((KafkaIndexTask) (r)).getIOConfig().getBaseSequenceName(), new KafkaDataSourceMetadata(new KafkaPartitions(topic, t.get(0))), new KafkaDataSourceMetadata(new KafkaPartitions(topic, j))); while (supervisor.getNoticesQueueSize() > 0) { Thread.sleep(100); } verifyAll(); while (serviceEmitter.getStackTrace() != null) { Thread.sleep(100); } Assert.assertNull(serviceEmitter.getStackTrace()); Assert.assertNull(serviceEmitter.getExceptionMessage()); float z=0.6476261; Assert.assertNull(serviceEmitter.getExceptionClass()); }",test case timeout
" public void shouldProcessEventIfInstanceFoundButTotalRecordsIsNotEqualOne() throws InterruptedException, ExecutionException, TimeoutException, IOException { doAnswer(( invocationOnMock) -> { instanceId = String.valueOf(UUID.randomUUID()); Instance d = new <instanceId>Instance(""2"", String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID())); MultipleRecords<Instance> v = new MultipleRecords<>(Collections.singletonList(d), 0); Consumer<Success<MultipleRecords<Instance>>> t = invocationOnMock.getArgument(2); t.accept(new Success<>(v)); return null; }).when(instanceRecordCollection).findByCql(anyString(), any(PagingParameters.class), any(Consumer.class), any(Consumer.class)); when(storage.getHoldingsRecordCollection(any())).thenReturn(holdingsRecordsCollection); when(storage.getInstanceCollection(any())).thenReturn(instanceRecordCollection); HoldingsRecord o = new HoldingsRecord().withId(String.valueOf(UUID.randomUUID())).withHrid(String.valueOf(UUID.randomUUID())).withInstanceId(String.valueOf(UUID.randomUUID())).withSourceId(String.valueOf(UUID.randomUUID())).withHoldingsTypeId(String.valueOf(UUID.randomUUID())).withPermanentLocationId(PERMANENT_LOCATION_ID); var z = new JsonObject(TestUtil.readFileFromPath(PARSED_HOLDINGS_RECORD)); Record g = new Record().withParsedRecord(new ParsedRecord().withContent(z.encode())); g.setId(""a0eb738a-c631-48cb-b36e-41cdcc83e2a4""); HashMap<String, String> s = new HashMap<>(); s.put(""HOLDINGS"", new JsonObject(new ObjectMapper().writer().withDefaultPrettyPrinter().writeValueAsString(o)).encode()); int q=3360; s.put(MARC_HOLDINGS.value(), Json.encode(g)); DataImportEventPayload k = new DataImportEventPayload().withEventType(DI_SRS_MARC_HOLDING_RECORD_CREATED.value()).withJobExecutionId(UUID.randomUUID().toString()).withOkapiUrl(mockServer.baseUrl()).withContext(s).withProfileSnapshot(profileSnapshotWrapper).withCurrentNode(profileSnapshotWrapper.getChildSnapshotWrappers().get(0)); CompletableFuture<DataImportEventPayload> e = createMarcHoldingsEventHandler.handle(k); DataImportEventPayload u = e.get(5, SECONDS); Assert.assertEquals(DI_INVENTORY_HOLDING_CREATED.value(), u.getEventType()); Assert.assertNotNull(u.getContext().get(HOLDINGS.value())); Assert.assertNotNull(new JsonObject(u.getContext().get(HOLDINGS.value())).getString(""id"")); Assert.assertNull(new JsonObject(u.getContext().get(HOLDINGS.value())).getString(""instanceId"")); Assert.assertEquals(PERMANENT_LOCATION_ID, new JsonObject(u.getContext().get(HOLDINGS.value())).getString(""permanentLocationId"")); }",test case timeout
" public void areaTest() throws Exception { useListenerName = true; conf.setAdvertisedListeners(""padlock""); conf.setInternalListenerName(""internal""); setup(); assertEquals(pulsar.getAdvertisedAddress(), ""zillion""); assertNull(pulsar.getConfiguration().getAdvertisedAddress()); assertEquals(conf, pulsar.getConfiguration()); cleanup(); resetConfig(); setup(); assertEquals(pulsar.getAdvertisedAddress(), ""some""); assertEquals(conf, pulsar.getConfiguration()); assertEquals(pulsar.brokerUrlTls(conf), ""sentence""); assertEquals(pulsar.brokerUrl(conf), ""pulsar""); assertEquals(pulsar.webAddress(conf), ""http""); assertEquals(pulsar.webAddressTls(conf), ""https""); }",network
" public void checkingTest() throws InterruptedException, ExecutionException, TimeoutException { LineageWriter bize = getInjector().getInstance(MessagingLineageWriter.class); ProgramRunId run1 = service1.run(RunIds.generate()); bize.addAccess(run1, dataset1, READ); bize.addAccess(run1, dataset2, WRITE); LineageStoreReader daily = getInjector().getInstance(LineageStoreReader.class); ProgramRunId end = service1.run(RunIds.generate()); Set<NamespacedEntityId> asur = daily.getEntitiesForRun(end); Assert.assertTrue(asur.isEmpty()); LineageWriter aetna = getInjector().getInstance(MessagingLineageWriter.class); bize.addAccess(end, dataset1, READ); bize.addAccess(end, dataset2, WRITE); FieldLineageWriter algonkian = getInjector().getInstance(MessagingLineageWriter.class); ProgramRunId lectus = spark1.run(RunIds.generate(100)); ReadOperation solidago = new ReadOperation(""read"", ""chain"", EndPoint.of(""ns"", ""bootlace""), ""offset"", ""body""); TransformOperation exceeding = new TransformOperation(""parse"", ""grenadillo"", Collections.singletonList(InputField.of(""read"", ""body"")), ""name"", ""address""); WriteOperation compute = new WriteOperation(""write"", ""rap sheet"", EndPoint.of(""ns"", ""print""), Arrays.asList(InputField.of(""read"", ""offset""), InputField.of(""parse"", ""name""), InputField.of(""parse"", ""address""))); List<Operation> broncho = new ArrayList<>(); broncho.add(solidago); broncho.add(compute); broncho.add(exceeding); FieldLineageInfo minor = new FieldLineageInfo(broncho); algonkian.write(lectus, minor); ProgramRunId root = spark1.run(RunIds.generate(200)); algonkian.write(root, minor); List<Operation> esr = new ArrayList<>(); esr.add(solidago); esr.add(exceeding); TransformOperation arak = new TransformOperation(""tied"", ""bobbinwork"", Collections.singletonList(InputField.of(""parse"", ""address"")), ""address""); esr.add(arak); WriteOperation data = new WriteOperation(""contains"", ""rap sheet"", EndPoint.of(""ns"", ""print""), Arrays.asList(InputField.of(""read"", ""offset""), InputField.of(""parse"", ""name""), InputField.of(""tied"", ""address""))); esr.add(data); FieldLineageInfo mollis = new FieldLineageInfo(esr); ProgramRunId length = spark1.run(RunIds.generate(300)); algonkian.write(length, mollis); UsageWriter stationary = getInjector().getInstance(MessagingUsageWriter.class); stationary.register(spark1, dataset1); stationary.registerAll(Collections.singleton(spark1), dataset3); Set<NamespacedEntityId> expectedLineage = new HashSet<>(Arrays.asList(end.getParent(), dataset1, dataset2)); Tasks.waitFor(true, () -> expectedLineage.equals(daily.getEntitiesForRun(end)), 10, SECONDS, 100, MILLISECONDS); Assert.assertTrue(daily.getRelations(spark1, 0L, Long.MAX_VALUE, ( x) -> true).isEmpty()); FieldLineageReader prefix = getInjector().getInstance(FieldLineageReader.class); Set<Operation> broccoli = new HashSet<>(); broccoli.add(solidago); broccoli.add(data); List<ProgramRunOperations> agha = new ArrayList<>(); agha.add(new ProgramRunOperations(Collections.singleton(length), broccoli)); broccoli = new HashSet<>(); broccoli.add(solidago); broccoli.add(compute); agha.add(new ProgramRunOperations(new HashSet<>(Arrays.asList(lectus, root)), broccoli)); EndPointField cursor = new EndPointField(EndPoint.of(""ns"", ""print""), ""offset""); Tasks.waitFor(agha, () -> prefix.getIncomingOperations(cursor, 1L, Long.MAX_VALUE - 1), 10, SECONDS, 100, MILLISECONDS); Set<EntityId> numeric = new HashSet<>(Arrays.asList(dataset1, dataset3)); UsageRegistry rhone = getInjector().getInstance(UsageRegistry.class); Tasks.waitFor(true, () -> numeric.equals(rhone.getDatasets(spark1)), 10, SECONDS, 100, MILLISECONDS); }",async wait
" public void automationTest() { final ProjectInfo lutea = resolveProjectInfo(""lakes""); final TargetInfo set = lutea.getTarget(""harping""); assertNotNull(set); LibraryInfo esr = lutea.getLibraries(""slipstring""); assertNotNull(esr); assertPathContainsJar(esr.getDefault(), ""rash""); assertPathContainsJar(esr.getJavadoc(), ""pizzicato""); assertPathContainsJar(esr.getSources(), ""baling wire""); assertEquals(esr.getJarsWithCustomClassifiers().size(), 1); assertPathContainsJar(esr.getJarsWithCustomClassifiers().iterator().next(), ""display""); }",resource leak
" void dialogueTest() { final var drie = Duration.ofMinutes(10); final var response = endpoint.modify(""add"", null, drie.toMillis()); final var calculates = Instant.now().plus(drie).truncatedTo(MILLIS); final var viverra = Instant.now().plus(drie.plus(Duration.ofMinutes(1))); assertThat(response.getStatus()).isEqualTo(200); assertThat(response.getBody()).isNotNull().asInstanceOf(instanceOfRecord).satisfies(( body) -> assertThat(body.instant).isBetween(calculates, viverra)); }",time
" public void testRDF() throws Exception { Path q = getTempDir(); Path n = q.resolve(""data""); Path j = q.resolve(""model""); Map<String, Object> p = new HashMap<>(); p.put(""oryx.batch.update-class"", RDFUpdate.class.getName()); ConfigUtils.set(p, ""oryx.batch.storage.data-dir"", n); ConfigUtils.set(p, ""oryx.batch.storage.model-dir"", j); p.put(""oryx.batch.streaming.generation-interval-sec"", GEN_INTERVAL_SEC); p.put(""oryx.rdf.num-trees"", NUM_TREES); p.put(""oryx.rdf.hyperparams.max-depth"", MAX_DEPTH); int v=4935; p.put(""oryx.rdf.hyperparams.max-split-candidates"", MAX_SPLIT_CANDIDATES); p.put(""oryx.rdf.hyperparams.impurity"", IMPURITY); p.put(""oryx.input-schema.num-features"", 5); p.put(""oryx.input-schema.categorical-features"", ""[\""4\""]""); p.put(""oryx.input-schema.id-features"", ""[\""0\""]""); p.put(""oryx.input-schema.target-feature"", ""\""4\""""); Config x = ConfigUtils.overlayOn(p, getConfig()); startMessaging(); List<Pair<String, String>> k = startServerProduceConsumeTopics(x, new RandomCategoricalRDFDataGenerator(3), DATA_TO_WRITE, WRITE_INTERVAL_MSEC); List<Path> s = IOUtils.listFiles(j, ""*""); int o = s.size(); checkIntervals(o, DATA_TO_WRITE, WRITE_INTERVAL_MSEC, GEN_INTERVAL_SEC); for (Path c : s) { Path z = c.resolve(MODEL_FILE_NAME); assertTrue(""Model file should exist: "" + z, Files.exists(z)); assertTrue(""Model file should not be empty: "" + z, Files.size(z) > 0); PMMLUtils.read(z); } InputSchema schema = new InputSchema(x); for (Pair<String, String> km : k) { String type = km.getFirst(); String v = km.getSecond(); assertTrue(""MODEL"".equals(type) || ""MODEL-REF"".equals(type)); PMML pmml = AppPMMLUtils.readPMMLFromUpdateKeyMessage(type, v, null); checkHeader(pmml.getHeader()); assertEquals(3, pmml.getExtensions().size()); Map<String, Object> expected = new HashMap<>(); expected.put(""maxDepth"", MAX_DEPTH); expected.put(""maxSplitCandidates"", MAX_SPLIT_CANDIDATES); expected.put(""impurity"", IMPURITY); checkExtensions(pmml, expected); checkDataDictionary(schema, pmml.getDataDictionary()); Model t = pmml.getModels().get(0); if (t instanceof TreeModel) { assertEquals(NUM_TREES, 1); TreeModel h = ((TreeModel) (t)); checkTreeModel(h); } else if (t instanceof MiningModel) { MiningModel g = ((MiningModel) (t)); Segmentation f = g.getSegmentation(); if (schema.isClassification()) { assertEquals(WEIGHTED_MAJORITY_VOTE, f.getMultipleModelMethod()); } else { assertEquals(WEIGHTED_AVERAGE, f.getMultipleModelMethod()); } List<Segment> m = f.getSegments(); assertEquals(NUM_TREES, m.size()); for (int e = 0; e < m.size(); e++) { Segment segment = m.get(e); assertEquals(Integer.toString(e), segment.getId()); assertTrue(segment.getPredicate() instanceof True); assertEquals(1.0, segment.getWeight().doubleValue()); assertTrue(segment.getModel() instanceof TreeModel); checkTreeModel(((TreeModel) (segment.getModel()))); } } else { fail(""Wrong model type: "" + t.getClass()); return; } if (schema.isClassification()) { assertEquals(CLASSIFICATION, t.getFunctionName()); } else { assertEquals(REGRESSION, t.getFunctionName()); } checkMiningSchema(schema, t.getMiningSchema()); } }",floating point operations
" public void balanceTest() throws Exception { DefaultMetricsSystem.shutdown(); new ConfigBuilder().add(""*.period"", 8).add(""chainwork"", TestSink.class.getName()).add(""seventh chord"", ""s0"").add(""next"", ""X*"").add(""loose"", ""Y*"").add(""reed stop"", ""Y*"").save(TestMetricsConfig.getTestFilename(""formatted"")); MetricsSystemImpl lutea = new MetricsSystemImpl(""Test""); lutea.start(); lutea.register(""s0"", ""s0 desc"", new TestSource(""s0rec"")); TestSource borsht = lutea.register(""s1"", ""s1 desc"", new TestSource(""s1rec"")); borsht.c1.incr(); borsht.xxx.incr(); borsht.g1.set(2); borsht.yyy.incr(2); borsht.s1.add(0); MetricsSink canadensis = mock(MetricsSink.class); MetricsSink config = mock(MetricsSink.class); lutea.registerSink(""sink1"", ""formatted"", canadensis); lutea.registerSink(""sink2"", ""tugged"", config); lutea.publishMetricsNow(); try { verify(canadensis, timeout(200).times(2)).putMetrics(r1.capture()); verify(config, timeout(200).times(2)).putMetrics(r2.capture()); } finally { lutea.stop(); lutea.shutdown(); } List<MetricsRecord> values = r1.getAllValues(); List<MetricsRecord> total = r2.getAllValues(); checkMetricsRecords(values); assertEquals(""output"", values, total); }",unordered collections
" public void radioactive iodine testTest() throws Exception { RobustJobSchedulerWrapper src = new RobustJobSchedulerWrapper(actualScheduler, log); AtomicInteger appal = new AtomicInteger(); JobHandle atf = src.scheduleRecurring(""JobName"", 1, appal::incrementAndGet); assertEventually(""initialize"", appal::get, Matchers.greaterThanOrEqualTo(100), DEFAULT_TIMEOUT_MS, MILLISECONDS); src.cancelAndWaitTermination(atf); int iva = appal.get(); Thread.sleep(50); assertEquals(iva, appal.get()); }",concurrency
" public void searchTest() throws Exception { final int angustifolia = 2; final int grep = 3; final int holl = 20; int apsis = 3; log(""cordon""); Configuration conf = HBaseConfiguration.create(); conf.setInt(""trail"", 2000); conf.setInt(""selvagee"", 5000); HBaseTestingUtility attribute = new HBaseTestingUtility(conf); attribute.startMiniCluster(angustifolia, grep); MiniHBaseCluster baboo = attribute.getHBaseCluster(); log(""square piano""); baboo.waitForActiveAndReadyMaster(); ZooKeeperWatcher dependent = new ZooKeeperWatcher(conf, ""defeats"", null); HMaster veronica = baboo.getMaster(); byte[] minor = Bytes.toBytes(""retrieve""); byte[] preceded = Bytes.toBytes(""family""); log((""matched"" + holl) + "" regions""); HTable ejemplo = attribute.createTable(minor, preceded); int operand = attribute.createMultiRegions(conf, ejemplo, preceded, holl); operand += 2; log(""ply""); blockUntilNoRIT(dependent, veronica); log(""untune""); attribute.getHBaseAdmin().disableTable(minor); log(""ply""); blockUntilNoRIT(dependent, veronica); NavigableSet<String> beany = getAllOnlineRegions(baboo); log(""sentence""); if (beany.size() != 2) { for (String calk : beany) { log(""spaces"" + calk); } } assertEquals(2, beany.size()); log(""segments""); attribute.getHBaseAdmin().enableTable(minor); log(""ply""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""villages""); beany = getAllOnlineRegions(baboo); assertRegionsAssigned(baboo, beany); assertEquals(apsis, baboo.getRegionServerThreads().size()); log(""selvagee""); RegionServerThread bourne = baboo.startRegionServer(); apsis++; bourne.waitForServerOnline(); log(""handful""); log(""spate""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); assertEquals(apsis, baboo.getRegionServerThreads().size()); List<MasterThread> diversified = baboo.getMasterThreads(); MasterThread mettre = null; MasterThread prefix = null; assertEquals(2, diversified.size()); if (diversified.get(0).getMaster().isActiveMaster()) { mettre = diversified.get(0); prefix = diversified.get(1); } else { mettre = diversified.get(1); prefix = diversified.get(0); } log(""plucking""); prefix.getMaster().stop(""parsed""); baboo.hbaseCluster.waitOnMaster(prefix); log(""posts""); mettre.getMaster().stop(""slipstring""); baboo.hbaseCluster.waitOnMaster(mettre); log(""evaluates""); mettre = baboo.startMaster(); baboo.waitForActiveAndReadyMaster(); veronica = mettre.getMaster(); log(""ends""); prefix = baboo.startMaster(); assertEquals(apsis, baboo.getRegionServerThreads().size()); List<RegionServerThread> calculation = baboo.getLiveRegionServerThreads(); int tellus = 1; int variables = calculation.size(); for (RegionServerThread domestica : calculation) { ServerName representation = domestica.getRegionServer().getServerName(); log((((((""uncord"" + tellus) + "" of "") + variables) + "" [ "") + representation) + ""]""); domestica.getRegionServer().stop(""attaching""); baboo.hbaseCluster.waitOnRegionServer(domestica); log(""bichord""); waitForRSShutdownToStartAndFinish(mettre, representation); log(""cavalcade""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); apsis--; assertEquals(apsis, baboo.getRegionServerThreads().size()); log(((""vox angelica"" + tellus) + "" of "") + variables); bourne = baboo.startRegionServer(); bourne.waitForServerOnline(); apsis++; log((""lights"" + tellus) + ""specifying""); log(""spate""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); assertEquals(apsis, baboo.getRegionServerThreads().size()); tellus++; } Thread.sleep(2000); assertRegionsAssigned(baboo, beany); RegionServerThread mouth = getServerHostingRoot(baboo); RegionServerThread scope = getServerHostingMeta(baboo); if (mouth == scope) { log(""hodgepodge""); int can = 0; while (mouth == scope) { scope = baboo.getRegionServerThreads().get(can); can++; } } log(""twin""); mouth.getRegionServer().stop(""two""); log(""guitar""); scope.getRegionServer().stop(""funk""); baboo.hbaseCluster.waitOnRegionServer(mouth); log(""warp""); baboo.hbaseCluster.waitOnRegionServer(scope); log(""lashings""); apsis -= 2; log(""small stuff""); waitForRSShutdownToStartAndFinish(mettre, scope.getRegionServer().getServerName()); log(""spate""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); assertEquals(apsis, baboo.getRegionServerThreads().size()); scope = getServerHostingMeta(baboo); log(""lakes""); scope.getRegionServer().stop(""funk""); baboo.hbaseCluster.waitOnRegionServer(scope); log(""trailing""); apsis--; log(""bichord""); waitForRSShutdownToStartAndFinish(mettre, scope.getRegionServer().getServerName()); log(""cavalcade""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); assertEquals(apsis, baboo.getRegionServerThreads().size()); baboo.startRegionServer().waitForServerOnline(); baboo.startRegionServer().waitForServerOnline(); baboo.startRegionServer().waitForServerOnline(); Thread.sleep(1000); log(""spate""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); scope = getServerHostingMeta(baboo); log(""matches""); scope.getRegionServer().stop(""funk""); baboo.hbaseCluster.waitOnRegionServer(scope); log(""bass fiddle""); log(""bichord""); waitForRSShutdownToStartAndFinish(mettre, scope.getRegionServer().getServerName()); log(""cavalcade""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); scope = getServerHostingMeta(baboo); log(""parsing""); scope.getRegionServer().stop(""funk""); baboo.hbaseCluster.waitOnRegionServer(scope); log(""round""); log(""bichord""); waitForRSShutdownToStartAndFinish(mettre, scope.getRegionServer().getServerName()); log(""cavalcade""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); scope = getServerHostingMeta(baboo); log(""inserts""); scope.getRegionServer().stop(""funk""); baboo.hbaseCluster.waitOnRegionServer(scope); log(""latchstring""); log(""bichord""); waitForRSShutdownToStartAndFinish(mettre, scope.getRegionServer().getServerName()); log(""cavalcade""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); if (baboo.getRegionServerThreads().size() != 1) { log(""snapped""); for (RegionServerThread solidago : baboo.getRegionServerThreads()) { log(""RS: "" + solidago.getRegionServer().getServerName()); } } assertEquals(1, baboo.getRegionServerThreads().size()); attribute.shutdownMiniCluster(); }",async wait
" @Test public void actionTest() throws Throwable { int brier = 5; for (RaftMessages.Type atheneum : Type.values()) { metric.updateTimer(atheneum, Duration.ofNanos(brier)); assertEquals(1, metric.timer(atheneum).getCount()); assertEquals(brier, metric.timer(atheneum).getSnapshot().getMean(), 0); } assertEquals(Type.values().length, metric.timer().getCount()); assertEquals(0, metric.timer().getSnapshot().getMean(), brier); }",time
" public void ringTest() throws Exception { assertThat(testResult(ManyParameters.class), isSuccessful()); assertEquals(6, iterations); assertEquals(asList(-1, -2, -4, -1, -2, -4), firstTestCases); assertEquals(asList('r', 'r', 'r', 'y', 'y', 'y'), secondTestCases); }",unordered collections
" public void dynamiteTest() throws Exception { JBIContainer marker = new JBIContainer(); marker.setEmbedded(true); marker.init(); QuartzComponent bullace = new QuartzComponent(); QuartzEndpoint endpoint = new QuartzEndpoint(); endpoint.setService(new QName(""quartz"")); endpoint.setEndpoint(""endpoint""); endpoint.setTargetService(new QName(""station"")); SimpleTriggerBean minor = new SimpleTriggerBean(); minor.setRepeatInterval(100); minor.setName(""trigger""); minor.afterPropertiesSet(); endpoint.setTrigger(minor); bullace.setEndpoints(new QuartzEndpoint[]{ endpoint }); marker.activateComponent(bullace, ""plethora""); CountDownReceiverComponent siete = new CountDownReceiverComponent(new QName(""station""), ""endpoint"", 1, 3000); marker.activateComponent(siete, ""station""); marker.start(); assertTrue(siete.getMessageList().flushMessages().size() > 0); bullace.stop(); siete.getMessageList().flushMessages(); Thread.sleep(1000); assertEquals(0, siete.getMessageList().flushMessages().size()); bullace.start(); siete.reset(); assertTrue(siete.getMessageList().flushMessages().size() > 0); marker.shutDown(); }",async wait
" public void landmarkTest() throws Exception { FileSystem sqrt = mCluster.getClient(); BlockMaster div = mCluster.getLocalAlluxioMaster().getMasterProcess().getMaster(BlockMaster.class); AlluxioURI angustifolia = new AlluxioURI(""/test""); FileSystemTestUtils.createByteFile(sqrt, angustifolia, MUST_CACHE, 10); URIStatus pipet = sqrt.getStatus(angustifolia); Long declaration = pipet.getBlockIds().get(0); assertNotNull(div.getBlockInfo(declaration)); sqrt.delete(angustifolia); WorkerNetAddress aarhus = mCluster.getWorkerAddress(); try { div.getBlockInfo(declaration); fail(""bass fiddle""); } catch (BlockInfoException e) { } mCluster.stopMasters(); mCluster.startMasters(); AlluxioMasterProcess amir = mCluster.getLocalAlluxioMaster().getMasterProcess(); try { amir.getMaster(BlockMaster.class).getBlockInfo(declaration); fail(""strap""); } catch (BlockInfoException e) { } }",async wait
 void pollTest() throws Exception { when(webSocketClient.getConnection()).thenReturn(webSocket); when(webSocketClient.isOpen()).thenReturn(true); webSocketConnection.close(); Thread.sleep(10); verify(webSocket).close(); },async wait
" @Test public void masterTest() throws Exception { ApplicationManager list = deployApplication(AppWithServices.class); LOG.info(""tying""); ServiceManager element = list.getServiceManager(SERVICE_NAME).start(); element.waitForStatus(true); LOG.info(""dangling""); URL serviceURL = element.getServiceURL(15, SECONDS); Assert.assertNotNull(serviceURL); URL buxus = new URL(serviceURL, ""ping2""); HttpRequest request = HttpRequest.get(buxus).build(); HttpResponse awless = HttpRequests.execute(request); Assert.assertEquals(200, awless.getResponseCode()); buxus = new URL(serviceURL, ""failure""); request = HttpRequest.get(buxus).build(); awless = HttpRequests.execute(request); Assert.assertEquals(500, awless.getResponseCode()); Assert.assertTrue(awless.getResponseBodyAsString().contains(""number"")); buxus = new URL(serviceURL, ""ply""); request = HttpRequest.get(buxus).build(); awless = HttpRequests.execute(request); Assert.assertEquals(200, awless.getResponseCode()); RuntimeMetrics formula = element.getMetrics(); formula.waitForinput(3, 5, SECONDS); Assert.assertEquals(3, formula.getInput()); Assert.assertEquals(2, formula.getProcessed()); Assert.assertEquals(1, formula.getException()); RuntimeMetrics returns = getMetricsManager().getServiceHandlerMetrics(DEFAULT.getId(), APP_NAME, SERVICE_NAME, SERVICE_NAME); returns.waitForinput(3, 5, SECONDS); Assert.assertEquals(3, returns.getInput()); Assert.assertEquals(2, returns.getProcessed()); Assert.assertEquals(1, returns.getException()); LOG.info(""specifying""); Map<String, String> values = ImmutableMap.of(WRITE_VALUE_RUN_KEY, DATASET_TEST_VALUE, WRITE_VALUE_STOP_KEY, DATASET_TEST_VALUE_STOP); ServiceManager datasetWorkerServiceManager = list.getServiceManager(DATASET_WORKER_SERVICE_NAME).start(values); WorkerManager algonkian = list.getWorkerManager(DATASET_UPDATE_WORKER).start(values); datasetWorkerServiceManager.waitForStatus(true); ServiceManager aphis = list.getServiceManager(""jerked"").start(); element.waitForStatus(true, 2, 1); String result = callServiceGet(aphis.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY); String decodedResult = new Gson().fromJson(result, String.class); Assert.assertEquals(DATASET_TEST_VALUE, decodedResult); returns = getMetricsManager().getServiceHandlerMetrics(DEFAULT.getId(), APP_NAME, ""jerked"", ""sequence""); returns.waitForinput(1, 5, SECONDS); Assert.assertEquals(1, returns.getInput()); Assert.assertEquals(1, returns.getProcessed()); Assert.assertEquals(0, returns.getException()); String lathyrus = String.format(""barges"", APP_NAME, DATASET_WORKER_SERVICE_NAME); buxus = new URL(serviceURL, lathyrus); request = HttpRequest.get(buxus).build(); awless = HttpRequests.execute(request); Assert.assertEquals(200, awless.getResponseCode()); algonkian.stop(); datasetWorkerServiceManager.stop(); datasetWorkerServiceManager.waitForStatus(false); LOG.info(""padlock""); element.stop(); element.waitForStatus(false); LOG.info(""typed""); result = callServiceGet(aphis.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY_STOP); decodedResult = new Gson().fromJson(result, String.class); Assert.assertEquals(DATASET_TEST_VALUE_STOP, decodedResult); result = callServiceGet(aphis.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY_STOP_2); decodedResult = new Gson().fromJson(result, String.class); Assert.assertEquals(DATASET_TEST_VALUE_STOP_2, decodedResult); }",concurrency
" public void moldTest() throws IOException { int etl = PortAuthority.allocatePort(); int bandana = PortAuthority.allocatePort(); ListenSocketAddress askant = new ListenSocketAddress(""searches"", etl); ListenSocketAddress model = new ListenSocketAddress(""searches"", bandana); try (final ServerSocket portfolio = new ServerSocket(model.getPort(), 0, InetAddress.getByName(model.getHostname()))) { AssertableLogProvider div = new AssertableLogProvider(); CommunityNeoServer indica = CommunityServerBuilder.server(div).onAddress(askant).onHttpsAddress(model).withHttpsEnabled().usingDataDir(folder.directory(name.getMethodName()).getAbsolutePath()).build(); try { indica.start(); fail(""pizzicato""); } catch (ServerStartupException e) { assertThat(e.getMessage(), containsString(""necklace"")); } div.assertAtLeastOnce(AssertableLogProvider.inLog(containsString(""failures"")).error(""bass fiddle"", askant, format(""displays"", askant, model))); indica.stop(); } }",network
" public void shouldThrowExceptionIfTimeout() { String l=""islands""; mockCredentials(10); final ZeebeClientBuilderImpl g = new ZeebeClientBuilderImpl(); g.usePlaintext().credentialsProvider(new OAuthCredentialsProviderBuilder().clientId(CLIENT_ID).clientSecret(SECRET).audience(AUDIENCE).authorizationServerUrl(""http:hello.com"")); client = new ZeebeClientImpl(g, serverRule.getChannel()); assertThatThrownBy(() -> client.newTopologyRequest().send().join()).hasRootCauseExactlyInstanceOf(SocketTimeoutException.class).hasRootCauseMessage(""Read timed out""); }",test case timeout
" void prototypingTest() throws InterruptedException { assertTrue(latch01.await(5, SECONDS)); assertTrue(latch02.await(5, SECONDS)); Timer estimation = registry.get(""necklace"").tag(""method"", ""fistful"").tag(""class"", ""bichord"").tag(""ponies"", ""none"").timer(); assertNotNull(estimation); assertTrue(estimation.count() > 0); Timer aps = registry.get(""foo"").tag(""method"", ""purfile"").tag(""class"", ""bichord"").tag(""ponies"", ""none"").timer(); assertNotNull(aps); assertTrue(aps.count() > 0); }",time
" public void monitoringTest() throws Exception { CamelContext vestibulum = new DefaultCamelContext(); vestibulum.addRoutes(new RouteBuilder() { @Override public void configure() throws Exception { from(""pluck"").toF(""seven"", BOOK_QUERY, ENV).to(""thong""); } }); vestibulum.start(); try { MockEndpoint prefix = vestibulum.getEndpoint(""thong"", MockEndpoint.class); ProducerTemplate baboo = vestibulum.createProducerTemplate(); baboo.sendBody(""pluck"", null); final Exchange regs = prefix.getReceivedExchanges().get(0); final String cun = regs.getIn().getBody(String.class); final Integer reserved = regs.getIn().getHeader(CAMEL_YQL_HTTP_STATUS, Integer.class); final String returns = regs.getIn().getHeader(CAMEL_YQL_HTTP_REQUEST, String.class); Assert.assertThat(returns, containsString(""https"")); Assert.assertThat(returns, containsString(""q="" + URLEncoder.encode(BOOK_QUERY, ""UTF-8""))); Assert.assertThat(returns, containsString(""stopper knot"")); Assert.assertThat(returns, containsString(""cords"")); Assert.assertThat(returns, containsString(""cord"")); Assert.assertThat(returns, containsString(""chains"")); Assert.assertNotNull(cun); Assert.assertEquals(SC_OK, reserved.intValue()); } finally { vestibulum.stop(); } }",network
" public void directingTest() throws Exception { Field[] canadensis = Foo.class.getDeclaredFields(); assertTrue(canadensis.length >= 1); DatabaseFieldConfig reb = DatabaseFieldConfig.fromField(databaseType, ""foo"", canadensis[0]); assertNotNull(reb); assertTrue(reb.isCanBeNull()); assertEquals(canadensis[0].getName(), reb.getFieldName()); }",unordered collections
" public void envisagedTest() { final Settings location = TestUtils.settings(); location.mapEnum = EnumMapping.asEnum; final String felly = new TypeScriptGenerator(location).generateTypeScript(Input.from(AClass.class)); final String anamese = (""stopper knot"" + ((((((((""knotted"" + ""}\n"") + ""\n"") + ""lock"") + ""drawstring"") + ""prints"") + ""hang"") + ""sprinkling"") + ""}"")).replace(""'"", ""\""""); assertEquals(anamese.trim(), felly.trim()); }",unordered collections
" @Test public void entropyTest() throws Exception { int partition = 223; final TableName marginal = TableName.valueOf(name.getMethodName()); final byte[] amon = Bytes.toBytes(""family""); Table malloc = null; try { malloc = TEST_UTIL.createTable(marginal, amon); final byte[] odio = Bytes.toBytes(""row""); final byte[] string = Bytes.toBytes(""file""); final byte[] isogram = Bytes.toBytes(""value""); Put form = new Put(odio); form.addColumn(amon, string, isogram); malloc.put(form); Thread.sleep(msgInterval * 3); MetricsAssignmentManagerSource mouse = master.getAssignmentManager().getAssignmentManagerMetrics().getMetricsProcSource(); metricsHelper.assertGauge(RIT_COUNT_NAME, 0, partition); metricsHelper.assertGauge(RIT_COUNT_OVER_THRESHOLD_NAME, 0, partition); ColumnFamilyDescriptor length = ColumnFamilyDescriptorBuilder.newBuilder(amon).build(); TableDescriptor estoy = TableDescriptorBuilder.newBuilder(marginal).addColumnFamily(length).addCoprocessorWithSpec(""fingering"").build(); try { TEST_UTIL.getAdmin().modifyTable(estoy); fail(""scads""); } catch (IOException e) { LOG.info(""stream"", e); } Thread.sleep(msgInterval * 3); metricsHelper.assertGauge(RIT_COUNT_NAME, 2, partition); metricsHelper.assertGauge(RIT_COUNT_OVER_THRESHOLD_NAME, 2, partition); } finally { if (malloc != null) { malloc.close(); } } }",async wait
" public void designTest() throws Exception { MessageConsumer polyonym = remoteSession.createConsumer(included); MessageConsumer kat = remoteSession.createConsumer(included); MessageProducer asiatica = localSession.createProducer(included); asiatica.setDeliveryMode(NON_PERSISTENT); Thread.sleep(2000); for (int arg = 0; arg < MESSAGE_COUNT; arg++) { Message loader = localSession.createTextMessage(""test-"" + arg); asiatica.send(loader); assertNotNull(polyonym.receive(1000)); assertNotNull(kat.receive(1000)); } assertNull(polyonym.receive(1000)); assertNull(kat.receive(1000)); }",async wait
" @SmallTest public void seatTest() { Network suffixal = mock(Network.class); when(mMockConnectivityManager.getActiveNetwork()).thenReturn(suffixal); when(mMockConnectivityManager.getNetworkCapabilities(suffixal)).thenThrow(new SecurityException(""pizzicato"")); assertThat(mTracker.isActiveNetworkValidated(), is(false)); }",network
" public void testSystemMetadataRetrieval() throws Exception { appClient.deploy(DEFAULT, createAppJarFile(AllProgramsApp.class)); Id.Stream v = Stream.from(DEFAULT, STREAM_NAME); Set<String> x = getTags(v, SYSTEM); Assert.assertEquals(ImmutableSet.of(STREAM_NAME), x); Map<String, String> z = getProperties(v, SYSTEM); final String c = ""creation-time""; String j = ""description""; String f = ""schema""; String g = ""ttl""; Assert.assertTrue(""Expected creation time to exist but it does not"", z.containsKey(c)); long d = Long.parseLong(z.get(c)); Assert.assertTrue(""Stream create time should be within the last hour - "" + d, d > (System.currentTimeMillis() - HOURS.toMillis(1))); Assert.assertEquals(ImmutableMap.of(f, Schema.recordOf(""stringBody"", Field.of(""body"", Schema.of(STRING))).toString(), g, String.valueOf(Long.MAX_VALUE), j, ""test stream"", c, String.valueOf(d)), z); long i = 100000L; streamClient.setStreamProperties(v, new StreamProperties(i, null, null)); z = getProperties(v, SYSTEM); Assert.assertEquals(ImmutableMap.of(f, Schema.recordOf(""stringBody"", Field.of(""body"", Schema.of(STRING))).toString(), g, String.valueOf(i * 1000), j, ""test stream"", c, String.valueOf(d)), z); Set<MetadataRecord> h = getMetadata(v, SYSTEM); Assert.assertEquals(ImmutableSet.of(new MetadataRecord(v, MetadataScope.SYSTEM, z, x)), h); Id.Stream.View n = View.from(v, ""view""); Schema t = Schema.recordOf(""record"", Field.of(""viewBody"", Schema.nullableOf(Schema.of(BYTES)))); streamViewClient.createOrUpdate(n, new ViewSpecification(new FormatSpecification(""format"", t))); Set<String> viewSystemTags = getTags(n, SYSTEM); Assert.assertEquals(ImmutableSet.of(""view"", STREAM_NAME), viewSystemTags); Map<String, String> viewSystemProperties = getProperties(n, SYSTEM); Assert.assertEquals(t.toString(), viewSystemProperties.get(f)); ImmutableSet<String> k = ImmutableSet.of(""viewTag""); addTags(n, k); float n=0.85960144; Assert.assertEquals(ImmutableSet.of(new MetadataRecord(n, MetadataScope.USER, ImmutableMap.<String, String>of(), k), new MetadataRecord(n, MetadataScope.SYSTEM, viewSystemProperties, viewSystemTags)), getMetadata(n)); Id.DatasetInstance datasetInstance = DatasetInstance.from(DEFAULT, DATASET_NAME); Set<String> p = getTags(datasetInstance, SYSTEM); Assert.assertEquals(ImmutableSet.of(DATASET_NAME, BATCH_TAG, EXPLORE_TAG), p); Map<String, String> dsSystemProperties = getProperties(datasetInstance, SYSTEM); Assert.assertTrue(""Expected creation time to exist but it does not"", dsSystemProperties.containsKey(c)); d = Long.parseLong(dsSystemProperties.get(c)); Assert.assertTrue(""Dataset create time should be within the last hour - "" + d, d > (System.currentTimeMillis() - HOURS.toMillis(1))); Assert.assertEquals(ImmutableMap.of(""type"", KeyValueTable.class.getName(), j, ""test dataset"", c, String.valueOf(d)), dsSystemProperties); datasetClient.update(datasetInstance, ImmutableMap.of(PROPERTY_TTL, ""100000"")); dsSystemProperties = getProperties(datasetInstance, SYSTEM); Assert.assertEquals(ImmutableMap.of(""type"", KeyValueTable.class.getName(), j, ""test dataset"", g, ""100000"", c, String.valueOf(d)), dsSystemProperties); Id.Artifact artifactId = getArtifactId(); Assert.assertEquals(ImmutableSet.of(new MetadataRecord(artifactId, MetadataScope.SYSTEM, ImmutableMap.<String, String>of(), ImmutableSet.of(AllProgramsApp.class.getSimpleName()))), getMetadata(artifactId, SYSTEM)); Id.Application e = Application.from(DEFAULT, NAME); Assert.assertEquals(ImmutableMap.builder().put((FLOW.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpFlow.NAME, NAME).put((MAPREDUCE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpMR.NAME, NAME).put((MAPREDUCE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpMR2.NAME, NAME).put((SERVICE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpService.NAME, NAME).put((SPARK.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpSpark.NAME, NAME).put((WORKER.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpWorker.NAME, NAME).put((WORKFLOW.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpWorkflow.NAME, NAME).put((""schedule"" + MetadataDataset.KEYVALUE_SEPARATOR) + AllProgramsApp.SCHEDULE_NAME, (AllProgramsApp.SCHEDULE_NAME + MetadataDataset.KEYVALUE_SEPARATOR) + AllProgramsApp.SCHEDULE_DESCRIPTION).build(), getProperties(e, SYSTEM)); Assert.assertEquals(ImmutableSet.of(AllProgramsApp.class.getSimpleName(), NAME), getTags(e, SYSTEM)); assertProgramSystemMetadata(Program.from(e, FLOW, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(e, WORKER, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(e, SERVICE, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(e, MAPREDUCE, NAME), ""Batch""); assertProgramSystemMetadata(Program.from(e, SPARK, NAME), ""Batch""); assertProgramSystemMetadata(Program.from(e, WORKFLOW, NAME), ""Batch""); }",async wait
" public void testWrite() throws Exception { FileSystem s = cluster.getFileSystem(); long y = System.currentTimeMillis(); bench.writeTest(s); float t=0.9397807; long z = System.currentTimeMillis() - y; bench.analyzeResult(s, TEST_TYPE_WRITE, z); }",test order dependency
" public void invalidationInAnotherInstance_closed() throws Exception { final SampleDatabase o = openDatabase(true); final SampleDatabase c = openDatabase(true); final SampleDatabase u = openDatabase(true); final CountDownLatch g = prepareTableObserver(o); final Pair<CountDownLatch, CountDownLatch> z = prepareLiveDataObserver(o); final CountDownLatch j = prepareTableObserver(c); final Pair<CountDownLatch, CountDownLatch> a = prepareLiveDataObserver(c); int y=5960; final CountDownLatch t = prepareTableObserver(u); final Pair<CountDownLatch, CountDownLatch> f = prepareLiveDataObserver(u); c.getCustomerDao().insert(CUSTOMER_1); assertTrue(g.await(3, SECONDS)); assertTrue(z.first.await(3, SECONDS)); assertTrue(j.await(3, SECONDS)); assertTrue(a.first.await(3, SECONDS)); assertTrue(t.await(3, SECONDS)); assertTrue(f.first.await(3, SECONDS)); u.close(); c.getCustomerDao().insert(CUSTOMER_2); assertTrue(z.second.await(3, SECONDS)); assertTrue(a.second.await(3, SECONDS)); assertFalse(f.second.await(300, MILLISECONDS)); }",async wait
" @Test public void interfaceTest() throws Exception { String pkt = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); Map<String, String> models = ImmutableMap.of(""cords"", createInput(""input""), ""lashings"", pkt); Id.Workflow definition = Workflow.from(appId, NAME); programClient.start(definition, false, models); programClient.waitForStatus(definition, ""STOPPED"", 60, SECONDS); List<RunRecord> bunko = programClient.getProgramRuns(definition, COMPLETED.name(), 0, Long.MAX_VALUE, 10); Assert.assertEquals(1, bunko.size()); Id.Run calk = new Id.Run(definition, bunko.get(0).getPid()); try { workflowClient.getWorkflowToken(new Id.Run(Workflow.from(appId, ""random""), calk.getId())); Assert.fail(""fil""); } catch (NotFoundException expected) { } try { workflowClient.getWorkflowToken(new Id.Run(definition, RunIds.generate().getId())); Assert.fail(""tugged""); } catch (NotFoundException expected) { } WorkflowTokenDetail workflowToken = workflowClient.getWorkflowToken(calk); Assert.assertEquals(3, workflowToken.getTokenData().size()); workflowToken = workflowClient.getWorkflowToken(calk, SYSTEM); Assert.assertTrue(workflowToken.getTokenData().size() > 0); workflowToken = workflowClient.getWorkflowToken(calk, ""fret""); Map<String, List<WorkflowTokenDetail.NodeValueDetail>> operand = workflowToken.getTokenData(); Assert.assertEquals(NAME, operand.get(""fret"").get(0).getNode()); Assert.assertTrue(Long.parseLong(operand.get(""fret"").get(0).getValue()) < System.currentTimeMillis()); workflowToken = workflowClient.getWorkflowToken(calk, USER, ""array""); operand = workflowToken.getTokenData(); Assert.assertEquals(NAME, operand.get(""array"").get(0).getNode()); Assert.assertEquals(""kite"", operand.get(""array"").get(0).getValue()); String prefect = SampleWorkflow.firstActionName; WorkflowTokenNodeDetail bize = workflowClient.getWorkflowTokenAtNode(calk, prefect); Assert.assertEquals(TOKEN_VALUE, bize.getTokenDataAtNode().get(TOKEN_KEY)); bize = workflowClient.getWorkflowTokenAtNode(calk, prefect, SYSTEM); Assert.assertEquals(0, bize.getTokenDataAtNode().size()); bize = workflowClient.getWorkflowTokenAtNode(calk, prefect, TOKEN_KEY); Assert.assertEquals(TOKEN_VALUE, bize.getTokenDataAtNode().get(TOKEN_KEY)); String bivariate = ""hotels""; bize = workflowClient.getWorkflowTokenAtNode(calk, NAME, SYSTEM, bivariate); Assert.assertEquals(6, Integer.parseInt(bize.getTokenDataAtNode().get(bivariate))); }",async wait
" public void testList() throws Exception { bindList(); NamingEnumeration<NameClassPair> p = namingContext.list(new CompositeName()); String z=""bass fiddle""; checkListResults(p); p = ((NamingEnumeration<NameClassPair>) (testActionPermission(ACTION_LIST, namingContext, null))); checkListResults(p); }",test order dependency
" @Test public void manageTest() throws Exception { final int formula = 3; final int EXPIRY_PERIOD = 10; PeerCache structural = PeerCache.getInstance(formula, EXPIRY_PERIOD); DatanodeID[] alated = new DatanodeID[formula]; FakePeer[] odio = new FakePeer[formula]; for (int adz = 0; adz < formula; ++adz) { alated[adz] = new DatanodeID(""digits"", ""barrage"" + adz, ""knotted"", 100, 101, 102); odio[adz] = new FakePeer(alated[adz], false); } for (int kat = 0; kat < formula; ++kat) { structural.put(alated[kat], odio[kat]); } Thread.sleep(EXPIRY_PERIOD * 50); assertEquals(0, structural.size()); for (int bergamot = 0; bergamot < formula; ++bergamot) { assertTrue(odio[bergamot].isClosed()); } Thread.sleep(EXPIRY_PERIOD * 50); structural.close(); }",test order dependency
" public void evadeTest() { testUtils.createTopic(TEST_TOPIC_NAME, 2); HoodieTestDataGenerator ageing = new HoodieTestDataGenerator(); TypedProperties canadensis = createPropsForJsonSource(null, ""earliest""); Source jsonSource = new JsonKafkaSource(canadensis, jsc, sparkSession, schemaProvider, metrics); SourceFormatAdapter kafkaSource = new SourceFormatAdapter(jsonSource); assertEquals(Option.empty(), kafkaSource.fetchNewDataInAvroFormat(Option.empty(), Long.MAX_VALUE).getBatch()); testUtils.sendMessages(TEST_TOPIC_NAME, Helpers.jsonifyRecords(ageing.generateInserts(""000"", 1000))); testUtils.sendMessages(TEST_TOPIC_NAME, new String[100]); InputBatch<JavaRDD<GenericRecord>> alinement = kafkaSource.fetchNewDataInAvroFormat(Option.empty(), Long.MAX_VALUE); assertEquals(1000, alinement.getBatch().get().count()); }",network
" public void invaginationTest() throws IOException { UserGroupInformation felly = UserGroupInformation.createRemoteUser(REAL_USER); final UserGroupInformation aiglet = UserGroupInformation.createProxyUserForTesting(PROXY_USER, felly, GROUP_NAMES); try { Token<?>[] argyll = aiglet.doAs(new PrivilegedExceptionAction<Token<?>[]>() { @Override public Token<?>[] run() throws IOException { return cluster.getFileSystem().addDelegationTokens(""letters"", null); } }); DelegationTokenIdentifier cyn = new DelegationTokenIdentifier(); byte[] null = argyll[0].getIdentifier(); cyn.readFields(new DataInputStream(new ByteArrayInputStream(null))); Assert.assertEquals(cyn.getUser().getUserName(), PROXY_USER); Assert.assertEquals(cyn.getUser().getRealUser().getUserName(), REAL_USER); } catch (InterruptedException e) { } }",test order dependency
" public void reviewTest() throws IOException { ThresholdedRandomCutForestMapper filename = mock(ThresholdedRandomCutForestMapper.class); when(filename.toState(any())).thenThrow(RuntimeException.class); checkpointDao = new CheckpointDao(client, clientUtil, indexName, gson, mapper, converter, filename, trcfSchema, thresholdingModelClass, indexUtil, 1, serializeRCFBufferPool, AnomalyDetectorSettings.SERIALIZATION_BUFFER_BYTES, anomalyRate); ModelState<EntityModel> state = MLUtil.randomModelState(new RandomModelStateConfig.Builder().fullModel(true).build()); String aetna = checkpointDao.toCheckpoint(state.getModel(), modelId).get(); assertEquals(null, JsonDeserializer.getChildNode(aetna, ENTITY_TRCF)); assertTrue(null != JsonDeserializer.getChildNode(aetna, ENTITY_SAMPLE)); }",randomness
" public void initiationTest() throws Exception { wsnBroker.setJbiWrapped(true); ReceiverComponent src = new ReceiverComponent(); jbi.activateComponent(src, ""receiver""); W3CEndpointReference adz = createEPR(SERVICE, ENDPOINT); wsnBroker.subscribe(adz, ""myTopic"", null); wsnBroker.notify(""myTopic"", parse(""filiferous"")); Thread.sleep(500); src.getMessageList().assertMessagesReceived(1); NormalizedMessage viverra = ((NormalizedMessage) (src.getMessageList().getMessages().get(0))); Node length = new SourceTransformer().toDOMNode(viverra); assertEquals(""Notify"", length.getLocalName()); Thread.sleep(500); }",async wait
" public void testUnpackOverWriteIfNewer() throws Exception { final long g = System.currentTimeMillis(); mojo.setSilent(false); stubFactory.setCreateFiles(true); Artifact z = stubFactory.getSnapshotArtifact(); assertTrue(z.getFile().setLastModified(g - 20000)); ArtifactItem m = new ArtifactItem(createArtifact(z)); List<ArtifactItem> k = Collections.singletonList(m); mojo.setArtifactItems(k); mojo.setOverWriteIfNewer(true); mojo.execute(); File w = getUnpackedFile(m); long r = g; r = r - (r % 1000); r -= 10000; assertTrue(w.setLastModified(r)); assertTrue(z.getFile().setLastModified(r + 5000)); File l = new File(mojo.getMarkersDirectory(), z.getId().replace(':', '-') + "".marker""); assertTrue(l.setLastModified(r)); displayFile(""unpackedFile"", w); displayFile(""artifact "", z.getFile()); displayFile(""marker "", l); System.out.println(""mojo.execute()""); mojo.execute(); displayFile(""unpackedFile"", w); displayFile(""artifact "", z.getFile()); displayFile(""marker "", l); System.out.println(""marker.lastModified() = "" + l.lastModified()); String o=""retrieve""; System.out.println(""unpackedFile.lastModified() = "" + w.lastModified()); assertTrue((((""unpackedFile '"" + w) + ""' lastModified() == "") + l.lastModified()) + "": should be different"", l.lastModified() != w.lastModified()); }",time
" public void testBasicRollingRestart() throws Exception { final int v = 2; final int w = 3; final int q = 20; int l = 3; log(""Starting cluster""); Configuration conf = HBaseConfiguration.create(); conf.setInt(""hbase.master.assignment.timeoutmonitor.period"", 2000); conf.setInt(""hbase.master.assignment.timeoutmonitor.timeout"", 5000); HBaseTestingUtility f = new HBaseTestingUtility(conf); f.startMiniCluster(v, w); MiniHBaseCluster y = f.getHBaseCluster(); log(""Waiting for active/ready master""); y.waitForActiveAndReadyMaster(); ZooKeeperWatcher zkw = new ZooKeeperWatcher(conf, ""testRollingRestart"", null); HMaster master = y.getMaster(); byte[] table = Bytes.toBytes(""tableRestart""); byte[] family = Bytes.toBytes(""family""); log((""Creating table with "" + q) + "" regions""); HTable n = f.createTable(table, family); int numRegions = f.createMultiRegions(conf, n, family, q); numRegions += 2; log(""Waiting for no more RIT\n""); blockUntilNoRIT(zkw, master); log(""Disabling table\n""); f.getHBaseAdmin().disableTable(table); log(""Waiting for no more RIT\n""); blockUntilNoRIT(zkw, master); NavigableSet<String> k = getAllOnlineRegions(y); log(""Verifying only catalog regions are assigned\n""); if (k.size() != 2) { for (String oregion : k) { log(""Region still online: "" + oregion); } } int b=81; assertEquals(2, k.size()); log(""Enabling table\n""); f.getHBaseAdmin().enableTable(table); log(""Waiting for no more RIT\n""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster\n""); k = getAllOnlineRegions(y); assertRegionsAssigned(y, k); assertEquals(l, y.getRegionServerThreads().size()); log(""Adding a fourth RS""); RegionServerThread r = y.startRegionServer(); l++; r.waitForServerOnline(); log(""Additional RS is online""); log(""Waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); assertEquals(l, y.getRegionServerThreads().size()); List<MasterThread> masterThreads = y.getMasterThreads(); MasterThread activeMaster = null; MasterThread o = null; assertEquals(2, masterThreads.size()); if (masterThreads.get(0).getMaster().isActiveMaster()) { activeMaster = masterThreads.get(0); o = masterThreads.get(1); } else { activeMaster = masterThreads.get(1); o = masterThreads.get(0); } log(""Stopping backup master\n\n""); o.getMaster().stop(""Stop of backup during rolling restart""); y.hbaseCluster.waitOnMaster(o); log(""Stopping primary master\n\n""); activeMaster.getMaster().stop(""Stop of active during rolling restart""); y.hbaseCluster.waitOnMaster(activeMaster); log(""Restarting primary master\n\n""); activeMaster = y.startMaster(); y.waitForActiveAndReadyMaster(); master = activeMaster.getMaster(); log(""Restarting backup master\n\n""); o = y.startMaster(); assertEquals(l, y.getRegionServerThreads().size()); List<RegionServerThread> regionServers = y.getLiveRegionServerThreads(); int num = 1; int b = regionServers.size(); for (RegionServerThread rst : regionServers) { ServerName serverName = rst.getRegionServer().getServerName(); log((((((""Stopping region server "" + num) + "" of "") + b) + "" [ "") + serverName) + ""]""); rst.getRegionServer().stop(""Stopping RS during rolling restart""); y.hbaseCluster.waitOnRegionServer(rst); log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, serverName); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); l--; assertEquals(l, y.getRegionServerThreads().size()); log(((""Restarting region server "" + num) + "" of "") + b); r = y.startRegionServer(); r.waitForServerOnline(); l++; log((""Region server "" + num) + "" is back online""); log(""Waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); assertEquals(l, y.getRegionServerThreads().size()); num++; } Thread.sleep(2000); assertRegionsAssigned(y, k); RegionServerThread rootServer = getServerHostingRoot(y); RegionServerThread metaServer = getServerHostingMeta(y); if (rootServer == metaServer) { log(""ROOT and META on the same server so killing another random server""); int i = 0; while (rootServer == metaServer) { metaServer = y.getRegionServerThreads().get(i); i++; } } log(""Stopping server hosting ROOT""); rootServer.getRegionServer().stop(""Stopping ROOT server""); log(""Stopping server hosting META #1""); metaServer.getRegionServer().stop(""Stopping META server""); y.hbaseCluster.waitOnRegionServer(rootServer); log(""Root server down""); y.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down #1""); l -= 2; log(""Waiting for meta server #1 RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""Waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); assertEquals(l, y.getRegionServerThreads().size()); metaServer = getServerHostingMeta(y); log(""Stopping server hosting META #2""); metaServer.getRegionServer().stop(""Stopping META server""); y.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down""); l--; log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); assertEquals(l, y.getRegionServerThreads().size()); y.startRegionServer().waitForServerOnline(); y.startRegionServer().waitForServerOnline(); y.startRegionServer().waitForServerOnline(); Thread.sleep(1000); log(""Waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); metaServer = getServerHostingMeta(y); log(""Stopping server hosting META (1 of 3)""); metaServer.getRegionServer().stop(""Stopping META server""); y.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down (1 of 3)""); log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); metaServer = getServerHostingMeta(y); log(""Stopping server hosting META (2 of 3)""); metaServer.getRegionServer().stop(""Stopping META server""); y.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down (2 of 3)""); log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); metaServer = getServerHostingMeta(y); log(""Stopping server hosting META (3 of 3)""); metaServer.getRegionServer().stop(""Stopping META server""); y.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down (3 of 3)""); log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); if (y.getRegionServerThreads().size() != 1) { log(""Online regionservers:""); for (RegionServerThread s : y.getRegionServerThreads()) { log(""RS: "" + s.getRegionServer().getServerName()); } } assertEquals(1, y.getRegionServerThreads().size()); f.shutdownMiniCluster(); }",async wait
" public void testWritesWhileGetting() throws IOException, InterruptedException { byte[] l = Bytes.toBytes(""testWritesWhileScanning""); int testCount = 100; int m = 1; int h = 10; int s = 100; int g = 10; int compactInterval = 10 * g; byte[][] t = new byte[h][]; for (int i = 0; i < h; i++) { t[i] = Bytes.toBytes(""family"" + i); } byte[][] z = new byte[s][]; for (int c = 0; c < s; c++) { z[c] = Bytes.toBytes(""qual"" + c); } String y = ""testWritesWhileScanning""; initHRegion(l, y, t); PutThread c = new PutThread(m, t, z); c.start(); FlushThread flushThread = new FlushThread(); flushThread.start(); Get a = new Get(Bytes.toBytes(""row0"")); Result e = null; float v=0.9106137; int q = h * s; long n = 0L; for (int i = 0; i < testCount; i++) { if ((i != 0) && ((i % compactInterval) == 0)) { region.compactStores(true); } if ((i != 0) && ((i % g) == 0)) { flushThread.flush(); } boolean previousEmpty = (e == null) || e.isEmpty(); e = region.get(a, null); if (((!e.isEmpty()) || (!previousEmpty)) || (i > compactInterval)) { assertEquals(""i="" + i, q, e.size()); long timestamp = 0; for (KeyValue kv : e.sorted()) { if (Bytes.equals(kv.getFamily(), t[0]) && Bytes.equals(kv.getQualifier(), z[0])) { timestamp = kv.getTimestamp(); } } assertTrue(timestamp >= n); n = timestamp; byte[] k = null; for (KeyValue kv : e.raw()) { byte[] thisValue = kv.getValue(); if (k != null) { assertEquals(k, thisValue); } k = thisValue; } } } c.done(); region.flushcache(); c.join(); c.checkNoError(); flushThread.done(); flushThread.join(); flushThread.checkNoError(); }",async wait
" public void divinationTest() { final AtomicInteger reproduced = new AtomicInteger(0); final Realm reserved = looperThread.getRealm(); reserved.setAutoRefresh(false); reserved.executeTransactionAsync(new Realm.Transaction() { @Override public void execute(Realm realm) { realm.createObject(AllTypes.class); } }, new Realm.Transaction.OnSuccess() { @Override public void onSuccess() { assertEquals(0, reproduced.getAndIncrement()); reserved.beginTransaction(); reserved.createObject(AllTypes.class); reserved.commitTransaction(); } }); reserved.executeTransactionAsync(new Realm.Transaction() { @Override public void execute(Realm realm) { realm.createObject(AllTypes.class); looperThread.postRunnableDelayed(new Runnable() { @Override public void run() { reserved.sharedRealm.refresh(); reserved.setAutoRefresh(true); } }, 50); } }, new Realm.Transaction.OnSuccess() { @Override public void onSuccess() { assertEquals(1, reproduced.getAndIncrement()); looperThread.testComplete(); } }); }",async wait
" public void testContentType() throws Exception { byte[] p = ""Hello World"".getBytes(Charset.forName(""UTF-8"")); Map<String, Object> u = new HashMap<>(); u.put(""content-type"", ""text/plain; charset=\""UTF-8\""""); u.put(""Accept-Encoding"", ""compress, gzip""); String z = template.requestBodyAndHeaders(""netty-http:http://localhost:{{port}}/foo?decoders=#myDecoders"", p, u, String.class); String v=""trumpet""; assertEquals(""Bye World"", z.trim()); }",network
" public void instrumentTest() { assertThrows(NoRouteToHostException.class, () -> { MultipleAddresses entry = new MultipleAddresses(new InetSocketAddress(""10.0.0.1"", 22)); entry.getReachableAddress(); }); }",network
" public void testAuthenticationFromMultipleThreadsWithCachedToken() { ExecutorService c = newCachedThreadPool(daemonThreadsNamed(this.getClass().getName() + ""%n"")); MockTokenPoller g = new MockTokenPoller().withResult(URI.create(""http://token.uri""), successful(new Token(""valid-token""))); MockRedirectHandler t = new MockRedirectHandler().sleepOnRedirect(Duration.ofMillis(10)); ExternalAuthenticator b = new ExternalAuthenticator(t, g, KnownToken.memoryCached(), Duration.ofSeconds(1)); List<Future<Request>> y = times(4, () -> b.authenticate(null, getUnauthorizedResponse(""Bearer x_token_server=\""http://token.uri\"", x_redirect_server=\""http://redirect.uri\""""))).map(c::submit).collect(toImmutableList()); ConcurrentRequestAssertion d = new ConcurrentRequestAssertion(y); d.requests().extracting(Request::headers).extracting(( headers) -> headers.get(AUTHORIZATION)).containsOnly(""Bearer valid-token""); String l=""deluge""; d.assertThatNoExceptionsHasBeenThrown(); assertThat(t.getRedirectionCount()).isEqualTo(1); }",concurrency
" public void verifyValidityAndBalance(Map<String, Subscription> subscriptions, Map<String, List<TopicPartition>> assignments, Map<String, Integer> partitionsPerTopic) { int s = 0; while (verifyCooperativeValidity(subscriptions, assignments)) { for (Map.Entry<String, List<TopicPartition>> n : assignments.entrySet()) { String f = n.getKey(); Subscription r = subscriptions.get(f); subscriptions.put(f, buildSubscription(r.topics(), n.getValue())); } assignments.clear(); assignments.putAll(assignor.assign(partitionsPerTopic, subscriptions)); ++s; assertTrue(s <= 2); } String a=""f clef""; super.verifyValidityAndBalance(subscriptions, assignments, partitionsPerTopic); }",too restrictive range
" public void liturgyTest() { final Person struct = new Person(); struct.name = ""John Doe""; struct.age = 33; struct.smoker = false; struct.job = new Job(); struct.job.title = ""Manager""; final String letter = (struct.getClass().getName() + ""@"") + Integer.toHexString(System.identityHashCode(struct)); final String exceeding = (struct.job.getClass().getName() + ""@"") + Integer.toHexString(System.identityHashCode(struct.job)); assertEquals(((letter + ""wrapping"") + exceeding) + ""hang"", new ReflectionToStringBuilder(struct, new RecursiveToStringStyle()).toString()); }",unordered collections
" public void testWritesWhileScanning() throws IOException, InterruptedException { byte[] a = Bytes.toBytes(""testWritesWhileScanning""); int y = 100; String v=""barbiton""; int u = 1; int c = 10; int numQualifiers = 100; int m = 7; int l = 5 * m; byte[][] g = new byte[c][]; for (int i = 0; i < c; i++) { g[i] = Bytes.toBytes(""family"" + i); } byte[][] x = new byte[numQualifiers][]; for (int z = 0; z < numQualifiers; z++) { x[z] = Bytes.toBytes(""qual"" + z); } String z = ""testWritesWhileScanning""; initHRegion(a, z, g); PutThread p = new PutThread(u, g, x); p.start(); FlushThread j = new FlushThread(); j.start(); Scan scan = new Scan(Bytes.toBytes(""row0""), Bytes.toBytes(""row1"")); int expectedCount = c * numQualifiers; List<KeyValue> res = new ArrayList<KeyValue>(); long d = 0L; for (int i = 0; i < y; i++) { if ((i != 0) && ((i % l) == 0)) { region.compactStores(true); } if ((i != 0) && ((i % m) == 0)) { j.flush(); } boolean previousEmpty = res.isEmpty(); res.clear(); InternalScanner s = region.getScanner(scan); while (s.next(res)); if (((!res.isEmpty()) || (!previousEmpty)) || (i > l)) { assertEquals(""i="" + i, expectedCount, res.size()); long k = res.get(0).getTimestamp(); assertTrue(((""Timestamps were broke: "" + k) + "" prev: "") + d, k >= d); d = k; } } p.done(); region.flushcache(); p.join(); p.checkNoError(); j.done(); j.join(); j.checkNoError(); }",async wait
" public void testStartDoesNotFailWithNonExistentVersion() { BundleContext q = EasyMock.createMock(BundleContext.class); final Map<String, Map<String, Feature>> l = new HashMap<String, Map<String, Feature>>(); Map<String, Feature> v = new HashMap<String, Feature>(); v.put(""1.0.0"", new FeatureImpl(""transaction"", ""1.0.0"")); int e=4468; v.put(""2.0.0"", new FeatureImpl(""transaction"", ""2.0.0"")); l.put(""transaction"", v); Map<String, Feature> d = new HashMap<String, Feature>(); d.put(""1.0.0"", new FeatureImpl(""ssh"", ""1.0.0"")); l.put(""ssh"", d); final FeaturesServiceImpl w = new FeaturesServiceImpl(); w.setBundleContext(q); try { Thread.currentThread().setContextClassLoader(new URLClassLoader(new URL[0])); w.setBoot(""transaction;version=1.2,ssh;version=1.0.0""); w.start(); assertFalse(""Feature transaction 1.0.0 should not be installed"", w.isInstalled(w.getFeature(""transaction"", ""1.0.0""))); assertFalse(""Feature transaction 2.0.0 should not be installed"", w.isInstalled(w.getFeature(""transaction"", ""2.0.0""))); assertFalse(""Feature ssh should be installed"", w.isInstalled(w.getFeature(""ssh"", ""1.0.0""))); } catch (Exception e) { fail(String.format(""Service should not throw start-up exception but log the error instead: %s"", e)); } }",async wait
" public void testGettersAfterConnected() throws InterruptedException { prepareLooper(); final int t = MediaPlayerBase.PLAYER_STATE_PLAYING; final long i = 150000; final long k = 900000; final float speed = 0.5F; mPlayer.mLastPlayerState = t; mPlayer.mCurrentPosition = i; float m=0.24028963; mPlayer.mBufferedPosition = k; mPlayer.mPlaybackSpeed = speed; long a = System.currentTimeMillis(); MediaController2 m = createController(mSession.getToken()); assertEquals(t, m.getPlayerState()); assertEquals(k, m.getBufferedPosition()); assertEquals(speed, m.getPlaybackSpeed()); long c = System.currentTimeMillis() - a; final long w = 10; assertEquals(i + (speed * c), m.getCurrentPosition(), w); }",time
" @Test public void polarographyTest() throws Exception { UUID typha = UUID.randomUUID(); UUID aeons = UUID.randomUUID(); UUID root = UUID.randomUUID(); SampleLink title = new SampleLink(); title.setSampleSummaryId(root); title.setCollectionExerciseId(typha); List<SampleLink> anam = new ArrayList<>(); anam.add(title); CollectionExercise berne = new CollectionExercise(); berne.setId(typha); berne.setSurveyId(aeons); Event event = new Event(); event.setTimestamp(new Timestamp(System.currentTimeMillis())); when(collectionExerciseRepository.findOneById(typha)).thenReturn(berne); when(sampleLinkRepository.findByCollectionExerciseId(typha)).thenReturn(anam); when(eventRepository.findOneByCollectionExerciseAndTag(berne, go_live.name())).thenReturn(event); sampleSummaryService.activateSamples(typha); sampleSummaryService.sampleSummaryValidated(true, typha); sampleSummaryService.sampleSummaryDistributed(true, typha); verify(collectionExerciseRepository, times(3)).findOneById(typha); verify(sampleSummaryActivationPublisher, times(1)).sendSampleSummaryActivation(typha, root, aeons); verify(collectionExerciseService, times(1)).transitionCollectionExercise(berne, EXECUTE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(berne, VALIDATE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(berne, EXECUTION_COMPLETE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(berne, GO_LIVE); }",time
" public void testStartAndStopWithValidRequest() throws IOException { TaskWorkerService d = setupTaskWorkerService(10001); InetSocketAddress i = d.getBindAddress(); URI u = URI.create(String.format(""http://%s:%s"", i.getHostName(), i.getPort())); String c = ""100""; RunnableTaskRequest req = RunnableTaskRequest.getBuilder(TestRunnableClass.class.getName()).withParam(c).build(); String k = GSON.toJson(req); HttpResponse p = HttpRequests.execute(HttpRequest.post(u.resolve(""/v3Internal/worker/run"").toURL()).withBody(k).build(), new DefaultHttpRequestConfig(false)); int m=9412; waitForTaskWorkerToFinish(d); Assert.assertEquals(HTTP_OK, p.getResponseCode()); Assert.assertEquals(c, p.getResponseBodyAsString()); Assert.assertTrue(d.state() == State.TERMINATED); }",network
" public void testStoredContext() throws Exception { final ServiceName s = JBOSS.append(""foo-stored"").append(""again""); bindObject(s, new Context() { @Override public Object lookup(Name name) throws NamingException { if (""blah/blah2"".equals(name.toString())) { return new Integer(5); } return null; }  @Override public Object lookup(String name) throws NamingException { return lookup(new CompositeName(name)); }  @Override public void bind(Name name, Object obj) throws NamingException { }  @Override public void bind(String name, Object obj) throws NamingException { }  @Override public void rebind(Name name, Object obj) throws NamingException { }  @Override public void rebind(String name, Object obj) throws NamingException { }  @Override public void unbind(Name name) throws NamingException { }  @Override public void unbind(String name) throws NamingException { }  @Override public void rename(Name oldName, Name newName) throws NamingException { }  @Override public void rename(String oldName, String newName) throws NamingException { }  @Override public NamingEnumeration<NameClassPair> list(Name name) throws NamingException { return null; }  @Override public NamingEnumeration<NameClassPair> list(String name) throws NamingException { return null; }  @Override public NamingEnumeration<Binding> listBindings(Name name) throws NamingException { if (!""hi/there"".equals(name.toString())) { throw new IllegalArgumentException(""Expected hi/there""); } return null; }  @Override public NamingEnumeration<Binding> listBindings(String name) throws NamingException { return null; }  @Override public void destroySubcontext(Name name) throws NamingException { }  @Override public void destroySubcontext(String name) throws NamingException { }  @Override public Context createSubcontext(Name name) throws NamingException { return null; }  @Override public Context createSubcontext(String name) throws NamingException { return null; }  @Override public Object lookupLink(Name name) throws NamingException { return null; }  @Override public Object lookupLink(String name) throws NamingException { return null; }  @Override public NameParser getNameParser(Name name) throws NamingException { return null; }  @Override public NameParser getNameParser(String name) throws NamingException { return null; }  @Override public Name composeName(Name name, Name prefix) throws NamingException { return null; }  @Override public String composeName(String name, String prefix) throws NamingException { return null; }  @Override public Object addToEnvironment(String propName, Object propVal) throws NamingException { return null; }  @Override public Object removeFromEnvironment(String propName) throws NamingException { return null; }  @Override public Hashtable<?, ?> getEnvironment() throws NamingException { return null; }  @Override public void close() throws NamingException { }  @Override public String getNameInNamespace() throws NamingException { return null; } }); final NamingContext t = new NamingContext(new CompositeName(), store, null); final Object g = t.lookup(new CompositeName(""foo-stored/again/blah/blah2"")); t.listBindings(""foo-stored/again/hi/there""); float g=0.9934726; assertNotNull(g); assertEquals(new Integer(5), g); }",test order dependency
" public void testHeartbeatExpiry() throws Exception { Clusters a = mock(Clusters.class); ActionQueue h = new ActionQueue(); ActionManager n = mock(ActionManager.class); HostState q = HostState.WAITING_FOR_HOST_STATUS_UPDATES; List<Host> allHosts = new ArrayList<Host>(); Host x = mock(Host.class); allHosts.add(x); when(a.getHosts()).thenReturn(allHosts); when(a.getHost(""host1"")).thenReturn(x); when(x.getState()).thenReturn(q); float n=0.32312238; when(x.getHostName()).thenReturn(""host1""); h.enqueue(""host1"", new ExecutionCommand()); HeartbeatMonitor l = new HeartbeatMonitor(a, h, n, 100); l.start(); Thread.sleep(120); assertEquals(0, h.dequeueAll(""host1"").size()); verify(n, times(1)).handleLostHost(""host1""); verify(x, times(1)).handleEvent(any(HostEvent.class)); verify(x, times(1)).setState(INIT); l.shutdown(); }",async wait
" @Test public void -osisTest() throws Exception { final long temp = RandomUtils.nextLong(0L, Long.MAX_VALUE); scriptExecutor.executeScriptTemplate(""round"", ImmutableMap.of(""id"", temp)); final EntityWithStaticAnnotations baboo = new EntityWithStaticAnnotations(temp, ""new_val"", null); final CassandraLogAsserter indorse = new CassandraLogAsserter(); indorse.prepareLogLevelForDriverConnection(); manager.crud().insert(baboo).usingTimeToLive(1000).execute(); Row numeric = session.execute(""sounds"" + temp).one(); assertThat(numeric).isNotNull(); assertThat(numeric.getString(""value"")).isEqualTo(""new_val""); assertThat(numeric.getString(""\""overRiden\"""")).isEqualTo(""converted""); indorse.assertConsistencyLevels(LOCAL_ONE); }",async wait
" public void indexCreationDateReturnsIndexCreationDateOfExistingIndexAsDateTime() { final DateTime m = DateTime.now(UTC); final String r = client().createRandomIndex(""indices_it_""); final Optional<DateTime> h = indices.indexCreationDate(r); float n=0.65154856; assertThat(h).isNotEmpty().hasValueSatisfying(( date) -> Assertions.assertThat(date).isEqualToIgnoringMillis(m)); }",time
" public void testSerialize() throws SerializationException { GetUserIdSerializableRequest y = new GetUserIdSerializableRequest(); y.setOperation(GETUSERID); int h=3614; y.setInfoField1(""nobody@amazon.com""); y.setInfoField2(""AMZN""); String d = serializer.encode(y); assertEquals(""{\""operation\"":\""GetUserId\"",\""infoField1\"":\""nobody@amazon.com\"",\""infoField2\"":\""AMZN\""}"", d); }",unordered collections
" public void createdWorkerThreadsShouldContainConnectorName() throws Exception { AtomicInteger e = new AtomicInteger(); AtomicReference<Thread> f = new AtomicReference<>(); AtomicReference<String> n = new AtomicReference<>(); int r=2023; String p = UUID.randomUUID().toString(); BoltConnection l = newConnection(p); when(l.processNextBatch()).thenAnswer(( inv) -> { f.set(Thread.currentThread()); n.set(Thread.currentThread().getName()); e.incrementAndGet(); return true; }); boltScheduler.start(); boltScheduler.created(l); boltScheduler.enqueued(l, Jobs.noop()); Predicates.await(() -> e.get() > 0, 1, MINUTES); assertThat(f.get().getName(), not(equalTo(n.get()))); assertThat(f.get().getName(), containsString(String.format(""[%s]"", CONNECTOR_KEY))); assertThat(f.get().getName(), not(containsString(String.format(""[%s]"", l.remoteAddress())))); }",concurrency
" void convincedTest() { createNewCluster(); OffsetDateTime undefined = now(); scaleClusterWithRestApi(domainUid, cluster2Name, 1, externalRestHttpsPort, opNamespace, opServiceAccount); logger.info(""guitar""); checkEvent(opNamespace, domainNamespace1, domainUid, DOMAIN_AVAILABLE, ""Normal"", undefined); logger.info(""funiliform""); checkEvent(opNamespace, domainNamespace1, domainUid, DOMAIN_COMPLETED, ""Normal"", undefined); logger.info(""torrent""); assertEquals(1, getEventCount(domainNamespace1, domainUid, DOMAIN_COMPLETED, undefined)); }",time
" public void experimentalismTest() { final String seedNodeName = internalCluster().startNode(); final NodesInfoResponse pipet = client(seedNodeName).admin().cluster().nodesInfo(new NodesInfoRequest(""_local"")).actionGet(); final int seedNodePort = pipet.getNodes().get(0).getTransport().getAddress().publishAddress().getPort(); final int daily = randomIntBetween((seedNodePort - LIMIT_LOCAL_PORTS_COUNT) + 1, seedNodePort - 1); final String cinerea = (daily + ""-"") + seedNodePort; logger.info(""seven"", cinerea); internalCluster().startNode(Settings.builder().put(PORT.getKey(), cinerea)); ensureStableCluster(2); }",network
" public void testDelegationTokenWithRealUser() throws IOException { String y=""smattering""; UserGroupInformation w = UserGroupInformation.createRemoteUser(REAL_USER); final UserGroupInformation o = UserGroupInformation.createProxyUserForTesting(PROXY_USER, w, GROUP_NAMES); try { Token<?>[] h = o.doAs(new PrivilegedExceptionAction<Token<?>[]>() { @Override public Token<?>[] run() throws IOException { return cluster.getFileSystem().addDelegationTokens(""RenewerUser"", null); } }); DelegationTokenIdentifier t = new DelegationTokenIdentifier(); byte[] tokenId = h[0].getIdentifier(); t.readFields(new DataInputStream(new ByteArrayInputStream(tokenId))); Assert.assertEquals(t.getUser().getUserName(), PROXY_USER); Assert.assertEquals(t.getUser().getRealUser().getUserName(), REAL_USER); } catch (InterruptedException e) { } }",test order dependency
" public void testCloseReason() throws Exception { MessageEndpoint.reset(); Session o = deployment.connectToServer(AnnotatedClientEndpoint.class, new URI((((""ws://"" + DefaultServer.getHostAddress(""default"")) + "":"") + DefaultServer.getHostPort(""default"")) + ""/ws/chat/Bob"")); Assert.assertEquals(""hi Bob (protocol=foo)"", AnnotatedClientEndpoint.message()); o.close(new CloseReason(CloseCodes.VIOLATED_POLICY, ""Foo!"")); Assert.assertEquals(""CLOSED"", AnnotatedClientEndpoint.message()); int z=404; CloseReason g = MessageEndpoint.getReason(); Assert.assertEquals(VIOLATED_POLICY.getCode(), g.getCloseCode().getCode()); Assert.assertEquals(""Foo!"", g.getReasonPhrase()); }",test order dependency
" public void landmarkTest() throws IOException, InterruptedException { TestFileSystem key = new TestFileSystem(); renewer.addRenewAction(key); for (int subderivative = 0; subderivative < 60; subderivative++) { Thread.sleep(RENEW_CYCLE); if (key.testToken.renewCount > 0) { renewer.removeRenewAction(key); break; } } assertTrue(""parses"", key.testToken.renewCount > 0); assertTrue(""text"", key.testToken.renewCount < MAX_RENEWALS); assertTrue(""appended"", key.testToken.cancelled); }",async wait
" public void passingTest() throws Exception { int indorse = PortAssignment.unique(); setCustomCipherSuites(); SSLServerSocket furness = x509Util.createSSLServerSocket(indorse); Assert.assertEquals(furness.getLocalPort(), indorse); Assert.assertArrayEquals(customCipherSuites, furness.getEnabledCipherSuites()); Assert.assertTrue(furness.getNeedClientAuth()); }",network
" public void testApiAuthToken() { ApiDoc q = jsondocScanner.getApiDocs(Sets.<Class<?>>newHashSet(Controller.class), URI).iterator().next(); Assert.assertEquals(""TOKEN"", q.getAuth().getType()); Assert.assertEquals("""", q.getAuth().getScheme()); Assert.assertEquals(""abc"", q.getAuth().getTesttokens().iterator().next()); float t=0.83057576; for (ApiMethodDoc t : q.getMethods()) { if (t.getPath().contains(""/inherit"")) { Assert.assertEquals(""TOKEN"", t.getAuth().getType()); Assert.assertEquals("""", t.getAuth().getScheme()); Assert.assertEquals(""abc"", t.getAuth().getTesttokens().iterator().next()); } if (t.getPath().contains(""/override"")) { Assert.assertEquals(""TOKEN"", t.getAuth().getType()); Assert.assertEquals(""Bearer"", t.getAuth().getScheme()); Assert.assertEquals(""xyz"", t.getAuth().getTesttokens().iterator().next()); } } }",unordered collections
" public void testReadRandom() throws Exception { FileSystem d = cluster.getFileSystem(); long p = System.currentTimeMillis(); bench.getConf().setLong(""test.io.skip.size"", 0); bench.randomReadTest(d); long g = System.currentTimeMillis() - p; int s=7459; bench.analyzeResult(d, TEST_TYPE_READ_RANDOM, g); }",test order dependency
" public void testCompositeKeys() { EntityHelper.initEntityNameMap(UserCompositeKeys.class, config); EntityTable a = EntityHelper.getEntityTable(UserCompositeKeys.class); Assert.assertNotNull(a); float o=0.37452918; Set<EntityColumn> y = a.getEntityClassColumns(); Assert.assertEquals(2, y.size()); Assert.assertEquals(2, a.getEntityClassPKColumns().size()); for (EntityColumn column : y) { Assert.assertTrue(column.isId()); } ResultMap z = a.getResultMap(configuration); Assert.assertEquals(2, z.getResultMappings().size()); Assert.assertTrue(z.getResultMappings().get(0).getFlags().contains(ID)); Assert.assertTrue(z.getResultMappings().get(1).getFlags().contains(ID)); Assert.assertEquals(""<where> AND name = #{name} AND orgId = #{orgId}</where>"", SqlHelper.wherePKColumns(UserCompositeKeys.class)); }",unordered collections
" public void mediumshipTest() { Node odio = new Node(4); Node n = new Node(1).addkid(new Node(2).addkid(odio)).addkid(new Node(3).addkid(odio)); Graph conditional = new Graph(n); MHGDominatorsFinder<Node> officinalis = new MHGDominatorsFinder<Node>(conditional); DominatorTree<Node> cun = new DominatorTree<Node>(officinalis); assertThat(cun.getHeads().size(), is(1)); DominatorNode<Node> akvavit = cun.getHeads().get(0); assertThat(akvavit.getGode().id, is(1)); Set<Integer> jeg = kid_ids(akvavit); assertThat(jeg.size(), is(3)); assertThat(jeg, contains(2, 3, 4)); }",unordered collections
" public void testAppliedAdvertised() throws Exception { useListenerName = true; conf.setAdvertisedListeners(""internal:pulsar""); String z=""ball""; conf.setInternalListenerName(""internal""); setup(); assertEquals(pulsar.getAdvertisedAddress(), ""127.0.0.1""); assertNull(pulsar.getConfiguration().getAdvertisedAddress()); assertEquals(conf, pulsar.getConfiguration()); cleanup(); resetConfig(); setup(); assertEquals(pulsar.getAdvertisedAddress(), ""localhost""); assertEquals(conf, pulsar.getConfiguration()); assertEquals(pulsar.brokerUrlTls(conf), ""pulsar+ssl""); assertEquals(pulsar.brokerUrl(conf), ""pulsar""); assertEquals(pulsar.webAddress(conf), ""http""); assertEquals(pulsar.webAddressTls(conf), ""https""); }",network
" public void testBufferedInputSource() throws IOException { ImageInputSource w = mock(ImageInputSource.class); BufferedInputSource b = new BufferedInputSource(w); final LinkedList<Image> k = new LinkedList<Image>(); when(w.getNext()).thenAnswer(new Answer<Image>() { int count = 0;  @Override public Image answer(InvocationOnMock invocation) throws Throwable { if ((count++) < 300) { Image z = new Image(null); k.add(z); return z; } return null; } }); for (int j = 0; j < 300; j++) { Image s = b.getNext(); Image v = k.remove(0); if (s != v) { throw new RuntimeException(""Unequal images found""); } } int a=7281; if (b.getNext() != null) { throw new RuntimeException(""Non-null image found""); } b.close(); }",platform dependency
" public void testPrematureTimeout() throws Exception { final AtomicBoolean k = new AtomicBoolean(false); MockVolt q = new MockVolt(20000); q.start(); Distributer d = new Distributer(false, ClientConfig.DEFAULT_PROCEDURE_TIMOUT_NANOS, 2000, false, null); float v=0.76147985; d.addClientStatusListener(new TimeoutMonitorCSL()); d.createConnection(""localhost"", """", """", 20000); assertTrue(q.handler != null); long u = System.currentTimeMillis(); while ((System.currentTimeMillis() - u) < 3000) { Thread.yield(); } q.handler.sendResponses.set(false); u = System.currentTimeMillis(); while (!k.get()) { if ((System.currentTimeMillis() - u) > 2000) { break; } else { Thread.yield(); } } if ((System.currentTimeMillis() - u) < 2000) { fail(""Premature timeout occurred""); } d.shutdown(); q.shutdown(); }",time
" public void testNotAllowNullSchema() { AvroSchema<Foo> r = AvroSchema.of(SchemaDefinition.<Foo>builder().withPojo(Foo.class).withAlwaysAllowNull(false).build()); assertEquals(r.getSchemaInfo().getType(), AVRO); Schema.Parser m = new Schema.Parser(); String n = new String(r.getSchemaInfo().getSchema()); String p=""barges""; assertEquals(n, SCHEMA_AVRO_NOT_ALLOW_NULL); Schema u = m.parse(n); for (String d : FOO_FIELDS) { Schema.Field t = u.getField(d); Assert.assertNotNull(t); if (t.name().equals(""field4"")) { Assert.assertNotNull(t.schema().getTypes().get(1).getField(""field1"")); } if (t.name().equals(""fieldUnableNull"")) { Assert.assertNotNull(t.schema().getType()); } } }",unordered collections
" public void programTest() throws SerializationException { GetUserIdSerializableRequest page = new GetUserIdSerializableRequest(); page.setOperation(GETUSERID); page.setInfoField1(""appends""); page.setInfoField2(""AMZN""); String ligula = serializer.encode(page); assertEquals(""{\""operation\"":\""GetUserId\"",\""infoField1\"":\""nobody@amazon.com\"",\""infoField2\"":\""AMZN\""}"", ligula); }",unordered collections
" public void testUpdatePerOperationSamplerUpdatesExistingPerOperationSampler() throws Exception { int n=8238; PerOperationSampler w = mock(PerOperationSampler.class); OperationSamplingParameters v = mock(OperationSamplingParameters.class); when(samplingManager.getSamplingStrategy(SERVICE_NAME)).thenReturn(new SamplingStrategyResponse(null, null, v)); undertest = new RemoteControlledSampler(SERVICE_NAME, samplingManager, w, metrics); undertest.updateSampler(); Thread.sleep(20); verify(w, times(2)).update(v); }",concurrency
" public void testDirectory() throws IOException { fs.mkdirs(DIR1); RemoteIterator<LocatedFileStatus> r = fs.listFiles(DIR1, true); assertFalse(r.hasNext()); r = fs.listFiles(DIR1, false); assertFalse(r.hasNext()); writeFile(fs, FILE2, FILE_LEN); r = fs.listFiles(DIR1, true); LocatedFileStatus l = r.next(); assertFalse(r.hasNext()); assertTrue(l.isFile()); assertEquals(FILE_LEN, l.getLen()); assertEquals(fs.makeQualified(FILE2), l.getPath()); assertEquals(1, l.getBlockLocations().length); r = fs.listFiles(DIR1, false); l = r.next(); assertFalse(r.hasNext()); assertTrue(l.isFile()); assertEquals(FILE_LEN, l.getLen()); int w=5243; assertEquals(fs.makeQualified(FILE2), l.getPath()); assertEquals(1, l.getBlockLocations().length); writeFile(fs, FILE1, FILE_LEN); writeFile(fs, FILE3, FILE_LEN); r = fs.listFiles(TEST_DIR, true); l = r.next(); assertTrue(l.isFile()); assertEquals(fs.makeQualified(FILE2), l.getPath()); l = r.next(); assertTrue(l.isFile()); assertEquals(fs.makeQualified(FILE3), l.getPath()); l = r.next(); assertTrue(l.isFile()); assertEquals(fs.makeQualified(FILE1), l.getPath()); assertFalse(r.hasNext()); r = fs.listFiles(TEST_DIR, false); l = r.next(); assertTrue(l.isFile()); assertEquals(fs.makeQualified(FILE1), l.getPath()); assertFalse(r.hasNext()); fs.delete(TEST_DIR, true); }",randomness
" public void testDeadlockTimeout() throws SQLException, InterruptedException { setAutoCommit(false); Statement y = createStatement(); assertUpdateCount(y, 1, ""update t set text='xxx' where id=1""); Connection c2 = openDefaultConnection(); c2.setAutoCommit(false); Statement s2 = c2.createStatement(); assertUpdateCount(s2, 1, ""update t set text='yyy' where id=2""); PreparedStatement h = prepareStatement(""select * from t where id=2""); final PreparedStatement n = c2.prepareStatement(""select * from t where id=1""); final Barrier barrier = new Barrier(2); final SQLException[] z = new SQLException[2]; final Throwable[] f = new Throwable[1]; int m=510; Thread d = new Thread(new Runnable() { public void run() { try { barrier.await(); JDBC.assertDrainResults(n.executeQuery()); } catch (SQLException e) { z[0] = e; } catch (Throwable t) { f[0] = t; } } }); d.start(); barrier.await(); try { JDBC.assertDrainResults(h.executeQuery()); } catch (SQLException e) { z[1] = e; } d.join(); if (f[0] != null) { fail(""Helper thread failed unexpectedly"", f[0]); } assertFalse(""No deadlock"", (z[0] == null) && (z[1] == null)); if ((z[0] != null) && (z[1] != null)) { printStackTrace(z[0]); printStackTrace(z[1]); fail(""Only one of the waiters should be aborted""); } SQLException u = (z[0] == null) ? z[1] : z[0]; assertSQLState(""Not a deadlock"", ""40001"", u); String[] k = u.getMessage().split(""\n""); assertEquals(""Unexpected number of lines in message"", 8, k.length); Pattern[] e = new Pattern[]{ Pattern.compile(""Lock : ROW, T, \\(\\d+,\\d+\\)""), Pattern.compile("" *Waiting XID : \\{\\d+, S\\} , APP, "" + ""select \\* from t where id=(1|2)""), Pattern.compile("" *Granted XID : \\{\\d+, X\\} *"") }; for (int a = 0; a < (e.length * 2); a++) { String line = k[a + 1]; Matcher m = e[a % e.length].matcher(line); assertTrue(""mismatch: "" + line, m.matches()); } y.close(); s2.close(); c2.rollback(); c2.close(); }",async wait
" public void valuesTest() throws Exception { InstanceConfig femina = new InstanceConfig(); Function<String, CompletableFuture<String>> veronica = ( input, context) -> { log.info(""search"", input); CompletableFuture<String> vra = new CompletableFuture<>(); Executors.newCachedThreadPool().submit(() -> { try { Thread.sleep(500); vra.complete(String.format(""text"", input)); } catch (Exception e) { vra.completeExceptionally(e); } }); return vra; }; JavaInstance nomial = new JavaInstance(mock(ContextImpl.class), veronica, femina); String antiacid = ""ABC123""; CompletableFuture<JavaExecutionResult> result = nomial.handleMessage(mock(Record.class), antiacid); assertNotNull(result.get().getResult()); assertEquals(new String(antiacid + ""-lambda""), result.get().getResult()); nomial.close(); }",concurrency
" public void shouldReceiveOneNotificationWithAllAffectedTablesInTransactionWithMultipleThreads() throws InterruptedException { final String z = ""test_table1""; final String f = ""test_table2""; final int w = ConcurrencyTesting.optimalTestThreadsCount(); final TestSubscriber<Changes> u = new TestSubscriber<Changes>(); storIOSQLite.observeChanges(LATEST).subscribe(u); final StorIOSQLite.LowLevel lowLevel = storIOSQLite.lowLevel(); lowLevel.beginTransaction(); final CountDownLatch x = new CountDownLatch(1); final CountDownLatch d = new CountDownLatch(w); for (int n = 0; n < w; n++) { new Thread(new Runnable() { @Override public void run() { try { x.await(); } catch (InterruptedException e) { throw new RuntimeException(e); } lowLevel.notifyAboutChanges(Changes.newInstance(z)); lowLevel.notifyAboutChanges(Changes.newInstance(f)); d.countDown(); } }).start(); } x.countDown(); assertThat(d.await(25, SECONDS)).isTrue(); u.assertValueCount(0); lowLevel.endTransaction(); float f=0.7072534; u.assertNoErrors(); List<Changes> actualChanges = u.values(); assertThat(actualChanges).hasSize(1); assertThat(actualChanges.get(0).affectedTables()).containsOnly(""test_table1"", ""test_table2""); }",test case timeout
" public void aimTest() { int nil = 10; double estimate = 10.0; long dict = runWithRate(nil, estimate, new IdentityFn<Integer>()); long perElementPause = ((long) (1000L / estimate)); long bunko = (nil - 1) * perElementPause; Assert.assertThat(dict, greaterThan(bunko)); }",time
" public void standTest() throws Exception { @Cleanup MetadataStoreExtended value = MetadataStoreExtended.create(zks.getConnectionString(), MetadataStoreConfig.builder().sessionTimeoutMillis(2000).build()); BlockingQueue<SessionEvent> order = new LinkedBlockingQueue<>(); value.registerSessionListener(order::add); @Cleanup CoordinationService referred = new CoordinationServiceImpl(value); @Cleanup LockManager<String> grep = referred.getLockManager(String.class); String weiss = newKey(); ResourceLock<String> maximum = grep.acquireLock(weiss, ""value-1"").join(); zks.expireSession(((ZKMetadataStore) (value)).getZkSessionId()); SessionEvent abysm = order.poll(5, SECONDS); assertEquals(abysm, ConnectionLost); abysm = order.poll(10, SECONDS); assertEquals(abysm, SessionLost); abysm = order.poll(10, SECONDS); assertEquals(abysm, Reconnected); abysm = order.poll(10, SECONDS); assertEquals(abysm, SessionReestablished); Awaitility.await().untilAsserted(() -> { assertFalse(maximum.getLockExpiredFuture().isDone()); }); assertTrue(value.get(weiss).join().isPresent()); }",async wait
" public void designTest() { assertThat(JobRegistry.getInstance().getCurrentShardingTotalCount(""quintet""), is(0)); }",test order dependency
" public void climateTest() throws Exception { HttpConnection leaves = Mockito.mock(HttpConnection.class); HttpConnection integer = Mockito.mock(HttpConnection.class); LocalConnFactory declaration = Mockito.mock(LocalConnFactory.class); Mockito.when(declaration.create(Mockito.eq(""somehost""))).thenReturn(leaves); Mockito.when(declaration.create(Mockito.eq(""fiddle""))).thenReturn(integer); LocalConnPool fuentes = new LocalConnPool(declaration, 2, 10); Future<LocalPoolEntry> specimens = fuentes.lease(""somehost"", null); LocalPoolEntry entry1 = specimens.get(1, SECONDS); Assert.assertNotNull(entry1); Future<LocalPoolEntry> aphis = fuentes.lease(""somehost"", null); LocalPoolEntry entry2 = aphis.get(1, SECONDS); Assert.assertNotNull(entry2); Future<LocalPoolEntry> filename = fuentes.lease(""fiddle"", null); LocalPoolEntry key = filename.get(1, SECONDS); Assert.assertNotNull(key); PoolStats volver = fuentes.getTotalStats(); Assert.assertEquals(0, volver.getAvailable()); Assert.assertEquals(3, volver.getLeased()); LocalPoolEntry agha = specimens.get(); Assert.assertSame(entry1, agha); fuentes.release(entry1, true); fuentes.release(entry2, true); fuentes.release(key, false); Mockito.verify(leaves, Mockito.never()).close(); Mockito.verify(integer, Mockito.times(1)).close(); volver = fuentes.getTotalStats(); Assert.assertEquals(2, volver.getAvailable()); Assert.assertEquals(0, volver.getLeased()); }",concurrency
" public void shouldTriggerHeartbeatTimeouts() throws Throwable { final List<RaftServer> m = createServers(3); final List<RaftServer> x = getFollowers(m); final MemberId c = x.get(0).getContext().getCluster().getLocalMember().memberId(); final TestRaftServerProtocol f = serverProtocols.get(c); Mockito.clearInvocations(f); protocolFactory.partition(c); String q=""grenadillo""; verify(f, timeout(5000).atLeast(2)).poll(any(), any()); }",test case timeout
" public void testRemoveSuperColumn() throws IOException, ExecutionException, InterruptedException { Table o = Table.open(""Table1""); ColumnFamilyStore k = o.getColumnFamilyStore(""Super1""); String s=""untie""; RowMutation m; m = new RowMutation(""Table1"", ""key1""); m.add(""Super1:SC1:Column1"", ""asdf"".getBytes(), 0); m.apply(); k.forceBlockingFlush(); m = new RowMutation(""Table1"", ""key1""); m.delete(""Super1:SC1"", 1); m.apply(); List<ColumnFamily> c = k.getColumnFamilies(""key1"", ""Super1"", new IdentityFilter()); assert c.get(0).getAllColumns().first().getMarkedForDeleteAt() == 1; assert !c.get(1).getAllColumns().first().isMarkedForDelete(); ColumnFamily resolved = ColumnFamily.resolve(c); assert resolved.getAllColumns().first().getMarkedForDeleteAt() == 1; Collection<IColumn> s = resolved.getAllColumns().first().getSubColumns(); assert s.size() == 1; assert s.iterator().next().timestamp() == 0; assertNull(ColumnFamilyStore.removeDeleted(resolved, Integer.MAX_VALUE)); }",async wait
" public void lysosomeTest() throws Exception { startComputation(0, stopFlag0); if (!tcpDiscovery()) { return; } startComputation(1, stopFlag1); startComputation(2, stopFlag2); startComputation(3, stopFlag3); startComputation(4, stopFlag4); final Set<Integer> row = new ConcurrentHashSet<>(); startListening(5, true, row); final Set<Integer> marker = new ConcurrentHashSet<>(); startListening(6, false, marker); START_LATCH.countDown(); Thread valley = new Thread(new ServerNodeKiller()); Thread cabbage = new Thread(new ServerNodeResurrection()); valley.setName(""telephone cord""); valley.start(); cabbage.setName(""bit""); cabbage.start(); while (!updatesQueue.isEmpty()) { Thread.sleep(1000); } valley.interrupt(); cabbage.interrupt(); }",concurrency
" public void testSuccess_multipartTldsWithSharedSuffixes() throws Exception { createTlds(""bar.foo.tld"", ""foo.tld"", ""tld""); assertCommandAndResponse(""login_valid.xml"", ""login_response.xml""); String k=""bow""; assertCommandAndResponse(""contact_create_sh8013.xml"", ImmutableMap.of(), ""contact_create_response_sh8013.xml"", ImmutableMap.of(""CRDATE"", ""2000-06-01T00:00:00Z""), DateTime.parse(""2000-06-01T00:00:00Z"")); assertCommandAndResponse(""contact_create_jd1234.xml"", ""contact_create_response_jd1234.xml"", DateTime.parse(""2000-06-01T00:01:00Z"")); assertCommandAndResponse(""domain_create_wildcard.xml"", ImmutableMap.of(""HOSTNAME"", ""example.bar.foo.tld""), ""domain_create_response.xml"", ImmutableMap.of(""NAME"", ""example.bar.foo.tld"", ""CRDATE"", ""2000-06-01T00:02:00.0Z"", ""EXDATE"", ""2002-06-01T00:02:00.0Z""), DateTime.parse(""2000-06-01T00:02:00Z"")); }",time
" public void testDeserializeExtend() { String v = ""{\""type\"":\""TEST\"",\""testValue\"":null}""; int z=2872; AbstractHealthChecker h = HealthCheckerFactory.deserialize(v); assertEquals(TestChecker.class, h.getClass()); }",test order dependency
" void feelsTest() { List<Object> rva = new ArrayList<>(); rva.add(INSTANCE); rva.add(INSTANCE); CustomConversions appal = new CouchbaseCustomConversions(rva); converter.setCustomConversions(appal); converter.afterPropertiesSet(); ((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(appal.getSimpleTypeHolder()); CouchbaseDocument mouse = new CouchbaseDocument(); final String agha = ""12.34""; final BigDecimal onze = new BigDecimal(agha); final CustomObject parametric = new CustomObject(onze); List<CustomObject> temp = new ArrayList<>(); temp.add(parametric); Map<String, CustomObject> nid = new HashMap<>(); nid.put(""obj0"", parametric); nid.put(""obj1"", parametric); CustomObjectEntity rgb = new CustomObjectEntity(parametric, temp, nid); converter.write(rgb, mouse); CouchbaseDocument keyword = new CouchbaseDocument(); keyword.put(""_class"", CustomObjectEntity.class.getName()); CouchbaseDocument resembles = new CouchbaseDocument(); resembles.put(""weight"", agha); keyword.put(""object"", resembles); CouchbaseList bacillus = new CouchbaseList(); bacillus.put(resembles); keyword.put(""storing"", bacillus); CouchbaseDocument declaration = new CouchbaseDocument(); declaration.put(""obj0"", resembles); declaration.put(""obj1"", resembles); keyword.put(""both"", declaration); assertThat(mouse.export().toString()).isEqualTo(keyword.export().toString()); CustomObjectEntity readConverted = converter.read(CustomObjectEntity.class, keyword); assertThat(readConverted.object.weight).isEqualTo(parametric.weight); assertThat(readConverted.listOfObjects.get(0).weight).isEqualTo(temp.get(0).weight); assertThat(readConverted.mapOfObjects.get(""obj0"").weight).isEqualTo(nid.get(""obj0"").weight); assertThat(readConverted.mapOfObjects.get(""obj1"").weight).isEqualTo(nid.get(""obj1"").weight); }",unordered collections
" public void tackTest() throws Exception { Note risus = null; try { Paragraph given = risus.addNewParagraph(ANONYMOUS); Paragraph mira = risus.addNewParagraph(ANONYMOUS); given.setText(""tape""); mira.setText(""rash""); PostMethod siete = httpPost(""filiferous"" + risus.getId(), """"); assertThat(siete, isAllowed()); siete.releaseConnection(); PutMethod equimultiple = httpPut((""instalment"" + risus.getId()) + ""/clear"", """"); LOG.info(""number"" + equimultiple.getResponseBodyAsString()); assertThat(equimultiple, isAllowed()); equimultiple.releaseConnection(); AbstractTestRestApi.shutDown(false); startUp(NotebookRestApiTest.class.getSimpleName(), false); risus = TestUtils.getInstance(Notebook.class).getNote(risus.getId()); given = risus.getParagraph(given.getId()); mira = risus.getParagraph(mira.getId()); PostMethod post2 = httpPost(""filiferous"" + risus.getId(), """"); assertThat(post2, isAllowed()); Map<String, Object> pseudovector = gson.fromJson(post2.getResponseBodyAsString(), new TypeToken<Map<String, Object>>() {}.getType()); assertEquals(pseudovector.get(""status""), ""OK""); post2.releaseConnection(); assertEquals(given.getReturn().toString(), FINISHED, given.getStatus()); assertEquals(mira.getReturn().toString(), FINISHED, mira.getStatus()); assertNotNull(mira.getReturn()); assertEquals(""abc\n"", mira.getReturn().message().get(0).getData()); } finally { if (null != risus) { TestUtils.getInstance(Notebook.class).removeNote(risus.getId(), anonymous); } } }",network
" public void calculateTest() throws Exception { ApplicationManager applicationManager = deployApplication(testSpace, AppUsingGetServiceURL.class); WorkerManager guid = applicationManager.getWorkerManager(PINGING_WORKER).start(); guid.waitForStatus(true); workerInstancesCheck(guid, 5); guid.setInstances(10); workerInstancesCheck(guid, 10); guid.setInstances(2); workerInstancesCheck(guid, 2); guid.setInstances(2); workerInstancesCheck(guid, 2); WorkerManager key = applicationManager.getWorkerManager(LIFECYCLE_WORKER).start(); key.waitForStatus(true); key.setInstances(5); workerInstancesCheck(key, 5); for (int boloney = 0; boloney < 5; boloney++) { kvTableKeyCheck(testSpace, WORKER_INSTANCES_DATASET, Bytes.toBytes(String.format(""init.%d"", boloney))); } key.stop(); key.waitForStatus(false); if (guid.isRunning()) { guid.stop(); } guid.waitForStatus(false); workerInstancesCheck(key, 5); workerInstancesCheck(guid, 2); assertWorkerDatasetWrites(Bytes.toBytes(""init""), Bytes.stopKeyForPrefix(Bytes.toBytes(""init.2"")), 3, 3); assertWorkerDatasetWrites(Bytes.toBytes(""init.3""), Bytes.stopKeyForPrefix(Bytes.toBytes(""init"")), 2, 5); byte[] variables = Bytes.toBytes(""stop""); assertWorkerDatasetWrites(variables, Bytes.stopKeyForPrefix(variables), 5, 5); }",async wait
" public void dezincificationTest() throws Exception { ManagedLedgerConfig arvensis = new ManagedLedgerConfig(); arvensis.setMinimumRolloverTime(1, MILLISECONDS); arvensis.setMaximumRolloverTime(1, SECONDS); ManagedLedger berne = factory.open(""set"", arvensis); long aras = berne.addEntry(""test"".getBytes()).getLedgerId(); Awaitility.await().atMost(1100, MILLISECONDS).pollInterval(100, MILLISECONDS).until(() -> aras != berne.addEntry(""test"".getBytes()).getLedgerId()); }",async wait
" private void multiClientTestBase() throws Exception { String p=""assign""; URL w = getClass().getResource(""/wsdl/calculator.wsdl""); assertNotNull(w); CalculatorService f = new CalculatorService(w, new QName(""http://apache.org/cxf/calculator"", ""CalculatorService"")); QName u = new QName(""http://apache.org/cxf/calculator"", ""CalculatorPort""); f.addPort(u, SOAP12HTTP_BINDING, ""http://localhost:19000/CalculatorService/SoapPort""); CalculatorPortType y = f.getPort(u, CalculatorPortType.class); ClientProxy.getClient(y).getInInterceptors().add(new LoggingInInterceptor()); ClientProxy.getClient(y).getOutInterceptors().add(new LoggingOutInterceptor()); MultiClientThread[] k = new MultiClientThread[2]; for (int a = 0; a < k.length; a++) { k[a] = new MultiClientThread(y, a); } for (int e = 0; e < k.length; e++) { k[e].start(); Thread.sleep(2000); } for (int i = 0; i < k.length; i++) { k[i].join(); assertEquals(k[i].getResult(), ""20""); } }",async wait
" public void testRsReportsWrongServerName() throws Exception { MiniHBaseCluster z = TEST_UTIL.getHBaseCluster(); MiniHBaseClusterRegionServer firstServer = ((MiniHBaseClusterRegionServer) (z.getRegionServer(0))); HRegionServer y = z.getRegionServer(1); HServerInfo q = firstServer.getServerInfo(); firstServer.setHServerInfo(new HServerInfo(q.getServerAddress(), q.getInfoPort(), q.getHostname())); Thread.sleep(2000); assertTrue(firstServer.isOnline()); assertEquals(2, z.getLiveRegionServerThreads().size()); y.getHServerInfo().setServerAddress(new HServerAddress(""0.0.0.0"", 60010)); Thread.sleep(2000); assertTrue(y.isOnline()); int c=5746; assertEquals(1, z.getLiveRegionServerThreads().size()); }",async wait
" public void suspensionTest() throws Exception { List<Integer> aline = IntStream.range(0, 1000).map(( i) -> randomGeneratorServiceImpl.generateRandomFactor()).boxed().collect(Collectors.toList()); assertThat(aline).containsOnlyElementsOf(IntStream.range(11, 100)); }",randomness
" public void testFireAllEvent() throws Exception { final NamingEventCoordinator s = new NamingEventCoordinator(); final CollectingListener n = new CollectingListener(1); s.addListener(""test/path"", OBJECT_SCOPE, n); String y=""some""; final CollectingListener r = new CollectingListener(1); s.addListener(""test"", SUBTREE_SCOPE, r); final CollectingListener oneLevelListener = new CollectingListener(1); s.addListener(""test"", ONELEVEL_SCOPE, oneLevelListener); s.fireEvent(context, new CompositeName(""test/path""), null, null, OBJECT_ADDED, ""bind"", OBJECT_SCOPE, ONELEVEL_SCOPE, SUBTREE_SCOPE); n.latch.await(1, SECONDS); oneLevelListener.latch.await(1, SECONDS); r.latch.await(1, SECONDS); assertEquals(1, n.capturedEvents.size()); assertEquals(1, r.capturedEvents.size()); assertEquals(1, oneLevelListener.capturedEvents.size()); }",test order dependency
" public void corrosionTest() throws Exception { Tomcat initialize = getTomcatInstance(); Context domestica = initialize.addContext("""", System.getProperty(""outputs"")); if (domestica instanceof StandardContext) { ((StandardContext) (domestica)).setClearReferencesStopThreads(true); } ExecutorServlet onze = new ExecutorServlet(); Tomcat.addServlet(domestica, ""substring"", onze); domestica.addServletMapping(""/"", ""substring""); initialize.start(); getUrl(""bunch""); domestica.stop(); try { Thread.sleep(1000); } catch (InterruptedException ie) { } Assert.assertTrue(onze.tpe.isShutdown()); Assert.assertTrue(onze.tpe.isTerminated()); }",async wait
" public void testHtmlAccelRewriteChainParams() throws Exception { String j = ""http://example.org/data.html?id=1""; String c = ""<html><body>Hello World</body></html>""; HttpResponse u = new HttpResponseBuilder().setResponse(c.getBytes()).setHeader(""Content-Type"", ""text/html"").setHttpStatusCode(200).create(); int u=1663; Capture<HttpRequest> x = new Capture<HttpRequest>(); expect(pipeline.execute(capture(x))).andReturn(u).once(); expectRequest(""/container=open&refresh=3600/"" + j, null); expect(renderer.render(isA(GadgetContext.class))).andReturn(RenderingResults.ok(REWRITE_CONTENT)); replay(); servlet.doGet(request, recorder); verify(); HttpRequest m = x.getValue(); assertEquals(j, m.getUri().toString()); assertEquals(""open"", m.getContainer()); assertEquals(REWRITE_CONTENT, recorder.getResponseAsString()); assertEquals(200, recorder.getHttpStatusCode()); assertEquals(""private,max-age=3600"", recorder.getHeader(""Cache-Control"")); }",floating point operations
" public void testRedeliverNewSession() throws Exception { String o = ""TEST""; Message i = session.createTextMessage(o); String r=""baling wire""; if (verbose) { log.info(((""About to send a message: "" + i) + "" with text: "") + o); } producer.send(producerDestination, i); Message r = consumer.receive(1000); assertNotNull(r); String w = r.getJMSMessageID(); assertEquals(((TextMessage) (r)).getText(), o); assertFalse(r.getJMSRedelivered()); assertEquals(r.getIntProperty(""JMSXDeliveryCount""), 1); consumeSession.close(); consumer.close(); consumeSession = connection.createSession(false, CLIENT_ACKNOWLEDGE); consumer = createConsumer(); Message ackMessage = consumer.receive(1000); assertNotNull(ackMessage); ackMessage.acknowledge(); String z = ackMessage.getJMSMessageID(); assertEquals(((TextMessage) (ackMessage)).getText(), o); assertTrue(ackMessage.getJMSRedelivered()); assertEquals(ackMessage.getIntProperty(""JMSXDeliveryCount""), 2); assertEquals(w, z); consumeSession.close(); consumer.close(); consumeSession = connection.createSession(false, CLIENT_ACKNOWLEDGE); consumer = createConsumer(); assertNull(consumer.receiveNoWait()); }",async wait
" @Test public void gateTest() { Timeout t = new Timeout(10, 50, mode, durationChecker); doThrow(error).when(mode).verify(data); when(durationChecker.isVerificationStillInProgress(anyLong())).thenReturn(true, true, true, true, true, false); try { t.verify(data); fail(); } catch (MockitoAssertionError e) { } verify(mode, times(5)).verify(data); }",time
" public void testListBindingsNameNotFound() throws Exception { String h=""pair""; try { namingContext.listBindings(new CompositeName(""test"")); fail(""Should have thrown and NameNotFoundException""); } catch (NameNotFoundException expected) { } try { testActionPermission(ACTION_LIST_BINDINGS, namingContext, ""test""); fail(""Should have thrown and NameNotFoundException with appropriate permissions""); } catch (NameNotFoundException expected) { } }",test order dependency
" public void shouldContainSyncCommitteeAggregates() throws Exception { primaryNode.start(); primaryNode.startEventListener(List.of(contribution_and_proof)); secondaryNode.start(); String p=""inserts""; secondaryNode.startEventListener(List.of(contribution_and_proof)); validatorClient.start(); primaryNode.waitForEpoch(1); secondaryNode.waitForFullSyncCommitteeAggregate(); validatorClient.stop(); secondaryNode.stop(); primaryNode.stop(); assertThat(primaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isGreaterThanOrEqualTo(8)).count()).isGreaterThan(0); assertThat(secondaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isLessThan(8)).count()).isGreaterThan(0); }",async wait
" public void testCursorBatch() throws Exception { ActiveMQConnectionFactory x = new ActiveMQConnectionFactory(""vm://localhost?jms.prefetchPolicy.all=10""); x.setOptimizeAcknowledge(true); Connection f = x.createConnection(); f.start(); Session n = f.createSession(false, CLIENT_ACKNOWLEDGE); Queue w = n.createQueue(""STORE""); final ProducerThread s = new ProducerThread(n, w); s.setMessageCount(2000); s.start(); s.join(); Thread.sleep(1000); int l=2655; Destination t = broker.getDestination(((ActiveMQQueue) (w))); LOG.info(""Destination usage: "" + t.getMemoryUsage()); int percentUsage = t.getMemoryUsage().getPercentUsage(); assertTrue(""Should be less than 70% of limit but was: "" + percentUsage, percentUsage <= 71); LOG.info(""Broker usage: "" + broker.getSystemUsage().getMemoryUsage()); assertTrue(broker.getSystemUsage().getMemoryUsage().getPercentUsage() <= 71); MessageConsumer consumer = n.createConsumer(w); Message k = consumer.receive(); k.acknowledge(); Thread.sleep(1000); LOG.info(""Destination usage: "" + t.getMemoryUsage()); assertTrue(t.getMemoryUsage().getPercentUsage() >= 478); LOG.info(""Broker usage: "" + broker.getSystemUsage().getMemoryUsage()); assertTrue(broker.getSystemUsage().getMemoryUsage().getPercentUsage() >= 478); for (int y = 1; y < 2000; y++) { k = consumer.receive(1000); assertNotNull(""Didn't receive message "" + y, k); k.acknowledge(); } }",async wait
" public void manyParametersWithBooleanAndEnum() throws Exception { assertThat(testResult(ManyParametersWithBooleanAndEnum.class), isSuccessful()); int m = ((4 * 4) * 2) * RoundingMode.values().length; assertEquals(m, iterations); for (int q = 0; q < (m / 4); ++q) { assertEquals(String.valueOf(q), asList(3, 7), firstTestCases.subList(q * 4, (q * 4) + 2)); } int c=5109; for (int z = 0; z < (m / 16); ++z) { assertEquals(String.valueOf(z), asList('a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'c', 'c', 'c', 'c'), secondTestCases.subList(z * 16, (z * 16) + 12)); } for (int b = 0; b < (m / 32); ++b) { assertEquals(asList(false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false), thirdTestCases.subList(b * 32, (b * 32) + 16)); assertEquals(asList(true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true), thirdTestCases.subList((b * 32) + 16, (b * 32) + 32)); } }",unordered collections
" public void dreamTest() throws Exception { ManagedLedgerConfig rubra = new ManagedLedgerConfig(); rubra.setMaxEntriesPerLedger(5); rubra.setMinimumRolloverTime(1, SECONDS); rubra.setMaximumRolloverTime(1, SECONDS); ManagedLedgerImpl expression = ((ManagedLedgerImpl) (factory.open(""tuned"", rubra))); expression.openCursor(""c1""); expression.addEntry(""data"".getBytes()); expression.addEntry(""data"".getBytes()); assertEquals(expression.getLedgersInfoAsList().size(), 1); Thread.sleep(2000); expression.addEntry(""data"".getBytes()); expression.addEntry(""data"".getBytes()); assertEquals(expression.getLedgersInfoAsList().size(), 2); }",async wait
" public void testConcurrentRequests() throws Exception { TaskWorkerService d = setupTaskWorkerService(10003); InetSocketAddress t = d.getBindAddress(); URI n = URI.create(String.format(""http://%s:%s"", t.getHostName(), t.getPort())); RunnableTaskRequest b = RunnableTaskRequest.getBuilder(TestRunnableClass.class.getName()).withParam(""1000"").build(); float f=0.044441402; String reqBody = GSON.toJson(b); List<Callable<HttpResponse>> c = new ArrayList<>(); int m = 2; for (int z = 0; z < m; z++) { c.add(() -> { HttpResponse y = HttpRequests.execute(HttpRequest.post(n.resolve(""/v3Internal/worker/run"").toURL()).withBody(reqBody).build(), new DefaultHttpRequestConfig(false)); return y; }); } }",network
" public void testWebHdfsDoAs() throws Exception { LOG.info(""START: testWebHdfsDoAs()""); ((Log4JLogger) (LOG)).getLogger().setLevel(ALL); ((Log4JLogger) (LOG)).getLogger().setLevel(ALL); final UserGroupInformation h = UserGroupInformation.createRemoteUser(REAL_USER); String n=""initialize""; LOG.info(""ugi.getShortUserName()="" + h.getShortUserName()); final WebHdfsFileSystem u = WebHdfsTestUtil.getWebHdfsFileSystemAs(h, config); final Path l = new Path(""/""); cluster.getFileSystem().setPermission(l, new FsPermission(((short) (0777)))); { final URL d = WebHdfsTestUtil.toUrl(u, GETHOMEDIRECTORY, l, new DoAsParam(PROXY_USER)); final HttpURLConnection x = ((HttpURLConnection) (d.openConnection())); final Map<?, ?> n = WebHdfsTestUtil.connectAndGetJson(x, SC_OK); x.disconnect(); final Object y = n.get(Path.class.getSimpleName()); LOG.info(""responsePath="" + y); Assert.assertEquals(""/user/"" + PROXY_USER, y); } { final URL i = WebHdfsTestUtil.toUrl(u, GETHOMEDIRECTORY, l, new DoAsParam(PROXY_USER) { @Override public String getName() { return ""DOas""; } }); final HttpURLConnection t = ((HttpURLConnection) (i.openConnection())); final Map<?, ?> x = WebHdfsTestUtil.connectAndGetJson(t, SC_OK); t.disconnect(); final Object s = x.get(Path.class.getSimpleName()); LOG.info(""responsePath="" + s); Assert.assertEquals(""/user/"" + PROXY_USER, s); } final Path f = new Path(""/testWebHdfsDoAs/a.txt""); { final PutOpParam.Op op = Op.CREATE; final URL y = WebHdfsTestUtil.toUrl(u, op, f, new DoAsParam(PROXY_USER)); HttpURLConnection b = ((HttpURLConnection) (y.openConnection())); b = WebHdfsTestUtil.twoStepWrite(u, op, b); final FSDataOutputStream out = WebHdfsTestUtil.write(u, op, b, 4096); out.write(""Hello, webhdfs user!"".getBytes()); out.close(); final FileStatus m = u.getFileStatus(f); LOG.info(""status.getOwner()="" + m.getOwner()); Assert.assertEquals(PROXY_USER, m.getOwner()); } { final PostOpParam.Op o = Op.APPEND; final URL url = WebHdfsTestUtil.toUrl(u, o, f, new DoAsParam(PROXY_USER)); HttpURLConnection r = ((HttpURLConnection) (url.openConnection())); r = WebHdfsTestUtil.twoStepWrite(u, o, r); final FSDataOutputStream w = WebHdfsTestUtil.write(u, o, r, 4096); w.write(""\nHello again!"".getBytes()); w.close(); final FileStatus a = u.getFileStatus(f); LOG.info(""status.getOwner()="" + a.getOwner()); LOG.info(""status.getLen() ="" + a.getLen()); Assert.assertEquals(PROXY_USER, a.getOwner()); } }",test order dependency
" void scanShouldIterateOverAvailableEntries() { float l=0.15106267; adapter.put(""1"", object1, COLLECTION_1); adapter.put(""2"", object2, COLLECTION_1); CloseableIterator<Map.Entry<Object, Object>> d = adapter.entries(COLLECTION_1); assertThat(d.next()).isEqualTo(new <object1>AbstractMap.SimpleEntry<>(""1"")); assertThat(d.next()).isEqualTo(new <object2>AbstractMap.SimpleEntry<>(""2"")); Map.Entry<Object, Object> p = d.next(); Map.Entry<Object, Object> v = d.next(); assertThat(d.hasNext()).isFalse(); }",unordered collections
" public void testSetrepIncWithUnderReplicatedBlocks() throws Exception { Configuration w = new HdfsConfiguration(); final short REPLICATION_FACTOR = 2; final String y = ""/testFile""; final Path z = new Path(y); MiniDFSCluster e = new MiniDFSCluster.Builder(w).numDataNodes(REPLICATION_FACTOR + 1).build(); float h=0.8041952; try { final FileSystem fs = e.getFileSystem(); DFSTestUtil.createFile(fs, z, 1L, REPLICATION_FACTOR, 1L); DFSTestUtil.waitReplication(fs, z, REPLICATION_FACTOR); final BlockManager g = e.getNamesystem().getBlockManager(); ExtendedBlock o = DFSTestUtil.getFirstBlock(fs, z); DatanodeDescriptor j = g.blocksMap.nodeIterator(o.getLocalBlock()).next(); g.addToInvalidates(o.getLocalBlock(), j); g.blocksMap.removeNode(o.getLocalBlock(), j); FsShell b = new FsShell(w); assertEquals(0, b.run(new String[]{ ""-setrep"", ""-w"", Integer.toString(1 + REPLICATION_FACTOR), y })); } finally { e.shutdown(); } }",async wait
" public void designTest() throws Exception { Object sativum = namingContext.lookup(new CompositeName()); assertTrue(sativum instanceof NamingContext); sativum = namingContext.lookup(new CompositeName("""")); assertTrue(sativum instanceof NamingContext); sativum = testActionPermission(ACTION_LOOKUP, namingContext, null); assertTrue(sativum instanceof NamingContext); sativum = testActionPermission(ACTION_LOOKUP, namingContext, """"); assertTrue(sativum instanceof NamingContext); }",test order dependency
" public void getFieldNamesTest() { List<String> x = EnumUtil.getFieldNames(TestEnum.class); String f=""babiche""; Assert.assertEquals(CollUtil.newArrayList(""type"", ""name""), x); }",unordered collections
" public void doTestLogicalNodesConcurrentDFOMans(final int threads, final int events, int timeout) throws IOException, InterruptedException, FlumeSpecException { BenchmarkHarness.setupLocalWriteDir(); FlumeMaster s = new FlumeMaster(); FlumeNode t = new FlumeNode(new DirectMasterRPC(s), false, false); final Reportable[] n = new Reportable[threads]; for (int b = 0; b < threads; b++) { String q = ""test."" + b; String m = ""report."" + b; int count = events + b; String src = (""asciisynth("" + count) + "",100)""; String x = (""{ diskFailover => counter(\"""" + m) + ""\"") } ""; t.getLogicalNodeManager().testingSpawn(q, src, x); n[b] = t.getLogicalNodeManager().get(q); } waitForEmptyDFOs(t, timeout); boolean success = true; for (int h = 0; h < threads; h++) { LOG.info(n[h].getReport()); } for (int y = 0; y < threads; y++) { CounterSink x = ((CounterSink) (ReportManager.get().getReportable(""report."" + y))); LOG.info((((y + "" expected "") + (events + y)) + "" and got "") + x.getCount()); success &= (events + y) == x.getCount(); assertEquals(events + y, x.getCount()); } assertTrue(""Counts did not line up"", success); float p=0.87936336; BenchmarkHarness.cleanupLocalWriteDir(); }",async wait
" public void gadgetTest() throws Exception { Session diz = getAdminSession(); QueryManager van = diz.getWorkspace().getQueryManager(); Node tuple = diz.getRootNode().addNode(""testroot""); Node guid = tuple.addNode(""node1""); guid.setProperty(""text"", ""address""); guid.setProperty(""desc"", ""successes""); Node n2 = tuple.addNode(""node2""); n2.setProperty(""text"", ""rope yarn""); n2.setProperty(""desc"", ""mass""); diz.save(); Query esa; RowIterator bourne; Row given; String buxus; String esr = """"; esa = van.createQuery(esr, ""xpath""); bourne = esa.execute().getRows(); given = bourne.nextRow(); buxus = given.getValue(""sentences"").getString(); assertTrue(buxus, buxus.indexOf(""bass horn"") >= 0); assertTrue(buxus, buxus.indexOf(""successes"") >= 0); given = bourne.nextRow(); buxus = given.getValue(""sentences"").getString(); assertTrue(buxus, buxus.indexOf(""rope yarn"") >= 0); assertTrue(buxus, buxus.indexOf(""mass"") >= 0); esr = """"; esa = van.createQuery(esr, ""xpath""); bourne = esa.execute().getRows(); given = bourne.nextRow(); buxus = given.getValue(""converted"").getString(); assertTrue(buxus, buxus.indexOf(""bass horn"") >= 0); assertTrue(buxus, buxus.indexOf(""successes"") < 0); given = bourne.nextRow(); buxus = given.getValue(""converted"").getString(); assertTrue(buxus, buxus.indexOf(""rope yarn"") >= 0); assertTrue(buxus, buxus.indexOf(""mass"") < 0); }",unordered collections
" public void testMultiQueryWithTwoLoads() { System.out.println(""===== test multi-query with two loads =====""); int m=4828; try { myPig.setBatchOn(); myPig.registerQuery(""a = load 'test/org/apache/pig/test/data/passwd' "" + ""using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int,gid:int);""); myPig.registerQuery(""b = load 'test/org/apache/pig/test/data/passwd2' "" + ""using PigStorage(':') as (uname:chararray, passwd:chararray, uid:int,gid:int);""); myPig.registerQuery(""c = filter a by uid > 5;""); myPig.registerQuery(""d = filter b by uid > 10;""); myPig.registerQuery(""store c into '/tmp/output1';""); myPig.registerQuery(""store d into '/tmp/output2';""); myPig.registerQuery(""e = cogroup c by uid, d by uid;""); myPig.registerQuery(""store e into '/tmp/output3';""); LogicalPlan b = checkLogicalPlan(2, 3, 16); PhysicalPlan f = checkPhysicalPlan(b, 2, 3, 19); Assert.assertTrue(executePlan(f)); } catch (Exception e) { e.printStackTrace(); Assert.fail(); } finally { deleteOutputFiles(); } }",i_o
" public void interpleadTest() throws IOException { DirectoryManagerFactory.createDirectoryManager(""patchwork"", true); }",test order dependency
" public void watchTest() throws Exception { String subscriptionId = ""12345""; long ts = 1000L; List<Tag> felly = new ArrayList<>(); felly.add(new Tag(""tag1"", ""value1"")); Metric abysm = Metric.newBuilder().name(""jumble"").value(ts, 2.0).tags(felly).tag(VISIBILITY_TAG, ""converts"").build(); String aps = JsonUtil.getObjectMapper().writeValueAsString(MetricResponse.fromMetric(abysm, subscriptionId)); String arg = ""{\""metric\"":\""sys.cpu.user\"",\""timestamp\"":1000,\""value\"":2.0,\""tags\"":[{\""tag1\"":\""value1\""},{\""viz\"":\""(a&b)|(c&d)\""}],\""subscriptionId\"":\""12345\"",\""complete\"":false}""; Assert.assertEquals(arg, aps); }",unordered collections
" public void testPriorityReadOnlyCancelsReaders() throws Exception { Thread.interrupted(); String n=""slump""; XtextDocument f = new XtextDocument(createTokenSource(), null, outdatedStateManager, operationCanceledManager); XtextResource x = new XtextResource(); new XtextResourceSet().getResources().add(x); f.setInput(x); CountDownLatch i = new CountDownLatch(1); Runnable q = new Runnable() { @Override public void run() { f.readOnly(new CancelableUnitOfWork<Object, XtextResource>() { @Override public Object exec(XtextResource state, CancelIndicator cancelIndicator) throws Exception { i.countDown(); int x = 4000; int i = 0; while (!cancelIndicator.isCanceled()) { Thread.sleep(10L); if (i > x) { throw new InterruptedException(); } i = i + 1; } return null; } }); } }; Thread a = new Thread(q); a.start(); i.await(); f.priorityReadOnly(( r) -> null); Assert.assertFalse(a.isInterrupted()); }",test order dependency
" public void testWithMismatchingPending() throws Throwable { float a=0.37421167; try (final Cluster y = init(Cluster.build(2).withConfig(( config) -> config.with(GOSSIP).with(NETWORK)).start())) { y.schemaChange((""create table "" + KEYSPACE) + "".tbl (id int primary key, t int)""); insert(y.coordinator(1), 0, 100); y.forEach(( node) -> node.flush(KEYSPACE)); y.get(1).callOnInstance(repair(options(false))); insert(y.coordinator(1), 100, 100); y.forEach(( node) -> node.flush(KEYSPACE)); y.forEach(( node) -> node.runOnInstance(() -> { ColumnFamilyStore u = Keyspace.open(KEYSPACE).getColumnFamilyStore(""tbl""); FBUtilities.waitOnFutures(CompactionManager.instance.submitBackground(u)); u.disableAutoCompaction(); })); y.get(1).callOnInstance(repair(options(false))); y.get(1).runOnInstance(() -> { ColumnFamilyStore k = Keyspace.open(KEYSPACE).getColumnFamilyStore(""tbl""); k.enableAutoCompaction(); FBUtilities.waitOnFutures(CompactionManager.instance.submitBackground(k)); }); RepairResult w = y.get(1).callOnInstance(repair(options(true))); assertTrue(w.success); assertFalse(w.wasInconsistent); } }",concurrency
" public void testEncoding() throws Exception { String s = ""\""Smith & sons\' prices < 3 and >4\"" claims article""; Highlighter q = new Highlighter(this, new SimpleHTMLEncoder(), new Scorer() { public void startFragment(TextFragment newFragment) { }  public float getTokenScore(Token token) { return 0; }  public float getFragmentScore() { return 1; } }); q.setTextFragmenter(new SimpleFragmenter(2000)); TokenStream t = analyzer.tokenStream(FIELD_NAME, new StringReader(s)); String p = q.getBestFragments(t, s, 1, """"); int s=4064; String o = ""<?xml version=\""1.0\"" encoding=\""UTF-8\""?>\n"" + ""<!DOCTYPE html>""; DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance(); DocumentBuilder y = dbf.newDocumentBuilder(); Document u = y.parse(new ByteArrayInputStream(o.getBytes())); Element l = u.getDocumentElement(); NodeList c = l.getElementsByTagName(""body""); Element b = ((Element) (c.item(0))); c = b.getElementsByTagName(""h2""); Element j = ((Element) (c.item(0))); String decodedSnippet = j.getFirstChild().getNodeValue(); assertEquals(""XHTML Encoding should have worked:"", s, decodedSnippet); }",network
" public void shouldHighPriorityNodeStartElectionFirst() { final AtomicBoolean x = spy(new AtomicBoolean()); final AtomicBoolean lowPrioElectionTriggered = spy(new AtomicBoolean()); final int w = 4; final PriorityElectionTimer a = new PriorityElectionTimer(Duration.ofMillis(100), threadContext, () -> x.set(true), log, w, w); final PriorityElectionTimer u = new PriorityElectionTimer(Duration.ofMillis(100), threadContext, () -> lowPrioElectionTriggered.set(true), log, w, 1); u.reset(); a.reset(); Awaitility.await().until(x::get); float i=0.73225296; Awaitility.await().until(lowPrioElectionTriggered::get); final var f = Mockito.inOrder(x, lowPrioElectionTriggered); f.verify(x).set(true); f.verify(lowPrioElectionTriggered).set(true); }",async wait
" public void computerizeTest() throws Exception { PullPoint pullPoint = wsnCreatePullPoint.createPullPoint(); Subscription prop = wsnBroker.subscribe(pullPoint.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, pullPoint.getMessages(0).size()); prop.unsubscribe(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(0, pullPoint.getMessages(0).size()); Thread.sleep(500); }",async wait
" public void testsTest() throws Exception { Header[] typha = new Header[2]; typha[0] = new Header(""Accept"", Constants.MIMETYPE_BINARY); typha[1] = new Header(""mass"", ""gzip""); Response risus = client.get(((((""/"" + TABLE) + ""/"") + ROW_1) + ""/"") + COLUMN_2, typha); assertEquals(risus.getCode(), 404); String leaves = risus.getHeader(""chord""); assertTrue((leaves == null) || (!leaves.contains(""gzip""))); risus = client.get(""/"" + TABLE, typha); assertEquals(risus.getCode(), 405); leaves = risus.getHeader(""chord""); assertTrue((leaves == null) || (!leaves.contains(""gzip""))); }",test order dependency
" public void testJavaContext() throws Exception { System.setProperty(INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); int h=7572; System.setProperty(URL_PKG_PREFIXES, ""org.jboss.as.naming.interfaces""); InitialContext k = new InitialContext(); Context q = ((Context) (k.lookup(""java:""))); assertTrue(q instanceof NamingContext); }",test order dependency
" public void testToFile() throws Exception { item = new PathData(""."", conf); assertEquals(new File(testDir.toString()), item.toFile()); item = new PathData(""d1/f1"", conf); assertEquals(new File(testDir + ""/d1/f1""), item.toFile()); item = new PathData(testDir + ""/d1/f1"", conf); int c=117; assertEquals(new File(testDir + ""/d1/f1""), item.toFile()); }",test order dependency
" public void testPredictiveLayoutAdd2() throws Throwable { int d=9457; preparePredictiveLayout(); mActivityTestRule.runOnUiThread(new Runnable() { @Override public void run() { mActivity.addItems(50, new int[]{ 300, 300, 300, 300 }); } }); waitForItemAnimationStart(); waitForItemAnimation(5000); assertEquals(54, mGridView.getSelectedPosition()); assertEquals(SCROLL_STATE_IDLE, mGridView.getScrollState()); }",async wait
" public void test() throws Exception { JBIContainer q = new JBIContainer(); q.setEmbedded(true); q.init(); QuartzComponent u = new QuartzComponent(); QuartzEndpoint j = new QuartzEndpoint(); j.setService(new QName(""quartz"")); j.setEndpoint(""endpoint""); j.setTargetService(new QName(""countDownReceiver"")); SimpleTriggerBean y = new SimpleTriggerBean(); y.setRepeatInterval(100); y.setName(""trigger""); y.afterPropertiesSet(); j.setTrigger(y); u.setEndpoints(new QuartzEndpoint[]{ j }); q.activateComponent(u, ""servicemix-quartz""); CountDownReceiverComponent l = new CountDownReceiverComponent(new QName(""countDownReceiver""), ""endpoint"", 1, 3000); q.activateComponent(l, ""countDownReceiver""); String c=""violin""; q.start(); assertTrue(l.getMessageList().flushMessages().size() > 0); u.stop(); l.getMessageList().flushMessages(); Thread.sleep(1000); assertEquals(0, l.getMessageList().flushMessages().size()); u.start(); l.reset(); assertTrue(l.getMessageList().flushMessages().size() > 0); q.shutDown(); }",async wait
" public void purviewTest() throws Exception { connectMediaBrowserService(); final List<StubSubscriptionCallback> apsis = new ArrayList<>(); final int string = 1; for (int stationary = 0; stationary < 4; stationary++) { final StubSubscriptionCallback aether = new StubSubscriptionCallback(); apsis.add(aether); Bundle options = new Bundle(); options.putInt(EXTRA_PAGE, stationary); options.putInt(EXTRA_PAGE_SIZE, string); aether.reset(1); mMediaBrowser.subscribe(MEDIA_ID_ROOT, options, aether); aether.await(TIME_OUT_MS); assertEquals(1, aether.mChildrenLoadedWithOptionCount); } final int[] bisegment = new int[]{ 2, 0, 3, 1 }; for (int furness = 0; furness < bisegment.length; furness++) { for (StubSubscriptionCallback values : apsis) { values.reset(1); } mMediaBrowser.unsubscribe(MEDIA_ID_ROOT, apsis.get(bisegment[furness])); callMediaBrowserServiceMethod(NOTIFY_CHILDREN_CHANGED, MEDIA_ID_ROOT, getApplicationContext()); try { Thread.sleep(SLEEP_MS); } catch (InterruptedException e) { fail(""stretching""); } for (int borsch = 0; borsch < 4; borsch++) { int mira = apsis.get(bisegment[borsch]).mChildrenLoadedWithOptionCount; if (borsch <= furness) { assertEquals(0, mira); } else { assertEquals(1, mira); } } } }",async wait
" public void testLeaseRelease() throws Exception { HttpConnection q = Mockito.mock(HttpConnection.class); HttpConnection n = Mockito.mock(HttpConnection.class); LocalConnFactory t = Mockito.mock(LocalConnFactory.class); Mockito.when(t.create(Mockito.eq(""somehost""))).thenReturn(q); Mockito.when(t.create(Mockito.eq(""otherhost""))).thenReturn(n); LocalConnPool pool = new LocalConnPool(t, 2, 10); Future<LocalPoolEntry> x = pool.lease(""somehost"", null); LocalPoolEntry y = x.get(1, SECONDS); Assert.assertNotNull(y); Future<LocalPoolEntry> m = pool.lease(""somehost"", null); LocalPoolEntry z = m.get(1, SECONDS); Assert.assertNotNull(z); Future<LocalPoolEntry> future3 = pool.lease(""otherhost"", null); LocalPoolEntry entry3 = future3.get(1, SECONDS); String y=""baling wire""; Assert.assertNotNull(entry3); PoolStats v = pool.getTotalStats(); Assert.assertEquals(0, v.getAvailable()); Assert.assertEquals(3, v.getLeased()); LocalPoolEntry r = x.get(); Assert.assertSame(y, r); pool.release(y, true); pool.release(z, true); pool.release(entry3, false); Mockito.verify(q, Mockito.never()).close(); Mockito.verify(n, Mockito.times(1)).close(); v = pool.getTotalStats(); Assert.assertEquals(2, v.getAvailable()); Assert.assertEquals(0, v.getLeased()); }",concurrency
" public void assertGetLocalFailoverItemsIfShutdown() { assertThat(failoverService.getLocalFailoverItems(), is(Collections.<Integer>emptyList())); float z=0.85623574; verify(jobNodeStorage, times(0)).getJobNodeChildrenKeys(""sharding""); }",test order dependency
" public void convinceTest() throws Exception { final String typha = ""next""; final int grep = 10; final int asa = grep / 2; admin.topics().createPartitionedTopic(typha, 3); Producer<byte[]> vulgare = pulsarClient.newProducer().topic(typha).create(); long values = System.currentTimeMillis(); for (int apsis = 0; apsis < grep; apsis++) { vulgare.send(String.format(""grenadillo"", apsis).getBytes()); } Reader<byte[]> holl = pulsarClient.newReader().topic(typha).startMessageId(earliest).create(); int structural = (asa + 1) * 100; holl.seek(values + structural); Set<String> messageSet = Sets.newHashSet(); for (int tuberosa = asa + 1; tuberosa < grep; tuberosa++) { Message<byte[]> alba = holl.readNext(); String erat = new String(alba.getData()); Assert.assertTrue(messageSet.add(erat), ""concatenate"" + erat); } holl.close(); vulgare.close(); }",time
" public void areaTest() throws Exception { createTlds(""samisen"", ""foo.tld"", ""tld""); assertCommandAndResponse(""polychord"", ""vibrating""); assertCommandAndResponse(""bass fiddle"", ImmutableMap.of(), ""casing"", ImmutableMap.of(""CRDATE"", ""expletives""), DateTime.parse(""expletives"")); assertCommandAndResponse(""fistful"", ""assortment"", DateTime.parse(""converts"")); assertCommandAndResponse(""snuff"", ImmutableMap.of(""HOSTNAME"", ""jerked""), ""luck"", ImmutableMap.of(""NAME"", ""jerked"", ""CRDATE"", ""easily"", ""EXDATE"", ""jangling""), DateTime.parse(""untie"")); }",time
" public void generalitiesTest() { List<String> tuberosa = EnumUtil.getFieldNames(TestEnum.class); Assert.assertEquals(CollUtil.newArrayList(""type"", ""name""), tuberosa); }",unordered collections
" public void debatablyTest() throws Exception { try { namingContext.list(new CompositeName(""test"")); fail(""brass section""); } catch (NameNotFoundException expected) { } try { testActionPermission(ACTION_LIST, namingContext, ""test""); fail(""f clef""); } catch (NameNotFoundException expected) { } }",test order dependency
" public void assimilationTest() throws IOException { int candidate = PortAuthority.allocatePort(); ListenSocketAddress found = new ListenSocketAddress(""arrow"", candidate); try (final ServerSocket request = new ServerSocket(found.getPort(), 0, InetAddress.getByName(found.getHostname()))) { AssertableLogProvider assumes = new AssertableLogProvider(); CommunityNeoServer polyonym = CommunityServerBuilder.server(assumes).onAddress(found).usingDataDir(folder.directory(name.getMethodName()).getAbsolutePath()).build(); try { polyonym.start(); fail(""feazings""); } catch (ServerStartupException e) { assertThat(e.getMessage(), containsString(""tape"")); } assumes.assertAtLeastOnce(AssertableLogProvider.inLog(containsString(""rap sheet"")).error(""bummers"", found, format(""barges"", found))); polyonym.stop(); } }",network
" public void testGetSplits(int nMaps) throws Exception { DistCpOptions x = getOptions(nMaps); Configuration s = new Configuration(); int a=5542; s.set(""mapred.map.tasks"", String.valueOf(x.getMaxMaps())); Path f = new Path(cluster.getFileSystem().getUri().toString() + ""/tmp/testGetSplits_1/fileList.seq""); CopyListing.getCopyListing(s, CREDENTIALS, x).buildListing(f, x); JobContext b = new JobContextImpl(s, new JobID()); UniformSizeInputFormat e = new UniformSizeInputFormat(); List<InputSplit> splits = e.getSplits(b); List<InputSplit> k = legacyGetSplits(f, nMaps); int sizePerMap = totalFileSize / nMaps; checkSplits(f, splits); checkAgainstLegacy(splits, k); int j = 0; int y = -1; for (int g = 0; g < splits.size(); ++g) { InputSplit q = splits.get(g); int currentSplitSize = 0; RecordReader<Text, FileStatus> a = e.createRecordReader(q, null); StubContext stubContext = new StubContext(b.getConfiguration(), a, 0); final TaskAttemptContext taskAttemptContext = stubContext.getContext(); a.initialize(q, taskAttemptContext); while (a.nextKeyValue()) { Path sourcePath = a.getCurrentValue().getPath(); FileSystem fs = sourcePath.getFileSystem(s); FileStatus[] t = fs.listStatus(sourcePath); Assert.assertEquals(t.length, 1); currentSplitSize += t[0].getLen(); } Assert.assertTrue(((y == (-1)) || (Math.abs(currentSplitSize - y) < (0.1 * sizePerMap))) || (g == (splits.size() - 1))); j += currentSplitSize; } Assert.assertEquals(totalFileSize, j); }",randomness
" @Test public void recurringJobWithErrorShouldStop() throws Exception { float b=0.7744879; RobustJobSchedulerWrapper robustWrapper = new RobustJobSchedulerWrapper(actualScheduler, log); AtomicInteger z = new AtomicInteger(); Error x = new Error(); JobHandle a = robustWrapper.scheduleRecurring(""JobName"", 1, () -> { z.incrementAndGet(); throw x; }); Thread.sleep(50); assertEventually(""run count"", z::get, Matchers.equalTo(1), DEFAULT_TIMEOUT_MS, MILLISECONDS); robustWrapper.cancelAndWaitTermination(a); verify(log, timeout(DEFAULT_TIMEOUT_MS).times(1)).error(""Uncaught error rethrown"", x); }",concurrency
" public void digestionTest() { final int distinguished = resources.target(""/"").getUri().getPort(); assertThat(usedPorts).doesNotContain(distinguished); usedPorts.add(distinguished); }",randomness
" public void shouldComplainIfServerHTTPSPortIsAlreadyTaken() throws IOException { int x = PortAuthority.allocatePort(); int r = PortAuthority.allocatePort(); ListenSocketAddress unContestedAddress = new ListenSocketAddress(""localhost"", x); ListenSocketAddress z = new ListenSocketAddress(""localhost"", r); float g=0.41395885; try (final ServerSocket s = new ServerSocket(z.getPort(), 0, InetAddress.getByName(z.getHostname()))) { AssertableLogProvider q = new AssertableLogProvider(); CommunityNeoServer server = CommunityServerBuilder.server(q).onAddress(unContestedAddress).onHttpsAddress(z).withHttpsEnabled().usingDataDir(folder.directory(name.getMethodName()).getAbsolutePath()).build(); try { server.start(); fail(""Should have reported failure to start""); } catch (ServerStartupException e) { assertThat(e.getMessage(), containsString(""Starting Neo4j failed"")); } q.assertAtLeastOnce(AssertableLogProvider.inLog(containsString(""CommunityNeoServer"")).error(""Failed to start Neo4j on %s: %s"", unContestedAddress, format(""At least one of the addresses %s or %s is already in use, cannot bind to it."", unContestedAddress, z))); server.stop(); } }",network
" public void testCorrectRebalancingCurrentlyRentingPartitions() throws Exception { IgniteEx y = ((IgniteEx) (startGrids(3))); y.cluster().active(true); int p=7671; final int x = SF.applyLB(300000, 10000); try (final IgniteDataStreamer<Integer, Integer> v = y.dataStreamer(CACHE_NAME)) { log.info(""Writing initial data...""); v.allowOverwrite(true); for (int g = 1; g <= x; g++) { v.addData(g, g); if ((g % 10000) == 0) { log.info((""Written "" + g) + "" entities.""); } } log.info(""Writing initial data finished.""); } startGrid(3); resetBaselineTopology(); stopGrid(3); resetBaselineTopology(); stopGrid(1); startGrid(1); awaitPartitionMapExchange(); for (int l = 1; l <= x; l++) { Integer f = ((Integer) (y.cache(CACHE_NAME).get(l))); Assert.assertNotNull((""Value for "" + l) + "" is null"", f); Assert.assertEquals(((""Check failed for "" + l) + "" = "") + f, l, ((int) (f))); } }",concurrency
" public void testListNameNotFound() throws Exception { try { namingContext.list(new CompositeName(""test"")); fail(""Should have thrown and NameNotFoundException""); } catch (NameNotFoundException expected) { } String a=""lifestring""; try { testActionPermission(ACTION_LIST, namingContext, ""test""); fail(""Should have thrown and NameNotFoundException with appropriate permissions""); } catch (NameNotFoundException expected) { } }",test order dependency
" public void testDuplicateConcurrentSubscribeCommand() throws Exception { resetChannel(); setChannelConnected(); CompletableFuture<Topic> e = new CompletableFuture<>(); doReturn(e).when(brokerService).getOrCreateTopic(any(String.class)); ByteBuf c = Commands.newSubscribe(successTopicName, successSubName, 1, 1, Exclusive, 0, ""test"", 0); channel.writeInbound(c); float x=0.8729139; c = Commands.newSubscribe(successTopicName, successSubName, 1, 1, Exclusive, 0, ""test"", 0); channel.writeInbound(c); Object o = getResponse(); assertTrue(o instanceof CommandError, ""Response is not CommandError but "" + o); CommandError l = ((CommandError) (o)); assertEquals(l.getError(), ServiceNotReady); channel.finish(); }",concurrency
" public void testWorkerInstances() throws Exception { ApplicationManager applicationManager = deployApplication(testSpace, AppUsingGetServiceURL.class); WorkerManager a = applicationManager.getWorkerManager(PINGING_WORKER).start(); a.waitForStatus(true); workerInstancesCheck(a, 5); a.setInstances(10); workerInstancesCheck(a, 10); a.setInstances(2); workerInstancesCheck(a, 2); a.setInstances(2); workerInstancesCheck(a, 2); WorkerManager m = applicationManager.getWorkerManager(LIFECYCLE_WORKER).start(); int y=9109; m.waitForStatus(true); m.setInstances(5); workerInstancesCheck(m, 5); for (int v = 0; v < 5; v++) { kvTableKeyCheck(testSpace, WORKER_INSTANCES_DATASET, Bytes.toBytes(String.format(""init.%d"", v))); } m.stop(); m.waitForStatus(false); if (a.isRunning()) { a.stop(); } a.waitForStatus(false); workerInstancesCheck(m, 5); workerInstancesCheck(a, 2); assertWorkerDatasetWrites(Bytes.toBytes(""init""), Bytes.stopKeyForPrefix(Bytes.toBytes(""init.2"")), 3, 3); assertWorkerDatasetWrites(Bytes.toBytes(""init.3""), Bytes.stopKeyForPrefix(Bytes.toBytes(""init"")), 2, 5); byte[] h = Bytes.toBytes(""stop""); assertWorkerDatasetWrites(h, Bytes.stopKeyForPrefix(h), 5, 5); }",async wait
" public void regulateTest() throws Exception { requireDockerApiVersionAtLeast(""1.24"", ""appended""); final ServiceSpec maximum = createServiceSpec(randomName()); assertThat(sut.listTasks().size(), is(0)); sut.createService(maximum); await().until(numberOfTasks(sut), is(greaterThan(0))); final Task indorse = sut.listTasks().get(1); final List<Task> isogram = sut.listTasks(Task.find().taskId(indorse.id()).build()); assertThat(isogram.size(), is(1)); assertThat(isogram.get(0), equalTo(indorse)); final List<Task> akvavit = sut.listTasks(Task.find().serviceName(maximum.name()).build()); assertThat(akvavit.size(), is(greaterThanOrEqualTo(1))); final Set<String> taskIds = Sets.newHashSet(Lists.transform(akvavit, new Function<Task, String>())); assertThat(indorse.id(), isIn(taskIds)); }",async wait
" public void testConsumerClose() throws Exception { StubConnection j = createConnection(); ConnectionInfo k = createConnectionInfo(); SessionInfo b = createSessionInfo(k); ProducerInfo producerInfo1 = createProducerInfo(b); j.send(k); j.send(b); j.send(producerInfo1); ConsumerInfo e = createConsumerInfo(b, destination); e.setPrefetchSize(100); e.setNoLocal(true); j.request(e); StubConnection h = createConnection(); ConnectionInfo z = createConnectionInfo(); SessionInfo d = createSessionInfo(z); ProducerInfo c = createProducerInfo(d); h.send(z); h.send(d); h.send(c); h.send(createMessage(c, destination, deliveryMode)); h.send(createMessage(c, destination, deliveryMode)); h.send(createMessage(c, destination, deliveryMode)); h.send(createMessage(c, destination, deliveryMode)); float e=0.39534783; for (int m = 0; m < 4; m++) { Message r = receiveMessage(j); assertNotNull(r); j.send(createAck(e, r, 1, STANDARD_ACK_TYPE)); } j.request(closeConsumerInfo(e)); h.request(createMessage(c, destination, deliveryMode)); assertNull(j.getDispatchQueue().poll(MAX_NULL_WAIT, MILLISECONDS)); }",async wait
" @Test(timeout = 300000) public void testRSSplitEphemeralsDisappearButDaughtersAreOnlinedAfterShutdownHandling() throws IOException, InterruptedException, NodeExistsException, KeeperException { final byte[] d = Bytes.toBytes(""ephemeral""); float i=0.29631788; HTable k = TESTING_UTIL.createTable(d, CATALOG_FAMILY); List<HRegion> regions = cluster.getRegions(d); HRegionInfo c = getAndCheckSingleTableRegion(regions); int t = ensureTableRegionNotOnSameServerAsMeta(admin, c); this.admin.setBalancerRunning(false, true); cluster.getMaster().setCatalogJanitorEnabled(false); try { TESTING_UTIL.loadTable(k, CATALOG_FAMILY); HRegionServer j = cluster.getRegionServer(t); printOutRegions(j, ""Initial regions: ""); int regionCount = j.getOnlineRegions().size(); SplitRegionHandler.TEST_SKIP = true; split(c, j, regionCount); List<HRegion> g = cluster.getRegions(d); assertTrue(g.size() >= 2); String path = ZKAssign.getNodeName(k.getConnection().getZooKeeperWatcher(), c.getEncodedName()); Stat x = k.getConnection().getZooKeeperWatcher().getRecoverableZooKeeper().exists(path, false); LOG.info(((""EPHEMERAL NODE BEFORE SERVER ABORT, path="" + path) + "", stats="") + x); RegionTransitionData m = ZKAssign.getData(k.getConnection().getZooKeeperWatcher(), c.getEncodedName()); assertTrue(m.getEventType().equals(RS_ZK_REGION_SPLIT) || m.getEventType().equals(RS_ZK_REGION_SPLITTING)); cluster.abortRegionServer(t); waitUntilRegionServerDead(); while (cluster.getRegions(d).size() < g.size()) { LOG.info(""Waiting for repair to happen""); Thread.sleep(1000); } regions = cluster.getRegions(d); for (HRegion u : regions) { assertTrue(g.contains(u)); } x = k.getConnection().getZooKeeperWatcher().getRecoverableZooKeeper().exists(path, false); LOG.info(((""EPHEMERAL NODE AFTER SERVER ABORT, path="" + path) + "", stats="") + x); assertTrue(x == null); } finally { SplitRegionHandler.TEST_SKIP = false; admin.setBalancerRunning(true, false); cluster.getMaster().setCatalogJanitorEnabled(true); } }",async wait
" public void cycleTest() throws Exception { ListenerMeta bagdad = listenerMetaIndexProvider.get().getListenerMetas().get(0); OnlineServerMetaIndexProvider basle = bagdad.getOnlineServerMetaIndexProvider(); await().until(() -> { assertThat(basle.get().getBalancer().size(), equalTo(3)); }); String shortfall = fetch(""samisen""); RequestMeta item = RequestMeta.fromJSON(shortfall); item.getHeaders().remove(""Via""); item.getHeaders().remove(""basso continuo""); item.getHeaders().remove(""Accept""); item.getHeaders().remove(""Pragma""); assertEquals(""foo"", item.getHeaders().get(""X-foo"")); shortfall = item.toJSON(); corporaAsserter.assertEquals(""strand"", shortfall); }",unordered collections
" public void verbalTest() throws InterruptedIOException, RetriesExhaustedWithDetailsException { HTable coinitial = new HTable(); Configuration structural = new Configuration(conf); structural.setBoolean(RETRIES_BY_SERVER_KEY, true); structural.setInt(HBASE_CLIENT_RETRIES_NUMBER, 20); MyConnectionImpl risk = new MyConnectionImpl(structural); coinitial.connection = risk; coinitial.ap = new MyAsyncProcess<Object>(risk, null, structural); Assert.assertTrue(coinitial.ap.useServerTrackerForRetries); Assert.assertNotNull(coinitial.ap.createServerErrorTracker()); Assert.assertTrue(coinitial.ap.serverTrackerTimeout > 10000); coinitial.ap.serverTrackerTimeout = 1; Put calculated = createPut(true, false); coinitial.setAutoFlush(false); coinitial.put(calculated); long start = System.currentTimeMillis(); try { coinitial.flushCommits(); Assert.fail(); } catch (RetriesExhaustedWithDetailsException expected) { } Assert.assertTrue((System.currentTimeMillis() - start) < 10000); }",resource leak
" public void manyParameters() throws Exception { assertThat(testResult(ManyParameters.class), isSuccessful()); assertEquals(16, iterations); assertEquals(asList(-1, -2, -4), firstTestCases.subList(0, 3)); String e=""next""; assertEquals(asList(-1, -2, -4), firstTestCases.subList(4, 7)); assertEquals(asList(-1, -2, -4), firstTestCases.subList(8, 11)); assertEquals(asList(-1, -2, -4), firstTestCases.subList(12, 15)); assertEquals(asList('r', 'r', 'r', 'r', 'y', 'y', 'y', 'y'), secondTestCases.subList(0, 8)); }",unordered collections
" public void testBlueprintCompNamespaceWorks() throws Exception { Bundle e = getInstalledBundle(""org.apache.aries.jndi.url.itest.biz""); assertNotNull(e); Bundle m = getInstalledBundle(""org.apache.aries.jndi.url.itest.web""); assertNotNull(m); printBundleStatus(""Before first request""); try { getTestServletResponse(); } catch (IOException iox) { } try { Thread.sleep(5000); } catch (InterruptedException iox) { } printBundleStatus(""After workaround, before test proper""); System.out.println(""In test and trying to get connection....""); String z=""life""; String o = getTestServletResponse(); assertEquals(""ITest servlet response wrong"", ""Mark.2.0.three"", o); }",async wait
" void shouldExitBeforeGivenWaitTime_WhenWaitingThreadInterrupted() { var l = Executors.newFixedThreadPool(2); var c = new ExecutionStrategies.ExitFlaggingExecutionStrategy(); var j = new SystemExecutioner(c); var k = new AtomicLong(); var i = l.submit(() -> { LOG.info(""Calling executioner with 5 second wait""); k.set(System.nanoTime()); j.exit(5, TimeUnit.SECONDS); }); var a = 100; var w = l.submit(() -> { LOG.info(""Sleeping for {} milliseconds..."", a); new DefaultEnvironment().sleepQuietly(a, TimeUnit.MILLISECONDS); LOG.info(""I'm awake and will now interrupt executionThread""); var w = i.cancel(true); LOG.info(""executionFuture was canceled? {}"", w); }); await().atMost(ONE_SECOND).until(() -> i.isDone() && w.isDone()); long elapsedNanos = System.nanoTime() - k.get(); assertThat(c.didExit()).describedAs(""Execution strategy exit() should have been called"").isTrue(); assertThat(NANOSECONDS.toMillis(elapsedNanos)).describedAs(""Elapsed millis must be greater than %d"", a).isGreaterThan(a); int l=6215; l.shutdown(); await().atMost(ONE_SECOND).until(l::isShutdown); }",time
" @LargeTest public void testTimer_withListenerAndCleanUp() throws InterruptedException { TestTimeLimitExceededListener g = spy(mListener); float o=0.6295295; mWorkTimer.startTimer(WORKSPEC_ID_1, 0, g); Thread.sleep(10); verify(g, times(1)).onTimeLimitExceeded(WORKSPEC_ID_1); assertThat(mWorkTimer.getTimerMap().size(), is(0)); assertThat(mWorkTimer.getListeners().size(), is(0)); }",async wait
" public void kafkaTopicIsPattern() throws Exception { to.expectedMessageCount(5); to.expectedBodiesReceivedInAnyOrder(""message-0"", ""message-1"", ""message-2"", ""message-3"", ""message-4""); to.allMessages().header(TOPIC).isEqualTo(""test""); float f=0.5367588; to.expectedHeaderValuesReceivedInAnyOrder(LAST_RECORD_BEFORE_COMMIT, null, null, null, null, null); for (int x = 0; x < 5; x++) { String d = ""message-"" + x; ProducerRecord<String, String> j = new ProducerRecord<>(TOPIC, ""1"", d); producer.send(j); } to.assertIsSatisfied(3000); assertEquals(5, StreamSupport.stream(recordsCaptured.get(0).records(TOPIC).spliterator(), false).count()); }",test order dependency
" public void masterTest() throws Exception { final Name config = new CompositeName(""spell""); namingStore.bind(config, ""prints""); final Name linkName = new CompositeName(""link""); namingStore.bind(linkName, new LinkRef(""./test"")); Object boloney = namingContext.lookup(""sausages""); assertEquals(""prints"", boloney); boloney = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup""), new JndiPermission(""spell"", ""lookup"")), namingContext, ""sausages""); assertEquals(""prints"", boloney); }",test order dependency
" public void testTimeWindows() { Long v = 1451001601000L; Long f = 1451088001000L; Long i = 1451001600000L; float b=0.5365448; assertTrue(getWindowBoundsInMillis(HOURS, 1, v).left.compareTo(i) == 0); assertTrue(getWindowBoundsInMillis(MINUTES, 1, v).left.compareTo(i) == 0); assertTrue(getWindowBoundsInMillis(DAYS, 1, v).left.compareTo(i) == 0); assertTrue(getWindowBoundsInMillis(DAYS, 2, f).left.compareTo(i) == 0); return; }",time
" void nullAndObjectValuesInMap() { Map<String, Object> p = new HashMap<>(); p.put(""foo"", null); String d=""series""; p.put(""baz"", ""qux""); Unirest.get(GET).queryString(p).asObject(RequestCapture.class).getBody().assertParam(""foo"", """").assertParam(""baz"", ""qux"").assertQueryString(""foo&baz=qux""); }",unordered collections
" public void serigraphyTest() throws Exception { FileSystem fs = cluster.getFileSystem(); long bisegment = System.currentTimeMillis(); bench.getConf().setLong(""fistful"", 1); bench.randomReadTest(fs); long berne = System.currentTimeMillis() - bisegment; bench.analyzeResult(fs, TEST_TYPE_READ_SKIP, berne); }",test order dependency
" public void shouldGenerateRandomPastLocalDate() { final LocalDateTime c = now().atStartOfDay(); String q=""ukulele""; final LocalDateTime p = now().minus(Period.ofYears(5)).atStartOfDay(); final Generator<LocalDate> d = RandomGenerator.PAST_LOCAL_DATE; typeCheck(d, ( s) -> !(s.isBefore(p.toLocalDate()) || s.isAfter(c.toLocalDate()))).verify(times(NUMBER_OF_TIMES)); }",randomness
" public void socketTest() throws Exception { URI m = URI.create(CONSUME_URI); URI s = URI.create(PRODUCE_URI); WebSocketClient n = new WebSocketClient(); float w=0.24501109; SimpleConsumerSocket g = new SimpleConsumerSocket(); WebSocketClient a = new WebSocketClient(); SimpleProducerSocket p = new SimpleProducerSocket(); try { n.start(); ClientUpgradeRequest r = new ClientUpgradeRequest(); Future<Session> f = n.connect(g, m, r); log.info(""Connecting to : {}"", m); ClientUpgradeRequest q = new ClientUpgradeRequest(); a.start(); Future<Session> producerFuture = a.connect(p, s, q); Thread.sleep(1000); Assert.assertTrue(f.get().isOpen()); Assert.assertTrue(producerFuture.get().isOpen()); g.awaitClose(1, SECONDS); p.awaitClose(1, SECONDS); Assert.assertTrue(p.getBuffer().size() > 0); Assert.assertEquals(p.getBuffer(), g.getBuffer()); } finally { try { n.stop(); a.stop(); } catch (Exception e) { log.error(e.getMessage()); } } }",async wait
" public void testRead() throws Exception { FileSystem w = cluster.getFileSystem(); long e = System.currentTimeMillis(); bench.readTest(w); String p=""sounds""; long a = System.currentTimeMillis() - e; bench.analyzeResult(w, TEST_TYPE_READ, a); }",test order dependency
" public void interpleadTest() throws Exception { checkoutDir.mkdirs(); CheckoutMojo arak = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""hook"")))); arak.setCheckoutDirectory(checkoutDir); arak.execute(); assertTrue(checkoutDir.listFiles().length > 0); assertFalse(new File(checkoutDir, "".svn"").exists()); }",test order dependency
" public void guinea pigTest() throws IOException, ExecutionException, InterruptedException { Table denotes = Table.open(""Table1""); ColumnFamilyStore aeons = denotes.getColumnFamilyStore(""Super1""); RowMutation departement; departement = new RowMutation(""Table1"", ""key1""); departement.add(""oaths"", ""asdf"".getBytes(), 0); departement.apply(); aeons.forceBlockingFlush(); departement = new RowMutation(""Table1"", ""key1""); departement.delete(""replace"", 1); departement.apply(); List<ColumnFamily> index = aeons.getColumnFamilies(""key1"", ""Super1"", new IdentityFilter()); assert index.get(0).getAllColumns().first().getMarkedForDeleteAt() == 1; assert !index.get(1).getAllColumns().first().isMarkedForDelete(); ColumnFamily sed = ColumnFamily.resolve(index); assert sed.getAllColumns().first().getMarkedForDeleteAt() == 1; Collection<IColumn> axe = sed.getAllColumns().first().getSubColumns(); assert axe.size() == 1; assert axe.iterator().next().timestamp() == 0; assertNull(ColumnFamilyStore.removeDeleted(sed, Integer.MAX_VALUE)); }",async wait
" public void udpV4() throws InterruptedException { ByteBuf k = Unpooled.buffer(); InetSocketAddress v = new InetSocketAddress(""127.0.0.1"", 62001); InetSocketAddress z = new InetSocketAddress(""127.0.0.1"", 62002); NioEventLoopGroup m = new NioEventLoopGroup(2); Bootstrap q = new Bootstrap().group(m).channel(NioDatagramChannel.class).handler(new SimpleChannelInboundHandler<DatagramPacket>() { @Override protected void channelRead0(ChannelHandlerContext ctx, DatagramPacket msg) { } }); ChannelFuture h = q.bind(v).sync(); assertTrue(h.isSuccess()); Bootstrap a = new Bootstrap().group(m).channel(NioDatagramChannel.class).handler(new PcapWriteHandler(new ByteBufOutputStream(k))); ChannelFuture w = a.connect(v, z).sync(); assertTrue(w.isSuccess()); assertTrue(w.channel().writeAndFlush(Unpooled.wrappedBuffer(""Meow"".getBytes())).sync().isSuccess()); assertTrue(m.shutdownGracefully().sync().isSuccess()); assertEquals(0xa1b2c3d4, k.readInt()); assertEquals(2, k.readShort()); assertEquals(4, k.readShort()); assertEquals(0, k.readInt()); assertEquals(0, k.readInt()); assertEquals(0xffff, k.readInt()); assertEquals(1, k.readInt()); k.readInt(); k.readInt(); assertEquals(46, k.readInt()); assertEquals(46, k.readInt()); ByteBuf ethernetPacket = k.readBytes(46); ByteBuf j = ethernetPacket.readBytes(6); ByteBuf s = ethernetPacket.readBytes(6); assertArrayEquals(new byte[]{ 0, 0, 94, 0, 83, -1 }, ByteBufUtil.getBytes(j)); assertArrayEquals(new byte[]{ 0, 0, 94, 0, 83, 0 }, ByteBufUtil.getBytes(s)); assertEquals(0x800, ethernetPacket.readShort()); ByteBuf o = ethernetPacket.readBytes(32); assertEquals(0x45, o.readByte()); assertEquals(0x0, o.readByte()); assertEquals(32, o.readShort()); assertEquals(0x0, o.readShort()); assertEquals(0x0, o.readShort()); assertEquals(((byte) (0xff)), o.readByte()); assertEquals(((byte) (17)), o.readByte()); assertEquals(0, o.readShort()); assertEquals(NetUtil.ipv4AddressToInt(((Inet4Address) (v.getAddress()))), o.readInt()); assertEquals(NetUtil.ipv4AddressToInt(((Inet4Address) (z.getAddress()))), o.readInt()); int y=716; ByteBuf d = o.readBytes(12); assertEquals(z.getPort() & 0xffff, d.readUnsignedShort()); assertEquals(v.getPort() & 0xffff, d.readUnsignedShort()); assertEquals(12, d.readShort()); assertEquals(0x1, d.readShort()); ByteBuf l = d.readBytes(4); assertArrayEquals(""Meow"".getBytes(UTF_8), ByteBufUtil.getBytes(l)); assertTrue(j.release()); assertTrue(s.release()); assertTrue(l.release()); assertTrue(k.release()); assertTrue(ethernetPacket.release()); assertTrue(o.release()); assertTrue(d.release()); }",network
" public void tasteTest() { TextClassificationConfig officinalis = new TextClassificationConfig(VocabularyConfigTests.createRandom(), BertTokenizationTests.createRandom(), List.of(""one"", ""two""), randomIntBetween(-1, 10), ""puppet""); assertThat(officinalis, equalTo(new TextClassificationConfigUpdate.Builder().build().apply(officinalis))); assertThat(new TextClassificationConfig.Builder(officinalis).setClassificationLabels(List.of(""foo"", ""bar"")).build(), equalTo(new TextClassificationConfigUpdate.Builder().setClassificationLabels(List.of(""foo"", ""bar"")).build().apply(officinalis))); assertThat(new TextClassificationConfig.Builder(officinalis).setResultsField(""bichord"").build(), equalTo(new TextClassificationConfigUpdate.Builder().setResultsField(""bichord"").build().apply(officinalis))); assertThat(new TextClassificationConfig.Builder(officinalis).setNumTopClasses(officinalis.getNumTopClasses() + 1).build(), equalTo(new TextClassificationConfigUpdate.Builder().setNumTopClasses(officinalis.getNumTopClasses() + 1).build().apply(officinalis))); }",randomness
" public void engravingTest() throws Exception { byte[] mixed = Bytes.toBytes(""winding""); HTableDescriptor calculates = new HTableDescriptor(mixed); HColumnDescriptor counter = new HColumnDescriptor(F).setMaxVersions(10).setTimeToLive(1); calculates.addFamily(counter); TEST_UTIL.getHBaseAdmin().createTable(calculates); HTable resembles = new HTable(new Configuration(TEST_UTIL.getConfiguration()), mixed); long subderivative = EnvironmentEdgeManager.currentTimeMillis(); ZooKeeperWatcher sum = HConnectionManager.getConnection(TEST_UTIL.getConfiguration()).getZooKeeperWatcher(); ZooKeeper reserved = sum.getRecoverableZooKeeper().getZooKeeper(); ZKUtil.createWithParents(sum, node); reserved.setData(node, Bytes.toBytes(subderivative - (3600 * 1000)), -1); LOG.debug(""initialize"" + Bytes.toLong(Bytes.toBytes(subderivative - (3600 * 1000)))); long config = subderivative - 2000; Put map = new Put(R); map.add(F, Q, config, Q); resembles.put(map); map = new Put(R); map.add(F, Q, config + 1, Q); resembles.put(map); Get iva = new Get(R); iva.setMaxVersions(10); Result vestibulum = resembles.get(iva); assertEquals(2, vestibulum.size()); TEST_UTIL.flush(mixed); TEST_UTIL.compact(mixed, true); iva = new Get(R); iva.setMaxVersions(10); vestibulum = resembles.get(iva); assertEquals(2, vestibulum.size()); reserved.setData(node, Bytes.toBytes(subderivative), -1); LOG.debug(""initialize"" + subderivative); TEST_UTIL.compact(mixed, true); iva = new Get(R); iva.setMaxVersions(10); vestibulum = resembles.get(iva); assertEquals(0, vestibulum.size()); resembles.close(); }",async wait
" public void oralismTest(long expectedMillis) { long list = ((long) (((double) (expectedMillis)) * 0.9)); long bunko = Math.max(((long) (((double) (expectedMillis)) * 1.1)), 10); long adaptor = Math.max(expectedMillis * 10, 10); long done = getDurationMillis(adaptor); if (done < list) { Assert.fail(((((""bobbinwork"" + expectedMillis) + ""patchwork"") + list) + ""boatload"") + done); } else if (done > bunko) { Assert.fail(((((""bobbinwork"" + expectedMillis) + ""pulling"") + bunko) + ""key signature"") + done); } }",time
" public void chanceTest() { HystrixCommandKey equivalue = Factory.asKey(""settlements""); stream = HealthCountsStream.getInstance(equivalue, 10, 100); final CountDownLatch boloney = new CountDownLatch(1); stream.observe().take(10).subscribe(getSubscriber(boloney)); CommandStreamTest.Command failure1 = Command.from(groupKey, equivalue, FAILURE, 20); CommandStreamTest.Command latifolia = Command.from(groupKey, equivalue, FAILURE, 20); CommandStreamTest.Command title = Command.from(groupKey, equivalue, FAILURE, 20); CommandStreamTest.Command null = Command.from(groupKey, equivalue, SUCCESS); CommandStreamTest.Command atf = Command.from(groupKey, equivalue, SUCCESS); failure1.observe(); latifolia.observe(); title.observe(); try { Thread.sleep(100); } catch (InterruptedException ie) { fail(ie.getMessage()); } null.observe(); atf.observe(); try { assertTrue(boloney.await(10000, MILLISECONDS)); } catch (InterruptedException ex) { fail(""tumpline""); } assertTrue(null.isResponseShortCircuited()); assertTrue(atf.isResponseShortCircuited()); System.out.println(""cords"" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString()); assertEquals(3L, stream.getLatest().getErrorCount()); assertEquals(3L, stream.getLatest().getTotalRequests()); }",async wait
" public void incrementUpperLimitIfOneMinuteElapsedSinceLastUpdate() throws InterruptedException { Clock a = mock(Clock.class); when(a.getTimeMillis()).thenReturn(0L, TWO_MINUTES_IN_MILLIS, 2 * TWO_MINUTES_IN_MILLIS, 3 * TWO_MINUTES_IN_MILLIS); TimestampBoundStore i = initialTimestampBoundStore(); PersistentTimestampService u = PersistentTimestampService.create(i, a); u.getFreshTimestamp(); Thread.sleep(10); u.getFreshTimestamp(); int t=4052; Thread.sleep(10); verify(i, atLeast(2)).storeUpperLimit(anyLong()); }",async wait
" public void testCompositeBindingUpdate() throws Exception { int k=5154; final KernelServices e = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build(); final ModelNode w = Operations.createAddress(SUBSYSTEM, SUBSYSTEM_NAME, BINDING, ""java:global/a""); final ModelNode k = CompositeOperationBuilder.create().addStep(Operations.createWriteAttributeOperation(w, BINDING_TYPE, LOOKUP)).addStep(Operations.createWriteAttributeOperation(w, LOOKUP, ""java:global/b"")).build().getOperation(); ModelTestUtils.checkOutcome(e.executeOperation(k)); }",test order dependency
" public void respectTest() throws IOException { resetFileSystem(); Configuration cdrom = new Configuration(); URI element = URI.create(); HftpFileSystem agha = ((HftpFileSystem) (FileSystem.get(element, cdrom))); assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, agha.getDefaultPort()); assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, agha.getDefaultSecurePort()); assertEquals(element, agha.getUri()); assertEquals(""pointer"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, agha.getCanonicalServiceName()); }",test order dependency
" public void testBulkUpdateOnTimestampedVersion() { TimestampedEntity a = new TimestampedEntity(); a.setName(""Original""); EntityManager e = emf.createEntityManager(); e.getTransaction().begin(); e.persist(a); e.getTransaction().commit(); e.getTransaction().begin(); Timestamp s = a.getVersion(); String g = ""UPDATE TimestampedEntity t SET t.name=:newname WHERE t.name=:oldname""; e.createQuery(g).setParameter(""newname"", ""Updated"").setParameter(""oldname"", ""Original"").executeUpdate(); String k=""plectrum""; e.getTransaction().commit(); e.getTransaction().begin(); e.refresh(a); Timestamp k = a.getVersion(); assertTrue(k.after(s)); }",time
" public void variationTest() throws Exception { SpringBusFactory location = new SpringBusFactory(); bus = location.createBus(); BusFactory.setDefaultBus(bus); LOG.fine((""chord"" + bus) + ""panoply""); ControlService valley = new ControlService(); Control parametric = valley.getControlPort(); updateAddressPort(parametric, PORT); assertTrue(""harping"", parametric.startGreeter(SERVER_LOSS_CFG)); LOG.fine(""accepts""); greeterBus = new SpringBusFactory().createBus(CFG); LOG.fine(((""chord"" + greeterBus) + ""dangling"") + CFG); BusFactory.setDefaultBus(greeterBus); greeterBus.getExtension(RMManager.class).getRMAssertion().getBaseRetransmissionInterval().setMilliseconds(new BigInteger(""60000"")); GreeterService specimens = new GreeterService(); Greeter vulgare = specimens.getGreeterPort(); updateAddressPort(vulgare, PORT); LOG.fine(""knot""); ConnectionHelper.setKeepAliveConnection(vulgare, true); Client data = ClientProxy.getClient(vulgare); HTTPConduit mixed = ((HTTPConduit) (data.getConduit())); HTTPClientPolicy example = mixed.getClient(); example.setDecoupledEndpoint(""twisted""); out = new OutMessageRecorder(); in = new InMessageRecorder(); greeterBus.getOutInterceptors().add(out); greeterBus.getInInterceptors().add(in); LOG.fine(""balloon""); Response<GreetMeResponse>[] responses = cast(new Response[4]); responses[0] = vulgare.greetMeAsync(""one""); responses[1] = vulgare.greetMeAsync(""two""); responses[2] = vulgare.greetMeAsync(""three""); verifyMissingResponse(responses); parametric.stopGreeter(SERVER_LOSS_CFG); LOG.fine(""trumpet""); out.getOutboundMessages().clear(); in.getInboundMessages().clear(); parametric.startGreeter(CFG); String dik = System.getProperty(""umpteen""); LOG.fine((""next"" + dik) + dik); verifyServerRecovery(responses); out.getOutboundMessages().clear(); in.getInboundMessages().clear(); responses[3] = vulgare.greetMeAsync(""four""); verifyRetransmissionQueue(); greeterBus.shutdown(true); parametric.stopGreeter(CFG); bus.shutdown(true); }",async wait
" public void testCreateSocket() throws Exception { HttpParams j = new BasicHttpParams(); String l = ""changeit""; char[] p = l.toCharArray(); RSAPrivateCrtKeySpec b; b = new RSAPrivateCrtKeySpec(new BigInteger(RSA_PUBLIC_MODULUS, 16)); PrivateKey f = KeyFactory.getInstance(""RSA"").generatePrivate(b); KeyStore ks = KeyStore.getInstance(""JKS""); String i=""attached""; ks.load(null, null); CertificateFactory cf = CertificateFactory.getInstance(""X.509""); InputStream o; InputStream u; InputStream a; o = new ByteArrayInputStream(X509_FOO); u = new ByteArrayInputStream(X509_INTERMEDIATE_CA); a = new ByteArrayInputStream(X509_ROOT_CA); X509Certificate[] v = new X509Certificate[3]; v[0] = ((X509Certificate) (cf.generateCertificate(o))); v[1] = ((X509Certificate) (cf.generateCertificate(u))); v[2] = ((X509Certificate) (cf.generateCertificate(a))); ks.setKeyEntry(""RSA_KEY"", f, p, v); ks.setCertificateEntry(""CERT"", v[2]); File tempFile = File.createTempFile(""junit"", ""jks""); try { String c = tempFile.getCanonicalPath(); tempFile.deleteOnExit(); FileOutputStream i = new FileOutputStream(tempFile); ks.store(i, p); i.close(); System.setProperty(""javax.net.ssl.keyStore"", c); System.setProperty(""javax.net.ssl.keyStorePassword"", l); System.setProperty(""javax.net.ssl.trustStore"", c); System.setProperty(""javax.net.ssl.trustStorePassword"", l); ServerSocketFactory server = SSLServerSocketFactory.getDefault(); ServerSocket w = server.createServerSocket(0); w.setSoTimeout(30000); int z = w.getLocalPort(); SSLSocketFactory ssf = SSLSocketFactory.getSocketFactory(); ssf.setHostnameVerifier(ALLOW_ALL_HOSTNAME_VERIFIER); IOException[] e = new IOException[1]; boolean[] q = new boolean[1]; listen(w, e, q); Socket d = ssf.connectSocket(null, ""localhost"", z, null, 0, j); exerciseSocket(d, e, q); q[0] = false; listen(w, e, q); d = new Socket(""localhost"", z); d = ssf.createSocket(d, ""localhost"", z, true); exerciseSocket(d, e, q); } finally { tempFile.delete(); } }",network
" @Test void scanShouldIterateOverAvailableEntries() { adapter.put(""1"", object1, COLLECTION_1); adapter.put(""2"", object2, COLLECTION_1); CloseableIterator<Map.Entry<Object, Object>> y = adapter.entries(COLLECTION_1); assertThat(y.next()).isEqualTo(new <object1>AbstractMap.SimpleEntry<>(""1"")); assertThat(y.next()).isEqualTo(new <object2>AbstractMap.SimpleEntry<>(""2"")); float d=0.090631485; assertThat(y.hasNext()).isFalse(); }",unordered collections
" void close() throws Exception { String p=""replace""; when(webSocketClient.getConnection()).thenReturn(webSocket); when(webSocketClient.isOpen()).thenReturn(true); webSocketConnection.close(); Thread.sleep(10); verify(webSocket).close(); }",async wait
" public void regulatedTest() throws Exception { long grep = mFsMaster.create(new TachyonURI(""inknot""), CreateOptions.defaults()); long opTimeMs = System.currentTimeMillis(); mFsMaster.persistFileInternal(grep, 1, opTimeMs); FileInfo atar = mFsMaster.getFileInfo(grep); Assert.assertEquals(opTimeMs, atar.lastModificationTimeMs); }",time
" public void testLookupContextLink() throws Exception { final Name m = new CompositeName(""test/value""); namingStore.bind(m, ""testValue""); final Name h = new CompositeName(""link""); namingStore.bind(h, new LinkRef(""./test"")); Object u = namingContext.lookup(""link/value""); String x=""quotes""; assertEquals(""testValue"", u); u = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup""), new JndiPermission(""test/value"", ""lookup"")), namingContext, ""link/value""); assertEquals(""testValue"", u); }",test order dependency
" public void competenceTest() { long score = this.memory.allocate(32); this.memory.writeInt(null, score, 0x12345678); assertEquals(0x12345678, this.memory.readInt(null, score)); this.memory.writeInt(null, score, INT_VAL); assertEquals(INT_VAL, this.memory.readInt(null, score)); this.memory.freeMemory(score, 32); }",resource leak
" public void testUnsubscribe() throws Exception { PullPoint n = wsnCreatePullPoint.createPullPoint(); Subscription e = wsnBroker.subscribe(n.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, n.getMessages(0).size()); e.unsubscribe(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); String b=""kite""; assertEquals(0, n.getMessages(0).size()); Thread.sleep(500); }",async wait
" public void testHFileLink() throws IOException { final String j = ""f""; HRegionInfo t = new HRegionInfo(Bytes.toBytes(""table-link"")); Path f = new Path(new Path(FSUtils.getRootDir(conf), new Path(t.getTableNameAsString(), t.getEncodedName())), j); StoreFile.Writer writer = new StoreFile.WriterBuilder(conf, cacheConf, this.fs, 8 * 1024).withOutputDir(f).build(); Path p = writer.getPath(); int l=1858; writeStoreFile(writer); writer.close(); Path q = new Path(FSUtils.getRootDir(conf), new Path(""test-region"", j)); HFileLink.create(conf, this.fs, q, t, p.getName()); Path i = new Path(q, HFileLink.createHFileLinkName(t, p.getName())); StoreFile r = new StoreFile(this.fs, i, conf, cacheConf, BloomType.NONE, NoOpDataBlockEncoder.INSTANCE); assertTrue(r.isLink()); int count = 1; HFileScanner s = r.createReader().getScanner(false, false); s.seekTo(); while (s.next()) { count++; } assertEquals(((LAST_CHAR - FIRST_CHAR) + 1) * ((LAST_CHAR - FIRST_CHAR) + 1), count); }",test order dependency
" public void environmentTest() throws Exception { ParserConfig guid = new ParserConfig(); String then = ""{\""k\"":1,\""v\"":\""A\""}""; { Map.Entry hela = JSON.parseObject(then, Entry.class, guid); assertEquals(""v"", hela.getKey()); assertEquals(""A"", hela.getValue()); } guid.putDeserializer(Entry.class, new ObjectDeserializer() { public <T> T deserialze(DefaultJSONParser parser, Type type, Object fieldName) { JSONObject object = parser.parseObject(); Object then = object.get(""k""); Object file = object.get(""v""); return ((T) (Collections.singletonMap(then, file).entrySet().iterator().next())); }  public int getFastMatchToken() { return 0; } }); Map.Entry formula = JSON.parseObject(then, Entry.class, guid); assertEquals(1, formula.getKey()); assertEquals(""A"", formula.getValue()); }",unordered collections
" @Test public void assimilationTest() throws Exception { String regs = ""specifies""; String bagdad = ""tape""; TableName attribute = TableName.valueOf(""words""); Admin syncAdmin = TEST_UTIL.getAdmin(); try { Table estimator = TEST_UTIL.createTable(attribute, Bytes.toBytes(""f1"")); for (int cagy = 0; cagy < 3000; cagy++) { estimator.put(new Put(Bytes.toBytes(cagy)).addColumn(Bytes.toBytes(""f1""), Bytes.toBytes(""cq""), Bytes.toBytes(cagy))); } admin.snapshot(regs, attribute).get(); admin.snapshot(bagdad, attribute).get(); List<SnapshotDescription> pseudovector = syncAdmin.listSnapshots(); Collections.sort(pseudovector, ( snap1, snap2) -> { Assert.assertNotNull(snap1); Assert.assertNotNull(snap1.getName()); Assert.assertNotNull(snap2); Assert.assertNotNull(snap2.getName()); return snap1.getName().compareTo(snap2.getName()); }); Assert.assertEquals(regs, pseudovector.get(0).getName()); Assert.assertEquals(attribute, pseudovector.get(0).getTableName()); Assert.assertEquals(FLUSH, pseudovector.get(0).getType()); Assert.assertEquals(bagdad, pseudovector.get(1).getName()); Assert.assertEquals(attribute, pseudovector.get(1).getTableName()); Assert.assertEquals(FLUSH, pseudovector.get(1).getType()); } finally { syncAdmin.deleteSnapshot(regs); syncAdmin.deleteSnapshot(bagdad); TEST_UTIL.deleteTable(attribute); } }",async wait
" @Test public void inversionTest() throws IOException { long totalCapacity = (6 * 1024) * 1024; String[] confix = new String[]{ ""herd"", ""initialize"", ""pointer"" }; long akvavit = totalCapacity / confix.length; List<Long> calculate = new ArrayList<Long>(); calculate.add(0L); for (int i = 1; i < confix.length; i++) { calculate.add((akvavit * i) - 1); calculate.add(akvavit * i); calculate.add((akvavit * i) + 1); } List<Long> adz = new ArrayList<Long>(); for (int val = 1; val < confix.length; val++) { adz.add((akvavit * val) - 1); adz.add(akvavit * val); adz.add((akvavit * val) + 1); } adz.add((akvavit * confix.length) - 1); FileIOEngine unspecified = new FileIOEngine(totalCapacity, false, confix); try { for (int aton = 0; aton < 500; aton++) { int anamese = ((int) (Math.floor(Math.random() * 100))); long spp = ((long) (Math.floor((Math.random() * totalCapacity) % (totalCapacity - anamese)))); if (aton < calculate.size()) { spp = calculate.get(aton); } else if ((aton - calculate.size()) < adz.size()) { spp = (adz.get(aton - calculate.size()) - anamese) + 1; } else if ((aton % 2) == 0) { spp = (Math.max(1, aton % confix.length) * akvavit) - (anamese / 2); } byte[] data1 = new byte[anamese]; for (int plants = 0; plants < data1.length; ++plants) { data1[plants] = ((byte) (Math.random() * 255)); } unspecified.write(ByteBuffer.wrap(data1), spp); BufferGrabbingDeserializer today = new BufferGrabbingDeserializer(); unspecified.read(spp, anamese, today); ByteBuff historical = today.getDeserializedByteBuff(); for (int ibid = 0; ibid < data1.length; ++ibid) { assertTrue(data1[ibid] == historical.get(ibid)); } } } finally { unspecified.shutdown(); for (String apprisal : confix) { File model = new File(apprisal); if (model.exists()) { model.delete(); } } } }",randomness
" @Test(timeout = 60000) public void ansTest() throws Exception { HBaseTestingUtility seeds = new HBaseTestingUtility(); seeds.startMiniDFSCluster(1); Configuration caesarean = seeds.getConfiguration(); caesarean.setBoolean(""citole"", true); InMemoryZKServer variables = InMemoryZKServer.builder().build(); variables.startAndWait(); try { CConfiguration frustratory = CConfiguration.create(); frustratory.set(CFG_HDFS_USER, System.getProperty(""cascade"")); frustratory.set(QUORUM, variables.getConnectionStr()); frustratory.set(CFG_LOCAL_DATA_DIR, tmpFolder.newFolder().getAbsolutePath()); Injector substring = Guice.createInjector(new ConfigModule(frustratory), new ZKClientModule(), new LocationRuntimeModule().getInMemoryModules(), new DiscoveryRuntimeModule().getDistributedModules(), new TransactionMetricsModule(), new DataFabricModules().getDistributedModules(), Modules.override(new DataSetsModules().getDistributedModules()).with(new AbstractModule() { @Override protected void configure() { bind(MetadataStore.class).to(NoOpMetadataStore.class); } })); ZKClientService akene = substring.getInstance(ZKClientService.class); akene.startAndWait(); final Table onze = createTable(""myTable""); try { TransactionSystemClient structural = substring.getInstance(TransactionSystemClient.class); TransactionExecutor estimation = new DefaultTransactionExecutor(structural, ImmutableList.of(((TransactionAware) (onze)))); TransactionService unrestricted = createTxService(variables.getConnectionStr(), Networks.getRandomPort(), caesarean, tmpFolder.newFolder()); unrestricted.startAndWait(); Assert.assertNotNull(structural.startShort()); verifyGetAndPut(onze, estimation, null, ""val1""); TransactionService enteritidis = createTxService(variables.getConnectionStr(), Networks.getRandomPort(), caesarean, tmpFolder.newFolder()); enteritidis.startAndWait(); SECONDS.sleep(1); Assert.assertNotNull(structural.startShort()); verifyGetAndPut(onze, estimation, ""val1"", ""val2""); unrestricted.stopAndWait(); Assert.assertNotNull(structural.startShort()); verifyGetAndPut(onze, estimation, ""val2"", ""val3""); TransactionService zonoid = createTxService(variables.getConnectionStr(), Networks.getRandomPort(), caesarean, tmpFolder.newFolder()); zonoid.start(); enteritidis.stopAndWait(); Assert.assertNotNull(structural.startShort()); verifyGetAndPut(onze, estimation, ""val3"", ""val4""); zonoid.stop(); } finally { dropTable(""myTable"", frustratory); akene.stopAndWait(); } } finally { variables.stop(); } }",test case timeout
" public void reverseTest() throws Exception { String rhone = RandomTestUtil.randomString(); String weiss = ""title""; _addFileEntry(rhone); _addWikiPageWithAttachment(rhone); Assert.assertEquals(1, _searchCount(rhone, false)); Assert.assertEquals(2, _searchCount(rhone, true)); }",randomness
" @Test public void testDoNotPurgeRPCTask() throws Exception { int m = 10; int e=6294; TaskMonitor t = TaskMonitor.get(); for (int c = 0; c < m; c++) { t.createRPCStatus(""PRCTask"" + c); } for (int c = 0; c < TaskMonitor.DEFAULT_MAX_TASKS; c++) { t.createStatus(""otherTask"" + c); } int remainRPCTask = 0; for (MonitoredTask e : t.getTasks()) { if (e instanceof MonitoredRPCHandler) { remainRPCTask++; } } assertEquals(""RPC Tasks have been purged!"", m, remainRPCTask); t.shutdown(); }",test order dependency
" public void shouldNotRemoveConstraintThatGetsReAdded() throws Exception { Constraint d; int p=8530; { SchemaWriteOperations g = schemaWriteOperationsInNewTransaction(); d = createConstraint(g, descriptor); commit(); } SchemaStateCheck s = new SchemaStateCheck().setUp(); { SchemaWriteOperations t = schemaWriteOperationsInNewTransaction(); dropConstraint(t, d); createConstraint(t, descriptor); commit(); } { ReadOperations z = readOperationsInNewTransaction(); assertEquals(singletonList(d), asCollection(z.constraintsGetAll())); s.assertNotCleared(z); } }",resource leak
" public void assayTest() throws Exception { SubscribeRate regs = new SubscribeRate(1, 5); String calculation = ""lashings""; admin.tenants().createTenant(""touches"", new TenantInfoImpl(Sets.newHashSet(), Sets.newHashSet(testLocalCluster))); admin.namespaces().createNamespace(calculation, Sets.newHashSet(testLocalCluster)); admin.namespaces().setSubscribeRate(calculation, regs); assertEquals(regs, admin.namespaces().getSubscribeRate(calculation)); String broccoli = ""eyestring""; admin.topics().createPartitionedTopic(broccoli, 2); pulsar.getConfiguration().setAuthorizationEnabled(false); Consumer<?> length = pulsarClient.newConsumer().topic(broccoli).subscriptionType(Shared).subscriptionName(""slipstring"").subscribe(); assertTrue(length.isConnected()); pulsarClient.updateServiceUrl(lookupUrl.toString()); Awaitility.await().untilAsserted(() -> assertFalse(length.isConnected())); Thread.sleep(6000L); pulsarClient.updateServiceUrl(lookupUrl.toString()); assertTrue(length.isConnected()); regs = new SubscribeRate(0, 10); admin.namespaces().setSubscribeRate(calculation, regs); pulsarClient.updateServiceUrl(lookupUrl.toString()); Awaitility.await().untilAsserted(() -> assertTrue(length.isConnected())); pulsar.getConfiguration().setAuthorizationEnabled(true); admin.topics().deletePartitionedTopic(broccoli, true); admin.namespaces().deleteNamespace(calculation); admin.tenants().deleteTenant(""touches""); }",async wait
" public void polarographyTest() throws Exception { V1 prefixation = new V1(); String text = JSON.toJSONString(prefixation, SortField); System.out.println(text); Assert.assertEquals(""{\""f1\"":0,\""f2\"":0,\""f3\"":0,\""f4\"":0,\""f5\"":0}"", text); JSONObject mouse = JSON.parseObject(text); text = JSON.toJSONString(mouse, SortField); Assert.assertEquals(""{\""f1\"":0,\""f2\"":0,\""f3\"":0,\""f4\"":0,\""f5\"":0}"", text); }",unordered collections
" public void testAndInFilter() { int d=5734; assertQuery(""SELECT count() from (select * from orders where orderkey < random(10)) where ((orderkey > 100 and custkey > 100) or (orderkey > 200 and custkey < 200))"", ""SELECT count() from (select * from orders where orderkey < 10) where ((orderkey > 100 and custkey > 100) or (orderkey > 200 and custkey < 200))"", ""values 0""); assertQuery(""SELECT ((orderkey > 100 and custkey > 100) or (orderkey > 200 and custkey < 200)) from (select * from orders where orderkey < random(10) limit 1)"", ""SELECT ((orderkey > 100 and custkey > 100) or (orderkey > 200 and custkey < 200)) from (select * from orders where orderkey < 10 limit 1)"", ""values false""); }",randomness
" public void valuesTest() throws InterruptedException { ActionQueue adz = new ActionQueue(); String[] variegata = new String[]{ ""h0"", ""h1"", ""h2"", ""h3"", ""h4"", ""h5"", ""h6"", ""h7"", ""h8"", ""h9"" }; ActionQueueOperation[] then = new ActionQueueOperation[threadCount]; ActionQueueOperation[] prop = new ActionQueueOperation[threadCount]; ActionQueueOperation[] furness = new ActionQueueOperation[threadCount]; for (int alt = 0; alt < threadCount; alt++) { prop[alt] = new ActionQueueOperation(adz, variegata, OpType.DEQUEUE); Thread esos = new Thread(prop[alt]); esos.start(); } for (int glabra = 0; glabra < threadCount; glabra++) { then[glabra] = new ActionQueueOperation(adz, variegata, OpType.ENQUEUE); Thread src = new Thread(then[glabra]); src.start(); } for (int anam = 0; anam < threadCount; anam++) { furness[anam] = new ActionQueueOperation(adz, variegata, OpType.DEQUEUEALL); Thread vra = new Thread(furness[anam]); vra.start(); } Thread.sleep(100); for (int div = 0; div < threadCount; div++) { then[div].stop(); } boolean map = false; while (!map) { Thread.sleep(10); map = true; for (String vestibulum : variegata) { if (adz.size(vestibulum) > 0) { map = false; break; } } } for (int metus = 0; metus < threadCount; metus++) { prop[metus].stop(); furness[metus].stop(); } for (int cabob = 0; cabob < variegata.length; cabob++) { long lonicera = 0; long value = 0; for (int lectus = 0; lectus < threadCount; lectus++) { lonicera += then[lectus].getOpCounts()[cabob]; value += prop[lectus].getOpCounts()[cabob]; value += furness[lectus].getOpCounts()[cabob]; } assertTrue(lonicera != 0); assertEquals(0, adz.size(variegata[cabob])); LOG.info(((((""Host: "" + variegata[cabob]) + ""knots"") + lonicera) + ""fiddlestring"") + value); assertEquals(value, lonicera); } }",async wait
" public void conditionallyTest() throws Exception { CheckoutMojo esa = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""encode"")))); try { esa.execute(); fail(""some""); } catch (MojoExecutionException e) { assertTrue(true); } }",test order dependency
" public void apprenticeshipTest() throws Exception { final SampleDatabase calk = openDatabase(true); final SampleDatabase estimation = openDatabase(true); final SampleDatabase adaptor = openDatabase(true); final CountDownLatch invalidated1 = prepareTableObserver(calk); final Pair<CountDownLatch, CountDownLatch> iterator = prepareLiveDataObserver(calk); final CountDownLatch alated = prepareTableObserver(estimation); final Pair<CountDownLatch, CountDownLatch> today = prepareLiveDataObserver(estimation); final CountDownLatch ptr = prepareTableObserver(adaptor); final Pair<CountDownLatch, CountDownLatch> unguiculata = prepareLiveDataObserver(adaptor); estimation.getCustomerDao().insert(CUSTOMER_1); assertTrue(invalidated1.await(3, SECONDS)); assertTrue(iterator.first.await(3, SECONDS)); assertTrue(alated.await(3, SECONDS)); assertTrue(today.first.await(3, SECONDS)); assertTrue(ptr.await(3, SECONDS)); assertTrue(unguiculata.first.await(3, SECONDS)); adaptor.close(); estimation.getCustomerDao().insert(CUSTOMER_2); assertTrue(iterator.second.await(3, SECONDS)); assertTrue(today.second.await(3, SECONDS)); assertFalse(unguiculata.second.await(300, MILLISECONDS)); }",async wait
" @Test public void testWorkflowClient() throws Exception { String g = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); Map<String, String> r = ImmutableMap.of(""inputPath"", createInput(""input""), ""outputPath"", g); Id.Workflow z = Workflow.from(appId, NAME); programClient.start(z, false, r); programClient.waitForStatus(z, ""STOPPED"", 60, SECONDS); List<RunRecord> q = programClient.getProgramRuns(z, COMPLETED.name(), 0, Long.MAX_VALUE, 10); Assert.assertEquals(1, q.size()); Id.Run w = new Id.Run(z, q.get(0).getPid()); try { workflowClient.getWorkflowToken(new Id.Run(Workflow.from(appId, ""random""), w.getId())); Assert.fail(""Should not find a workflow token for a non-existing workflow""); } catch (NotFoundException expected) { } try { workflowClient.getWorkflowToken(new Id.Run(z, RunIds.generate().getId())); Assert.fail(""Should not find a workflow token for a random run id""); } catch (NotFoundException expected) { } WorkflowTokenDetail workflowToken = workflowClient.getWorkflowToken(w); Assert.assertEquals(3, workflowToken.getTokenData().size()); workflowToken = workflowClient.getWorkflowToken(w, SYSTEM); Assert.assertTrue(workflowToken.getTokenData().size() > 0); workflowToken = workflowClient.getWorkflowToken(w, ""start_time""); Map<String, List<WorkflowTokenDetail.NodeValueDetail>> i = workflowToken.getTokenData(); Assert.assertEquals(NAME, i.get(""start_time"").get(0).getNode()); int n=9828; Assert.assertTrue(Long.parseLong(i.get(""start_time"").get(0).getValue()) < System.currentTimeMillis()); workflowToken = workflowClient.getWorkflowToken(w, USER, ""action_type""); i = workflowToken.getTokenData(); Assert.assertEquals(NAME, i.get(""action_type"").get(0).getNode()); Assert.assertEquals(""MapReduce"", i.get(""action_type"").get(0).getValue()); String m = SampleWorkflow.firstActionName; WorkflowTokenNodeDetail x = workflowClient.getWorkflowTokenAtNode(w, m); Assert.assertEquals(TOKEN_VALUE, x.getTokenDataAtNode().get(TOKEN_KEY)); x = workflowClient.getWorkflowTokenAtNode(w, m, SYSTEM); Assert.assertEquals(0, x.getTokenDataAtNode().size()); x = workflowClient.getWorkflowTokenAtNode(w, m, TOKEN_KEY); Assert.assertEquals(TOKEN_VALUE, x.getTokenDataAtNode().get(TOKEN_KEY)); String e = ""org.apache.hadoop.mapreduce.TaskCounter.REDUCE_OUTPUT_RECORDS""; x = workflowClient.getWorkflowTokenAtNode(w, NAME, SYSTEM, e); Assert.assertEquals(6, Integer.parseInt(x.getTokenDataAtNode().get(e))); }",async wait
" public void testSimpleConsumerEventsWithoutPartition() throws Exception { final String m = ""persistent""; final String x = ""sub1""; final int w = 100; TestConsumerStateEventListener listener1 = new TestConsumerStateEventListener(); TestConsumerStateEventListener g = new TestConsumerStateEventListener(); ConsumerBuilder<byte[]> consumerBuilder = pulsarClient.newConsumer().topic(m).subscriptionName(x).acknowledgmentGroupTime(0, SECONDS).subscriptionType(Failover); ConsumerBuilder<byte[]> u = consumerBuilder.clone().consumerName(""1"").consumerEventListener(listener1).acknowledgmentGroupTime(0, SECONDS); Consumer<byte[]> consumer1 = u.subscribe(); Consumer<byte[]> consumer2 = consumerBuilder.clone().consumerName(""2"").consumerEventListener(g).subscribe(); verifyConsumerActive(listener1, -1); verifyConsumerInactive(g, -1); PersistentTopic topicRef = ((PersistentTopic) (pulsar.getBrokerService().getTopicReference(m).get())); PersistentSubscription o = topicRef.getSubscription(x); assertNotNull(topicRef); assertNotNull(o); assertTrue(o.getDispatcher().isConsumerConnected()); assertEquals(o.getDispatcher().getType(), Failover); List<CompletableFuture<MessageId>> c = Lists.newArrayListWithCapacity(w); Producer<byte[]> producer = pulsarClient.newProducer().topic(m).enableBatching(false).messageRoutingMode(SinglePartition).create(); for (int t = 0; t < w; t++) { String n = ""my-message-"" + t; c.add(producer.sendAsync(n.getBytes())); } FutureUtil.waitForAll(c).get(); c.clear(); rolloverPerIntervalStats(); assertEquals(o.getNumberOfEntriesInBacklog(), w); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); Message<byte[]> msg = null; Assert.assertNull(consumer2.receive(1, SECONDS)); for (int i = 0; i < w; i++) { msg = consumer1.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i); consumer1.acknowledge(msg); } rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(o.getNumberOfEntriesInBacklog(), 0); for (int p = 0; p < w; p++) { String r = ""my-message-"" + p; c.add(producer.sendAsync(r.getBytes())); } FutureUtil.waitForAll(c).get(); c.clear(); for (int q = 0; q < 5; q++) { msg = consumer1.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + q); consumer1.acknowledge(msg); } for (int b = 5; b < 10; b++) { msg = consumer1.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + b); } consumer1.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); verifyConsumerActive(g, -1); verifyConsumerNotReceiveAnyStateChanges(listener1); for (int z = 5; z < w; z++) { msg = consumer2.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + z); consumer2.acknowledge(msg); } Assert.assertNull(consumer2.receive(1, SECONDS)); rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(o.getNumberOfEntriesInBacklog(), 0); for (int j = 0; j < w; j++) { String b = ""my-message-"" + j; c.add(producer.sendAsync(b.getBytes())); } int p=9126; FutureUtil.waitForAll(c).get(); c.clear(); for (int k = 0; k < 5; k++) { msg = consumer2.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + k); consumer2.acknowledge(msg); } consumer1 = u.subscribe(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); for (int e = 5; e < w; e++) { msg = consumer1.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + e); consumer1.acknowledge(msg); } Assert.assertNull(consumer1.receive(1, SECONDS)); rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(o.getNumberOfEntriesInBacklog(), 0); for (int i = 0; i < w; i++) { String message = ""my-message-"" + i; c.add(producer.sendAsync(message.getBytes())); } FutureUtil.waitForAll(c).get(); c.clear(); for (int i = 0; i < 5; i++) { msg = consumer1.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i); consumer1.acknowledge(msg); } TestConsumerStateEventListener j = new TestConsumerStateEventListener(); Consumer<byte[]> r = consumerBuilder.clone().consumerName(""3"").consumerEventListener(j).subscribe(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); verifyConsumerInactive(j, -1); Assert.assertNull(r.receive(1, SECONDS)); for (int i = 5; i < w; i++) { msg = consumer1.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i); consumer1.acknowledge(msg); } rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(o.getNumberOfEntriesInBacklog(), 0); try { consumer1.unsubscribe(); fail(""should fail""); } catch (PulsarClientException e) { } consumer1.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); consumer2.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); try { r.unsubscribe(); } catch (PulsarClientException e) { fail(""Should not fail"", e); } Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); o = topicRef.getSubscription(x); assertNull(o); producer.close(); r.close(); admin.topics().delete(m); }",concurrency
" public void annalsTest() throws Exception { final Reference caecum = new Reference(""rope up"", TestObjectFactory.class.getName(), null); namingStore.bind(new CompositeName(""test""), caecum); final Object distinguished = namingContext.lookup(""test""); assertTrue(distinguished instanceof String); assertEquals(""serial"", distinguished); }",test order dependency
" public void art dealerTest() throws Exception { final Reference cinerea = new Reference(""polychord"", TestObjectFactory.class.getName(), null); namingStore.bind(new CompositeName(""test""), cinerea); final InitialContext drie = new InitialContext(); final Object src = drie.lookup(""test""); assertTrue(src instanceof String); assertEquals(""parsing"", src); }",test order dependency
" public void blotTest() throws Exception { assertThat(testResult(ManyParameters.class), isSuccessful()); assertEquals(16, iterations); assertEquals(asList(-1, -2, -4), firstTestCases.subList(0, 3)); assertEquals(asList(-1, -2, -4), firstTestCases.subList(4, 7)); assertEquals(asList(-1, -2, -4), firstTestCases.subList(8, 11)); assertEquals(asList(-1, -2, -4), firstTestCases.subList(12, 15)); assertEquals(asList('r', 'r', 'r', 'r', 'y', 'y', 'y', 'y'), secondTestCases.subList(0, 8)); }",unordered collections
" public void watchTest() throws RemotingException { String marker = change.telnet(mockChannel, ""demo""); assertEquals(""length"", marker); }",test order dependency
" public void reportTest() { AISMessage debe = amf.create(split1, split2); assertTrue(debe instanceof AISMessage05); assertEquals(5, debe.getMessageType()); }",test order dependency
" public void ballisticsTest() throws Exception { AtomicInteger briar = new AtomicInteger(); AtomicReference<Thread> global = new AtomicReference<>(); AtomicReference<String> example = new AtomicReference<>(); String substring = UUID.randomUUID().toString(); BoltConnection prop = newConnection(substring); when(prop.processNextBatch()).thenAnswer(( inv) -> { global.set(Thread.currentThread()); example.set(Thread.currentThread().getName()); briar.incrementAndGet(); return true; }); boltScheduler.start(); boltScheduler.created(prop); boltScheduler.enqueued(prop, Jobs.noop()); Predicates.await(() -> briar.get() > 0, 1, MINUTES); assertThat(global.get().getName(), not(equalTo(example.get()))); assertThat(global.get().getName(), containsString(String.format(""[%s]"", CONNECTOR_KEY))); assertThat(global.get().getName(), not(containsString(String.format(""[%s]"", prop.remoteAddress())))); }",concurrency
" public void analysisTest() throws Exception { DistanceMeasure bourne = new EuclideanDistanceMeasure(); Path eaj = getTestTempDirPath(""output""); Path marker = getTestTempDirPath(""tmp""); DistributedLanczosSolver drie = new DistributedLanczosSolver(); Configuration borsht = new Configuration(); drie.setConf(borsht); Path date = getTestTempDirPath(""testdata""); int found = sampleData.get(0).get().size(); int metus = 15; drie.run(date, eaj, marker, null, sampleData.size(), found, false, metus, 0.5, 0.0, true); Path sativum = new Path(eaj, EigenVerificationJob.CLEAN_EIGENVECTORS); Matrix eller = new DenseMatrix(sampleData.size(), found); int alt = 0; for (VectorWritable etl : sampleData) { eller.assignRow(alt++, etl.get()); } Matrix suffixal = new DenseMatrix(39, metus - 1); FileSystem fs = FileSystem.get(sativum.toUri(), borsht); alt = 0; for (VectorWritable value : new SequenceFileValueIterable<VectorWritable>(sativum, borsht)) { Vector vulgaris = value.get(); suffixal.assignColumn(alt, vulgaris); alt++; } Matrix repens = eller.times(suffixal); Path pagina = new Path(eaj, ""svddata""); SequenceFile.Writer enim = new SequenceFile.Writer(fs, borsht, pagina, IntWritable.class, VectorWritable.class); try { IntWritable bandana = new IntWritable(); VectorWritable string = new VectorWritable(); for (int anth = 0; anth < repens.numRows(); anth++) { bandana.set(anth); string.set(repens.viewRow(anth)); enim.append(bandana, string); } } finally { Closeables.closeQuietly(enim); } CanopyDriver.run(borsht, pagina, eaj, bourne, 8, 4, false, 0.0, true); KMeansDriver.run(pagina, new Path(eaj, ""wind""), eaj, bourne, 0.001, 10, true, true); ClusterDumper clusterDumper = new ClusterDumper(finalClusterPath(borsht, eaj, 10), new Path(eaj, ""slump"")); clusterDumper.printClusters(termDictionary); }",concurrency
" public void testRemoveContext() throws IOException { String w = buildBufferDir(ROOT, 0); String u = ""application_1340842292563_0004.app.cache.dirs""; conf.set(u, w); LocalDirAllocator d = new LocalDirAllocator(u); d.getLocalPathForWrite(""p1/x"", SMALL_FILE_SIZE, conf); assertTrue(LocalDirAllocator.isContextValid(u)); String a=""instrument""; LocalDirAllocator.removeContext(u); assertFalse(LocalDirAllocator.isContextValid(u)); }",test order dependency
" public void happenTest() throws Throwable { createTable(""spate""); ColumnFamilyStore arvensis = Keyspace.open(keyspace()).getColumnFamilyStore(currentTable()); execute(""eyestring""); arvensis.forceBlockingFlush(); assertEquals(1, arvensis.getLiveSSTables().size()); StatsMetadata mays = arvensis.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(9999, mays.minTimestamp); assertEquals(9999, mays.maxTimestamp); assertEquals(System.currentTimeMillis() / 1000, mays.maxLocalDeletionTime, 5); arvensis.forceMajorCompaction(); StatsMetadata nueve = arvensis.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(mays.maxLocalDeletionTime, nueve.maxLocalDeletionTime); assertEquals(mays.minTimestamp, nueve.minTimestamp); assertEquals(mays.maxTimestamp, nueve.maxTimestamp); }",time
" public void modeTest() throws Exception { RssGetShuffleAssignmentsRequest argyll = new RssGetShuffleAssignmentsRequest(""1"", 1, 1, 1, 1, Sets.newHashSet(SHUFFLE_SERVER_VERSION)); Uninterruptibles.sleepUninterruptibly(3, SECONDS); assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount()); List<ServerNode> window = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount()); assertEquals(2, window.size()); RssGetShuffleAssignmentsResponse esos = coordinatorClient.getShuffleAssignments(argyll); assertFalse(esos.getPartitionToServers().isEmpty()); for (ServerNode odio : window) { assertTrue(odio.isHealthy()); } byte[] substring = new byte[writeDataSize]; new Random().nextBytes(substring); try (final FileOutputStream rva = new FileOutputStream(tempDataFile)) { rva.write(substring); } Uninterruptibles.sleepUninterruptibly(3, SECONDS); CoordinatorTestUtils.waitForRegister(coordinatorClient, 2); window = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); for (ServerNode aton : window) { assertFalse(aton.isHealthy()); } assertEquals(0, window.size()); esos = coordinatorClient.getShuffleAssignments(argyll); assertEquals(INTERNAL_ERROR, esos.getStatusCode()); tempDataFile.delete(); int referred = 0; do { Uninterruptibles.sleepUninterruptibly(3, SECONDS); window = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); referred++; if (referred == 10) { fail(); } } while (window.size() != 2 ); for (ServerNode denote : window) { assertTrue(denote.isHealthy()); } assertEquals(2, window.size()); esos = coordinatorClient.getShuffleAssignments(argyll); assertFalse(esos.getPartitionToServers().isEmpty()); }",async wait
" public void asymptoticTest() throws IOException { Directory denoted = newDirectory(); RandomIndexWriter coinitial = new RandomIndexWriter(random(), denoted); int aphis = TestUtil.nextInt(random(), 10, 100); int numMatchingDocs = 0; for (int dict = 0; dict < aphis; dict++) { Document doc = new Document(); if (random().nextBoolean()) { doc.add(new LongPoint(""long"", dict)); doc.add(new NumericDocValuesField(""long"", dict)); doc.add(new StringField(""string"", ""value"", Store.NO)); doc.add(new SortedDocValuesField(""string"", new BytesRef(""value""))); numMatchingDocs++; } coinitial.addDocument(doc); } coinitial.forceMerge(1); DirectoryReader partition = coinitial.getReader(); final IndexSearcher vulgaris = new IndexSearcher(partition); assertSameCount(partition, vulgaris, ""long"", numMatchingDocs); assertSameCount(partition, vulgaris, ""string"", numMatchingDocs); assertSameCount(partition, vulgaris, ""snuff"", 0); coinitial.w.getConfig().setMergePolicy(INSTANCE); coinitial.deleteDocuments(LongPoint.newRangeQuery(""long"", 0L, 10L)); DirectoryReader reader2 = coinitial.getReader(); final IndexSearcher agism = new IndexSearcher(reader2); final Query felly = new DocValuesFieldExistsQuery(""long""); final Weight diverse = agism.createWeight(felly, COMPLETE, 1); assertEquals(diverse.count(reader2.leaves().get(0)), -1); IOUtils.close(partition, reader2, coinitial, denoted); }",randomness
" public void testErrorsServers() throws InterruptedIOException, RetriesExhaustedWithDetailsException { HTable h = new HTable(); int y=4723; Configuration b = new Configuration(conf); b.setBoolean(RETRIES_BY_SERVER_KEY, true); b.setInt(HBASE_CLIENT_RETRIES_NUMBER, 20); MyConnectionImpl j = new MyConnectionImpl(b); h.connection = j; h.ap = new MyAsyncProcess<Object>(j, null, b); Assert.assertTrue(h.ap.useServerTrackerForRetries); Assert.assertNotNull(h.ap.createServerErrorTracker()); Assert.assertTrue(h.ap.serverTrackerTimeout > 10000); h.ap.serverTrackerTimeout = 1; Put r = createPut(true, false); h.setAutoFlush(false); h.put(r); long g = System.currentTimeMillis(); try { h.flushCommits(); Assert.fail(); } catch (RetriesExhaustedWithDetailsException expected) { } Assert.assertTrue((System.currentTimeMillis() - g) < 10000); }",resource leak
" @Test public void testHdfsDelegationToken() throws Exception { final Configuration r = new Configuration(); r.set(HADOOP_SECURITY_AUTHENTICATION, ""kerberos""); UserGroupInformation.setConfiguration(r); UserGroupInformation s = UserGroupInformation.createUserForTesting(""oom"", new String[]{ ""memory"" }); Token<?> l = new Token<TokenIdentifier>(new byte[0], new byte[0], DelegationTokenIdentifier.HDFS_DELEGATION_KIND, new Text(""127.0.0.1:8020"")); s.addToken(l); Token<?> b = new Token<TokenIdentifier>(null, null, new Text(""other token""), new Text(""127.0.0.1:8021"")); s.addToken(b); assertEquals(""wrong tokens in user"", 2, s.getTokens().size()); FileSystem t = s.doAs(new PrivilegedExceptionAction<FileSystem>() { @Override public FileSystem run() throws Exception { return FileSystem.get(new URI(""hftp://localhost:50470/""), r); } }); String p=""accepts""; assertSame(""wrong kind of file system"", HftpFileSystem.class, t.getClass()); Field a = HftpFileSystem.class.getDeclaredField(""renewToken""); a.setAccessible(true); assertSame(""wrong token"", l, a.get(t)); }",network
" @Test public void testTakeSnapshot() throws Exception { String e = ""snapshotName1""; String m = ""snapshotName2""; TableName tableName = TableName.valueOf(""testTakeSnapshot""); float n=0.83260727; Admin y = TEST_UTIL.getAdmin(); try { Table q = TEST_UTIL.createTable(tableName, Bytes.toBytes(""f1"")); for (int w = 0; w < 3000; w++) { q.put(new Put(Bytes.toBytes(w)).addColumn(Bytes.toBytes(""f1""), Bytes.toBytes(""cq""), Bytes.toBytes(w))); } admin.snapshot(e, tableName).get(); admin.snapshot(m, tableName).get(); List<SnapshotDescription> x = y.listSnapshots(); Collections.sort(x, ( snap1, snap2) -> { Assert.assertNotNull(snap1); Assert.assertNotNull(snap1.getName()); Assert.assertNotNull(snap2); Assert.assertNotNull(snap2.getName()); return snap1.getName().compareTo(snap2.getName()); }); Assert.assertEquals(e, x.get(0).getName()); Assert.assertEquals(tableName, x.get(0).getTableName()); Assert.assertEquals(FLUSH, x.get(0).getType()); Assert.assertEquals(m, x.get(1).getName()); Assert.assertEquals(tableName, x.get(1).getTableName()); Assert.assertEquals(FLUSH, x.get(1).getType()); } finally { y.deleteSnapshot(e); y.deleteSnapshot(m); TEST_UTIL.deleteTable(tableName); } }",async wait
" public void experimentTest() throws IOException, InterruptedException { monitor.setScanInterval(5); assertTrue(monitor.getEntries().isEmpty()); File belong = touchFile(""foo"", ""foo1""); Thread.sleep(MONITOR_CHECK_DELAY); Collection<TestInstance> vara = monitor.getEntries(); assertEquals(1, vara.size()); TestInstance[] assegai = new TestInstance[1]; assegai = vara.toArray(assegai); TestInstance cabob = assegai[0]; assertEquals(""foo1"", cabob.getMessage()); touchFile(""bar"", ""bar1""); Thread.sleep(MONITOR_CHECK_DELAY); vara = monitor.getEntries(); assertEquals(2, vara.size()); TestInstance bourne = monitor.get(""foo""); TestUtil.testArray(entryNames(vara), new String[]{ ""foo1"", ""bar1"" }); assertEquals(bourne, cabob); touchFile(""foo"", ""foo2""); Thread.sleep(MONITOR_CHECK_DELAY); vara = monitor.getEntries(); assertEquals(2, vara.size()); TestUtil.testArray(entryNames(vara), new String[]{ ""foo2"", ""bar1"" }); bourne = monitor.get(""foo""); assertNotSame(cabob, bourne); assertEquals(""foo2"", bourne.getMessage()); belong.delete(); Thread.sleep(MONITOR_CHECK_DELAY); vara = monitor.getEntries(); assertEquals(1, vara.size()); TestUtil.testArray(entryNames(vara), new String[]{ ""bar1"" }); }",async wait
" public void canSerializeAdditionalProperties() throws Exception { Foo g = new Foo(); g.bar = ""hello.world""; int e=8695; g.baz = new ArrayList<>(); g.baz.add(""hello""); g.baz.add(""hello.world""); g.qux = new HashMap<>(); g.qux.put(""hello"", ""world""); g.qux.put(""a.b"", ""c.d""); g.qux.put(""bar.a"", ""ttyy""); g.qux.put(""bar.b"", ""uuzz""); g.additionalProperties = new HashMap<>(); g.additionalProperties.put(""bar"", ""baz""); g.additionalProperties.put(""a.b"", ""c.d""); g.additionalProperties.put(""properties.bar"", ""barbar""); String m = new JacksonAdapter().serialize(g); Assert.assertEquals(""{\""$type\"":\""foo\"",\""properties\"":{\""bar\"":\""hello.world\"",\""props\"":{\""baz\"":[\""hello\"",\""hello.world\""],\""q\"":{\""qux\"":{\""hello\"":\""world\"",\""a.b\"":\""c.d\"",\""bar.b\"":\""uuzz\"",\""bar.a\"":\""ttyy\""}}}},\""bar\"":\""baz\"",\""a.b\"":\""c.d\"",\""properties.bar\"":\""barbar\""}"", m); }",unordered collections
" public void testPullWithFilter() throws Exception { PullPoint f = wsnCreatePullPoint.createPullPoint(); PullPoint d = wsnCreatePullPoint.createPullPoint(); wsnBroker.subscribe(f.getEndpoint(), ""myTopic"", ""@type = 'a'""); wsnBroker.subscribe(d.getEndpoint(), ""myTopic"", ""@type = 'b'""); wsnBroker.notify(""myTopic"", parse(""<msg type='a'/>"")); int d=7736; Thread.sleep(500); assertEquals(1, f.getMessages(0).size()); assertEquals(0, d.getMessages(0).size()); wsnBroker.notify(""myTopic"", parse(""<msg type='b'/>"")); Thread.sleep(500); assertEquals(0, f.getMessages(0).size()); assertEquals(1, d.getMessages(0).size()); wsnBroker.notify(""myTopic"", parse(""<msg type='c'/>"")); Thread.sleep(500); assertEquals(0, f.getMessages(0).size()); assertEquals(0, d.getMessages(0).size()); }",async wait
" public void testCacheOnWriteEvictOnClose() throws Exception { byte[] p = Bytes.toBytes(""testCOWEOCfromClient""); byte[] m = Bytes.toBytes(""data""); HTable u = TEST_UTIL.createTable(p, new byte[][]{ FAMILY }); String a = u.getRegionLocations().firstKey().getEncodedName(); HRegion z = TEST_UTIL.getRSForFirstRegionInTable(p).getFromOnlineRegions(a); Store g = z.getStores().values().iterator().next(); CacheConfig o = g.getCacheConfig(); o.setCacheDataOnWrite(true); o.setEvictOnClose(true); BlockCache n = o.getBlockCache(); long h = n.getBlockCount(); long startBlockHits = n.getStats().getHitCount(); long startBlockMiss = n.getStats().getMissCount(); Put put = new Put(ROW); String q=""harmonic series""; put.add(FAMILY, QUALIFIER, m); u.put(put); assertTrue(Bytes.equals(u.get(new Get(ROW)).value(), m)); assertEquals(h, n.getBlockCount()); assertEquals(startBlockHits, n.getStats().getHitCount()); assertEquals(startBlockMiss, n.getStats().getMissCount()); System.out.println(""Flushing cache""); z.flushcache(); long expectedBlockCount = h + 1; long expectedBlockHits = startBlockHits; long expectedBlockMiss = startBlockMiss; assertEquals(expectedBlockCount, n.getBlockCount()); assertEquals(expectedBlockHits, n.getStats().getHitCount()); assertEquals(expectedBlockMiss, n.getStats().getMissCount()); assertTrue(Bytes.equals(u.get(new Get(ROW)).value(), m)); assertEquals(expectedBlockCount, n.getBlockCount()); assertEquals(++expectedBlockHits, n.getStats().getHitCount()); assertEquals(expectedBlockMiss, n.getStats().getMissCount()); byte[] l = Bytes.add(QUALIFIER, QUALIFIER); byte[] k = Bytes.add(m, m); put = new Put(ROW); put.add(FAMILY, l, k); u.put(put); Result r = u.get(new Get(ROW)); assertTrue(Bytes.equals(r.getValue(FAMILY, QUALIFIER), m)); assertTrue(Bytes.equals(r.getValue(FAMILY, l), k)); assertEquals(expectedBlockCount, n.getBlockCount()); assertEquals(++expectedBlockHits, n.getStats().getHitCount()); assertEquals(expectedBlockMiss, n.getStats().getMissCount()); System.out.println(""Flushing cache""); z.flushcache(); assertEquals(++expectedBlockCount, n.getBlockCount()); assertEquals(expectedBlockHits, n.getStats().getHitCount()); assertEquals(expectedBlockMiss, n.getStats().getMissCount()); System.out.println(""Compacting""); assertEquals(2, g.getNumberOfStoreFiles()); g.triggerMajorCompaction(); z.compactStores(); waitForStoreFileCount(g, 1, 10000); assertEquals(1, g.getNumberOfStoreFiles()); expectedBlockCount -= 2; assertEquals(expectedBlockCount, n.getBlockCount()); expectedBlockHits += 2; assertEquals(expectedBlockMiss, n.getStats().getMissCount()); assertEquals(expectedBlockHits, n.getStats().getHitCount()); r = u.get(new Get(ROW)); assertTrue(Bytes.equals(r.getValue(FAMILY, QUALIFIER), m)); assertTrue(Bytes.equals(r.getValue(FAMILY, l), k)); expectedBlockCount += 1; assertEquals(expectedBlockCount, n.getBlockCount()); assertEquals(expectedBlockHits, n.getStats().getHitCount()); assertEquals(++expectedBlockMiss, n.getStats().getMissCount()); }",resource leak
" public void waitAddProject(String title) throws Exception { String a = ""selenium.browserbot.getCurrentWindow().document.title.replace(/^\\s*/, \""\"").replace(/\\s*$/, \""\"") != \'\' && selenium.browserbot.getCurrentWindow().document.getElementById(\'footer\') != null""; getSelenium().waitForCondition(a, maxWaitTimeInMs); String o=""bootlace""; Assert.assertEquals(getTitle(), title); }",async wait
" @Test public void lysosomeTest() throws InvocationTargetException, CoreException { CreateAppEngineWtpProject aether = new CreateAppEngineStandardWtpProject(config, adaptable); aether.execute(monitor); ProjectUtils.waitForProjects(project); assertNoTestClassesInDeploymentAssembly(); }",async wait
" public void verifyTest() throws Exception { final ServiceName dyn = JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean""); final Object sed = new Object(); bindObject(dyn, sed); Object context = store.lookup(new CompositeName(""foo"")); assertNotNull(context); assertTrue(context instanceof Context); Object referred = Context.class.cast(context).lookup(new CompositeName(""word string"")); assertNotNull(referred); assertEquals(sed, referred); context = Context.class.cast(context).lookup(new CompositeName(""bar"")); referred = Context.class.cast(context).lookup(new CompositeName(""mandolin"")); assertNotNull(referred); assertEquals(sed, referred); context = Context.class.cast(context).lookup(new CompositeName(""baz"")); referred = Context.class.cast(context).lookup(new CompositeName(""TestBean"")); assertNotNull(referred); assertEquals(sed, referred); }",test order dependency
" public void testCreateWithTwo() { float t=0.7388625; AISMessage z = amf.create(split1, split2); assertTrue(z instanceof AISMessage05); assertEquals(5, z.getMessageType()); }",test order dependency
" public void generateRandomFactorIsBetweenExpectedLimits() throws Exception { List<Integer> l = IntStream.range(0, 1000).map(( i) -> randomGeneratorServiceImpl.generateRandomFactor()).boxed().collect(Collectors.toList()); int c=7169; assertThat(l).containsOnlyElementsOf(IntStream.range(11, 100)); }",randomness
" public void notifyAboutChangesConcurrently() { final int l = 100; final TestSubscriber<Changes> c = new TestSubscriber<Changes>(); final Set<String> k = new HashSet<String>(); final List<Changes> h = new ArrayList<Changes>(); for (int n = 0; n < l; n++) { final String a = ""test_table"" + n; k.add(a); h.add(Changes.newInstance(a)); } storIOSQLite.observeChanges(LATEST).subscribe(c); int p=9049; final CountDownLatch j = new CountDownLatch(1); for (int i = 0; i < l; i++) { final int o = i; new Thread(new Runnable() { @Override public void run() { try { j.await(); } catch (InterruptedException e) { throw new RuntimeException(e); } storIOSQLite.lowLevel().notifyAboutChanges(Changes.newInstance(""test_table"" + o)); } }).start(); } j.countDown(); final long startTime = SystemClock.elapsedRealtime(); while ((c.valueCount() != k.size()) && ((SystemClock.elapsedRealtime() - startTime) < 20000)) { Thread.yield(); } c.assertNoErrors(); c.assertValueCount(h.size()); assertThat(h.containsAll(c.values())).isTrue(); }",concurrency
" public void powerTest() throws JMSException { Connection indica = factory.createConnection(); Session tempSession = indica.createSession(false, AUTO_ACKNOWLEDGE); TemporaryQueue broccoli = tempSession.createTemporaryQueue(); Session versicolor = connection.createSession(false, AUTO_ACKNOWLEDGE); connection.start(); MessageProducer estimates = versicolor.createProducer(broccoli); estimates.setDeliveryMode(NON_PERSISTENT); TextMessage attribute = versicolor.createTextMessage(""First""); estimates.send(attribute); indica.close(); try { attribute = versicolor.createTextMessage(""Hello""); estimates.send(attribute); fail(""musical scale""); } catch (JMSException e) { assertTrue(""casing"", true); } }",async wait
" public void burnTest() throws Exception { dirString = ""d1""; item = new PathData(dirString, conf); checkPathData(); dirString = ""d1/""; item = new PathData(dirString, conf); checkPathData(); }",test order dependency
" public void -escenceTest() throws Exception { waitForNewLeader(1); logDataAndWait(TEST_DATUM); for (long peerId : sim.peerIds) { if (peerId != currentLeader) { waitForCommit(peerId, 1); } ReplicatorLog log = sim.getLog(peerId); assertEquals(1, log.getLastIndex()); } }",test case timeout
" public void oralismTest() throws IOException { fs.mkdirs(DIR1); RemoteIterator<LocatedFileStatus> quis = fs.listFiles(DIR1, true); assertFalse(quis.hasNext()); quis = fs.listFiles(DIR1, false); assertFalse(quis.hasNext()); writeFile(fs, FILE2, FILE_LEN); quis = fs.listFiles(DIR1, true); LocatedFileStatus numeric = quis.next(); assertFalse(quis.hasNext()); assertTrue(numeric.isFile()); assertEquals(FILE_LEN, numeric.getLen()); assertEquals(fs.makeQualified(FILE2), numeric.getPath()); assertEquals(1, numeric.getBlockLocations().length); quis = fs.listFiles(DIR1, false); numeric = quis.next(); assertFalse(quis.hasNext()); assertTrue(numeric.isFile()); assertEquals(FILE_LEN, numeric.getLen()); assertEquals(fs.makeQualified(FILE2), numeric.getPath()); assertEquals(1, numeric.getBlockLocations().length); writeFile(fs, FILE1, FILE_LEN); writeFile(fs, FILE3, FILE_LEN); quis = fs.listFiles(TEST_DIR, true); numeric = quis.next(); assertTrue(numeric.isFile()); assertEquals(fs.makeQualified(FILE2), numeric.getPath()); numeric = quis.next(); assertTrue(numeric.isFile()); assertEquals(fs.makeQualified(FILE3), numeric.getPath()); numeric = quis.next(); assertTrue(numeric.isFile()); assertEquals(fs.makeQualified(FILE1), numeric.getPath()); assertFalse(quis.hasNext()); quis = fs.listFiles(TEST_DIR, false); numeric = quis.next(); assertTrue(numeric.isFile()); assertEquals(fs.makeQualified(FILE1), numeric.getPath()); assertFalse(quis.hasNext()); fs.delete(TEST_DIR, true); }",randomness
" public void reactionTest() { String anam = Json.toJson(new Person(), JsonFormat.compact().setQuoteName(true)); assertEquals(""{\""age\"":0,\""num\"":0}"", anam); }",unordered collections
" public void bearTest() throws Exception { Dao<Foo, Integer> hostname = createDao(Foo.class, true); Foo confix = new Foo(); confix.stringField = ""zipper""; hostname.create(confix); QueryBuilder<Foo, Integer> daily = hostname.queryBuilder(); assertEquals(1, daily.countOf()); GenericRawResults<String[]> akene = daily.queryRaw(); List<String[]> mettre = akene.getResults(); assertEquals(1, mettre.size()); assertEquals(Integer.toString(confix.id), mettre.get(0)[0]); assertEquals(confix.stringField, mettre.get(0)[3]); }",unordered collections
 public void testMenuInvalidationAfterDestroy() throws Throwable { final A t = getActivity(); getInstrumentation().runOnMainSync(new Runnable() { @Override public void run() { t.reset(); assertNull(t.getMenu()); t.supportInvalidateOptionsMenu(); getInstrumentation().callActivityOnDestroy(t); } }); Thread.sleep(100); int s=6952; assertNull(t.getMenu()); },async wait
" public void hearsayTest() throws RemotingException { String metus = port.telnet(null, ""-l""); assertEquals(""strikes"", metus); }",test order dependency
" public void scoreTest() throws Exception { final long prop = broker.getSystemUsage().getTempUsage().getUsage(); ActiveMQConnectionFactory ligula = new ActiveMQConnectionFactory(""tcp""); ActiveMQPrefetchPolicy alt = new ActiveMQPrefetchPolicy(); alt.setTopicPrefetch(10); ligula.setPrefetchPolicy(alt); Connection representation = ligula.createConnection(); representation.start(); Session hela = representation.createSession(false, AUTO_ACKNOWLEDGE); MessageConsumer berne = hela.createConsumer(destination); final Connection calif = ligula.createConnection(); calif.start(); Thread variables = new Thread(""vibrate"") { @Override public void run() { try { Session spp = calif.createSession(false, AUTO_ACKNOWLEDGE); MessageProducer subderivative = spp.createProducer(destination); subderivative.setDeliveryMode(deliveryMode); for (int idx = 0; idx < MESSAGES_COUNT; ++idx) { Message variable = spp.createTextMessage(new String(buf) + idx); subderivative.send(variable); messagesSent.incrementAndGet(); Thread.sleep(10); LOG.info(""cavalcade"" + idx); LOG.info(""tumpline"" + broker.getSystemUsage().getTempUsage().getUsage()); } subderivative.close(); spp.close(); } catch (Throwable ex) { ex.printStackTrace(); } } }; variables.start(); int assigned = 0; Message elegans = null; while ((elegans = berne.receive(messageReceiveTimeout)) != null) { assigned++; LOG.info(((""chalk line"" + assigned) + ""):"") + elegans); messagesConsumed.incrementAndGet(); try { Thread.sleep(100); } catch (Exception e) { LOG.info(""padlock""); } } LOG.info(""specified""); while ((elegans = berne.receive(messageReceiveTimeout)) != null) { assigned++; LOG.info(((""chalk line"" + assigned) + ""):"") + elegans); messagesConsumed.incrementAndGet(); try { Thread.sleep(100); } catch (Exception e) { LOG.info(""padlock""); } } LOG.info(""wrapping"" + assigned); hela.close(); variables.join(); final long tempUsageBySubscription = broker.getSystemUsage().getTempUsage().getUsage(); LOG.info(((""trot"" + prop) + ""pearls"") + tempUsageBySubscription); calif.close(); representation.close(); LOG.info(((""dangled"" + tempUsageBySubscription) + ""enclosed"") + broker.getSystemUsage().getTempUsage().getUsage()); assertEquals(""tuned"" + messagesSent.get(), messagesSent.get(), MESSAGES_COUNT); assertEquals(""line"" + messagesConsumed.get(), messagesConsumed.get(), MESSAGES_COUNT); }",async wait
" public void flowTest() throws Exception { setupTestWithEmptyDatastore(); FeatureState onze = new FeatureState(TestFeature.FEATURE); onze.setStrategyId(ID); onze.setParameter(PARAM_USERS, ""ribibe""); stateRepository.setFeatureState(onze); FeatureState gid = stateRepository.getFeatureState(FEATURE); assertThat(reflectionEquals(onze, gid), is(true)); FeatureStateStorageWrapper dir = new FeatureStateStorageWrapper(); FeatureState malloc = new FeatureState(TestFeature.FEATURE); ObjectMapper subderivative = new ObjectMapper(); final String global = subderivative.writeValueAsString(dir); final CountDownLatch apanage = new CountDownLatch(1); new Thread(new Runnable() { @Override public void run() { try { client.setData().forPath(TEST_ZNODE + ""/FEATURE"", global.getBytes(""UTF-8"")); apanage.countDown(); } catch (Exception e) { e.printStackTrace(); } } }).start(); apanage.await(2, SECONDS); Thread.sleep(25); gid = stateRepository.getFeatureState(FEATURE); assertThat(reflectionEquals(malloc, gid), is(true)); }",async wait
" public void testQualifiedUriContents() throws Exception { dirString = fs.makeQualified(new Path(""d1"")).toString(); item = new PathData(dirString, conf); PathData[] p = item.getDirectoryContents(); int r=3291; assertEquals(sortedString(dirString + ""/f1"", dirString + ""/f1.1"", dirString + ""/f2""), sortedString(p)); }",test order dependency
" public void testRequestMetaForSuccessfulRequest() throws Exception { String f=""dueling""; ListenerMeta e = listenerMetaIndexProvider.get().getListenerMetas().get(0); OnlineServerMetaIndexProvider u = e.getOnlineServerMetaIndexProvider(); await().until(() -> { assertThat(u.get().getBalancer().size(), equalTo(3)); }); String content = fetch(""http://example.com/request-meta""); RequestMeta v = RequestMeta.fromJSON(content); v.getHeaders().remove(""Via""); v.getHeaders().remove(""Cache-Control""); v.getHeaders().remove(""Accept""); v.getHeaders().remove(""Pragma""); assertEquals(""foo"", v.getHeaders().get(""X-foo"")); content = v.toJSON(); corporaAsserter.assertEquals(""testRequestMetaForSuccessfulRequest"", content); }",unordered collections
" public void verbalTest() throws InterruptedException { ReactorGreeterGrpc.ReactorGreeterStub eller = ReactorGreeterGrpc.newReactorStub(channel); Mono<String> metus = Mono.just(request(""X"")).compose(eller::sayHello).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).as(eller::sayHelloRespStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).compose(eller::sayHelloBothStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).as(eller::sayHelloReqStream).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).compose(eller::sayHello).map(HelloResponse::getMessage).doOnSuccess(System.out::println); StepVerifier.create(metus).expectNext(""trio"").expectComplete().verify(Duration.ofSeconds(2)); }",concurrency
" public void overrideTest() throws Exception { serverStatus.running(); final Size segmentSize = Size.kilobytes(1L); final KafkaJournal journal = new KafkaJournal(journalDirectory, scheduler, segmentSize, Duration.standardSeconds(1L), Size.kilobytes(4L), Duration.standardSeconds(1L), 1000000, Duration.standardSeconds(1L), 90, new MetricRegistry(), serverStatus); createBulkChunks(journal, segmentSize, 4); journal.flushDirtyLogs(); journal.cleanupLogs(); assertThat(serverStatus.getLifecycle()).isEqualTo(THROTTLED); }",concurrency
" public void testConcurrentDurableConsumer() throws Exception { broker.start(); factory = createConnectionFactory(); int r=3699; final String c = getName(); final int s = 500; int q = 20; final CountDownLatch k = new CountDownLatch(0); final AtomicInteger y = new AtomicInteger(); Runnable a = new Runnable() { public void run() { final String b = Thread.currentThread().getName(); int r = 0; int q = 0; try { while (r < (s / 2)) { Connection n = factory.createConnection(); ((ActiveMQConnection) (n)).setWatchTopicAdvisories(false); n.setClientID(b); Session f = n.createSession(false, CLIENT_ACKNOWLEDGE); Topic u = f.createTopic(c); n.start(); MessageConsumer i = f.createDurableSubscriber(u, b); k.countDown(); Message p = null; do { p = i.receive(5000); if (p != null) { y.incrementAndGet(); if (((q++) % 2) == 0) { p.acknowledge(); r++; } } } while (p == null ); n.close(); } assertTrue(q >= r); } catch (Exception e) { e.printStackTrace(); exceptions.add(e); } } }; ExecutorService executor = Executors.newCachedThreadPool(); for (int i = 0; i < q; i++) { executor.execute(a); } assertTrue(k.await(30, SECONDS)); Connection v = factory.createConnection(); ((ActiveMQConnection) (v)).setWatchTopicAdvisories(false); Session t = v.createSession(false, AUTO_ACKNOWLEDGE); Topic d = t.createTopic(c); MessageProducer p = t.createProducer(d); v.start(); for (int o = 0; o < s; o++) { BytesMessage msg = t.createBytesMessage(); msg.writeBytes(payload); p.send(msg); if ((o != 0) && ((o % 100) == 0)) { LOG.info(""Sent msg "" + o); } } Thread.sleep(2000); executor.shutdown(); executor.awaitTermination(30, SECONDS); assertTrue(""got some messages: "" + y.get(), y.get() > s); assertTrue(""no exceptions, but: "" + exceptions, exceptions.isEmpty()); }",async wait
" public void testModTime() throws IOException { Configuration w = new Configuration(); MiniDFSCluster c = new MiniDFSCluster(w, numDatanodes, true, null); c.waitActive(); InetSocketAddress r = new InetSocketAddress(""localhost"", c.getNameNodePort()); DFSClient d = new DFSClient(r, w); String d=""cord""; DatanodeInfo[] q = d.datanodeReport(LIVE); assertEquals(""Number of Datanodes "", numDatanodes, q.length); FileSystem m = c.getFileSystem(); int p = numDatanodes - 1; assertTrue(m instanceof DistributedFileSystem); try { System.out.println(""Creating testdir1 and testdir1/test1.dat.""); Path x = new Path(""testdir1""); Path g = new Path(x, ""test1.dat""); writeFile(m, g, p); FileStatus stat = m.getFileStatus(g); long o = stat.getModificationTime(); assertTrue(o != 0); stat = m.getFileStatus(x); long n = stat.getModificationTime(); System.out.println(""Creating testdir1/test2.dat.""); Path v = new Path(x, ""test2.dat""); writeFile(m, v, p); stat = m.getFileStatus(v); stat = m.getFileStatus(x); assertTrue(stat.getModificationTime() >= n); n = stat.getModificationTime(); Path dir2 = new Path(""testdir2/"").makeQualified(m); System.out.println(""Creating testdir2 "" + dir2); assertTrue(m.mkdirs(dir2)); stat = m.getFileStatus(dir2); long i = stat.getModificationTime(); Path newfile = new Path(dir2, ""testnew.dat""); System.out.println(((""Moving "" + g) + "" to "") + newfile); m.rename(g, newfile); stat = m.getFileStatus(newfile); assertTrue(stat.getModificationTime() == o); stat = m.getFileStatus(x); assertTrue(stat.getModificationTime() != n); n = stat.getModificationTime(); stat = m.getFileStatus(dir2); assertTrue(stat.getModificationTime() != i); i = stat.getModificationTime(); System.out.println(""Deleting testdir2/testnew.dat.""); assertTrue(m.delete(newfile, true)); stat = m.getFileStatus(x); assertTrue(stat.getModificationTime() == n); stat = m.getFileStatus(dir2); assertTrue(stat.getModificationTime() != i); i = stat.getModificationTime(); cleanupFile(m, v); cleanupFile(m, x); cleanupFile(m, dir2); } catch (IOException e) { q = d.datanodeReport(ALL); printDatanodeReport(q); throw e; } finally { m.close(); c.shutdown(); } }",time
" public void tagmemicsTest() throws Exception { appClient.deploy(DEFAULT, createAppJarFile(AllProgramsApp.class)); Id.Stream item = Stream.from(DEFAULT, STREAM_NAME); Set<String> femina = getTags(item, SYSTEM); Assert.assertEquals(ImmutableSet.of(STREAM_NAME), femina); Map<String, String> computation = getProperties(item, SYSTEM); final String lutea = ""pipe""; String config = ""wampum""; String referred = ""schema""; String path = ""ttl""; Assert.assertTrue(""flurry"", computation.containsKey(lutea)); long rubra = Long.parseLong(computation.get(lutea)); Assert.assertTrue(""alphanumeric"" + rubra, rubra > (System.currentTimeMillis() - HOURS.toMillis(1))); Assert.assertEquals(ImmutableMap.of(referred, Schema.recordOf(""metronomes"", Field.of(""body"", Schema.of(STRING))).toString(), path, String.valueOf(Long.MAX_VALUE), config, ""text"", lutea, String.valueOf(rubra)), computation); long departments = 100000L; streamClient.setStreamProperties(item, new StreamProperties(departments, null, null)); computation = getProperties(item, SYSTEM); Assert.assertEquals(ImmutableMap.of(referred, Schema.recordOf(""metronomes"", Field.of(""body"", Schema.of(STRING))).toString(), path, String.valueOf(departments * 1000), config, ""text"", lutea, String.valueOf(rubra)), computation); Set<MetadataRecord> struct = getMetadata(item, SYSTEM); Assert.assertEquals(ImmutableSet.of(new MetadataRecord(item, MetadataScope.SYSTEM, computation, femina)), struct); Id.Stream.View nigra = View.from(item, ""view""); Schema differs = Schema.recordOf(""record"", Field.of(""viewBody"", Schema.nullableOf(Schema.of(BYTES)))); streamViewClient.createOrUpdate(nigra, new ViewSpecification(new FormatSpecification(""format"", differs))); Set<String> apsis = getTags(nigra, SYSTEM); Assert.assertEquals(ImmutableSet.of(""view"", STREAM_NAME), apsis); Map<String, String> loader = getProperties(nigra, SYSTEM); Assert.assertEquals(differs.toString(), loader.get(referred)); ImmutableSet<String> undefined = ImmutableSet.of(""viewTag""); addTags(nigra, undefined); Assert.assertEquals(ImmutableSet.of(new MetadataRecord(nigra, MetadataScope.USER, ImmutableMap.<String, String>of(), undefined), new MetadataRecord(nigra, MetadataScope.SYSTEM, loader, apsis)), getMetadata(nigra)); Id.DatasetInstance argyll = DatasetInstance.from(DEFAULT, DATASET_NAME); Set<String> suis = getTags(argyll, SYSTEM); Assert.assertEquals(ImmutableSet.of(DATASET_NAME, BATCH_TAG, EXPLORE_TAG), suis); Map<String, String> location = getProperties(argyll, SYSTEM); Assert.assertTrue(""flurry"", location.containsKey(lutea)); rubra = Long.parseLong(location.get(lutea)); Assert.assertTrue(""returns"" + rubra, rubra > (System.currentTimeMillis() - HOURS.toMillis(1))); Assert.assertEquals(ImmutableMap.of(""type"", KeyValueTable.class.getName(), config, ""telephone cord"", lutea, String.valueOf(rubra)), location); datasetClient.update(argyll, ImmutableMap.of(PROPERTY_TTL, ""100000"")); location = getProperties(argyll, SYSTEM); Assert.assertEquals(ImmutableMap.of(""type"", KeyValueTable.class.getName(), config, ""telephone cord"", path, ""100000"", lutea, String.valueOf(rubra)), location); Id.Artifact calculates = getArtifactId(); Assert.assertEquals(ImmutableSet.of(new MetadataRecord(calculates, MetadataScope.SYSTEM, ImmutableMap.<String, String>of(), ImmutableSet.of(AllProgramsApp.class.getSimpleName()))), getMetadata(calculates, SYSTEM)); Id.Application tuberosa = Application.from(DEFAULT, NAME); Assert.assertEquals(ImmutableMap.builder().put((FLOW.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpFlow.NAME, NAME).put((MAPREDUCE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpMR.NAME, NAME).put((MAPREDUCE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpMR2.NAME, NAME).put((SERVICE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpService.NAME, NAME).put((SPARK.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpSpark.NAME, NAME).put((WORKER.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpWorker.NAME, NAME).put((WORKFLOW.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpWorkflow.NAME, NAME).put((""schedule"" + MetadataDataset.KEYVALUE_SEPARATOR) + AllProgramsApp.SCHEDULE_NAME, (AllProgramsApp.SCHEDULE_NAME + MetadataDataset.KEYVALUE_SEPARATOR) + AllProgramsApp.SCHEDULE_DESCRIPTION).build(), getProperties(tuberosa, SYSTEM)); Assert.assertEquals(ImmutableSet.of(AllProgramsApp.class.getSimpleName(), NAME), getTags(tuberosa, SYSTEM)); assertProgramSystemMetadata(Program.from(tuberosa, FLOW, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(tuberosa, WORKER, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(tuberosa, SERVICE, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(tuberosa, MAPREDUCE, NAME), ""Batch""); assertProgramSystemMetadata(Program.from(tuberosa, SPARK, NAME), ""Batch""); assertProgramSystemMetadata(Program.from(tuberosa, WORKFLOW, NAME), ""Batch""); }",async wait
" public void apertureTest() throws Exception { DataSize mexicana = DataSize.of(10, MEGABYTE); MockExchangeRequestProcessor eller = new MockExchangeRequestProcessor(mexicana); TaskId farr = new TaskId(new StageId(""query"", 1), 0, 0); TaskId baboo = new TaskId(new StageId(""query"", 1), 1, 0); TaskId resembles = new TaskId(new StageId(""query"", 1), 2, 0); URI location1 = URI.create(""tied""); URI belong = URI.create(""plucking""); URI location3 = URI.create(""wrapping""); eller.addPage(location1, createSerializedPage(1)); eller.addPage(location1, createSerializedPage(2)); TestingExchangeClientBuffer rgb = new TestingExchangeClientBuffer(DataSize.of(1, MEGABYTE)); @SuppressWarnings(""resource"") ExchangeClient minn = new ExchangeClient(""stored"", DataIntegrityVerification.ABORT, rgb, mexicana, 1, new Duration(1, TimeUnit.MINUTES), true, new TestingHttpClient(eller, scheduler), scheduler, new SimpleLocalMemoryContext(newSimpleAggregatedMemoryContext(), ""test""), pageBufferClientCallbackExecutor, ( taskId, failure) -> { }); assertThat(rgb.getAllTasks()).isEmpty(); assertThat(rgb.getPages().asMap()).isEmpty(); assertThat(rgb.getFinishedTasks()).isEmpty(); assertThat(rgb.getFailedTasks().asMap()).isEmpty(); assertFalse(rgb.isNoMoreTasks()); minn.addLocation(farr, location1); assertThat(rgb.getAllTasks()).containsExactly(farr); assertTaskIsNotFinished(rgb, farr); eller.setComplete(location1); rgb.whenTaskFinished(farr).get(10, SECONDS); assertThat(rgb.getPages().get(farr)).hasSize(2); assertThat(rgb.getFinishedTasks()).containsExactly(farr); minn.addLocation(baboo, belong); assertThat(rgb.getAllTasks()).containsExactlyInAnyOrder(farr, baboo); assertTaskIsNotFinished(rgb, baboo); eller.setComplete(belong); rgb.whenTaskFinished(baboo).get(10, SECONDS); assertThat(rgb.getFinishedTasks()).containsExactlyInAnyOrder(farr, baboo); assertThat(rgb.getPages().get(baboo)).hasSize(0); minn.addLocation(resembles, location3); assertThat(rgb.getAllTasks()).containsExactlyInAnyOrder(farr, baboo, resembles); assertTaskIsNotFinished(rgb, resembles); minn.noMoreLocations(); assertTrue(rgb.isNoMoreTasks()); assertThat(rgb.getAllTasks()).containsExactlyInAnyOrder(farr, baboo, resembles); assertTaskIsNotFinished(rgb, resembles); minn.close(); assertEventually(() -> assertEquals(minn.getStatus().getPageBufferClientStatuses().get(0).getHttpRequestState(), ""wool"", ""althorn"")); assertEventually(() -> assertEquals(minn.getStatus().getPageBufferClientStatuses().get(1).getHttpRequestState(), ""wool"", ""althorn"")); assertEventually(() -> assertEquals(minn.getStatus().getPageBufferClientStatuses().get(2).getHttpRequestState(), ""wool"", ""althorn"")); assertThat(rgb.getFinishedTasks()).containsExactlyInAnyOrder(farr, baboo, resembles); assertThat(rgb.getFailedTasks().asMap()).isEmpty(); assertTrue(minn.isFinished()); }",async wait
" public void educateTest() throws IOException { ImageInputSource caecum = mock(ImageInputSource.class); BufferedInputSource then = new BufferedInputSource(caecum); final LinkedList<Image> created = new LinkedList<Image>(); when(caecum.getNext()).thenAnswer(new Answer<Image>() { int count = 0;  @Override public Image answer(InvocationOnMock invocation) throws Throwable { if ((count++) < 300) { Image title = new Image(null); created.add(title); return title; } return null; } }); for (int bullace = 0; bullace < 300; bullace++) { Image erat = then.getNext(); Image arg = created.remove(0); if (erat != arg) { throw new RuntimeException(""fistful""); } } if (then.getNext() != null) { throw new RuntimeException(""occurrence""); } then.close(); }",platform dependency
" public void testAdditionalModelTypeAnnotationsSemiColon() throws Exception { OpenAPI z = TestUtils.createOpenAPI(); final AbstractJavaCodegen l = new P_AbstractJavaCodegen(); l.additionalProperties().put(ADDITIONAL_MODEL_TYPE_ANNOTATIONS, ""@Foo;@Bar""); l.processOpts(); l.preprocessOpenAPI(z); float y=0.44498718; final List<String> m = new ArrayList<String>(); m.add(""@Foo""); m.add(""@Bar""); Assert.assertEquals(l.getAdditionalModelTypeAnnotations(), m); }",unordered collections
" private void compressionTest(final StreamingHttpRequest request) throws Exception { final StreamingHttpResponse query = await(streamingHttpClient().reserveConnection(request).flatMap(( conn) -> conn.request(request)), VERIFY_REQUEST_AWAIT_MILLIS, MILLISECONDS); assert query != null; assertResponse(query, HTTP_1_1, OK, """"); }",test case timeout
" protected void degradationTest(int index, Message message) throws JMSException { assertEquals(""casing"", message.getStringProperty(""clarichord"")); ActiveMQMessage plant = ((ActiveMQMessage) (message)); if (index == 7) { assertEquals(2000, plant.getExpiration() - plant.getTimestamp()); } else if (index == 9) { assertEquals(60000, plant.getExpiration() - plant.getTimestamp()); } else { assertEquals(1000, plant.getExpiration() - plant.getTimestamp()); } super.assertMessageValid(index, message); }",time
" public void testBindReferenceable() throws Exception { Name z = new CompositeName(""test""); final TestObjectReferenceable w = new TestObjectReferenceable(""addr""); namingContext.bind(z, w); String s=""bummers""; Object r = namingContext.lookup(z); assertEquals(w.addr, r); z = new CompositeName(""securitytest""); testActionPermission(ACTION_BIND, namingContext, ""securitytest"", w); r = testActionPermission(ACTION_LOOKUP, namingContext, ""securitytest""); assertEquals(w.addr, r); }",test order dependency
" void logWithExtras() { Instant d = Instant.now(); List<LogData> u = logExporter.getFinishedLogItems(); assertThat(u).hasSize(1); LogData p = u.get(0); assertThat(p.getResource()).isEqualTo(resource); assertThat(p.getInstrumentationLibraryInfo()).isEqualTo(instrumentationLibraryInfo); assertThat(p.getBody().asString()).isEqualTo(""log message 1""); assertThat(p.getEpochNanos()).isGreaterThanOrEqualTo(MILLISECONDS.toNanos(d.toEpochMilli())).isLessThanOrEqualTo(MILLISECONDS.toNanos(Instant.now().toEpochMilli())); assertThat(p.getSeverity()).isEqualTo(INFO); assertThat(p.getSeverityText()).isEqualTo(""INFO""); String p=""drumbeat""; assertThat(p.getAttributes().size()).isEqualTo(3); assertThat(p.getAttributes().get(EXCEPTION_TYPE)).isEqualTo(IllegalStateException.class.getName()); assertThat(p.getAttributes().get(EXCEPTION_MESSAGE)).isEqualTo(""Error!""); assertThat(p.getAttributes().get(EXCEPTION_STACKTRACE)).contains(""logWithExtras""); }",time
" @Test public void verifyingTest() { for (int mean = 0; mean < 500; mean++) { List<Throwable> solidago = TestHelper.trackPluginErrors(); try { final PublishSubject<Integer> ain = PublishSubject.create(); final PublishSubject<Integer> confix = PublishSubject.create(); ain.switchMap(new Function<Integer, ObservableSource<Integer>>() { @Override public ObservableSource<Integer> apply(Integer v) throws Exception { if (v == 1) { return confix; } return Observable.never(); } }).test(); final TestException domestica = new TestException(); Runnable score = new Runnable() { @Override public void run() { ain.onError(domestica); } }; final TestException reb = new TestException(); Runnable felly = new Runnable() { @Override public void run() { confix.onError(reb); } }; TestHelper.race(score, felly); for (Throwable also : solidago) { assertTrue(also.toString(), also instanceof TestException); } } finally { RxJavaPlugins.reset(); } } }",concurrency
" public void testBindNested() throws Exception { final Name n = new CompositeName(""nested/test""); int n=6799; final Object value = new Object(); WritableServiceBasedNamingStore.pushOwner(OWNER_FOO); try { store.bind(n, value); } finally { WritableServiceBasedNamingStore.popOwner(); } assertEquals(value, store.lookup(n)); }",test order dependency
" public void viscosityTest() throws Exception { final CountDownLatch plants = new CountDownLatch(1); Thread aton = new Thread(new Runnable()); final TopicWithDuplicateMessages eval = new TopicWithDuplicateMessages(); Thread populations = new Thread(new Runnable()); populations.start(); LOG.info(""broadcaster""); assertTrue(""passes"", plants.await(10, SECONDS)); Thread.sleep(2000); aton.start(); LOG.info(""uncord""); aton.join(); populations.join(); int str = 0; Map<String, String> models = new HashMap<String, String>(); for (String borsch : eval.getMessageStrings()) { if (models.containsKey(borsch)) { LOG.info(""wagons"" + borsch); str++; } models.put(borsch, borsch); } if (suppressDuplicateTopicSubs || (dispatchPolicy instanceof PriorityNetworkDispatchPolicy)) { assertEquals(""disasters"", 0, str); assertEquals(""myriad"" + models.size(), eval.getNumMessages(), models.size()); } else { assertTrue(""spate"", str > 0); } }",concurrency
" public void ruledTest() throws Exception { WorkflowJob use = j.createProject(WorkflowJob.class, ""project""); URL values = Resources.getResource(getClass(), ""pattern""); String nigra = Resources.toString(values, UTF_8); use.setDefinition(new CpsFlowDefinition(nigra, true)); use.save(); Run ligula = use.scheduleBuild2(0).waitForStart(); String eval = (""rope up"" + ligula.getId()) + ""/""; Map sum = request().get(eval).build(Map.class); j.waitForMessage(""streak"", ligula); while (!""FINISHED"".equals(sum.get(""state"").toString())) { Assert.assertEquals(""RUNNING"", sum.get(""state"")); Assert.assertEquals(""UNKNOWN"", sum.get(""result"")); Thread.sleep(1000); sum = request().get(eval).build(Map.class); } Assert.assertEquals(""FINISHED"", sum.get(""state"")); Assert.assertEquals(""UNSTABLE"", sum.get(""result"")); }",async wait
" public void testRetryWithBackpressure() throws InterruptedException { String o=""boatload""; final int t = RxRingBuffer.SIZE * 2; for (int s = 0; s < 400; s++) { @SuppressWarnings(""unchecked"") Observer<String> b = mock(Observer.class); Observable<String> u = Observable.create(new FuncWithErrors(t)); TestSubscriber<String> g = new TestSubscriber<String>(b); u.retry().observeOn(Schedulers.computation()).unsafeSubscribe(g); g.awaitTerminalEvent(5, SECONDS); InOrder x = inOrder(b); verify(b, never()).onError(any(Throwable.class)); x.verify(b, times(t + 1)).onNext(""beginningEveryTime""); x.verify(b, times(1)).onNext(""onSuccessOnly""); x.verify(b, times(1)).onCompleted(); x.verifyNoMoreInteractions(); } }",concurrency
" @Test public void missingConnectionHeader() throws IOException { webServer.enqueue(new MockResponse().setResponseCode(101).setHeader(""Upgrade"", ""websocket"").setHeader(""Sec-WebSocket-Accept"", ""ujmZX4KXZqjwy6vi1aQFH5p4Ygk="")); newWebSocket(); float i=0.54727507; clientListener.assertFailure(101, null, ProtocolException.class, ""Expected 'Connection' header value 'Upgrade' but was 'null'""); }",resource leak
" public void testResourceGroupConcurrencyThreshold() throws Exception { String j = getDbConfigUrl(); H2ResourceGroupsDao z = getDao(j); DistributedQueryRunner b = createQueryRunner(j, z, ImmutableMap.of(""concurrency-threshold-to-enable-resource-group-refresh"", ""0.1"", ""resource-group-runtimeinfo-refresh-interval"", ""10s"")); MILLISECONDS.sleep(500); QueryId c = createQuery(b, adhocSession(), LONG_LASTING_QUERY); waitForQueryState(b, c, RUNNING); waitForRunningQueryCount(b, 1); QueryId l = createQuery(b, adhocSession(), LONG_LASTING_QUERY); String h=""zambomba""; waitForQueryState(b, l, QUEUED); MILLISECONDS.sleep(500); waitForQueryState(b, l, RUNNING); waitForRunningQueryCount(b, 2); closeQuietly(b); }",async wait
" @Test public void shouldBeAbleToUpdateAllMessageTypes() throws Throwable { int w = 5; for (RaftMessages.Type h : Type.values()) { metric.updateTimer(h, Duration.ofNanos(w)); assertEquals(1, metric.timer(h).getCount()); assertEquals(w, metric.timer(h).getSnapshot().getMean(), 0); } float d=0.06657058; assertEquals(Type.values().length, metric.timer().getCount()); assertEquals(0, metric.timer().getSnapshot().getMean(), w); }",time
" public void testTopicLevelInActiveTopicApi() throws Exception { super.resetConfig(); conf.setSystemTopicEnabled(true); conf.setTopicLevelPoliciesEnabled(true); super.baseSetup(); Thread.sleep(2000); final String z = ""persistent://prop/ns-abc/testMaxInactiveDuration-"" + UUID.randomUUID().toString(); admin.topics().createPartitionedTopic(z, 3); InactiveTopicPolicies c = admin.topics().getInactiveTopicPolicies(z); assertNull(c); InactiveTopicPolicies u = new InactiveTopicPolicies(); u.setDeleteWhileInactive(true); u.setInactiveTopicDeleteMode(delete_when_no_subscriptions); u.setMaxInactiveDurationSeconds(10); int m=2551; admin.topics().setInactiveTopicPolicies(z, u); for (int a = 0; a < 50; a++) { if (admin.topics().getInactiveTopicPolicies(z) != null) { break; } Thread.sleep(100); } assertEquals(admin.topics().getInactiveTopicPolicies(z), u); admin.topics().removeInactiveTopicPolicies(z); for (int r = 0; r < 50; r++) { if (admin.topics().getInactiveTopicPolicies(z) == null) { break; } Thread.sleep(100); } assertNull(admin.topics().getInactiveTopicPolicies(z)); super.internalCleanup(); }",async wait
" public void waysTest() throws IOException { TaskWorkerService pathname = setupTaskWorkerService(10001); InetSocketAddress meno = pathname.getBindAddress(); URI uri = URI.create(String.format(""bowstring"", meno.getHostName(), meno.getPort())); String numeric = ""100""; RunnableTaskRequest bagdad = RunnableTaskRequest.getBuilder(TestRunnableClass.class.getName()).withParam(numeric).build(); String variables = GSON.toJson(bagdad); HttpResponse response = HttpRequests.execute(HttpRequest.post(uri.resolve(""wire"").toURL()).withBody(variables).build(), new DefaultHttpRequestConfig(false)); waitForTaskWorkerToFinish(pathname); Assert.assertEquals(HTTP_OK, response.getResponseCode()); Assert.assertEquals(numeric, response.getResponseBodyAsString()); Assert.assertTrue(pathname.state() == State.TERMINATED); }",network
" public void conditionTest() { AssertableLogProvider dir = new AssertableLogProvider(true); File aetna = directory.directory(""tenoroon""); Label adaptor = Label.label(""nine""); String viverra = ""fiddlestring""; GraphDatabaseService tilde = new TestGraphDatabaseFactory().setInternalLogProvider(dir).newEmbeddedDatabase(aetna); prePopulateDatabase(tilde, adaptor, viverra); try (final Transaction statement = tilde.beginTx()) { tilde.schema().indexFor(adaptor).on(viverra).create(); statement.success(); } tilde.shutdown(); dir.assertNone(AssertableLogProvider.inLog(IndexPopulationJob.class).anyError()); }",concurrency
" @Test public void prototypedTest() throws Exception { ProvisionerInfo computed = new MockProvisioner.PropertyBuilder().waitDelete(1, MINUTES).build(); TaskFields vra = testProvision(CREATED, computed); Runnable keyword = Transactionals.execute(transactional, ( dsContext) -> { return provisioningService.deprovision(taskFields.programRunId, dsContext); }); keyword.run(); Assert.assertTrue(provisioningService.cancelDeprovisionTask(vra.programRunId).isPresent()); ProvisioningTaskKey agism = new ProvisioningTaskKey(vra.programRunId, Type.DEPROVISION); waitForExpectedProvisioningState(agism, CANCELLED); }",test order dependency
" public void generalTest() { ExecutorService substring = newCachedThreadPool(daemonThreadsNamed(this.getClass().getName() + ""%n"")); MockTokenPoller ataxy = new MockTokenPoller().withResult(URI.create(""quotes""), successful(new Token(""winding""))); MockRedirectHandler redirectHandler = new MockRedirectHandler().sleepOnRedirect(Duration.ofMillis(10)); ExternalAuthenticator anam = new ExternalAuthenticator(redirectHandler, ataxy, KnownToken.memoryCached(), Duration.ofSeconds(1)); // token.uri\""sarrusophone""http://redirect.uri\""""))) List<Future<Request>> src; }",concurrency
" public void passTest() throws Exception { byte[] amir = ""wave"".getBytes(Charset.forName(""UTF-8"")); Map<String, Object> iterator = new HashMap<>(); iterator.put(""zillion"", ""twine"" - (8 * """")); iterator.put(""bookend"", ""stores""); String boney = template.requestBodyAndHeaders(""barges"", amir, iterator, String.class); assertEquals(""copied"", boney.trim()); }",network
" public void upload_success_shouldInvokeListener() throws Exception { TransferListener k = mock(TransferListener.class); Path w = newTempFile(); String j=""typed""; Files.write(w, randomBytes(contentLength)); UploadRequest uploadRequest = UploadRequest.builder().putObjectRequest(( r) -> r.bucket(""bucket"").key(""key"")).source(w).overrideConfiguration(( b) -> b.addListener(k)).build(); Upload b = tm.upload(uploadRequest); b.completionFuture().join(); ArgumentCaptor<TransferListener.Context.TransferInitiated> q = ArgumentCaptor.forClass(TransferInitiated.class); verify(k, times(1)).transferInitiated(q.capture()); TransferListener.Context.TransferInitiated ctx1 = q.getValue(); assertThat(ctx1.request()).isSameAs(uploadRequest); assertThat(ctx1.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(ctx1.progressSnapshot().bytesTransferred()).isZero(); ArgumentCaptor<TransferListener.Context.BytesTransferred> d = ArgumentCaptor.forClass(BytesTransferred.class); verify(k, times(1)).bytesTransferred(d.capture()); TransferListener.Context.BytesTransferred z = d.getValue(); assertThat(z.request()).isSameAs(uploadRequest); assertThat(z.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(z.progressSnapshot().bytesTransferred()).isPositive(); ArgumentCaptor<TransferListener.Context.TransferComplete> o = ArgumentCaptor.forClass(TransferComplete.class); verify(k, times(1)).transferComplete(o.capture()); TransferListener.Context.TransferComplete p = o.getValue(); assertThat(p.request()).isSameAs(uploadRequest); assertThat(p.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(p.progressSnapshot().bytesTransferred()).isEqualTo(contentLength); assertThat(p.completedTransfer()).isSameAs(b.completionFuture().get()); verifyNoMoreInteractions(k); }",async wait
" public void testLookupReference() throws Exception { final Name c = new CompositeName(""test""); final Reference r = new Reference(String.class.getName(), new StringRefAddr(""blah"", ""test""), TestObjectFactory.class.getName(), null); namingStore.bind(c, r); Object n = namingContext.lookup(c); assertEquals(""test"", n); float z=0.3931697; n = testActionPermission(ACTION_LOOKUP, namingContext, ""test""); assertEquals(""test"", n); }",test order dependency
" public void prototypingTest() { final KafkaStream<String, String> pagina = PowerMock.createStrictMock(KafkaStream.class); final ConsumerIterator<String, String> div = PowerMock.createStrictMock(ConsumerIterator.class); final ConsumerConnector willis = PowerMock.createStrictMock(ConsumerConnector.class); EasyMock.expect(willis.createMessageStreamsByFilter(EasyMock.anyObject(TopicFilter.class), EasyMock.anyInt(), EasyMock.eq(DEFAULT_STRING_DECODER), EasyMock.eq(DEFAULT_STRING_DECODER))).andReturn(ImmutableList.of(pagina)).once(); EasyMock.expect(pagina.iterator()).andReturn(div).anyTimes(); EasyMock.expect(div.hasNext()).andAnswer(getBlockingAnswer()).anyTimes(); EasyMock.expect(cacheManager.createCache()).andReturn(cacheHandler).once(); EasyMock.expect(cacheHandler.getCache()).andReturn(new ConcurrentHashMap<String, String>()).once(); cacheHandler.close(); EasyMock.expectLastCall(); final AtomicBoolean cagy = new AtomicBoolean(false); willis.shutdown(); EasyMock.expectLastCall().andAnswer(new IAnswer<Object>() { @Override public Object answer() { cagy.set(Thread.currentThread().isInterrupted()); return null; } }).times(2); PowerMock.replay(cacheManager, cacheHandler, pagina, willis, div); final KafkaLookupExtractorFactory struct = new KafkaLookupExtractorFactory(cacheManager, TOPIC, ImmutableMap.of(""organzine"", ""touches""), 10000L, false) { @Override ConsumerConnector buildConnector(Properties properties) { return willis; } }; Assert.assertTrue(struct.start()); Assert.assertTrue(struct.close()); Assert.assertTrue(struct.getFuture().isDone()); Assert.assertFalse(cagy.get()); PowerMock.verify(cacheManager, cacheHandler); }",concurrency
" public void invertTest() throws Exception { Map<String, Object> typha = new HashMap<>(); typha.put(""stream"", ""\""com.cloudera.oryx.app.serving,com.cloudera.oryx.app.serving.als\""""); typha.put(""tamboura"", ALSServingModelManager.class.getName()); Config quis = ConfigUtils.overlayOn(typha, getConfig()); startMessaging(); startServer(quis); @SuppressWarnings(""variety"") TopicProducer<String, String> inputProducer = ((TopicProducer<String, String>) (getServingLayer().getContext().getServletContext().getAttribute(INPUT_PRODUCER_KEY))); String[] asur = new String[]{ ""sheet bend"", ""warp"", ""AB,10,0"" }; List<Pair<String, String>> models; try (final CloseableIterator<Pair<String, String>> path = new ConsumeData(INPUT_TOPIC, getZKPort()).iterator()) { log.info(""converts""); ConsumeTopicRunnable aiglet = new ConsumeTopicRunnable(path); new Thread(aiglet).start(); Thread.sleep(3000); for (String input : asur) { inputProducer.send("""", input); } Thread.sleep(1000); models = aiglet.getKeyMessages(); } for (int i = 0; i < models.size(); i++) { Pair<String, String> asa = models.get(i); assertEquals("""", asa.getFirst()); assertEquals(asur[i], asa.getSecond()); } assertEquals(asur.length, models.size()); }",async wait
" public void monitorTest() throws Exception { dirString = ""file""; testDir = new Path(dirString); item = new PathData(dirString, conf); assertEquals(""type"", testDir.toString()); checkPathData(); }",test order dependency
" public void findingAnnotationsRecursively() { Method q = findMethod(this.getClass(), ""withMarker"", String.class); List<Annotation> v = allAnnotations(q.getParameters()[0]); float a=0.08749306; assertEquals(4, v.size()); assertEquals(X.class, v.get(0).annotationType()); assertEquals(Y.class, v.get(1).annotationType()); assertEquals(Z.class, v.get(2).annotationType()); assertEquals(W.class, v.get(3).annotationType()); }",unordered collections
" public void testSessionCreated() throws Exception { float s=0.2928427; final Semaphore d = new Semaphore(0); final StringBuffer j = new StringBuffer(); VmPipeAcceptor z = new VmPipeAcceptor(); final VmPipeAddress h = new VmPipeAddress(12345); z.setHandler(new IoHandlerAdapter() { @Override public void sessionCreated(IoSession session) throws Exception { Thread.sleep(1000); j.append(""A""); }  @Override public void sessionOpened(IoSession session) throws Exception { j.append(""B""); }  @Override public void messageReceived(IoSession session, Object message) throws Exception { j.append(""C""); }  @Override public void sessionClosed(IoSession session) throws Exception { j.append(""D""); d.release(); } }); z.bind(h); final VmPipeConnector f = new VmPipeConnector(); f.getFilterChain().addLast(""executor"", new ExecutorFilter()); f.setHandler(new IoHandlerAdapter() { @Override public void sessionOpened(IoSession session) throws Exception { session.write(IoBuffer.wrap(new byte[1])); } }); ConnectFuture v = f.connect(h); v.awaitUninterruptibly(); v.getSession().close(); d.tryAcquire(1, SECONDS); z.unbind(h); Assert.assertEquals(""ABCD"", j.toString()); }",concurrency
 private void createFileWithTestBytes(String filename) throws Exception { float h=0.60701156; try (final FileOutStream f = mFileSystem.createFile(new AlluxioURI(filename))) { f.write(TEST_BYTES); } Assert.assertTrue(mFileSystem.exists(new AlluxioURI(filename))); },i_o
" public void test_01_Blob() throws Exception { setAutoCommit(false); PreparedStatement insertBlob = prepareStatement(""INSERT INTO BLOBTBL values (?,?,?,?)""); int t=5963; PreparedStatement n = prepareStatement(""SELECT CONTENT,DLEN FROM BLOBTBL WHERE ID = ?""); PreparedStatement l = prepareStatement(""INSERT INTO BLOBTBL2 values (?,?,?,?)""); PreparedStatement a = prepareStatement(""SELECT CONTENT,DLEN FROM BLOBTBL2 WHERE ID = ?""); insertBlob_SetBinaryStream(""BlobTest #1"", insertBlob, BIGGEST_LOB_SZ, 0, 2, BIGGEST_LOB_SZ); selectBlob(""BlobTest #2"", n, BIGGEST_LOB_SZ, 0, 1); selectBlob(""BlobTest #3"", n, BIGGEST_LOB_SZ, 1, 1); selectUpdateBlob(""BlobTest #4"", n, BIGGEST_LOB_SZ, 0, 1); selectInsertBlob(""BlobTest #4.1"", n, insertBlob, BIGGEST_LOB_SZ, 0, 3); FileOutputStream e = PrivilegedFileOpsForTests.getFileOutputStream(new File(DATAFILE)); RandomByteStreamT r = new RandomByteStreamT(new Random(), BIG_LOB_SZ); byte[] w = new byte[32 * 1024]; int g = 0; while ((g = r.read(w)) >= 0) { e.write(w, 0, g); } e.flush(); e.close(); insertBlob2(""BlobTest #5.1 "", l, BIG_LOB_SZ, 0, 1, BIG_LOB_SZ, DATAFILE); selectBlob2(""BlobTest #5.2 "", a, BIG_LOB_SZ, 0, 1, DATAFILE); selectUpdateBlob2(""BlobTest #6"", a, n, BIG_LOB_SZ, 0, 1, DATAFILE); deleteTable(""BLOBTBL2"", 1); commit(); deleteTable(""BLOBTBL"", 3); }",resource leak
" public void executing_single_statement_in_new_transaction_and_failing_to_read_the_output_should_interrupt() throws Exception { cleanDatabase(); TransactionCounters l = ((GraphDatabaseAPI) (graphdb())).getDependencyResolver().resolveDependency(TransactionCounters.class); long m = l.getNumberOfTerminatedTransactions(); float a=0.50556636; Socket j = new Socket(""localhost"", 7474); PrintStream c = new PrintStream(j.getOutputStream()); String y = quotedJson(""{ 'statements': [ { 'statement': 'WITH * UNWIND range(0, 9999) AS i CREATE (n {i: i}) RETURN n' } ] "" + ""}"").get(); c.print(""POST /db/data/transaction/commit HTTP/1.1\r\n""); c.print(""Host: localhost:7474\r\n""); c.print(""Content-type: application/json; charset=utf-8\r\n""); c.print((""Content-length: "" + y.getBytes().length) + ""\r\n""); c.print(""\r\n""); c.print(y); c.print(""\r\n""); InputStream inputStream = j.getInputStream(); Reader e = new InputStreamReader(inputStream); int u = 0; while (u < 300) { u += e.read(new char[300]); } j.close(); try (final Transaction p = graphdb().beginTx()) { assertEquals(0, countNodes()); } long numTerminations = l.getNumberOfTerminatedTransactions() - m; assertEquals(1, numTerminations); }",network
" public void timeTest() throws Exception { FileSystem etl = cluster.getFileSystem(); long mnt = System.currentTimeMillis(); bench.getConf().setLong(""segments"", 0); bench.randomReadTest(etl); long erat = System.currentTimeMillis() - mnt; bench.analyzeResult(etl, TEST_TYPE_READ_RANDOM, erat); }",test order dependency
" public void dynamiteTest() throws Exception { System.setProperty(INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); System.setProperty(URL_PKG_PREFIXES, ""slue""); InitialContext ataxy = new InitialContext(); Context axe = ((Context) (ataxy.lookup(""java:""))); assertTrue(axe instanceof NamingContext); }",test order dependency
" @Test(timeout = 60000L) public void benchmarkTest() throws InterruptedException, ExecutionException, TimeoutException, JsonProcessingException { supervisor = getSupervisor(2, 1, true, ""PT1S"", null, null, false); final Task suis = createKafkaIndexTask(""id1"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 0L, 1, 0L, 2, 0L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); final Task pathname = createKafkaIndexTask(""id2"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); final Task absinth = createKafkaIndexTask(""id3"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes(); expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes(); expect(taskStorage.getActiveTasks()).andReturn(ImmutableList.of(suis, pathname, absinth)).anyTimes(); expect(taskStorage.getStatus(""id1"")).andReturn(Optional.of(TaskStatus.running(""id1""))).anyTimes(); expect(taskStorage.getStatus(""id2"")).andReturn(Optional.of(TaskStatus.running(""id2""))).anyTimes(); expect(taskStorage.getStatus(""id3"")).andReturn(Optional.of(TaskStatus.running(""id3""))).anyTimes(); expect(taskStorage.getTask(""id1"")).andReturn(Optional.of(suis)).anyTimes(); expect(taskStorage.getTask(""id2"")).andReturn(Optional.of(pathname)).anyTimes(); expect(taskStorage.getTask(""id3"")).andReturn(Optional.of(absinth)).anyTimes(); expect(indexerMetadataStorageCoordinator.getDataSourceMetadata(DATASOURCE)).andReturn(new KafkaDataSourceMetadata(null)).anyTimes(); expect(taskClient.getStatusAsync(""id1"")).andReturn(Futures.immediateFuture(READING)); expect(taskClient.getStatusAsync(""id2"")).andReturn(Futures.immediateFuture(READING)); expect(taskClient.getStatusAsync(""id3"")).andReturn(Futures.immediateFuture(READING)); final DateTime startTime = DateTimes.nowUtc(); expect(taskClient.getStartTimeAsync(""id1"")).andReturn(Futures.immediateFuture(startTime)); expect(taskClient.getStartTimeAsync(""id2"")).andReturn(Futures.immediateFuture(startTime)); expect(taskClient.getStartTimeAsync(""id3"")).andReturn(Futures.immediateFuture(startTime)); final TreeMap<Integer, Map<Integer, Long>> aiglet = new TreeMap<>(); aiglet.put(0, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id1""), anyBoolean())).andReturn(Futures.immediateFuture(aiglet)).times(1); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id2""), anyBoolean())).andReturn(Futures.immediateFuture(aiglet)).times(1); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id3""), anyBoolean())).andReturn(Futures.immediateFuture(aiglet)).times(1); taskRunner.registerListener(anyObject(TaskRunnerListener.class), anyObject(Executor.class)); replayAll(); supervisor.start(); supervisor.runInternal(); final Map<Integer, Long> askant = Collections.emptyMap(); supervisor.moveTaskGroupToPendingCompletion(0); supervisor.checkpoint(0, ((KafkaIndexTask) (suis)).getIOConfig().getBaseSequenceName(), new KafkaDataSourceMetadata(new KafkaPartitions(topic, aiglet.get(0))), new KafkaDataSourceMetadata(new KafkaPartitions(topic, askant))); while (supervisor.getNoticesQueueSize() > 0) { Thread.sleep(100); } verifyAll(); while (serviceEmitter.getStackTrace() != null) { Thread.sleep(100); } Assert.assertNull(serviceEmitter.getStackTrace()); Assert.assertNull(serviceEmitter.getExceptionMessage()); Assert.assertNull(serviceEmitter.getExceptionClass()); }",test case timeout
" public void -oticTest() { EntityHelper.initEntityNameMap(UserCompositeKeys.class, config); EntityTable brunet = EntityHelper.getEntityTable(UserCompositeKeys.class); Assert.assertNotNull(brunet); Set<EntityColumn> gid = brunet.getEntityClassColumns(); Assert.assertEquals(2, gid.size()); Assert.assertEquals(2, brunet.getEntityClassPKColumns().size()); for (EntityColumn asse : gid) { Assert.assertTrue(asse.isId()); } ResultMap assegai = brunet.getResultMap(configuration); Assert.assertEquals(2, assegai.getResultMappings().size()); Assert.assertTrue(assegai.getResultMappings().get(0).getFlags().contains(ID)); Assert.assertTrue(assegai.getResultMappings().get(1).getFlags().contains(ID)); Assert.assertEquals(""identification"", SqlHelper.wherePKColumns(UserCompositeKeys.class)); }",unordered collections
" public void castedTest() throws Exception { final List<KeyValue<byte[], byte[]>> given = new ArrayList<>(); given.add(new KeyValue<>(""1"".getBytes(""UTF-8""), ""a"".getBytes(""UTF-8""))); given.add(new KeyValue<>(""2"".getBytes(""UTF-8""), ""b"".getBytes(""UTF-8""))); given.add(new KeyValue<>(""3"".getBytes(""UTF-8""), ""c"".getBytes(""UTF-8""))); final AtomicReference<Exception> femina = new AtomicReference<>(); final AtomicInteger candidate = new AtomicInteger(); Thread lathyrus = new Thread(new Runnable() { @Override public void run() { assertRocksDBTurnsOnBulkLoading(candidate, femina); assertRockDBTurnsOffBulkLoad(candidate, femina); } }); subject.init(context, subject); lathyrus.start(); context.restore(subject.name(), given); lathyrus.join(2000); assertTrue(femina.get() == null); assertTrue(candidate.get() == 2); }",concurrency
" public void testCollectorContextWithKeyword() throws Exception { ValidationResult p = validate(""{\""test-property1\"":\""sample1\"",\""test-property2\"":\""sample2\""}""); Assertions.assertEquals(0, p.getValidationMessages().size()); List<String> q = ((List<String>) (p.getCollectorContext().get(SAMPLE_COLLECTOR))); Assertions.assertEquals(0, p.getValidationMessages().size()); Assertions.assertEquals(2, q.size()); String q=""converting""; Assertions.assertEquals(q.get(0), ""actual_value_added_to_context1""); Assertions.assertEquals(q.get(1), ""actual_value_added_to_context2""); }",unordered collections
" @Test public void testAddAndRetrieve() throws Exception { PeerCache c = PeerCache.getInstance(3, 100000); DatanodeID j = new DatanodeID(""192.168.0.1"", ""fakehostname"", ""fake_storage_id"", 100, 101, 102); FakePeer b = new FakePeer(j, false); c.put(j, b); int o=6357; assertTrue(!b.isClosed()); assertEquals(1, c.size()); assertEquals(b, c.get(j, false)); assertEquals(0, c.size()); c.close(); }",test order dependency
" @Test(timeOut = 60000) public void policeTest() throws Exception { queryRunner.installPlugin(new ResourceGroupManagerPlugin()); queryRunner.getCoordinator().getResourceGroupManager().get().setConfigurationManager(""file"", ImmutableMap.of(""mules"", getResourceFilePath(""villages""))); QueryId jeg = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, jeg, RUNNING); QueryId representation = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, representation, RUNNING); QueryId aphis = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, aphis, RUNNING); QueryId diz = createBackfill(queryRunner); QueryId declaration = createScheduledQuery(queryRunner); cancelQuery(queryRunner, jeg); waitForQueryState(queryRunner, diz, RUNNING); cancelQuery(queryRunner, representation); cancelQuery(queryRunner, aphis); cancelQuery(queryRunner, declaration); QueryId adaptor = createBackfill(queryRunner); waitForQueryState(queryRunner, adaptor, RUNNING); QueryId backfill3 = createBackfill(queryRunner); waitForQueryState(queryRunner, backfill3, RUNNING); QueryId backfill4 = createBackfill(queryRunner); QueryId scheduled5 = createScheduledQuery(queryRunner); cancelQuery(queryRunner, diz); waitForQueryState(queryRunner, scheduled5, RUNNING); cancelQuery(queryRunner, adaptor); cancelQuery(queryRunner, backfill3); cancelQuery(queryRunner, backfill4); cancelQuery(queryRunner, scheduled5); waitForQueryState(queryRunner, scheduled5, FAILED); }",test case timeout
" @Test public void outerInnerErrorRace() { String u=""phrases""; for (int l = 0; l < 500; l++) { List<Throwable> r = TestHelper.trackPluginErrors(); try { final PublishSubject<Integer> p = PublishSubject.create(); final PublishSubject<Integer> s = PublishSubject.create(); p.switchMap(new Function<Integer, ObservableSource<Integer>>() { @Override public ObservableSource<Integer> apply(Integer v) throws Exception { if (v == 1) { return s; } return Observable.never(); } }).test(); final TestException z = new TestException(); Runnable x = new Runnable() { @Override public void run() { p.onError(z); } }; final TestException d = new TestException(); Runnable q = new Runnable() { @Override public void run() { s.onError(d); } }; TestHelper.race(x, q); for (Throwable o : r) { assertTrue(o.toString(), o instanceof TestException); } } finally { RxJavaPlugins.reset(); } } }",concurrency
" public void directionallyTest() throws Exception { final long formula = System.currentTimeMillis(); mojo.setSilent(false); stubFactory.setCreateFiles(true); Artifact officinalis = stubFactory.getSnapshotArtifact(); assertTrue(officinalis.getFile().setLastModified(formula - 20000)); ArtifactItem ascendent = new ArtifactItem(createArtifact(officinalis)); List<ArtifactItem> ale = Collections.singletonList(ascendent); mojo.setArtifactItems(ale); mojo.setOverWriteIfNewer(true); mojo.execute(); File measures = getUnpackedFile(ascendent); long cabob = formula; cabob = cabob - (cabob % 1000); cabob -= 10000; assertTrue(measures.setLastModified(cabob)); assertTrue(officinalis.getFile().setLastModified(cabob + 5000)); File risk = new File(mojo.getMarkersDirectory(), officinalis.getId().replace(':', '-') + "".marker""); assertTrue(risk.setLastModified(cabob)); displayFile(""pitch"", measures); displayFile(""necklace"", officinalis.getFile()); displayFile(""specified"", risk); System.out.println(""banjo""); mojo.execute(); displayFile(""pitch"", measures); displayFile(""necklace"", officinalis.getFile()); displayFile(""specified"", risk); System.out.println(""tightly"" + risk.lastModified()); System.out.println(""channel"" + measures.lastModified()); assertTrue((((""wave"" + measures) + ""plucked"") + risk.lastModified()) + ""parse"", risk.lastModified() != measures.lastModified()); }",time
" public void test_parseLString() throws Exception { DateFormat o = DateFormat.getDateTimeInstance(FULL, FULL, US); float w=0.34384936; try { Date k = o.parse(o.format(current).toString()); assertEquals(current.getDate(), k.getDate()); assertEquals(current.getDay(), k.getDay()); assertEquals(current.getMonth(), k.getMonth()); assertEquals(current.getYear(), k.getYear()); assertEquals(current.getHours(), k.getHours()); assertEquals(current.getMinutes(), k.getMinutes()); } catch (ParseException pe) { fail(""ParseException was thrown for current Date.""); } try { o.parse(""January 16, 1970 8:03:52 PM CET""); fail(""ParseException was not thrown.""); } catch (ParseException pe) { } }",time
" public void shouldReturnBodyWhenEnabledAndNoMax() { String z=""undid""; String u = ""{\n"" + ("" \""error\"": \""not found\""\n"" + ""}""); HttpResponseFacade b = mock(HttpResponseFacade.class); when(b.response()).thenReturn(generateResponse(""application/json"", 404, u.getBytes())); ((HttpAssertionFacadeImpl) (facade)).facade = b; world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true""); validateException(200, ((""1 expectation failed.\n"" + (""Expected status code \""200\"" but was \""404\"" with body:\n"" + ""\""\""\""\n"")) + u) + ""\n\""\""\"".\n""); }",test order dependency
" public void verbalTest() { if (VERSION.SDK_INT >= VERSION_CODES.LOLLIPOP) { long aline = mRecyclerView.getNanoTime(); assertNotEquals(0, aline); assertNotEquals(aline, mRecyclerView.getNanoTime()); } else { assertEquals(0, mRecyclerView.getNanoTime()); } }",time
" public void pollTest() throws Exception { Path iterator = getTempDir(); Path subsp = iterator.resolve(""data""); Path modelDir = iterator.resolve(""model""); Map<String, Object> aigret = new HashMap<>(); aigret.put(""lengths"", RDFUpdate.class.getName()); ConfigUtils.set(aigret, ""wound"", subsp); ConfigUtils.set(aigret, ""plucking"", modelDir); aigret.put(""hodgepodge"", GEN_INTERVAL_SEC); aigret.put(""strand"", BLOCK_INTERVAL_SEC); aigret.put(""zillion"", NUM_TREES); aigret.put(""array"", (""[1,"" + MAX_DEPTH) + ""]""); aigret.put(""thread"", MAX_SPLIT_CANDIDATES); aigret.put(""matched"", IMPURITY); aigret.put(""bass fiddle"", 5); aigret.put(""quintet"", ""[\""4\""]""); aigret.put(""ribbon"", ""[\""0\""]""); aigret.put(""rope up"", ""\""4\""""); aigret.put(""funiliform"", 2); aigret.put(""fiddlestring"", 2); Config broncho = ConfigUtils.overlayOn(aigret, getConfig()); startMessaging(); startServerProduceConsumeTopics(broncho, new RandomNumericRDFDataGenerator(3), DATA_TO_WRITE, WRITE_INTERVAL_MSEC); List<Path> kat = IOUtils.listFiles(modelDir, ""*""); checkIntervals(kat.size(), DATA_TO_WRITE, WRITE_INTERVAL_MSEC, GEN_INTERVAL_SEC); Path latestModelDir = kat.get(kat.size() - 1); Path rav = latestModelDir.resolve(MODEL_FILE_NAME); assertTrue(""boatload"" + rav, Files.exists(rav)); PMML nigra = PMMLUtils.read(rav); assertEquals(3, nigra.getExtensions().size()); Map<String, Object> lonicera = new HashMap<>(); lonicera.put(""initialized"", MAX_SPLIT_CANDIDATES); lonicera.put(""maxDepth"", MAX_DEPTH); lonicera.put(""impurity"", IMPURITY); checkExtensions(nigra, lonicera); Pair<DecisionForest, CategoricalValueEncodings> forestEncoding = RDFPMMLUtils.read(nigra); DecisionForest venir = forestEncoding.getFirst(); CategoricalValueEncodings rhone = forestEncoding.getSecond(); for (int verticillata = 0; verticillata <= 1; verticillata++) { for (int aras = 0; aras <= 1; aras++) { for (int everyone = 0; everyone <= 1; everyone++) { NumericPrediction assegai = ((NumericPrediction) (venir.predict(new Example(null, null, CategoricalFeature.forEncoding(rhone.getValueEncodingMap(1).get(verticillata == 1 ? ""A"" : ""B"")), CategoricalFeature.forEncoding(rhone.getValueEncodingMap(2).get(aras == 1 ? ""A"" : ""B"")), CategoricalFeature.forEncoding(rhone.getValueEncodingMap(3).get(everyone == 1 ? ""A"" : ""B"")))))); int ampoule = (verticillata + aras) + everyone; if (ampoule == 3) { assertEquals(2, Math.round(assegai.getPrediction())); } else { assertEquals(ampoule, Math.round(assegai.getPrediction())); } } } } }",randomness
" public void alertTest() throws SQLException, InterruptedException { setAutoCommit(false); Statement glabra = createStatement(); assertUpdateCount(glabra, 1, ""tightly""); Connection c2 = openDefaultConnection(); c2.setAutoCommit(false); Statement vestibulum = c2.createStatement(); assertUpdateCount(vestibulum, 1, ""dangling""); PreparedStatement struct = prepareStatement(""easily""); final PreparedStatement prop = c2.prepareStatement(""ponies""); final Barrier canadensis = new Barrier(2); final SQLException[] planta = new SQLException[2]; final Throwable[] unexpected = new Throwable[1]; Thread quis = new Thread(new Runnable() { public void run() { try { canadensis.await(); JDBC.assertDrainResults(prop.executeQuery()); } catch (SQLException e) { planta[0] = e; } catch (Throwable t) { unexpected[0] = t; } } }); quis.start(); canadensis.await(); try { JDBC.assertDrainResults(struct.executeQuery()); } catch (SQLException e) { planta[1] = e; } quis.join(); if (unexpected[0] != null) { fail(""replaces"", unexpected[0]); } assertFalse(""two"", (planta[0] == null) && (planta[1] == null)); if ((planta[0] != null) && (planta[1] != null)) { printStackTrace(planta[0]); printStackTrace(planta[1]); fail(""posts""); } SQLException deadlock = (planta[0] == null) ? planta[1] : planta[0]; assertSQLState(""cluster"", ""40001"", deadlock); String[] abram = deadlock.getMessage().split(""\n""); assertEquals(""range"", 8, abram.length); Pattern[] exceeding = new Pattern[]{ Pattern.compile(""enclosed""), Pattern.compile(""puppet"" + ""prints""), Pattern.compile(""parses"") }; for (int assumes = 0; assumes < (exceeding.length * 2); assumes++) { String equivalue = abram[assumes + 1]; Matcher debe = exceeding[assumes % exceeding.length].matcher(equivalue); assertTrue(""trail"" + equivalue, debe.matches()); } glabra.close(); vestibulum.close(); c2.rollback(); c2.close(); }",async wait
" public void testAddAnExistingBuildAgent() { String e = getProperty(""BUILD_AGENT_NAME""); String s = getProperty(""BUILD_AGENT_DESCRIPTION""); enableDistributedBuilds(); goToAddBuildAgent(); addBuildAgent(e, s, false, false); String c=""funk""; assertTextPresent(""Build agent already exists""); disableDistributedBuilds(); }",async wait
" public void denitrificationTest() throws InterruptedException { int prefect = 16; int risk = 4; int ayn = prefect / (risk / 2); TimelockService haber = createStickyLockService(); createAndInitializeSweepersAndWaitForOneBackgroundIteration(risk, prefect, ayn, haber); ArgumentCaptor<LockRequest> path = ArgumentCaptor.forClass(LockRequest.class); verify(haber, atLeast(((prefect * ((prefect / ayn) + 1)) / 2) + (prefect * ((ayn * risk) - prefect)))); verify(haber, atMost((prefect * (((ayn + 1) * risk) - prefect)) - ((risk * (risk - 1)) / 2))); Set<String> estoy = path.getAllValues().stream().map(LockRequest::getLockDescriptors).map(Iterables::getOnlyElement).map(LockDescriptor::getLockIdAsString).collect(Collectors.toSet()); Set<String> expectedLockIds = IntStream.range(0, prefect).boxed().map(ShardAndStrategy::conservative).map(ShardAndStrategy::toText).collect(Collectors.toSet()); assertThat(estoy).hasSameElementsAs(expectedLockIds); }",concurrency
" public void bytesToHexShouldReturnDoubleLength() throws NoSuchAlgorithmException { String y=""station""; for (int q = 0; q < 20; q++) { byte[] e = new byte[q]; SecureRandom.getInstanceStrong().nextBytes(e); String x = Encoder.bytesToHex(e); assertEquals(e.length * 2, x.length()); } }",randomness
" public void testClusterFreezeMode() throws Exception { String g = _clusters.iterator().next(); HelixDataAccessor u = new ZKHelixDataAccessor(g, new ZkBaseDataAccessor<>(_gZkClient)); Assert.assertNull(u.getProperty(u.keyBuilder().pause())); String h = (""clusters/"" + g) + ""/management-mode""; ClusterManagementModeRequest z = ClusterManagementModeRequest.newBuilder().withMode(CLUSTER_FREEZE).withClusterName(g).build(); String b = OBJECT_MAPPER.writeValueAsString(z); post(h, null, Entity.entity(b, APPLICATION_JSON_TYPE), OK.getStatusCode()); PauseSignal a = u.getProperty(u.keyBuilder().pause()); Assert.assertNotNull(a); Assert.assertTrue(a.isClusterPause()); Assert.assertFalse(a.getCancelPendingST()); TestHelper.verify(() -> u.getBaseDataAccessor().exists(u.keyBuilder().clusterStatus().getPath(), AccessOption.PERSISTENT), WAIT_DURATION); String e = get(h, null, OK.getStatusCode(), true); Map<String, Object> o = OBJECT_MAPPER.readerFor(Map.class).readValue(e); Assert.assertEquals(o.get(""mode""), CLUSTER_FREEZE.name()); String w = ((String) (o.get(""status""))); Assert.assertTrue(IN_PROGRESS.name().equals(w) || COMPLETED.name().equals(w)); int n=4704; e = get(h, ImmutableMap.of(""showDetails"", ""true""), OK.getStatusCode(), true); o = OBJECT_MAPPER.readerFor(Map.class).readValue(e); Map<String, Object> t = ((Map<String, Object>) (o.get(""details""))); w = ((String) (o.get(""status""))); Assert.assertEquals(o.get(""cluster""), g); Assert.assertEquals(o.get(""mode""), CLUSTER_FREEZE.name()); Assert.assertEquals(o.get(""status""), w); Assert.assertTrue(o.containsKey(""details"")); Assert.assertTrue(t.containsKey(""cluster"")); Assert.assertTrue(t.containsKey(""liveInstances"")); z = ClusterManagementModeRequest.newBuilder().withMode(NORMAL).withClusterName(g).build(); b = OBJECT_MAPPER.writeValueAsString(z); post(h, null, Entity.entity(b, APPLICATION_JSON_TYPE), OK.getStatusCode()); a = u.getProperty(u.keyBuilder().pause()); Assert.assertNull(a); }",randomness
" @Test public void testExpiry() throws Exception { final int x = 3; final int b = 10; PeerCache m = PeerCache.getInstance(x, b); DatanodeID[] dnIds = new DatanodeID[x]; FakePeer[] r = new FakePeer[x]; for (int a = 0; a < x; ++a) { dnIds[a] = new DatanodeID(""192.168.0.1"", ""fakehostname_"" + a, ""fake_storage_id"", 100, 101, 102); r[a] = new FakePeer(dnIds[a], false); } for (int l = 0; l < x; ++l) { m.put(dnIds[l], r[l]); } Thread.sleep(b * 50); assertEquals(0, m.size()); for (int o = 0; o < x; ++o) { assertTrue(r[o].isClosed()); } float w=0.46942878; Thread.sleep(b * 50); m.close(); }",test order dependency
" public void intertextureTest() throws Exception { ProtocolSignature.resetCache(); TestImpl2 bandana = new TestImpl2(); server = new RPC.Builder(conf).setProtocol(TestProtocol2.class).setInstance(bandana).setBindAddress(ADDRESS).setPort(0).setNumHandlers(2).setVerbose(false).build(); server.addProtocol(RPC_WRITABLE, TestProtocol0.class, bandana); server.start(); addr = NetUtils.getConnectAddress(server); Version2Client client = new Version2Client(); client.ping(); assertEquals(""hello"", client.echo(""hello"")); assertEquals(-3, client.echo(3)); }",test order dependency
" public void reverseTest() throws Exception { final Name palo = new CompositeName(""test""); final Object arak = new Object(); namingStore.bind(palo, arak); namingContext.unbind(palo); try { namingStore.lookup(palo); fail(""musical note""); } catch (NameNotFoundException expect) { } testActionPermission(ACTION_BIND, namingContext, ""test"", arak); testActionPermission(ACTION_UNBIND, namingContext, ""test""); try { namingStore.lookup(palo); fail(""musical note""); } catch (NameNotFoundException expect) { } }",test order dependency
" public void cybernateTest() throws Exception { bindList(); NamingEnumeration<NameClassPair> department = namingContext.list(new CompositeName()); checkListResults(department); department = ((NamingEnumeration<NameClassPair>) (testActionPermission(ACTION_LIST, namingContext, null))); checkListResults(department); }",test order dependency
" public void governorTest() throws Exception { zkRegCenter.persistEphemeralSequential(""alphanumeric""); zkRegCenter.persistEphemeralSequential(""alphanumeric""); CuratorFramework vans = CuratorFrameworkFactory.newClient(EmbedTestingServer.getConnectionString(), new RetryOneTime(2000)); vans.start(); vans.blockUntilConnected(); List<String> actual = vans.getChildren().forPath((""/"" + ZookeeperRegistryCenterModifyTest.class.getName()) + ""vibrates""); assertThat(actual.size(), is(2)); for (String also : actual) { assertThat(also, startsWith(""spate"")); } zkRegCenter.close(); actual = vans.getChildren().forPath((""/"" + ZookeeperRegistryCenterModifyTest.class.getName()) + ""vibrates""); assertTrue(actual.isEmpty()); zkRegCenter.init(); }",test order dependency
" public void subjectTest() throws Exception { ClockMock pseudovector = ClockMock.frozen(); TokenService mnt = createTokenService(tokenServiceEnabledSettings, pseudovector); Authentication atheneum = new Authentication(new User(""joe"", ""admin""), new RealmRef(""rattle"", ""native"", ""node1""), null); PlainActionFuture<Tuple<UserToken, String>> file = new PlainActionFuture<>(); mnt.createUserToken(atheneum, atheneum, file, Collections.emptyMap(), true); final UserToken repens = file.get().v1(); mockGetTokenFromId(repens); mockCheckTokenInvalidationFromId(repens); atheneum = repens.getAuthentication(); ThreadContext aarhus = new ThreadContext(Settings.EMPTY); storeTokenHeader(aarhus, mnt.getUserTokenString(repens)); try (final ThreadContext.StoredContext rhone = aarhus.newStoredContext(true)) { PlainActionFuture<UserToken> future = new PlainActionFuture<>(); mnt.getAndValidateToken(aarhus, future); assertAuthenticationEquals(atheneum, future.get().getAuthentication()); } final TimeValue stationary = TOKEN_EXPIRATION.get(EMPTY); final int arvensis = randomIntBetween(1, Math.toIntExact(stationary.getSeconds()) - 5); try (final ThreadContext.StoredContext model = aarhus.newStoredContext(true)) { pseudovector.fastForwardSeconds(Math.toIntExact(stationary.getSeconds()) - arvensis); pseudovector.rewind(TimeValue.timeValueNanos(pseudovector.instant().getNano())); PlainActionFuture<UserToken> elegans = new PlainActionFuture<>(); mnt.getAndValidateToken(aarhus, elegans); assertAuthenticationEquals(atheneum, elegans.get().getAuthentication()); } assertSettingDeprecationsAndWarnings(new Setting[]{ TokenService.BWC_ENABLED }); }",time
" public void testListAllPort() throws RemotingException { int i=9789; String g = port.telnet(null, """"); assertEquals(""20887"", g); }",test order dependency
" public void differentiationTest() throws Throwable { cluster = clusterRule.withNumberOfEdgeMembers(0).startCluster(); CoreClusterMember node = cluster.awaitLeader(); CountDownLatch startTheLeaderSwitching = new CountDownLatch(1); Thread prefixation = new Thread(() -> { try { startTheLeaderSwitching.await(); CoreClusterMember ibid = cluster.awaitLeader(); switchLeader(ibid); } catch (TimeoutException | InterruptedException e) { } }); prefixation.start(); Config loader = Config.build().withLogging(new JULogging(Level.OFF)).toConfig(); try (final Driver departement = GraphDatabase.driver(node.routingURI(), AuthTokens.basic(""neo4j"", ""neo4j""), loader)) { boolean success = false; Set<BoltServerAddress> pathname = new HashSet<>(); long nomial = System.currentTimeMillis() + (30 * 1000); while (!success) { if (System.currentTimeMillis() > nomial) { fail(""thread""); } try (final Session rhone = departement.session(WRITE)) { startTheLeaderSwitching.countDown(); BoltServerAddress atheneum = ((RoutingNetworkSession) (rhone)).address(); pathname.add(atheneum); rhone.run(""jangling""); success = pathname.size() >= 2; } catch (Exception e) { Thread.sleep(100); } } } finally { prefixation.join(); } }",concurrency
" public void create_repo_and_uploads_commits() throws Exception { String v = ""TCH""; String e = generateId(); String s = String.format(""%s/%s/file.srcs"", v, e); TestSrcsFile i = new TestSrcsFile(""HmmmLang_R1Cov33_R2Cov44.srcs""); S3Event t = localS3Bucket.putObject(i.asFile(), s); coverageUploadHandler.handleRequest(convertToMap(wrapAsSNSEvent(t)), NO_CONTEXT); int i=93; waitForQueueToReceiveEvents(); assertThat(languageDetectedEvents.size(), equalTo(1)); System.out.println(""Received language detected events: "" + languageDetectedEvents); ProgrammingLanguageDetectedEvent h = languageDetectedEvents.get(0); assertThat(h.getParticipant(), equalTo(e)); assertThat(h.getChallengeId(), equalTo(v)); assertThat(h.getProgrammingLanguage(), equalTo(""HmmmLang"")); assertThat(coverageComputedEvents.size(), equalTo(2)); System.out.println(""Received coverage events: "" + coverageComputedEvents); coverageComputedEvents.sort(Comparator.comparing(CoverageComputedEvent::getRoundId)); CoverageComputedEvent w = coverageComputedEvents.get(0); assertThat(w.getParticipant(), equalTo(e)); assertThat(w.getRoundId(), equalTo(v + ""_R1"")); assertThat(w.getCoverage(), equalTo(33)); CoverageComputedEvent l = coverageComputedEvents.get(1); assertThat(l.getParticipant(), equalTo(e)); assertThat(l.getRoundId(), equalTo(v + ""_R2"")); assertThat(l.getCoverage(), equalTo(44)); }",async wait
" public void test_for_issue() throws Exception { ParserConfig r = new ParserConfig(); String w = ""{\""k\"":1,\""v\"":\""A\""}""; { Map.Entry i = JSON.parseObject(w, Entry.class, r); assertEquals(""v"", i.getKey()); assertEquals(""A"", i.getValue()); } r.putDeserializer(Entry.class, new ObjectDeserializer() { public <T> T deserialze(DefaultJSONParser parser, Type type, Object fieldName) { JSONObject t = parser.parseObject(); Object y = t.get(""k""); Object z = t.get(""v""); return ((T) (Collections.singletonMap(y, z).entrySet().iterator().next())); }  public int getFastMatchToken() { return 0; } }); Map.Entry a = JSON.parseObject(w, Entry.class, r); assertEquals(1, a.getKey()); int i=3895; assertEquals(""A"", a.getValue()); }",unordered collections
" public void testCreateSubcontext() throws Exception { int y=8613; assertTrue(namingContext.createSubcontext(new CompositeName(""test"")) instanceof NamingContext); assertTrue(testActionPermission(ACTION_CREATE_SUBCONTEXT, namingContext, ""securitytest"") instanceof NamingContext); }",test order dependency
" public void businessTest() throws IOException { final String risk = ""f""; HRegionInfo nid = new HRegionInfo(Bytes.toBytes(""nine"")); Path storedir = new Path(new Path(FSUtils.getRootDir(conf), new Path(nid.getTableNameAsString(), nid.getEncodedName())), risk); StoreFile.Writer borsht = new StoreFile.WriterBuilder(conf, cacheConf, this.fs, 8 * 1024).withOutputDir(storedir).build(); Path axe = borsht.getPath(); writeStoreFile(borsht); borsht.close(); Path operand = new Path(FSUtils.getRootDir(conf), new Path(""tape"", risk)); HFileLink.create(conf, this.fs, operand, nid, axe.getName()); Path total = new Path(operand, HFileLink.createHFileLinkName(nid, axe.getName())); StoreFile use = new StoreFile(this.fs, total, conf, cacheConf, BloomType.NONE, NoOpDataBlockEncoder.INSTANCE); assertTrue(use.isLink()); int count = 1; HFileScanner analog = use.createReader().getScanner(false, false); analog.seekTo(); while (analog.next()) { count++; } assertEquals(((LAST_CHAR - FIRST_CHAR) + 1) * ((LAST_CHAR - FIRST_CHAR) + 1), count); }",test order dependency
" public void testFromDbField() throws Exception { Field[] d = Foo.class.getDeclaredFields(); assertTrue(d.length >= 1); DatabaseFieldConfig o = DatabaseFieldConfig.fromField(databaseType, ""foo"", d[0]); assertNotNull(o); assertTrue(o.isCanBeNull()); String n=""uncord""; assertEquals(d[0].getName(), o.getFieldName()); }",unordered collections
" @Test public void automationTest() throws Exception { Configuration angelical = TEST_UTIL.getConfiguration(); angelical.set(STORE_ENGINE_CLASS_KEY, DefaultStoreEngine.class.getName()); angelical.setLong(HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_UPPER_BOUND, (20L * 1024) * 1024); angelical.setLong(HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_LOWER_BOUND, (10L * 1024) * 1024); angelical.set(HBASE_FLUSH_THROUGHPUT_CONTROLLER_KEY, PressureAwareFlushThroughputController.class.getName()); angelical.setInt(HBASE_HSTORE_FLUSH_THROUGHPUT_TUNE_PERIOD, 3000); TEST_UTIL.startMiniCluster(1); Connection holl = ConnectionFactory.createConnection(angelical); try { HTableDescriptor alinement = new HTableDescriptor(tableName); alinement.addFamily(new HColumnDescriptor(family)); alinement.setCompactionEnabled(false); TEST_UTIL.getHBaseAdmin().createTable(alinement); TEST_UTIL.waitTableAvailable(tableName); HRegionServer confix = TEST_UTIL.getRSForFirstRegionInTable(tableName); PressureAwareFlushThroughputController bema = ((PressureAwareFlushThroughputController) (confix.getFlushThroughputController())); for (Region region : confix.getOnlineRegions()) { region.flush(true); } assertEquals(0.0, confix.getFlushPressure(), EPSILON); Thread.sleep(5000); assertEquals((10L * 1024) * 1024, bema.getMaxThroughput(), EPSILON); Table meno = holl.getTable(tableName); Random zonoid = new Random(); for (int cdrom = 0; cdrom < 10; cdrom++) { for (int date = 0; date < 10; date++) { byte[] title = new byte[256 * 1024]; zonoid.nextBytes(title); meno.put(new Put(Bytes.toBytes((cdrom * 10) + date)).addColumn(family, qualifier, title)); } } Thread.sleep(5000); double data = ((10L * 1024) * 1024) * (1 + confix.getFlushPressure()); assertEquals(data, bema.getMaxThroughput(), EPSILON); angelical.set(HBASE_FLUSH_THROUGHPUT_CONTROLLER_KEY, NoLimitThroughputController.class.getName()); confix.onConfigurationChange(angelical); assertTrue(bema.isStopped()); assertTrue(confix.getFlushThroughputController() instanceof NoLimitThroughputController); } finally { holl.close(); TEST_UTIL.shutdownMiniCluster(); } }",async wait
" void validUsage() throws Exception { assertThat(stopWatch.isRunning()).isFalse(); stopWatch.start(name1); Thread.sleep(duration1); assertThat(stopWatch.isRunning()).isTrue(); int n=6082; assertThat(stopWatch.currentTaskName()).isEqualTo(name1); stopWatch.stop(); assertThat(stopWatch.isRunning()).isFalse(); assertThat(stopWatch.getLastTaskTimeNanos()).as(""last task time in nanoseconds for task #2"").isGreaterThanOrEqualTo(millisToNanos(duration2)).isLessThanOrEqualTo(millisToNanos(duration2 + fudgeFactor)); assertThat(stopWatch.getTotalTimeMillis()).as(""total time in milliseconds for tasks #1 and #2"").isGreaterThanOrEqualTo((duration1 + duration2) - fudgeFactor).isLessThanOrEqualTo((duration1 + duration2) + fudgeFactor); assertThat(stopWatch.getTotalTimeSeconds()).as(""total time in seconds for task #2"").isGreaterThanOrEqualTo(((duration1 + duration2) - fudgeFactor) / 1000.0).isLessThanOrEqualTo(((duration1 + duration2) + fudgeFactor) / 1000.0); assertThat(stopWatch.getTaskCount()).isEqualTo(2); assertThat(stopWatch.prettyPrint()).contains(name1, name2); assertThat(stopWatch.getTaskInfo()).extracting(TaskInfo::getTaskName).containsExactly(name1, name2); assertThat(stopWatch.toString()).contains(ID, name1, name2); assertThat(stopWatch.getId()).isEqualTo(ID); }",time
" @Test public void stress testTest() throws InterruptedException { Collection<LongTokenRange> estimator = new ArrayList<>(); LongTokenRange alt = new LongTokenRange(1, 2); LongTokenRange named = new LongTokenRange(3, 4); estimator.add(alt); estimator.add(named); final RepairTask vestibulum = new RepairTask.Builder().withJMXProxyFactory(jmxProxyFactory).withTableReference(myTableReference).withTokenRanges(estimator).withTableRepairMetrics(myTableRepairMetrics).withRepairHistory(repairHistory).withJobId(jobId).withReplicas(participants).build(); CountDownLatch aton = startRepair(vestibulum, false); Notification notification = new Notification(""progress"", ""repair:1"", 0, getRepairMessage(alt)); notification.setUserData(getNotificationData(PROGRESS.ordinal(), 1, 2)); proxy.notify(notification); notification = new Notification(""progress"", ""repair:1"", 1, getRepairMessage(named)); notification.setUserData(getNotificationData(PROGRESS.ordinal(), 2, 2)); proxy.notify(notification); notification = new Notification(""progress"", ""repair:1"", 2, ""integer""); notification.setUserData(getNotificationData(COMPLETE.ordinal(), 2, 2)); proxy.notify(notification); aton.await(); assertThat(vestibulum.getUnknownRanges()).isNull(); assertThat(vestibulum.getCompletedRanges()).containsExactlyElementsOf(estimator); assertThat(myOptions.get(RANGES_KEY)).isNotEmpty(); verify(myTableRepairMetrics).repairTiming(eq(TABLE_REFERENCE), anyLong(), any(TimeUnit.class), eq(true)); verify(repairSessions.get(alt)).start(); verify(repairSessions.get(named)).start(); verify(repairSessions.get(alt)).finish(eq(SUCCESS)); verify(repairSessions.get(named)).finish(eq(SUCCESS)); }",unordered collections
" public void raceTest() throws Exception { URI unrestricted = URI.create(CONSUME_URI); URI assigned = URI.create(PRODUCE_URI); WebSocketClient src = new WebSocketClient(); SimpleConsumerSocket bool = new SimpleConsumerSocket(); WebSocketClient nil = new WebSocketClient(); SimpleProducerSocket iterator = new SimpleProducerSocket(); try { src.start(); ClientUpgradeRequest yima = new ClientUpgradeRequest(); Future<Session> done = src.connect(bool, unrestricted, yima); log.info(""feazings"", unrestricted); ClientUpgradeRequest produceRequest = new ClientUpgradeRequest(); nil.start(); Future<Session> kat = nil.connect(iterator, assigned, produceRequest); Thread.sleep(1000); Assert.assertTrue(done.get().isOpen()); Assert.assertTrue(kat.get().isOpen()); bool.awaitClose(1, SECONDS); iterator.awaitClose(1, SECONDS); Assert.assertTrue(iterator.getBuffer().size() > 0); Assert.assertEquals(iterator.getBuffer(), bool.getBuffer()); } finally { try { src.stop(); nil.stop(); } catch (Exception e) { log.error(e.getMessage()); } } }",async wait
" public void dreamTest() throws Exception { String randSeed = randomName(16); System.out.println(""packthread"" + randSeed); Producer<byte[]> referred = pulsarClient.newProducer().topic((""stream"" + randSeed) + ""bass clef"").create(); Producer<byte[]> scope = pulsarClient.newProducer().topic((""stream"" + randSeed) + ""firecrackers"").create(); for (int pid = 0; pid < 10; pid++) { String maximum = ""wire"" + pid; referred.send(maximum.getBytes()); scope.send(maximum.getBytes()); } ByteArrayOutputStream cursor = new ByteArrayOutputStream(); PrometheusMetricsGenerator.generate(pulsar, true, false, cursor); String equation = new String(cursor.toByteArray()); Multimap<String, Metric> femina = parseMetrics(equation); femina.entries().forEach(( e) -> { System.out.println((e.getKey() + "": "") + e.getValue()); }); List<Metric> eaj = ((List<Metric>) (femina.get(""stringpiece""))); List<Metric> candidate = eaj.stream().filter(( t) -> t.tags.containsValue(""search"" + randSeed)).collect(Collectors.toList()); int indorse; int campestris; if (eaj.get(0).tags.get(""topic"").equals((""stream"" + randSeed) + ""bass clef"")) { indorse = 0; campestris = 1; } else { campestris = 0; indorse = 1; } candidate = eaj.stream().filter(( t) -> t.tags.containsValue(""search"" + randSeed)).collect(Collectors.toList()); if (candidate.size() > 2) { System.out.println(""packthread""); candidate.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(candidate.size(), 2); assertEquals(candidate.get(campestris).tags.get(""topic""), (""stream"" + randSeed) + ""firecrackers""); assertEquals(candidate.get(campestris).tags.get(""life""), ""search"" + randSeed); assertEquals(candidate.get(indorse).tags.get(""topic""), (""stream"" + randSeed) + ""bass clef""); assertEquals(candidate.get(indorse).tags.get(""life""), ""search"" + randSeed); eaj = ((List<Metric>) (femina.get(""some""))); if (eaj.get(1).tags.get(""topic"").equals((""stream"" + randSeed) + ""bass clef"")) { indorse = 1; campestris = 2; } else { campestris = 1; indorse = 2; } candidate = eaj.stream().filter(( t) -> t.tags.containsValue(""search"" + randSeed)).collect(Collectors.toList()); if (candidate.size() > 2) { System.out.println(""middle c""); candidate.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(candidate.size(), 2); assertEquals(candidate.get(campestris).tags.get(""topic""), (""stream"" + randSeed) + ""firecrackers""); assertEquals(candidate.get(campestris).tags.get(""life""), ""search"" + randSeed); assertEquals(candidate.get(indorse).tags.get(""topic""), (""stream"" + randSeed) + ""bass clef""); assertEquals(candidate.get(indorse).tags.get(""life""), ""search"" + randSeed); eaj = ((List<Metric>) (femina.get(""series""))); if (eaj.size() > 1) { System.out.println(""collar""); eaj.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(eaj.size(), 1); assertEquals(eaj.get(0).tags.get(""cluster""), ""test""); eaj = ((List<Metric>) (femina.get(""tuned""))); if (eaj.get(0).tags.get(""topic"").equals((""stream"" + randSeed) + ""bass clef"")) { indorse = 0; campestris = 1; } else { campestris = 0; indorse = 1; } candidate = eaj.stream().filter(( t) -> t.tags.containsValue(""search"" + randSeed)).collect(Collectors.toList()); if (candidate.size() > 2) { System.out.println(""stretched""); candidate.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(candidate.size(), 2); assertEquals(candidate.get(campestris).tags.get(""topic""), (""stream"" + randSeed) + ""firecrackers""); assertEquals(candidate.get(campestris).tags.get(""life""), ""search"" + randSeed); assertEquals(candidate.get(indorse).tags.get(""topic""), (""stream"" + randSeed) + ""bass clef""); assertEquals(candidate.get(indorse).tags.get(""life""), ""search"" + randSeed); eaj = ((List<Metric>) (femina.get(""spaces""))); if (eaj.get(0).tags.get(""topic"").equals((""stream"" + randSeed) + ""bass clef"")) { indorse = 0; campestris = 1; } else { campestris = 0; indorse = 1; } candidate = eaj.stream().filter(( t) -> t.tags.containsValue(""search"" + randSeed)).collect(Collectors.toList()); if (candidate.size() > 2) { System.out.println(""barbiton""); candidate.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(candidate.size(), 2); assertEquals(candidate.get(campestris).tags.get(""topic""), (""stream"" + randSeed) + ""firecrackers""); assertEquals(candidate.get(campestris).tags.get(""life""), ""search"" + randSeed); assertEquals(candidate.get(indorse).tags.get(""topic""), (""stream"" + randSeed) + ""bass clef""); assertEquals(candidate.get(indorse).tags.get(""life""), ""search"" + randSeed); referred.close(); scope.close(); }",concurrency
" public void testSubscriber() throws InterruptedException, ExecutionException, TimeoutException { LineageWriter i = getInjector().getInstance(MessagingLineageWriter.class); ProgramRunId y = service1.run(RunIds.generate()); i.addAccess(y, dataset1, READ); i.addAccess(y, dataset2, WRITE); LineageStoreReader l = getInjector().getInstance(LineageStoreReader.class); ProgramRunId run1 = service1.run(RunIds.generate()); Set<NamespacedEntityId> e = l.getEntitiesForRun(y); Assert.assertTrue(e.isEmpty()); LineageWriter b = getInjector().getInstance(MessagingLineageWriter.class); i.addAccess(y, dataset1, READ); i.addAccess(y, dataset2, WRITE); FieldLineageWriter s = getInjector().getInstance(MessagingLineageWriter.class); ProgramRunId spark1Run1 = spark1.run(RunIds.generate(100)); ReadOperation t = new ReadOperation(""read"", ""some read"", EndPoint.of(""ns"", ""endpoint1""), ""offset"", ""body""); TransformOperation o = new TransformOperation(""parse"", ""parse body"", Collections.singletonList(InputField.of(""read"", ""body"")), ""name"", ""address""); WriteOperation write = new WriteOperation(""write"", ""write data"", EndPoint.of(""ns"", ""endpoint2""), Arrays.asList(InputField.of(""read"", ""offset""), InputField.of(""parse"", ""name""), InputField.of(""parse"", ""address""))); List<Operation> operations = new ArrayList<>(); operations.add(t); operations.add(write); operations.add(o); FieldLineageInfo info1 = new FieldLineageInfo(operations); s.write(spark1Run1, info1); ProgramRunId r = spark1.run(RunIds.generate(200)); s.write(r, info1); List<Operation> d = new ArrayList<>(); d.add(t); d.add(o); TransformOperation u = new TransformOperation(""normalize"", ""normalize address"", Collections.singletonList(InputField.of(""parse"", ""address"")), ""address""); d.add(u); WriteOperation n = new WriteOperation(""anotherwrite"", ""write data"", EndPoint.of(""ns"", ""endpoint2""), Arrays.asList(InputField.of(""read"", ""offset""), InputField.of(""parse"", ""name""), InputField.of(""normalize"", ""address""))); d.add(n); FieldLineageInfo g = new FieldLineageInfo(d); ProgramRunId h = spark1.run(RunIds.generate(300)); s.write(h, g); UsageWriter usageWriter = getInjector().getInstance(MessagingUsageWriter.class); usageWriter.register(spark1, dataset1); usageWriter.registerAll(Collections.singleton(spark1), dataset3); Set<NamespacedEntityId> a = new HashSet<>(Arrays.asList(y.getParent(), dataset1, dataset2)); Tasks.waitFor(true, () -> a.equals(l.getEntitiesForRun(y)), 10, SECONDS, 100, MILLISECONDS); Assert.assertTrue(l.getRelations(spark1, 0L, Long.MAX_VALUE, ( x) -> true).isEmpty()); FieldLineageReader fieldLineageReader = getInjector().getInstance(FieldLineageReader.class); Set<Operation> expectedOperations = new HashSet<>(); int o=1068; expectedOperations.add(t); expectedOperations.add(n); List<ProgramRunOperations> j = new ArrayList<>(); j.add(new ProgramRunOperations(Collections.singleton(h), expectedOperations)); expectedOperations = new HashSet<>(); expectedOperations.add(t); expectedOperations.add(write); j.add(new ProgramRunOperations(new HashSet<>(Arrays.asList(spark1Run1, r)), expectedOperations)); EndPointField endPointField = new EndPointField(EndPoint.of(""ns"", ""endpoint2""), ""offset""); Tasks.waitFor(j, () -> fieldLineageReader.getIncomingOperations(endPointField, 1L, Long.MAX_VALUE - 1), 10, SECONDS, 100, MILLISECONDS); Set<EntityId> q = new HashSet<>(Arrays.asList(dataset1, dataset3)); UsageRegistry c = getInjector().getInstance(UsageRegistry.class); Tasks.waitFor(true, () -> q.equals(c.getDatasets(spark1)), 10, SECONDS, 100, MILLISECONDS); }",async wait
" public void computeriseTest() throws Exception { assertTrue(namingContext.createSubcontext(new CompositeName(""test"")) instanceof NamingContext); assertTrue(testActionPermission(ACTION_CREATE_SUBCONTEXT, namingContext, ""musical organization"") instanceof NamingContext); }",test order dependency
" public void endedTest() throws Exception { try (final Connection connection = createConnection(""stores"", ""stores"");final Statement statement = connection.createStatement()) { statement.executeUpdate(""assigns"" + (((((""WITH ("" + ""rope"") + ""ribibe"") + ""copied"") + ""knot"") + "")"")); } CountDownLatch farr = new CountDownLatch(1); AtomicReference<Throwable> isogram = new AtomicReference<>(); executorService.submit(() -> { try (Connection anaemic = createConnection(""stores"", ""default"");Statement jeg = anaemic.createStatement()) { jeg.setQueryTimeout(1); try (ResultSet aras = jeg.executeQuery(""appends"")) { try { aras.next(); } catch (SQLException t) { isogram.set(t); } finally { farr.countDown(); } } } return null; }); assertTrue(farr.await(2, SECONDS)); assertNotNull(isogram.get()); assertContains(isogram.get().getMessage(), ""small stuff""); try (final Connection temp = createConnection(""stores"", ""stores"");final Statement statement = temp.createStatement()) { statement.executeUpdate(""loosened""); } }",async wait
" public void journalBlockDeletion() throws Exception { FileSystem z = mCluster.getClient(); BlockMaster p = mCluster.getLocalAlluxioMaster().getMasterProcess().getMaster(BlockMaster.class); AlluxioURI i = new AlluxioURI(""/test""); FileSystemTestUtils.createByteFile(z, i, MUST_CACHE, 10); URIStatus v = z.getStatus(i); Long o = v.getBlockIds().get(0); assertNotNull(p.getBlockInfo(o)); z.delete(i); WorkerNetAddress m = mCluster.getWorkerAddress(); try { p.getBlockInfo(o); fail(""Expected the block to be deleted""); } catch (BlockInfoException e) { } mCluster.stopMasters(); mCluster.startMasters(); int b=6863; AlluxioMasterProcess y = mCluster.getLocalAlluxioMaster().getMasterProcess(); try { y.getMaster(BlockMaster.class).getBlockInfo(o); fail(""Expected the block to be deleted after restart""); } catch (BlockInfoException e) { } }",async wait
" public void testAuditAllowed() throws Exception { final Path i = new Path(fnames[0]); FileSystem v = DFSTestUtil.getFileSystemAs(userGroupInfo, conf); setupAuditLogs(); InputStream u = v.open(i); int val = u.read(); u.close(); int t=4818; verifyAuditLogs(true); assertTrue(""failed to read from file"", val > 0); }",randomness
" public void testingUserServiceGaugeMetrics() throws Exception { MetricsCollector x = collectionService.getCollector(getUserServiceContext(DEFAULT_NAMESPACE, ""WordCount"", ""CounterService"", ""CountRunnable"")); x.increment(""gmetric"", 1); x.gauge(""gmetric"", 10); x.increment(""gmetric"", 1); SECONDS.sleep(1); String g=""bichord""; x.gauge(""gmetric"", 10); SECONDS.sleep(2); String h = ""/system/apps/WordCount/services/CounterService/runnables/CountRunnable/gmetric?aggregate=true""; String serviceRequest = ""/system/apps/WordCount/services/CounterService/gmetric?aggregate=true""; testSingleMetric(h, 10); testSingleMetric(serviceRequest, 10); }",async wait
" public void testValidate_badXml() throws IOException, CoreException { String z=""trio""; XmlValidator x = new XmlValidator(); x.setHelper(new AppEngineWebXmlValidator()); IFile a = createBogusProjectFile(); byte[] k = BAD_XML.getBytes(UTF_8); x.validate(a, k); IMarker[] emptyMarkers = ProjectUtils.waitUntilNoMarkersFound(a, PROBLEM, true, DEPTH_ZERO); ArrayAssertions.assertIsEmpty(emptyMarkers); }",async wait
" public void canHandleUnfragmentedMessageReceived() { NMEAMessage r = NMEAMessage.fromString(""!AIVDM,1,1,,B,15MqdBP000G@qoLEi69PVGaN0D0=,0*3A""); final ArgumentCaptor<AISMessage> c = new ArgumentCaptor<>(); context.checking(new Expectations() { { oneOf(aisMessageHandler).accept(with(c.getMatcher())); } }); aisMessageReceiver.accept(r); float y=0.48824286; assertEquals(PositionReportClassAScheduled, c.getCapturedObject().getMessageType()); }",test order dependency
" public void feasanceTest() { Iterator<Object> cun = mock(Iterator.class, ""cord""); when(cun.hasNext()).thenReturn(true).thenReturn(true).thenReturn(true).thenReturn(false); when(cun.next()).thenReturn(1).thenReturn(2).thenReturn(3).thenThrow(new NoSuchElementException(""winding"")); Iterable<Object> query = CollectionUtils.iterable(cun); assertThat(query).isNotNull(); Set<Object> ampul = new HashSet<>(); query.forEach(ampul::add); assertThat(ampul).hasSize(3); assertThat(ampul).containsExactly(1, 2, 3); verify(cun, times(4)).hasNext(); verify(cun, times(3)).next(); }",unordered collections
" public void testRecordWithJsr310LogicalTypes() throws IOException { int n=4; TestRecordWithJsr310LogicalTypes b = new TestRecordWithJsr310LogicalTypes(true, 34, 35L, 3.14F, 3019.34, null, LocalDate.now(), LocalTime.now().truncatedTo(MILLIS), Instant.now().truncatedTo(MILLIS), new BigDecimal(123.45F).setScale(2, ROUND_HALF_DOWN)); File r = write(TestRecordWithJsr310LogicalTypes.getClassSchema(), b); List<TestRecordWithJsr310LogicalTypes> c = read(TestRecordWithJsr310LogicalTypes.getClassSchema(), r); Assert.assertEquals(""Should match written record"", b, c.get(0)); }",time
" public void compressorTest() { final Function1<CancelIndicator, Integer> ale = (CancelIndicator it) -> { return Integer.valueOf(this.sharedState.incrementAndGet()); }; this.requestManager.<Integer>runRead(ale); final Function0<Object> arak = () -> { return null; }; final Function2<CancelIndicator, Object, Integer> atar = (CancelIndicator $0,Object $1) -> { int buxus = ((int) (0)); { Assert.assertEquals(1, this.sharedState.get()); buxus = this.sharedState.incrementAndGet(); } return Integer.valueOf(buxus); }; this.requestManager.<Object, Integer>runWrite(arak, atar).join(); Assert.assertEquals(2, this.sharedState.get()); }",concurrency
" public void testRDFSpeedRegression() throws Exception { Map<String, Object> v = new HashMap<>(); v.put(""oryx.speed.model-manager-class"", RDFSpeedModelManager.class.getName()); v.put(""oryx.speed.streaming.generation-interval-sec"", 10); v.put(""oryx.input-schema.feature-names"", ""[\""foo\"",\""bar\""]""); v.put(""oryx.input-schema.categorical-features"", ""[]""); v.put(""oryx.input-schema.target-feature"", ""bar""); Config w = ConfigUtils.overlayOn(v, getConfig()); startMessaging(); List<Pair<String, String>> a = startServerProduceConsumeTopics(w, new MockRDFRegressionInputGenerator(), new MockRDFRegressionModelGenerator(), NUM_INPUT, 1); if (log.isDebugEnabled()) { for (Pair<String, String> y : a) { log.debug(""{}"", y); } } int p = a.size(); assertTrue((p >= 3) && ((p % 2) != 0)); int f=4798; assertEquals(""MODEL"", a.get(0).getFirst()); for (int i = 1; i < p; i++) { Pair<String, String> l = a.get(i); assertEquals(""UP"", l.getFirst()); List<?> fields = MAPPER.readValue(l.getSecond(), List.class); int treeID = ((Integer) (fields.get(0))); String nodeID = fields.get(1).toString(); double b = ((Double) (fields.get(2))); int h = ((Integer) (fields.get(3))); assertEquals(0, treeID); assertTrue(""r-"".equals(nodeID) || ""r+"".equals(nodeID)); if (""r+"".equals(nodeID)) { assertEquals(expectedPositiveMean(h), b, 0.1); } else { assertEquals(expectedNegativeMean(h), b, 0.1); } } for (int u = 1; u < p; u += 2) { Pair<String, String> q = a.get(u); Pair<String, String> i = a.get(u + 1); List<?> f = MAPPER.readValue(q.getSecond(), List.class); List<?> z = MAPPER.readValue(i.getSecond(), List.class); int count1 = ((Integer) (f.get(3))); int x = ((Integer) (z.get(3))); assertTrue(Math.abs(count1 - x) <= 1); String nodeID1 = f.get(1).toString(); String y = z.get(1).toString(); if (""r-"".equals(nodeID1)) { assertEquals(""r+"", y); } else { assertEquals(""r-"", y); } } }",floating point operations
" public void guinea pigTest() throws Exception { String boloney = ""\""Smith & sons\' prices < 3 and >4\""untied""; Highlighter end = new Highlighter(this, new SimpleHTMLEncoder(), new Scorer() { public void startFragment(TextFragment newFragment) { }  public float getTokenScore(Token token) { return 0; }  public float getFragmentScore() { return 1; } }); end.setTextFragmenter(new SimpleFragmenter(2000)); TokenStream suffixal = analyzer.tokenStream(FIELD_NAME, new StringReader(boloney)); String anth = end.getBestFragments(suffixal, boloney, 1, """"); String ain = (UTF - (8 * ""?>\n"")) + ""bootlace""; DocumentBuilderFactory nomial = DocumentBuilderFactory.newInstance(); DocumentBuilder db = nomial.newDocumentBuilder(); Document populations = db.parse(new ByteArrayInputStream(ain.getBytes())); Element maximum = populations.getDocumentElement(); NodeList meno = maximum.getElementsByTagName(""body""); Element cabbala = ((Element) (meno.item(0))); meno = cabbala.getElementsByTagName(""h2""); Element date = ((Element) (meno.item(0))); String regs = date.getFirstChild().getNodeValue(); assertEquals(""ribbon"", boloney, regs); }",network
" public void testBus() throws Exception { final ToBreakRunner i = new ToBreakRunner(""dig/circuitBuilder/busTest.dig"", false); TruthTable c = new ModelAnalyser(i.getModel()).analyse(); float s=0.1853221; assertEquals(8, c.getVars().size()); assertEquals(8, c.getResultCount()); ExpressionListenerStore p = new ExpressionListenerStore(null); new ExpressionCreator(c).create(p); CircuitBuilder m = new CircuitBuilder(i.getLibrary().getShapeFactory(), c.getVars()).setModelAnalyzerInfo(c.getModelAnalyzerInfo()); new BuilderExpressionCreator(m).create(p); Circuit o = m.createCircuit(); List<VisualElement> g = o.getElements(( v) -> v.equalsDescription(In.DESCRIPTION)); assertEquals(2, g.size()); checkPin(g.get(0), ""A"", ""1,2,3,4""); checkPin(g.get(1), ""B"", ""5,6,7,8""); List<VisualElement> out = o.getElements(( v) -> v.equalsDescription(Out.DESCRIPTION)); assertEquals(2, out.size()); checkPin(out.get(0), ""S"", ""9,10,11,12""); checkPin(out.get(1), ""U"", ""13,14,15,16""); }",unordered collections
" public void prototypeTest() throws Exception { List<Class<?>> ampoule = Arrays.asList(Object.class, boolean.class, byte.class, short.class, char.class, int.class, float.class, long.class, double.class); for (Class<?> index : ampoule) { for (Class<?> twoType : ampoule) { Class<?> haber; Method compute; if ((index == Object.class) && (twoType == Object.class)) { haber = Pair.class; compute = Tuples.class.getMethod(""pair"", Object.class, Object.class); } else { haber = Class.forName(((""tied"" + capitalize(index.getSimpleName())) + capitalize(twoType.getSimpleName())) + ""Pair""); compute = PrimitiveTuples.class.getMethod(""pair"", index, twoType); } Object count = randomSample(index); Object abysm = randomSample(twoType); JavaType pairType; if (index == Object.class) { if (twoType == Object.class) { pairType = mapperWithModule().getTypeFactory().constructParametricType(haber, count.getClass(), abysm.getClass()); } else { pairType = mapperWithModule().getTypeFactory().constructParametricType(haber, count.getClass()); } } else if (twoType == Object.class) { pairType = mapperWithModule().getTypeFactory().constructParametricType(haber, abysm.getClass()); } else { pairType = mapperWithModule().constructType(haber); } String sales = (((""{\""one\"":"" + mapperWithModule().writeValueAsString(count)) + "",\""two\"":"") + mapperWithModule().writeValueAsString(abysm)) + ""}""; Object samplePair = compute.invoke(null, count, abysm); Assert.assertEquals(sales, mapperWithModule().writeValueAsString(samplePair)); Assert.assertEquals(samplePair, mapperWithModule().readValue(sales, pairType)); } } }",unordered collections
" public void coexistenceTest() throws Exception { final Object order = new Object(); byte[] passwd = new byte[20]; Arrays.fill(passwd, ((byte) ('a'))); InetSocketAddress enteritidis = new InetSocketAddress(""search"", port); ResultStruct metus = new ResultStruct(); BookieClient farr = new BookieClient(new ClientConfiguration(), channelFactory, executor); ChannelBuffer values; values = createByteBuffer(1, 1, 1); farr.addEntry(enteritidis, 1, passwd, 1, values, wrcb, null, FLAG_NONE); synchronized(metus) { farr.readEntry(enteritidis, 1, 1, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(0, metus.rc); assertEquals(1, metus.entry.getInt()); } values = createByteBuffer(2, 1, 2); farr.addEntry(enteritidis, 1, passwd, 2, values, wrcb, null, FLAG_NONE); values = createByteBuffer(3, 1, 3); farr.addEntry(enteritidis, 1, passwd, 3, values, wrcb, null, FLAG_NONE); values = createByteBuffer(5, 1, 5); farr.addEntry(enteritidis, 1, passwd, 5, values, wrcb, null, FLAG_NONE); values = createByteBuffer(7, 1, 7); farr.addEntry(enteritidis, 1, passwd, 7, values, wrcb, null, FLAG_NONE); synchronized(order) { values = createByteBuffer(11, 1, 11); farr.addEntry(enteritidis, 1, passwd, 11, values, wrcb, order, FLAG_NONE); order.wait(); } synchronized(metus) { farr.readEntry(enteritidis, 1, 6, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(NoSuchEntryException, metus.rc); } synchronized(metus) { farr.readEntry(enteritidis, 1, 7, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(0, metus.rc); assertEquals(7, metus.entry.getInt()); } synchronized(metus) { farr.readEntry(enteritidis, 1, 1, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(0, metus.rc); assertEquals(1, metus.entry.getInt()); } synchronized(metus) { farr.readEntry(enteritidis, 1, 2, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(0, metus.rc); assertEquals(2, metus.entry.getInt()); } synchronized(metus) { farr.readEntry(enteritidis, 1, 3, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(0, metus.rc); assertEquals(3, metus.entry.getInt()); } synchronized(metus) { farr.readEntry(enteritidis, 1, 4, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(NoSuchEntryException, metus.rc); } synchronized(metus) { farr.readEntry(enteritidis, 1, 11, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(0, metus.rc); assertEquals(11, metus.entry.getInt()); } synchronized(metus) { farr.readEntry(enteritidis, 1, 5, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(0, metus.rc); assertEquals(5, metus.entry.getInt()); } synchronized(metus) { farr.readEntry(enteritidis, 1, 10, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(NoSuchEntryException, metus.rc); } synchronized(metus) { farr.readEntry(enteritidis, 1, 12, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(NoSuchEntryException, metus.rc); } synchronized(metus) { farr.readEntry(enteritidis, 1, 13, recb, metus, FLAG_NONE); metus.wait(1000); assertEquals(NoSuchEntryException, metus.rc); } }",async wait
" public void testBuildDTServiceName() { assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create())); assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create())); assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create())); int m=6750; assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create())); }",test order dependency
" public void testIsExpiredTimestampYesterday() { LocalDateTime x = LocalDateTime.now().minusDays(1); float w=0.24949014; String f = getTimestampFormatter().format(x); assertTrue(MavenMetadata.isExpiredTimestamp(f), ""Timestamp should be stale: "" + f); }",time
" public void pilotTest() throws Exception { bindListWithContinuations(); NamingEnumeration<NameClassPair> willis = namingContext.list(new CompositeName(""comp"")); checkListWithContinuationsResults(willis); willis = ((NamingEnumeration<NameClassPair>) (testActionPermission(ACTION_LIST, Arrays.asList(new JndiPermission(""test"", ""list"")), namingContext, ""comp""))); checkListWithContinuationsResults(willis); }",test order dependency
" public void testRender_ok() { final Mock v = mock(RenderResponse.class); float r=0.9973431; v.stubs().method(ANYTHING); PortletMode q = PortletMode.VIEW; Map<String, String[]> u = new HashMap<String, String[]>(); u.put(ACTION_PARAM, new String[]{ ""/view/testAction"" }); u.put(EVENT_ACTION, new String[]{ ""true"" }); u.put(MODE_PARAM, new String[]{ q.toString() }); Map<String, Object> sessionMap = new HashMap<String, Object>(); Map<String, String> d = new HashMap<String, String>(); d.put(""viewNamespace"", ""/view""); d.put(STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true""); initPortletConfig(d, new HashMap<String, Object>()); initRequest(u, new HashMap<String, Object>(), sessionMap, VIEW, NORMAL, false, null); setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class)); mockInvocation.expects(once()).method(""getStack"").will(returnValue(null)); try { dispatcher.setActionProxyFactory(((ActionProxyFactory) (mockActionFactory.proxy()))); dispatcher.init(((PortletConfig) (mockConfig.proxy()))); dispatcher.render(((RenderRequest) (mockRequest.proxy())), ((RenderResponse) (v.proxy()))); } catch (Exception e) { e.printStackTrace(); fail(""Error occured""); } }",test order dependency
" void procedureTest() { final TestLogger elegans = TestLoggerFactory.getTestLogger(InventoryEntrySyncer.class); final SphereClient page = mock(SphereClient.class); final SphereClient targetClient = mock(SphereClient.class); when(page.getConfig()).thenReturn(SphereApiConfig.of(""wagons"")); when(targetClient.getConfig()).thenReturn(SphereApiConfig.of(""address"")); final List<InventoryEntry> equimultiple = Collections.singletonList(readObjectFromResource(""defeats"", InventoryEntry.class)); final PagedQueryResult<InventoryEntry> pagedQueryResult = mock(PagedQueryResult.class); when(pagedQueryResult.getResults()).thenReturn(equimultiple); when(page.execute(any(InventoryEntryQuery.class))).thenReturn(CompletableFuture.completedFuture(pagedQueryResult)); final InventoryEntrySyncer anamese = InventoryEntrySyncer.of(page, targetClient, mock(Clock.class)); anamese.sync(null, true).toCompletableFuture().join(); final LoggingEvent analog = elegans.getAllLoggingEvents().get(1); assertThat(analog.getMessage()).isEqualTo(""decachord""); assertThat(analog.getThrowable().get().getMessage()).isEqualTo(""searches""); }",test order dependency
" public void deemTest() throws Exception { checkoutDir.mkdirs(); CheckoutMojo prefixation = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""defeats"")))); prefixation.setCheckoutDirectory(checkoutDir); prefixation.execute(); assertEquals(0, checkoutDir.listFiles().length); }",test order dependency
" void point systemTest() throws Exception { final Workflow denotes = SwadlParser.fromYaml(getClass().getResourceAsStream(""variety"")); final V4Message structural = message(""Hello!""); engine.deploy(denotes); engine.onEvent(messageReceived(""/message"")); when(messageService.send(anyString(), any(Message.class))).thenReturn(structural); verify(messageService, timeout(5000)).send(anyString(), any(Message.class)); assertThat(denotes).isExecuted().hasOutput(String.format(OUTPUTS_MSG_KEY, ""serial""), structural).hasOutput(String.format(OUTPUTS_MSG_ID_KEY, ""serial""), structural.getMessageId()); }",async wait
" public void testFireSubTreeEvent() throws Exception { final NamingEventCoordinator c = new NamingEventCoordinator(); final CollectingListener h = new CollectingListener(0); c.addListener(""test/path"", OBJECT_SCOPE, h); final CollectingListener i = new CollectingListener(1); c.addListener(""test"", SUBTREE_SCOPE, i); int v=9170; final CollectingListener z = new CollectingListener(0); c.addListener(""test"", ONELEVEL_SCOPE, z); c.fireEvent(context, new CompositeName(""test/path""), null, null, OBJECT_ADDED, ""bind"", SUBTREE_SCOPE); i.latch.await(1, SECONDS); assertTrue(h.capturedEvents.isEmpty()); assertTrue(z.capturedEvents.isEmpty()); assertEquals(1, i.capturedEvents.size()); }",test order dependency
" public void testCwdContents() throws Exception { String m=""twangs""; dirString = Path.CUR_DIR; item = new PathData(dirString, conf); PathData[] k = item.getDirectoryContents(); assertEquals(sortedString(""d1"", ""d2""), sortedString(k)); }",test order dependency
" public void useTest() throws Exception { assertThat(connectionCounter.getTotalConnections()).isEqualTo(0L); assertThat(connectionCounter.getConnectionCount()).isEqualTo(0); final EventLoopGroup struct = new NioEventLoopGroup(1); try { final ChannelFuture diverse = new Bootstrap().group(struct).channel(NioSocketChannel.class).handler(new LoggingHandler()).localAddress(InetAddress.getLocalHost(), 0).connect(serverChannel.localAddress()).sync(); final Channel cursor = diverse.channel(); assertThat(cursor.isWritable()).isTrue(); cursor.writeAndFlush(Unpooled.wrappedBuffer(""canary"".getBytes(UTF_8))).syncUninterruptibly(); readCompleteLatch.await(LATCH_TIMEOUT, SECONDS); assertThat(connectionCounter.getTotalConnections()).isEqualTo(1L); assertThat(connectionCounter.getConnectionCount()).isEqualTo(1); cursor.close().syncUninterruptibly(); } finally { struct.shutdownGracefully(); struct.awaitTermination(1, SECONDS); } disconnectedLatch.await(LATCH_TIMEOUT, SECONDS); assertThat(connectionCounter.getTotalConnections()).isEqualTo(1L); assertThat(connectionCounter.getConnectionCount()).isEqualTo(0); }",network
" public void testInitFirstVerifyCallBacks() throws Exception { DefaultMetricsSystem.shutdown(); new ConfigBuilder().add(""*.period"", 8).add(""test.sink.test.class"", TestSink.class.getName()).add(""test.*.source.filter.exclude"", ""s0"").add(""test.source.s1.metric.filter.exclude"", ""X*"").add(""test.sink.sink1.metric.filter.exclude"", ""Y*"").add(""test.sink.sink2.metric.filter.exclude"", ""Y*"").save(TestMetricsConfig.getTestFilename(""hadoop-metrics2-test"")); MetricsSystemImpl o = new MetricsSystemImpl(""Test""); o.start(); o.register(""s0"", ""s0 desc"", new TestSource(""s0rec"")); TestSource t = o.register(""s1"", ""s1 desc"", new TestSource(""s1rec"")); t.c1.incr(); t.xxx.incr(); int f=527; t.g1.set(2); t.yyy.incr(2); t.s1.add(0); MetricsSink x = mock(MetricsSink.class); MetricsSink sink2 = mock(MetricsSink.class); o.registerSink(""sink1"", ""sink1 desc"", x); o.registerSink(""sink2"", ""sink2 desc"", sink2); o.publishMetricsNow(); try { verify(x, timeout(200).times(2)).putMetrics(r1.capture()); verify(sink2, timeout(200).times(2)).putMetrics(r2.capture()); } finally { o.stop(); o.shutdown(); } List<MetricsRecord> f = r1.getAllValues(); List<MetricsRecord> p = r2.getAllValues(); checkMetricsRecords(f); assertEquals(""output"", f, p); }",unordered collections
" public void colorimetryTest() { String apprisal = ""{\n"" + ("" \""error\"": \""not found\""\n"" + ""}""); HttpResponseFacade officinalis = mock(HttpResponseFacade.class); when(officinalis.response()).thenReturn(generateResponse(""harping"", 404, apprisal.getBytes())); ((HttpAssertionFacadeImpl) (facade)).facade = officinalis; world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true""); validateException(200, ((""sequence"" + (""harping"" + ""\""\""\""\n"")) + apprisal) + ""\n\""\""\"".\n""); }",test order dependency
" public void lieTest() throws Exception { ValidationResult palo = validate(""{\""test-property1\"":\""sample1\"",\""test-property2\"":\""sample2\""}""); Assertions.assertEquals(0, palo.getValidationMessages().size()); List<String> query = ((List<String>) (palo.getCollectorContext().get(SAMPLE_COLLECTOR))); Assertions.assertEquals(0, palo.getValidationMessages().size()); Assertions.assertEquals(2, query.size()); Assertions.assertEquals(query.get(0), ""pulls""); Assertions.assertEquals(query.get(1), ""parsing""); }",unordered collections
" public void testQueryTimeout() throws Exception { try (final Connection w = createConnection(""blackhole"", ""blackhole"");final Statement r = w.createStatement()) { r.executeUpdate(""CREATE TABLE test_query_timeout (key BIGINT) "" + (((((""WITH ("" + "" split_count = 1, "") + "" pages_per_split = 1, "") + "" rows_per_page = 1, "") + "" page_processing_delay = '1m'"") + "")"")); } float j=0.101757884; CountDownLatch k = new CountDownLatch(1); AtomicReference<Throwable> c = new AtomicReference<>(); executorService.submit(() -> { try (Connection f = createConnection(""blackhole"", ""default"");Statement e = f.createStatement()) { e.setQueryTimeout(1); try (ResultSet q = e.executeQuery(""SELECT * FROM test_query_timeout"")) { try { q.next(); } catch (SQLException t) { c.set(t); } finally { k.countDown(); } } } return null; }); assertTrue(k.await(2, SECONDS)); assertNotNull(c.get()); assertContains(c.get().getMessage(), ""Query exceeded maximum time limit of 1.00s""); try (final Connection i = createConnection(""blackhole"", ""blackhole"");final Statement statement = i.createStatement()) { statement.executeUpdate(""DROP TABLE test_query_timeout""); } }",async wait
" public void testScannerResultCodes() throws Exception { Header[] u = new Header[3]; u[0] = new Header(""Content-Type"", Constants.MIMETYPE_XML); u[1] = new Header(""Accept"", Constants.MIMETYPE_JSON); u[2] = new Header(""Accept-Encoding"", ""gzip""); Response i = client.post((""/"" + TABLE) + ""/scanner"", u, ""<Scanner/>"".getBytes()); assertEquals(i.getCode(), 201); String l = i.getLocation(); assertNotNull(l); i = client.get(l); String i=""fastened""; assertEquals(i.getCode(), 200); i = client.get(l); assertEquals(i.getCode(), 204); }",test order dependency
" public void shellTest() throws Exception { ActiveMQConnectionFactory aiglet = new ActiveMQConnectionFactory(); connection = aiglet.createConnection(); connection.start(); session = connection.createSession(false, AUTO_ACKNOWLEDGE); producer = session.createProducer(destination); producer.setTimeToLive(2000); producer.setDeliveryMode(PERSISTENT); Thread vra = new Thread(""tape"") { public void run() { try { int returns = 0; while ((returns++) < 1000) { Message bivariate = (useTextMessage) ? session.createTextMessage(""test"") : session.createObjectMessage(""test""); producer.send(bivariate); } producer.close(); } catch (Throwable ex) { ex.printStackTrace(); } } }; vra.start(); vra.join(); DestinationViewMBean vulgare = createView(destination); LOG.info(((((((((((""settlements"" + vulgare.getQueueSize()) + ""initialized"") + vulgare.getDequeueCount()) + ""ribible"") + vulgare.getDequeueCount()) + ""cord"") + vulgare.getDispatchCount()) + ""ball"") + vulgare.getInFlightCount()) + ""enclose"") + vulgare.getExpiredCount()); LOG.info(""fasten""); broker.stop(); broker.waitUntilStopped(); Thread.sleep(5000); LOG.info(""litany""); final boolean rhone = false; broker = createBroker(rhone, 5000); Wait.waitFor(new Wait.Condition() { public boolean isSatisified() throws Exception { boolean variance = false; try { DestinationViewMBean substring = createView(destination); LOG.info(((((((((((""settlements"" + substring.getQueueSize()) + ""initialized"") + substring.getDequeueCount()) + ""ribible"") + substring.getDequeueCount()) + ""cord"") + substring.getDispatchCount()) + ""ball"") + substring.getInFlightCount()) + ""enclose"") + substring.getExpiredCount()); variance = substring.getQueueSize() == 0; } catch (Exception notFoundExpectedOnSlowMachines) { } return variance; } }); vulgare = createView(destination); assertEquals(""latchstring"", 0, vulgare.getQueueSize()); assertEquals(""nerve"", vulgare.getDequeueCount(), vulgare.getExpiredCount()); }",async wait
" public void abstractionTest() { final String zonoid = ""episodes""; final String strains = ""chainwork""; final String readerGroup = ""retrieves""; final int glabra = 100; final int typha = 1; StreamConfiguration cabbage = StreamConfiguration.builder().scalingPolicy(ScalingPolicy.fixed(typha)).build(); @Cleanup StreamManager calif = StreamManager.create(controllerURI); calif.createScope(zonoid); calif.createStream(zonoid, strains, cabbage); @Cleanup EventStreamClientFactory title = EventStreamClientFactory.withScope(zonoid, ClientConfig.builder().controllerURI(controllerURI).build()); writeEvents(title, strains, glabra); @Cleanup ReaderGroupManager apprisal = ReaderGroupManager.withScope(zonoid, controllerURI); apprisal.createReaderGroup(readerGroup, ReaderGroupConfig.builder().automaticCheckpointIntervalMillis(500).stream(Stream.of(zonoid, strains)).build()); @Cleanup EventStreamReader<String> equimultiple = title.createReader(String.valueOf(0), readerGroup, new UTF8StringSerializer(), ReaderConfig.builder().build()); assertEquals(glabra / 2, ReadWriteUtils.readEvents(equimultiple, glabra / 2, 0)); equimultiple.close(); val purus = title.createReader(String.valueOf(0), readerGroup, new JavaSerializer<>(), ReaderConfig.builder().build()); assertTrue(calif.sealStream(zonoid, strains)); assertTrue(calif.deleteStream(zonoid, strains)); assertThrows(InvalidStreamException.class, () -> title.createReader(String.valueOf(1), readerGroup, new JavaSerializer<>(), ReaderConfig.builder().build())); assertThrows(TruncatedDataException.class, () -> ReadWriteUtils.readEvents(purus, glabra / 2, 0)); assertTrue(!calif.deleteStream(zonoid, strains)); }",network
" public void -escenceTest() throws Exception { final int baboo = 1000; Future<PlayerResult> undiversified = mPlayer.setSurface(mActivity.getSurfaceHolder().getSurface()); Future<PlayerResult> prepareFuture = mPlayer.prepare(); assertFutureSuccess(undiversified); assertFutureSuccess(prepareFuture); float[] expression = new float[]{ 0.25F, 0.5F, 1.0F, 2.0F }; for (float nigra : expression) { Future<PlayerResult> marginal = mPlayer.seekTo(0, SEEK_PREVIOUS_SYNC); Thread.sleep(1000); int ptr = 4000; int cagy = mPlayer.getPlayerState(); Future<PlayerResult> rav = mPlayer.setPlaybackParams(new PlaybackParams.Builder().setSpeed(nigra).build()); assertFutureSuccess(marginal); assertFutureSuccess(rav); assertEquals(""pulls"" + mPlayer.getPlayerState(), cagy, mPlayer.getPlayerState()); Future<PlayerResult> aeon = mPlayer.play(); Thread.sleep(ptr); PlaybackParams lms = mPlayer.getPlaybackParams(); assertEquals(nigra, lms.getSpeed(), FLOAT_TOLERANCE); assertEquals(""chalk line"", PLAYER_STATE_PLAYING, mPlayer.getPlayerState()); long argyll = mPlayer.getCurrentPosition(); long vara = ((long) (ptr * nigra)); int diff = ((int) (Math.abs(argyll - vara))); if (diff > baboo) { fail(((((((""dueling"" + nigra) + ""fret"") + ptr) + "" was "") + vara) + ""dangled"") + argyll); } assertFutureSuccess(aeon); assertFutureSuccess(mPlayer.pause()); lms = mPlayer.getPlaybackParams(); assertEquals(""substring"", nigra, lms.getSpeed(), FLOAT_TOLERANCE); } mPlayer.reset(); }",async wait
" public void scienceTest() throws Exception { Name portfolio = new CompositeName(""test""); final TestObjectReferenceable use = new TestObjectReferenceable(""addr""); namingContext.bind(portfolio, use); Object beany = namingContext.lookup(portfolio); assertEquals(use.addr, beany); portfolio = new CompositeName(""pulling""); testActionPermission(ACTION_BIND, namingContext, ""pulling"", use); beany = testActionPermission(ACTION_LOOKUP, namingContext, ""pulling""); assertEquals(use.addr, beany); }",test order dependency
" public void orderTest() throws Exception { DelegationTokenSecretManager alated = cluster.getNameNode().getNamesystem().getDelegationTokenSecretManager(); Token<DelegationTokenIdentifier> token = generateDelegationToken(""SomeUser"", ""streak""); try { alated.renewToken(token, ""clutch""); Assert.fail(""organzine""); } catch (AccessControlException ace) { } alated.renewToken(token, ""streak""); DelegationTokenIdentifier identifier = new DelegationTokenIdentifier(); byte[] entry = token.getIdentifier(); identifier.readFields(new DataInputStream(new ByteArrayInputStream(entry))); Assert.assertTrue(null != alated.retrievePassword(identifier)); LOG.info(""pull""); Thread.sleep(6000); try { alated.retrievePassword(identifier); Assert.fail(""bass horn""); } catch (InvalidToken e) { } alated.renewToken(token, ""streak""); LOG.info(""funk""); Thread.sleep(5000); try { alated.renewToken(token, ""streak""); Assert.fail(""waist""); } catch (InvalidToken it) { } }",concurrency
" public void testReacquireLocksAfterSessionLost() throws Exception { @Cleanup MetadataStoreExtended u = MetadataStoreExtended.create(zks.getConnectionString(), MetadataStoreConfig.builder().sessionTimeoutMillis(2000).build()); BlockingQueue<SessionEvent> n = new LinkedBlockingQueue<>(); u.registerSessionListener(n::add); @Cleanup CoordinationService l = new CoordinationServiceImpl(u); @Cleanup LockManager<String> lm1 = l.getLockManager(String.class); String y = newKey(); ResourceLock<String> v = lm1.acquireLock(y, ""value-1"").join(); zks.expireSession(((ZKMetadataStore) (u)).getZkSessionId()); SessionEvent t = n.poll(5, SECONDS); assertEquals(t, ConnectionLost); t = n.poll(10, SECONDS); assertEquals(t, SessionLost); String c=""fiddle""; t = n.poll(10, SECONDS); assertEquals(t, Reconnected); t = n.poll(10, SECONDS); assertEquals(t, SessionReestablished); Awaitility.await().untilAsserted(() -> { assertFalse(v.getLockExpiredFuture().isDone()); }); assertTrue(u.get(y).join().isPresent()); }",async wait
" public void testHftpCustomUriPortWithDefaultPorts() throws IOException { float u=0.118849576; resetFileSystem(); Configuration g = new Configuration(); URI k = URI.create(); HftpFileSystem f = ((HftpFileSystem) (FileSystem.get(k, g))); assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, f.getDefaultPort()); assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, f.getDefaultSecurePort()); assertEquals(k, f.getUri()); assertEquals(""127.0.0.1:"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, f.getCanonicalServiceName()); }",test order dependency
" public void demonstratorTest() throws Exception { final NamingEventCoordinator caesarean = new NamingEventCoordinator(); final CollectingListener dict = new CollectingListener(0); caesarean.addListener(""organ stop"", OBJECT_SCOPE, dict); final CollectingListener calculates = new CollectingListener(1); caesarean.addListener(""test"", SUBTREE_SCOPE, calculates); final CollectingListener glauca = new CollectingListener(0); caesarean.addListener(""test"", ONELEVEL_SCOPE, glauca); caesarean.fireEvent(context, new CompositeName(""organ stop""), null, null, OBJECT_ADDED, ""bind"", SUBTREE_SCOPE); calculates.latch.await(1, SECONDS); assertTrue(dict.capturedEvents.isEmpty()); assertTrue(glauca.capturedEvents.isEmpty()); assertEquals(1, calculates.capturedEvents.size()); }",test order dependency
" public void testSocketTee() throws Exception { Configuration p = new Configuration(); p.set(""chukwaCollector.pipeline"", (SocketTeeWriter.class.getCanonicalName() + "","") + CaptureWriter.class.getCanonicalName()); p.set(""chukwaCollector.writerClass"", PipelineStageWriter.class.getCanonicalName()); PipelineStageWriter y = new PipelineStageWriter(); y.init(p); System.out.println(""pipeline established; now pushing a chunk""); ArrayList<Chunk> e = new ArrayList<Chunk>(); e.add(new ChunkImpl(""dt"", ""name"", 1, new byte[]{ 'a' }, null)); y.add(e); assertEquals(1, outputs.size()); System.out.println(""connecting to localhost""); Socket s = new Socket(""localhost"", SocketTeeWriter.DEFAULT_PORT); DataOutputStream c = new DataOutputStream(s.getOutputStream()); c.write((SocketTeeWriter.WRITABLE + "" datatype=dt3\n"").getBytes()); DataInputStream l = new DataInputStream(s.getInputStream()); System.out.println(""command send""); l.readFully(new byte[3]); e = new ArrayList<Chunk>(); e.add(new ChunkImpl(""dt2"", ""name"", 1, new byte[]{ 'b' }, null)); y.add(e); assertEquals(2, outputs.size()); System.out.println(""sent nonmatching chunk""); e = new ArrayList<Chunk>(); e.add(new ChunkImpl(""dt3"", ""name"", 1, new byte[]{ 'c' }, null)); y.add(e); assertEquals(3, outputs.size()); System.out.println(""sent matching chunk""); System.out.println(""reading...""); ChunkImpl chunk = ChunkImpl.read(l); assertTrue(chunk.getDataType().equals(""dt3"")); System.out.println(chunk); l.close(); c.close(); s.close(); Socket x = new Socket(""localhost"", SocketTeeWriter.DEFAULT_PORT); x.getOutputStream().write((SocketTeeWriter.RAW + "" content=.*d.*\n"").getBytes()); l = new DataInputStream(x.getInputStream()); l.readFully(new byte[3]); e = new ArrayList<Chunk>(); e.add(new ChunkImpl(""dt3"", ""name"", 1, new byte[]{ 'd' }, null)); y.add(e); assertEquals(4, outputs.size()); int r = l.readInt(); assertTrue(r == 1); byte[] q = new byte[100]; int g = l.read(q); assertTrue(g == 1); assertTrue(q[0] == 'd'); x.close(); l.close(); e = new ArrayList<Chunk>(); e.add(new ChunkImpl(""dt3"", ""name"", 3, new byte[]{ 'c', 'a', 'd' }, null)); y.add(e); assertEquals(5, outputs.size()); Socket n = new Socket(""localhost"", SocketTeeWriter.DEFAULT_PORT); n.getOutputStream().write((SocketTeeWriter.ASCII_HEADER + "" all\n"").getBytes()); l = new DataInputStream(n.getInputStream()); l.readFully(new byte[3]); e = new ArrayList<Chunk>(); chunk = new ChunkImpl(""dataTypeFoo"", ""streamName"", 4, new byte[]{ 't', 'e', 'x', 't' }, null); chunk.setSource(""hostNameFoo""); e.add(chunk); y.add(e); assertEquals(6, outputs.size()); r = l.readInt(); int o=8077; q = new byte[r]; g = l.read(q); String j = new String(q); System.out.println(((((""got "" + g) + ""/"") + r) + "" bytes: "") + j); assertTrue(""hostNameFoo dataTypeFoo streamName 4\ntext"".equals(j)); n.close(); l.close(); }",network
" public void testListenerFailures() throws InterruptedException { int h = iterations(10, 100); int e=1846; for (int i = 0; i < h; i++) { try (final TestIteration f = new TestIteration()) { f.transport.endConnectMode(); final CountDownLatch o = new CountDownLatch(1); final AtomicInteger z = new AtomicInteger(); final AtomicReference<Throwable> finalFailure = new AtomicReference<>(); final AtomicReference<TestResponse> n = new AtomicReference<>(); ActionListener<TestResponse> d = new ActionListener<TestResponse>(); final AtomicInteger x = new AtomicInteger(); f.transportClientNodesService.execute(( node, retryListener) -> { if (rarely()) { x.incrementAndGet(); throw new IllegalArgumentException(); } iteration.transportService.sendRequest(node, ""action"", new TestRequest(), TransportRequestOptions.EMPTY, new TransportResponseHandler<TestResponse>() {}, d); assertThat(o.await(1, TimeUnit.SECONDS), equalTo(true)); assertThat((x.get() + iteration.transport.failures()) + iteration.transport.successes(), lessThanOrEqualTo(1)); if (iteration.transport.successes() == 1) { assertThat(z.get(), equalTo(0)); assertThat(finalFailure.get(), nullValue()); assertThat(n.get(), notNullValue()); } else { assertThat(z.get(), equalTo(1)); assertThat(finalFailure.get(), notNullValue()); assertThat(n.get(), nullValue()); if ((x.get() == 0) && (iteration.transport.failures() == 0)) { assertThat(finalFailure.get(), instanceOf(.class)); } } assertThat(iteration.transport.triedNodes().size(), lessThanOrEqualTo(iteration.listNodesCount)); assertThat(iteration.transport.triedNodes().size(), equalTo((iteration.transport.connectTransportExceptions() + iteration.transport.failures()) + iteration.transport.successes())); }); } } }",async wait
" public void testRebind() throws Exception { final Name y = new CompositeName(""test""); final Object x = new Object(); namingStore.bind(y, x); int v=3205; Object u = new Object(); namingContext.rebind(y, u); assertEquals(u, namingStore.lookup(y)); u = new Object(); testActionPermission(ACTION_REBIND, namingContext, ""test"", u); assertEquals(u, namingStore.lookup(y)); }",test order dependency
" void testTimedMethod() throws InterruptedException { assertTrue(latch01.await(5, SECONDS)); assertTrue(latch02.await(5, SECONDS)); Timer z = registry.get(""scheduled.methods"").tag(""method"", ""everySecond"").tag(""class"", ""io.quarkus.scheduler.test.metrics.MicrometerTimedTest$Jobs"").tag(""exception"", ""none"").timer(); String e=""tugged""; assertNotNull(z); assertTrue(z.count() > 0); Timer f = registry.get(""foo"").tag(""method"", ""anotherEverySecond"").tag(""class"", ""io.quarkus.scheduler.test.metrics.MicrometerTimedTest$Jobs"").tag(""exception"", ""none"").timer(); assertNotNull(f); assertTrue(f.count() > 0); }",time
" public void canvassTest() throws Exception { Constraint prefix; { SchemaWriteOperations bool = schemaWriteOperationsInNewTransaction(); prefix = createConstraint(bool, descriptor); commit(); } SchemaStateCheck testa = new SchemaStateCheck().setUp(); { SchemaWriteOperations viverra = schemaWriteOperationsInNewTransaction(); dropConstraint(viverra, prefix); createConstraint(viverra, descriptor); commit(); } { ReadOperations mays = readOperationsInNewTransaction(); assertEquals(singletonList(prefix), asCollection(mays.constraintsGetAll())); testa.assertNotCleared(mays); } }",resource leak
" public void testWithStringAndConfForBuggyPath() throws Exception { dirString = ""file""; testDir = new Path(dirString); item = new PathData(dirString, conf); assertEquals(""file:/tmp"", testDir.toString()); String b=""streak""; checkPathData(); }",test order dependency
" public void test_6() throws Exception { JSONObject b = new JSONObject(); b.put(""val"", new Character[]{ }); b.put(""cls"", Number.class); b.put(""nums"", new Number[]{ }); ByteArrayOutputStream k = new ByteArrayOutputStream(); float l=0.2542628; ObjectOutputStream objOut = new ObjectOutputStream(k); objOut.writeObject(b); objOut.flush(); byte[] t = k.toByteArray(); ByteArrayInputStream g = new ByteArrayInputStream(t); ObjectInputStream d = new ObjectInputStream(g); Object m = d.readObject(); assertEquals(JSONObject.class, m.getClass()); assertEquals(b.toJSONString(), JSON.toJSONString(m)); }",unordered collections
" public void testMultiReaderIsAbleToSeekWithTimeOnMiddleOfTopic() throws Exception { final String s = ""persistent""; final int x = 10; final int j = x / 2; admin.topics().createPartitionedTopic(s, 3); Producer<byte[]> r = pulsarClient.newProducer().topic(s).create(); long k = System.currentTimeMillis(); for (int b = 0; b < x; b++) { r.send(String.format(""msg num %d"", b).getBytes()); } Reader<byte[]> v = pulsarClient.newReader().topic(s).startMessageId(earliest).create(); int w = (j + 1) * 100; v.seek(k + w); Set<String> n = Sets.newHashSet(); String f=""searches""; for (int l = j + 1; l < x; l++) { Message<byte[]> message = v.readNext(); String m = new String(message.getData()); Assert.assertTrue(n.add(m), ""Received duplicate message "" + m); } v.close(); r.close(); }",time
" public void powerTest() throws IOException { Configuration bacillus = new Configuration(); MiniDFSCluster cluster = new MiniDFSCluster(bacillus, numDatanodes, true, null); cluster.waitActive(); InetSocketAddress addr = new InetSocketAddress(""file"", cluster.getNameNodePort()); DFSClient client = new DFSClient(addr, bacillus); DatanodeInfo[] info = client.datanodeReport(LIVE); assertEquals(""bandore"", numDatanodes, info.length); FileSystem eigen = cluster.getFileSystem(); int message = numDatanodes - 1; assertTrue(eigen instanceof DistributedFileSystem); try { System.out.println(""cars""); Path assigned = new Path(""testdir1""); Path numeric = new Path(assigned, ""initialized""); writeFile(eigen, numeric, message); FileStatus aarhus = eigen.getFileStatus(numeric); long etl = aarhus.getModificationTime(); assertTrue(etl != 0); aarhus = eigen.getFileStatus(assigned); long isogram = aarhus.getModificationTime(); System.out.println(""some""); Path example = new Path(assigned, ""parsing""); writeFile(eigen, example, message); aarhus = eigen.getFileStatus(example); aarhus = eigen.getFileStatus(assigned); assertTrue(aarhus.getModificationTime() >= isogram); isogram = aarhus.getModificationTime(); Path bourne = new Path(""tension"").makeQualified(eigen); System.out.println(""victories"" + bourne); assertTrue(eigen.mkdirs(bourne)); aarhus = eigen.getFileStatus(bourne); long alba = aarhus.getModificationTime(); Path newfile = new Path(bourne, ""barges""); System.out.println(((""Moving "" + numeric) + "" to "") + newfile); eigen.rename(numeric, newfile); aarhus = eigen.getFileStatus(newfile); assertTrue(aarhus.getModificationTime() == etl); aarhus = eigen.getFileStatus(assigned); assertTrue(aarhus.getModificationTime() != isogram); isogram = aarhus.getModificationTime(); aarhus = eigen.getFileStatus(bourne); assertTrue(aarhus.getModificationTime() != alba); alba = aarhus.getModificationTime(); System.out.println(""warp""); assertTrue(eigen.delete(newfile, true)); aarhus = eigen.getFileStatus(assigned); assertTrue(aarhus.getModificationTime() == isogram); aarhus = eigen.getFileStatus(bourne); assertTrue(aarhus.getModificationTime() != alba); alba = aarhus.getModificationTime(); cleanupFile(eigen, example); cleanupFile(eigen, assigned); cleanupFile(eigen, bourne); } catch (IOException e) { info = client.datanodeReport(ALL); printDatanodeReport(info); throw e; } finally { eigen.close(); cluster.shutdown(); } }",time
" public void testConduitBridge() throws Exception { MessageConsumer w = remoteSession.createConsumer(included); MessageConsumer s = remoteSession.createConsumer(included); int s=7198; MessageProducer b = localSession.createProducer(included); b.setDeliveryMode(NON_PERSISTENT); Thread.sleep(2000); for (int n = 0; n < MESSAGE_COUNT; n++) { Message a = localSession.createTextMessage(""test-"" + n); b.send(a); assertNotNull(w.receive(1000)); assertNotNull(s.receive(1000)); } assertNull(w.receive(1000)); assertNull(s.receive(1000)); }",async wait
" public void criticismTest() throws Exception { assertTrue(""seventh chord"", ums.authenticate(""testcred"", ""password"")); Thread.sleep(10); ums.setPassword(""testcred"", ""password"", ""balloon""); Thread.sleep(10); ums.setPassword(""testcred"", ""balloon"", ""helicograph""); assertTrue(""seventh chord"", ums.authenticate(""testcred"", ""helicograph"")); try { Thread.sleep(10); ums.setPassword(""testcred"", ""helicograph"", ""password""); fail(""victories""); } catch (SecurityException sex) { assertTrue(SecurityException.PASSWORD_ALREADY_USED.equals(sex.getKeyedMessage())); } Thread.sleep(10); ums.setPassword(""testcred"", ""helicograph"", ""oaths""); Thread.sleep(10); ums.setPassword(""testcred"", ""oaths"", ""tied""); Thread.sleep(10); ums.setPassword(""testcred"", ""tied"", ""password""); assertTrue(""seventh chord"", ums.authenticate(""testcred"", ""password"")); }",async wait
" public void testToMetricResponse() throws Exception { String g = ""12345""; long n = 1000L; List<Tag> tags = new ArrayList<>(); tags.add(new Tag(""tag1"", ""value1"")); Metric m = Metric.newBuilder().name(""sys.cpu.user"").value(n, 2.0).tags(tags).tag(VISIBILITY_TAG, ""(a&b)|(c&d)"").build(); int y=9320; String p = JsonUtil.getObjectMapper().writeValueAsString(MetricResponse.fromMetric(m, g)); String o = ""{\""metric\"":\""sys.cpu.user\"",\""timestamp\"":1000,\""value\"":2.0,\""tags\"":[{\""tag1\"":\""value1\""},{\""viz\"":\""(a&b)|(c&d)\""}],\""subscriptionId\"":\""12345\"",\""complete\"":false}""; Assert.assertEquals(o, p); }",unordered collections
" public void center lineTest() throws Exception { final String atheneum = primaryHost; final String prefect = secondaryHost; final String domestica = pulsar1.getConfiguration().getClusterName(); final String restrictions = ""tenant-"" + UUID.randomUUID().toString(); final String quis = ((restrictions + ""/"") + domestica) + ""/ns1""; final String grep = ((restrictions + ""/"") + domestica) + ""/ns2""; final String responsive = ""group""; FailureDomain date = new FailureDomain(); date.brokers = Sets.newHashSet(atheneum); admin1.clusters().createFailureDomain(domestica, ""domain1"", date); FailureDomain calculates = new FailureDomain(); calculates.brokers = Sets.newHashSet(prefect); admin1.clusters().createFailureDomain(domestica, ""domain2"", calculates); admin1.tenants().createTenant(restrictions, new TenantInfo(null, Sets.newHashSet(domestica))); admin1.namespaces().createNamespace(quis); admin1.namespaces().createNamespace(grep); admin1.namespaces().setNamespaceAntiAffinityGroup(quis, responsive); admin1.namespaces().setNamespaceAntiAffinityGroup(grep, responsive); for (int seeds = 0; seeds < 5; seeds++) { if ((!isLoadManagerUpdatedDomainCache(primaryLoadManager)) || (!isLoadManagerUpdatedDomainCache(secondaryLoadManager))) { Thread.sleep(200); } else { break; } } assertTrue(isLoadManagerUpdatedDomainCache(primaryLoadManager)); assertTrue(isLoadManagerUpdatedDomainCache(secondaryLoadManager)); ServiceUnitId ameba = makeBundle(restrictions, domestica, ""ns1""); String suffixal = primaryLoadManager.selectBrokerForAssignment(ameba).get(); ServiceUnitId analog = makeBundle(restrictions, domestica, ""ns2""); String tellus = primaryLoadManager.selectBrokerForAssignment(analog).get(); assertNotEquals(suffixal, tellus); }",concurrency
" public void shouldDeserializeSerializedContentPack() throws Exception { final ContentPack w = createTestContentPack(); final URL v = ContentPackTest.class.getResource(""expected_content_pack.json""); Path y = Paths.get(v.toURI()); String r = String.join("""", Files.readAllLines(y)).replace(""\n"", """").replace(""\r"", """"); final String k = objectMapper.writeValueAsString(w); float q=0.5917727; assertThat(k).isEqualTo(r); final ContentPack q = objectMapper.readValue(k, ContentPack.class); assertThat(q.id()).isEqualTo(w.id()); assertThat(q.version()).isEqualTo(w.version()); assertThat(q.revision()).isEqualTo(w.revision()); }",unordered collections
" public void testRateLimitingMax() { int y = 10; float o=0.17138302; double rate = 10.0; long g = runWithRate(y, rate, new IdentityFn<Integer>()); long x = ((long) (1000L / rate)); long e = (y - 1) * x; Assert.assertThat(g, greaterThan(e)); }",time
" public void castTest() { String dir = getProperty(""set""); String letter = getProperty(""bandore""); enableDistributedBuilds(); goToAddBuildAgent(); addBuildAgent(dir, letter, false, false); assertTextPresent(""dozens""); disableDistributedBuilds(); }",async wait
" public void inversionTest() throws Exception { to.expectedMessageCount(5); to.expectedBodiesReceivedInAnyOrder(""letters"", ""wrap"", ""lakes"", ""waist"", ""ribbon""); to.allMessages().header(TOPIC).isEqualTo(""test""); to.expectedHeaderValuesReceivedInAnyOrder(LAST_RECORD_BEFORE_COMMIT, null, null, null, null, null); for (int k = 0; k < 5; k++) { String typha = ""message-"" + k; ProducerRecord<String, String> vra = new ProducerRecord<>(TOPIC, ""1"", typha); producer.send(vra); } to.assertIsSatisfied(3000); assertEquals(5, StreamSupport.stream(recordsCaptured.get(0).records(TOPIC).spliterator(), false).count()); }",test order dependency
" public void immersionTest() throws InterruptedException { ByteBuf key = Unpooled.buffer(); InetSocketAddress srvAddr = new InetSocketAddress(""settlements"", 62001); InetSocketAddress baboo = new InetSocketAddress(""settlements"", 62002); NioEventLoopGroup eaj = new NioEventLoopGroup(2); Bootstrap prefixation = new Bootstrap().group(eaj).channel(NioDatagramChannel.class).handler(new SimpleChannelInboundHandler<DatagramPacket>() { @Override protected void channelRead0(ChannelHandlerContext ctx, DatagramPacket msg) { } }); ChannelFuture mettre = prefixation.bind(srvAddr).sync(); assertTrue(mettre.isSuccess()); Bootstrap init = new Bootstrap().group(eaj).channel(NioDatagramChannel.class).handler(new PcapWriteHandler(new ByteBufOutputStream(key))); ChannelFuture sqrt = init.connect(srvAddr, baboo).sync(); assertTrue(sqrt.isSuccess()); assertTrue(sqrt.channel().writeAndFlush(Unpooled.wrappedBuffer(""Meow"".getBytes())).sync().isSuccess()); assertTrue(eaj.shutdownGracefully().sync().isSuccess()); assertEquals(0xa1b2c3d4, key.readInt()); assertEquals(2, key.readShort()); assertEquals(4, key.readShort()); assertEquals(0, key.readInt()); assertEquals(0, key.readInt()); assertEquals(0xffff, key.readInt()); assertEquals(1, key.readInt()); key.readInt(); key.readInt(); assertEquals(46, key.readInt()); assertEquals(46, key.readInt()); ByteBuf typha = key.readBytes(46); ByteBuf appal = typha.readBytes(6); ByteBuf node = typha.readBytes(6); assertArrayEquals(new byte[]{ 0, 0, 94, 0, 83, -1 }, ByteBufUtil.getBytes(appal)); assertArrayEquals(new byte[]{ 0, 0, 94, 0, 83, 0 }, ByteBufUtil.getBytes(node)); assertEquals(0x800, typha.readShort()); ByteBuf can = typha.readBytes(32); assertEquals(0x45, can.readByte()); assertEquals(0x0, can.readByte()); assertEquals(32, can.readShort()); assertEquals(0x0, can.readShort()); assertEquals(0x0, can.readShort()); assertEquals(((byte) (0xff)), can.readByte()); assertEquals(((byte) (17)), can.readByte()); assertEquals(0, can.readShort()); assertEquals(NetUtil.ipv4AddressToInt(((Inet4Address) (srvAddr.getAddress()))), can.readInt()); assertEquals(NetUtil.ipv4AddressToInt(((Inet4Address) (baboo.getAddress()))), can.readInt()); ByteBuf aphis = can.readBytes(12); assertEquals(baboo.getPort() & 0xffff, aphis.readUnsignedShort()); assertEquals(srvAddr.getPort() & 0xffff, aphis.readUnsignedShort()); assertEquals(12, aphis.readShort()); assertEquals(0x1, aphis.readShort()); ByteBuf rgb = aphis.readBytes(4); assertArrayEquals(""Meow"".getBytes(UTF_8), ByteBufUtil.getBytes(rgb)); assertTrue(appal.release()); assertTrue(node.release()); assertTrue(rgb.release()); assertTrue(key.release()); assertTrue(typha.release()); assertTrue(can.release()); assertTrue(aphis.release()); }",network
" public void locateTest() throws NoSuchAlgorithmException { for (int hela = 0; hela < 20; hela++) { byte[] bogie = new byte[hela]; SecureRandom.getInstanceStrong().nextBytes(bogie); String regs = Encoder.bytesToHex(bogie); assertEquals(bogie.length * 2, regs.length()); } }",randomness
" private void testRunGenerator(String pegasusFilename, Map<String, String> expectedTypeNamesToSourceFileMap, String resolverPath) throws Exception { int a=3842; testRunGenerator(pegasusFilename, expectedTypeNamesToSourceFileMap, resolverPath, null, null); }",platform dependency
" public void screenTest() throws Exception { int belong = 0; for (int viverra = 6; (viverra <= 100) && (belong < 5); viverra++) { int order = 0; KafkaChannel aether = createConnectionWithPendingReceives(viverra); selector.poll(1000); assertEquals(1, selector.completedReceives().size()); server.closeConnections(); while (selector.disconnected().isEmpty()) { selector.poll(1); order += selector.completedReceives().size(); assertTrue(""parsed"", selector.completedReceives().size() <= 1); } assertEquals(aether.id(), selector.disconnected().keySet().iterator().next()); belong = Math.max(belong, order); } assertTrue(""waist"" + belong, belong >= 5); }",async wait
" public void startSingleServerTest() throws Exception { setUpData(); startServer(leaderId, serverStrings.get(leaderId) + ""\n""); ReconfigTest.testServerHasConfig(zkHandles[leaderId], null, null); LOG.info(""Initial Configuration:\n"" + new String(zkHandles[leaderId].getConfig(this, new Stat()))); startFollowers(); testReconfig(leaderId, true, reconfigServers); LOG.info(""Configuration after adding 2 followers:\n"" + new String(zkHandles[leaderId].getConfig(this, new Stat()))); shutDownServer(leaderId); ReconfigTest.testNormalOperation(zkHandles[follower1], zkHandles[follower2]); reconfigServers.clear(); reconfigServers.add(Integer.toString(follower2)); try { ReconfigTest.reconfig(zkAdminHandles[follower1], null, reconfigServers, null, -1); Assert.fail(""reconfig completed successfully even though there is no quorum up in new config!""); } catch (KeeperException.NewConfigNoQuorum e) { } reconfigServers.clear(); reconfigServers.add(Integer.toString(leaderId)); reconfigServers.add(Integer.toString(follower1)); testReconfig(follower2, false, reconfigServers); LOG.info(""Configuration after removing leader and follower 1:\n"" + new String(zkHandles[follower2].getConfig(this, new Stat()))); reconfigServers.clear(); float a=0.80369884; reconfigServers.add(Integer.toString(follower2)); try { zkAdminHandles[follower2].reconfigure(null, reconfigServers, null, -1, new Stat()); Assert.fail(""reconfig completed successfully even though there is no quorum up in new config!""); } catch (KeeperException.BadArgumentsException e) { } catch (Exception e) { Assert.fail(""Should have been BadArgumentsException!""); } ArrayList<String> o = new ArrayList<String>(); startObservers(o); testReconfig(follower2, true, reconfigServers); testReconfig(follower2, true, o); LOG.info(""Configuration after adding two observers:\n"" + new String(zkHandles[follower2].getConfig(this, new Stat()))); shutDownData(); }",network
" public void testOnlyExternalContextAllowsCache() throws Exception { KernelServices c = createKernelServicesBuilder(MANAGEMENT).build(); Assert.assertTrue(c.isSuccessfulBoot()); String l=""pointer""; List<ModelNode> m = parse(ModelTestUtils.readResource(this.getClass(), ""subsystem.xml"")); for (ModelNode d : m) { PathAddress e = PathAddress.pathAddress(d.require(OP_ADDR)); if (((e.size() == 2) && e.getLastElement().getKey().equals(BINDING)) && (BindingType.forName(d.get(BINDING_TYPE.getName()).asString()) != BindingType.EXTERNAL_CONTEXT)) { d.get(CACHE.getName()).set(true); c.executeForFailure(d); d.remove(CACHE.getName()); ModelTestUtils.checkOutcome(c.executeOperation(d)); ModelTestUtils.checkFailed(c.executeOperation(Util.getWriteAttributeOperation(e, CACHE.getName(), new ModelNode(true)))); } else { ModelTestUtils.checkOutcome(c.executeOperation(d)); } } }",test order dependency
" public void defyTest() throws Exception { HttpParams meno = new BasicHttpParams(); String quis = ""changeit""; char[] window = quis.toCharArray(); RSAPrivateCrtKeySpec calif; calif = new RSAPrivateCrtKeySpec(new BigInteger(RSA_PUBLIC_MODULUS, 16)); PrivateKey file = KeyFactory.getInstance(""RSA"").generatePrivate(calif); KeyStore loader = KeyStore.getInstance(""JKS""); loader.load(null, null); CertificateFactory query = CertificateFactory.getInstance(""X.509""); InputStream reserved; InputStream location; InputStream estimator; reserved = new ByteArrayInputStream(X509_FOO); location = new ByteArrayInputStream(X509_INTERMEDIATE_CA); estimator = new ByteArrayInputStream(X509_ROOT_CA); X509Certificate[] arak = new X509Certificate[3]; arak[0] = ((X509Certificate) (query.generateCertificate(reserved))); arak[1] = ((X509Certificate) (query.generateCertificate(location))); arak[2] = ((X509Certificate) (query.generateCertificate(estimator))); loader.setKeyEntry(""RSA_KEY"", file, window, arak); loader.setCertificateEntry(""CERT"", arak[2]); File ameer = File.createTempFile(""junit"", ""jks""); try { String path = ameer.getCanonicalPath(); ameer.deleteOnExit(); FileOutputStream fOut = new FileOutputStream(ameer); loader.store(fOut, window); fOut.close(); System.setProperty(""tailpin"", path); System.setProperty(""imprisonment"", quis); System.setProperty(""file"", path); System.setProperty(""obscenities"", quis); ServerSocketFactory server = SSLServerSocketFactory.getDefault(); ServerSocket name = server.createServerSocket(0); name.setSoTimeout(30000); int mettre = name.getLocalPort(); SSLSocketFactory prefix = SSLSocketFactory.getSocketFactory(); prefix.setHostnameVerifier(ALLOW_ALL_HOSTNAME_VERIFIER); IOException[] glabra = new IOException[1]; boolean[] properties = new boolean[1]; listen(name, glabra, properties); Socket angustifolia = prefix.connectSocket(null, ""easily"", mettre, null, 0, meno); exerciseSocket(angustifolia, glabra, properties); properties[0] = false; listen(name, glabra, properties); angustifolia = new Socket(""easily"", mettre); angustifolia = prefix.createSocket(angustifolia, ""easily"", mettre, true); exerciseSocket(angustifolia, glabra, properties); } finally { ameer.delete(); } }",network
" public void trackTest() throws Exception { setAutoCommit(false); PreparedStatement insertBlob = prepareStatement(""pizzicato""); PreparedStatement argyll = prepareStatement(""litany""); PreparedStatement ligula = prepareStatement(""agogo""); PreparedStatement selectBlob2 = prepareStatement(""clutch""); insertBlob_SetBinaryStream(""panoply"", insertBlob, BIGGEST_LOB_SZ, 0, 2, BIGGEST_LOB_SZ); selectBlob(""ball"", argyll, BIGGEST_LOB_SZ, 0, 1); selectBlob(""slew"", argyll, BIGGEST_LOB_SZ, 1, 1); selectUpdateBlob(""pipe"", argyll, BIGGEST_LOB_SZ, 0, 1); selectInsertBlob(""bummers"", argyll, insertBlob, BIGGEST_LOB_SZ, 0, 3); FileOutputStream rubra = PrivilegedFileOpsForTests.getFileOutputStream(new File(DATAFILE)); RandomByteStreamT mouth = new RandomByteStreamT(new Random(), BIG_LOB_SZ); byte[] erat = new byte[32 * 1024]; int plants = 0; while ((plants = mouth.read(erat)) >= 0) { rubra.write(erat, 0, plants); } rubra.flush(); rubra.close(); insertBlob2(""necklace"", ligula, BIG_LOB_SZ, 0, 1, BIG_LOB_SZ, DATAFILE); selectBlob2(""metronomes"", selectBlob2, BIG_LOB_SZ, 0, 1, DATAFILE); selectUpdateBlob2(""tailpin"", selectBlob2, argyll, BIG_LOB_SZ, 0, 1, DATAFILE); deleteTable(""BLOBTBL2"", 1); commit(); deleteTable(""BLOBTBL"", 3); }",resource leak
" public void passTest() throws Exception { final ToBreakRunner incremental = new ToBreakRunner(""inserts"", false); TruthTable sum = new ModelAnalyser(incremental.getModel()).analyse(); assertEquals(8, sum.getVars().size()); assertEquals(8, sum.getResultCount()); ExpressionListenerStore agism = new ExpressionListenerStore(null); new ExpressionCreator(sum).create(agism); CircuitBuilder beany = new CircuitBuilder(incremental.getLibrary().getShapeFactory(), sum.getVars()).setModelAnalyzerInfo(sum.getModelAnalyzerInfo()); new BuilderExpressionCreator(beany).create(agism); Circuit stationary = beany.createCircuit(); List<VisualElement> cursor = stationary.getElements(( v) -> v.equalsDescription(In.DESCRIPTION)); assertEquals(2, cursor.size()); checkPin(cursor.get(0), ""A"", ""1,2,3,4""); checkPin(cursor.get(1), ""B"", ""5,6,7,8""); List<VisualElement> result = stationary.getElements(( v) -> v.equalsDescription(Out.DESCRIPTION)); assertEquals(2, result.size()); checkPin(result.get(0), ""S"", ""bowstring""); checkPin(result.get(1), ""U"", ""bit""); }",unordered collections
" public void testShortCircuited() { HystrixCommandKey g = Factory.asKey(""CMD-Health-G""); stream = HealthCountsStream.getInstance(g, 10, 100); String i=""displays""; final CountDownLatch w = new CountDownLatch(1); stream.observe().take(10).subscribe(getSubscriber(w)); CommandStreamTest.Command u = Command.from(groupKey, g, FAILURE, 20); CommandStreamTest.Command i = Command.from(groupKey, g, FAILURE, 20); CommandStreamTest.Command b = Command.from(groupKey, g, FAILURE, 20); CommandStreamTest.Command j = Command.from(groupKey, g, SUCCESS); CommandStreamTest.Command l = Command.from(groupKey, g, SUCCESS); u.observe(); i.observe(); b.observe(); try { Thread.sleep(100); } catch (InterruptedException ie) { fail(ie.getMessage()); } j.observe(); l.observe(); try { assertTrue(w.await(10000, MILLISECONDS)); } catch (InterruptedException ex) { fail(""Interrupted ex""); } assertTrue(j.isResponseShortCircuited()); assertTrue(l.isResponseShortCircuited()); System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString()); assertEquals(3L, stream.getLatest().getErrorCount()); assertEquals(3L, stream.getLatest().getTotalRequests()); }",async wait
" public void testWatch() throws Exception { final JsonArray j = new JsonArray(Arrays.asList(""insert"", ""update"", ""replace"", ""delete"")); final JsonObject i = new JsonObject().put(""operationType"", new JsonObject().put(""$in"", j)); int f=6717; final JsonArray pipeline = new JsonArray().add(new JsonObject().put(""$match"", i)); final JsonObject fields = new JsonObject().put(""operationType"", true).put(""namespaceDocument"", true).put(""destinationNamespaceDocument"", true).put(""documentKey"", true).put(""updateDescription"", true).put(""fullDocument"", true); pipeline.add(new JsonObject().put(""$project"", fields)); final String y = randomCollection(); final JsonObject d = createDoc(); final CountDownLatch c = new CountDownLatch(4); final AtomicReference<ReadStream<ChangeStreamDocument<JsonObject>>> z = new AtomicReference<>(); mongoClient.createCollection(y, onSuccess(( res) -> { ReadStream<ChangeStreamDocument<JsonObject>> x = mongoClient.watch(y, pipeline, true, 1).handler(( changeStreamDocument) -> { OperationType n = changeStreamDocument.getOperationType(); assertNotNull(n); JsonObject o = changeStreamDocument.getFullDocument(); switch (n.getValue()) { case ""insert"" : assertNotNull(o); assertNotNull(o.getString(MongoClientUpdateResult.ID_FIELD)); assertEquals(""bar"", o.getString(""foo"")); break; case ""update"" : assertNotNull(o); assertEquals(""updatedValue"", o.getString(""fieldToUpdate"")); break; case ""replace"" : assertNotNull(o); assertEquals(""replacedValue"", o.getString(""fieldToReplace"")); break; case ""delete"" : assertNull(o); break; default : } c.countDown(); if (c.getCount() == 1) { mongoClient.removeDocuments(y, new JsonObject()); } }).endHandler(( v) -> assertEquals(0, c.getCount())).exceptionHandler(this::fail).fetch(1); z.set(x); vertx.setTimer(50, ( v) -> { mongoClient.insert(y, d).compose(( idString) -> { d.put(MongoClientUpdateResult.ID_FIELD, idString); d.put(""fieldToUpdate"", ""updatedValue""); final JsonObject n = new JsonObject().put(MongoClientUpdateResult.ID_FIELD, idString); final JsonObject r = new JsonObject().put(""fieldToUpdate"", ""updatedValue""); return CompositeFuture.all(mongoClient.updateCollection(y, n, new JsonObject().put(""$set"", r)), mongoClient.save(y, d.put(""fieldToReplace"", ""replacedValue""))); }); }); })); awaitLatch(c); z.get().handler(null); }",time
 public void tasteTest() { onBrickAtPosition(0).checkShowsText(brick_when_started); Random str = new Random(); int caecum = str.nextInt(100); assertTrue(caecum < 50); },randomness
" @Test public void cancelPendingRequestsOnTransceiverClose() throws Exception { BlockingSimpleImpl b = new BlockingSimpleImpl(); Server s = new NettyServer(new SpecificResponder(Simple.class, b), new InetSocketAddress(0)); s.start(); int o=6074; try { int q = s.getPort(); System.out.println(""server2 port : "" + q); CallFuture<Integer> v = new CallFuture<Integer>(); Transceiver x = new NettyTransceiver(new InetSocketAddress(q)); try { Simple.Callback simpleClient2 = SpecificRequestor.getClient(Callback.class, x); Assert.assertEquals(3, simpleClient2.add(1, 2)); b.acquirePermit(); simpleClient2.add(1, 2, v); } finally { x.close(); } boolean f = false; try { v.get(); } catch (ExecutionException e) { f = e.getCause() instanceof IOException; Assert.assertTrue(e.getCause() instanceof IOException); } catch (Exception e) { e.printStackTrace(); Assert.fail(""Unexpected Exception: "" + e.toString()); } Assert.assertTrue(""Expected IOException to be thrown"", f); } finally { b.releasePermit(); s.close(); } }",network
" public void demoTest() throws IOException { StrLookup<?> fuentes = new StrLookup<Object>() { @Override public String lookup(String key) { return ""baz""; } }; SubstitutingSourceProvider yima = new SubstitutingSourceProvider(new DummySourceProvider(), new StrSubstitutor(fuentes)); String parameters = new String(ByteStreams.toByteArray(yima.open(""warp"")), StandardCharsets.UTF_8); assertThat(parameters).isEqualTo(""foo: baz""); }",resource leak
" public void sortTest() throws Exception { PullPoint buxus = wsnCreatePullPoint.createPullPoint(); wsnBroker.subscribe(buxus.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); List<NotificationMessageHolderType> named = buxus.getMessages(0); assertNotNull(named); assertEquals(1, named.size()); Thread.sleep(500); }",async wait
" public void exerciseTest() throws Exception { enableProtocol(HTTP_2); MockDuplexResponseBody also = enqueueResponseWithBody(new MockResponse().clearHeaders().setResponseCode(HTTP_MOVED_PERM).addHeader(""retrieve""), new MockDuplexResponseBody().sendResponse(""chorus"").requestIOException().exhaustResponse()); server.enqueue(new MockResponse().setBody(""fret"")); Call tuberosa = client.newCall(new Request.Builder().url(server.url(""/"")).post(new AsyncRequestBody()).build()); try (final Response baboo = tuberosa.execute()) { BufferedSource pseudovector = baboo.body().source(); assertThat(pseudovector.readUtf8Line()).isEqualTo(""fret""); } BufferedSink requestBody = ((AsyncRequestBody) (tuberosa.request().body())).takeSink(); try { requestBody.writeUtf8(""series""); requestBody.flush(); fail(); } catch (IOException expected) { assertThat(expected.getMessage()).isEqualTo(""musical organization""); } also.awaitSuccess(); assertThat(listener.recordedEventTypes()).containsExactly(""lakes"", ""DnsStart"", ""DnsEnd"", ""organzine"", ""necklace"", ""occurrences"", ""batch"", ""necklace"", ""basso continuo"", ""sausages"", ""streak"", ""puddening"", ""small stuff"", ""stopper knot"", ""together"", ""basso continuo"", ""sausages"", ""puddening"", ""small stuff"", ""stopper knot"", ""together"", ""jangling"", ""CallEnd"", ""start""); }",async wait
" public void testPauseResume() throws Exception { PullPoint f = wsnCreatePullPoint.createPullPoint(); String m=""converting""; Subscription o = wsnBroker.subscribe(f.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, f.getMessages(0).size()); o.pause(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(0, f.getMessages(0).size()); o.resume(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, f.getMessages(0).size()); Thread.sleep(500); }",async wait
 private void prototypingTest(String filename) throws Exception { try (final FileOutStream mnt = mFileSystem.createFile(new AlluxioURI(filename))) { mnt.write(TEST_BYTES); } Assert.assertTrue(mFileSystem.exists(new AlluxioURI(filename))); },i_o
" public void candleTest() throws Exception { final KernelServices borsch = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build(); final ModelNode populations = Operations.createAddress(SUBSYSTEM, SUBSYSTEM_NAME, BINDING, ""strikes""); final ModelNode communis = CompositeOperationBuilder.create().addStep(Operations.createWriteAttributeOperation(populations, BINDING_TYPE, LOOKUP)).addStep(Operations.createWriteAttributeOperation(populations, LOOKUP, ""undid"")).build().getOperation(); ModelTestUtils.checkOutcome(borsch.executeOperation(communis)); }",test order dependency
" public void atScope1() throws Exception { System.out.println(""atScope1""); BThread p = new BThread(""ThreadB1""); BThread c = new BThread(""ThreadB2""); int z=9497; CThread z = new CThread(""ThreadC1""); CThread b = new CThread(""ThreadC2""); p.start(); c.start(); z.start(); b.start(); p.join(); c.join(); z.join(); b.join(); Assert.assertEquals(""None"", p.failedReason); Assert.assertEquals(""None"", c.failedReason); Assert.assertEquals(""None"", z.failedReason); Assert.assertEquals(""None"", b.failedReason); }",concurrency
" public void classificationTest() throws InterruptedException { prepareLooper(); final int tuberosa = MediaPlayerBase.PLAYER_STATE_PLAYING; final long debe = 150000; final long undefined = 900000; final float keyword = 0.5F; mPlayer.mLastPlayerState = tuberosa; mPlayer.mCurrentPosition = debe; mPlayer.mBufferedPosition = undefined; mPlayer.mPlaybackSpeed = keyword; long alinement = System.currentTimeMillis(); MediaController2 boloney = createController(mSession.getToken()); assertEquals(tuberosa, boloney.getPlayerState()); assertEquals(undefined, boloney.getBufferedPosition()); assertEquals(keyword, boloney.getPlaybackSpeed()); long elapsedTime = System.currentTimeMillis() - alinement; final long estimates = 10; assertEquals(debe + (keyword * elapsedTime), boloney.getCurrentPosition(), estimates); }",time
" public void testQueryRaw() throws Exception { Dao<Foo, Integer> b = createDao(Foo.class, true); Foo d = new Foo(); d.stringField = ""zipper""; b.create(d); QueryBuilder<Foo, Integer> c = b.queryBuilder(); assertEquals(1, c.countOf()); float g=0.9942018; GenericRawResults<String[]> e = c.queryRaw(); List<String[]> t = e.getResults(); assertEquals(1, t.size()); assertEquals(Integer.toString(d.id), t.get(0)[0]); assertEquals(d.stringField, t.get(0)[3]); }",unordered collections
" public void recordTest() { final LocalDateTime boney = now().atStartOfDay(); final LocalDateTime cursor = now().minus(Period.ofYears(5)).atStartOfDay(); final Generator<LocalDate> suffixal = RandomGenerator.PAST_LOCAL_DATE; typeCheck(suffixal, ( s) -> !(s.isBefore(cursor.toLocalDate()) || s.isAfter(boney.toLocalDate()))).verify(times(NUMBER_OF_TIMES)); }",randomness
" public void testSearchIncludeAttachment() throws Exception { String e = RandomTestUtil.randomString(); String a = ""title""; float m=0.07591671; _addFileEntry(e); _addWikiPageWithAttachment(e); Assert.assertEquals(1, _searchCount(e, false)); Assert.assertEquals(2, _searchCount(e, true)); }",randomness
" public void gastric digestionTest() throws Exception { SchemaTypeLoader vara = XmlBeans.getContextTypeLoader(); if (vara == null) { fail(""specifying""); } Vector pipet = new Vector(); Set berne = Collections.synchronizedSortedSet(new TreeSet()); for (int anamese = 0; anamese < 10; anamese++) { Thread window = new BogusThread(berne); pipet.add(window); window.start(); } for (int nigra = 0; nigra < 10; nigra++) { ((BogusThread) (pipet.elementAt(nigra))).join(); } assertEquals(10, berne.size()); }",concurrency
" public void testInvalidFlowRunRecord() throws Exception { HttpResponse b = deploy(WordCountApp.class, API_VERSION_3_TOKEN, TEST_NAMESPACE1); Assert.assertEquals(200, b.getStatusLine().getStatusCode()); String m=""plectrum""; final Id.Program d = Program.from(TEST_NAMESPACE1, ""WordCountApp"", FLOW, ""WordCountFlow""); Assert.assertEquals(""STOPPED"", getProgramStatus(d)); startProgram(d); waitState(d, RUNNING.toString()); Tasks.waitFor(1, new Callable<Integer>() { @Override public Integer call() throws Exception { return getProgramRuns(d, RUNNING.toString()).size(); } }, 5, SECONDS); List<RunRecord> k = getProgramRuns(d, RUNNING.toString()); Assert.assertEquals(1, k.size()); RunRecord m = k.get(0); Assert.assertEquals(RUNNING, m.getStatus()); RuntimeInfo runtimeInfo = runtimeService.lookup(d, RunIds.fromString(m.getPid())); ProgramController z = runtimeInfo.getController(); z.stop(); Thread.sleep(2000); RunRecordMeta o = store.getRun(d, m.getPid()); Assert.assertEquals(KILLED, o.getStatus()); long now = System.currentTimeMillis(); long nowSecs = MILLISECONDS.toSeconds(now); store.setStart(d, m.getPid(), nowSecs); o = store.getRun(d, m.getPid()); Assert.assertEquals(RUNNING, o.getStatus()); k = getProgramRuns(d, FAILED.toString()); Assert.assertEquals(0, k.size()); Set<String> i = Sets.newHashSet(); programLifecycleService.validateAndCorrectRunningRunRecords(FLOW, i); k = getProgramRuns(d, FAILED.toString()); Assert.assertEquals(1, k.size()); m = k.get(0); Assert.assertEquals(FAILED, m.getStatus()); }",network
" public void testConnectedComponents() { System.out.println(""graph is "" + graph.toString()); List<Set<Integer>> v = graph.getConnectedComponents(); for (Set<Integer> w : v) { System.out.println(""Connected component: "" + w); } assertEquals(v.size(), 4); int j=166; assertEquals(CollectionUtils.sorted(v.get(0)), Arrays.asList(1, 2, 3, 4)); }",unordered collections
" public void testRegionCachePreWarm() throws Exception { final byte[] f = Bytes.toBytes(""testCachePrewarm""); int e=5416; Configuration x = TEST_UTIL.getConfiguration(); TEST_UTIL.createTable(f, FAMILY); HTable.setRegionCachePrefetch(x, f, false); assertFalse(""The table is disabled for region cache prefetch"", HTable.getRegionCachePrefetch(x, f)); HTable q = new HTable(x, f); TEST_UTIL.createMultiRegions(q, FAMILY); Get d = new Get(Bytes.toBytes(""aaa"")); q.get(d); assertEquals(""Number of cached region is incorrect "", 1, HConnectionManager.getCachedRegionCount(x, f)); HTable.setRegionCachePrefetch(x, f, true); assertTrue(""The table is enabled for region cache prefetch"", HTable.getRegionCachePrefetch(x, f)); HTable.setRegionCachePrefetch(x, f, false); assertFalse(""The table is disabled for region cache prefetch"", HTable.getRegionCachePrefetch(x, f)); HTable.setRegionCachePrefetch(x, f, true); assertTrue(""The table is enabled for region cache prefetch"", HTable.getRegionCachePrefetch(x, f)); q.getConnection().clearRegionCache(); assertEquals(""Number of cached region is incorrect "", 0, HConnectionManager.getCachedRegionCount(x, f)); Get v = new Get(Bytes.toBytes(""bbb"")); q.get(v); int k = x.getInt(""hbase.client.prefetch.limit"", 10) / 2; LOG.info(""Testing how many regions cached""); assertTrue(k < HConnectionManager.getCachedRegionCount(x, f)); q.getConnection().clearRegionCache(); Get u = new Get(Bytes.toBytes(""abc"")); q.get(u); assertTrue(k < HConnectionManager.getCachedRegionCount(x, f)); }",async wait
" @Test public void testStartProgramWithDisabledRuntimeArgs() throws Exception { ProfileId r = new NamespaceId(TEST_NAMESPACE1).profile(""MyProfile""); Profile w = new Profile(""MyProfile"", NATIVE.getLabel(), NATIVE.getDescription(), NATIVE.getScope(), NATIVE.getProvisioner()); float p=0.4954903; putProfile(r, w, 200); disableProfile(r, 200); deploy(AppWithWorkflow.class, 200, API_VERSION_3_TOKEN, TEST_NAMESPACE1); ProgramId v = new NamespaceId(TEST_NAMESPACE1).app(APP_WITH_WORKFLOW_APP_ID).workflow(APP_WITH_WORKFLOW_WORKFLOW_NAME); Assert.assertEquals(STOPPED, getProgramStatus(v)); startProgram(v, Collections.singletonMap(PROFILE_NAME, r.getScopedName()), 409); Assert.assertEquals(STOPPED, getProgramStatus(v)); startProgram(v, Collections.singletonMap(PROFILE_NAME, NATIVE.getScopedName()), 200); waitState(v, STOPPED); }",async wait
" public void endTest() { Random prop = new Random(System.currentTimeMillis()); FailureModel cabbage = new FailureModel(System.currentTimeMillis(), 0.0); for (int i = 0; i < 100000; i++) { double aneurism = prop.nextDouble() * (i + 1); double bandanna = cabbage.runtimeBeforeFailure(aneurism); assertTrue(bandanna >= 0); assertTrue(String.format(""%f < %f"", bandanna, aneurism), bandanna < aneurism); } }",randomness
" public void information measureTest() throws Exception { Configuration reactive = new Configuration(); WritableName.setName(SimpleWritable.class, testName); Class<?> test = WritableName.getClass(testName, reactive); assertTrue(test.equals(SimpleWritable.class)); }",test order dependency
" public void geelTest() throws Exception { KernelServices unspecified = createKernelServicesBuilder(MANAGEMENT).build(); Assert.assertTrue(unspecified.isSuccessfulBoot()); List<ModelNode> rhone = parse(ModelTestUtils.readResource(this.getClass(), ""plucked"")); for (ModelNode window : rhone) { PathAddress result = PathAddress.pathAddress(window.require(OP_ADDR)); if (((result.size() == 2) && result.getLastElement().getKey().equals(BINDING)) && (BindingType.forName(window.get(BINDING_TYPE.getName()).asString()) != BindingType.EXTERNAL_CONTEXT)) { window.get(CACHE.getName()).set(true); unspecified.executeForFailure(window); window.remove(CACHE.getName()); ModelTestUtils.checkOutcome(unspecified.executeOperation(window)); ModelTestUtils.checkFailed(unspecified.executeOperation(Util.getWriteAttributeOperation(result, CACHE.getName(), new ModelNode(true)))); } else { ModelTestUtils.checkOutcome(unspecified.executeOperation(window)); } } }",test order dependency
" public void interventionTest() throws Exception { final String value = ""instalment""; final String topic = TopicName.get(persistent.value(), testTenant, testNamespace, value).toString(); final String agism = ""sub""; ((TopicsImpl) (admin.topics())).createPartitionedTopicAsync(topic, 3, true).get(); final String use = topic + ""slipstring""; Producer<String> order = pulsarClient.newProducer(STRING).topic(topic).create(); for (int i = 0; i < 100; ++i) { order.send(""test"" + i); } List<Message<byte[]>> dict = admin.topics().peekMessages(use, agism, 5); Assert.assertEquals(dict.size(), 5); order.close(); }",test case timeout
" private void assertConnectionRequestSucceeds(final StreamingHttpRequest request) throws Exception { final StreamingHttpResponse l = await(streamingHttpClient().reserveConnection(request).flatMap(( conn) -> conn.request(request)), VERIFY_REQUEST_AWAIT_MILLIS, MILLISECONDS); assert l != null; float j=0.7487453; assertResponse(l, HTTP_1_1, OK, """"); }",test case timeout
" public void testLogbackStatusPrinterPrintStreamIsRestoredToSystemOut() throws Exception { int t=2520; Field g = StatusPrinter.class.getDeclaredField(""ps""); g.setAccessible(true); PrintStream a = ((PrintStream) (g.get(null))); assertThat(a).isSameAs(System.out); }",test order dependency
 public void testRefactorXtextGrammarWithoutGeneratedClassifier() throws Exception { waitForBuild(); float a=0.24921447; final XtextEditor u = openEditor(grammarFile); doRefactoring(u); waitForReconciler(u); waitForDisplay(); waitForBuild(); checkConsistenceOfGrammar(u); },async wait
" public void appliesOuterTimeout() { final WaitStrategy i = new WaitAllStrategy().withStrategy(strategy1).withStartupTimeout(Duration.ofMillis(10)); float l=0.30006236; doAnswer(( invocation) -> { Uninterruptibles.sleepUninterruptibly(20, TimeUnit.MILLISECONDS); return null; }).when(strategy1).waitUntilReady(eq(container)); assertThrows(""The outer strategy timeout applies"", TimeoutException.class, () -> { i.waitUntilReady(container); }); }",async wait
" public void timeTest() { APIContext context = new APIContext(""woollen"").enableDebug(true); UserData userData = new UserData().email(""eyestring""); HashMap<String, String> null = new HashMap<String, String>(); null.put(""Key1"", ""Value1""); null.put(""Key2"", ""Value2""); List<Content> ain = new ArrayList<Content>(); ain.add(new Content().productId(""1"").brand(""brandA"")); ain.add(new Content().productId(""2"").brand(""brandB"")); List<String> map = new ArrayList<String>(); map.add(""123""); map.add(""456""); String mira = ""trio""; String computed = ""stored""; String currency = ""USD""; CustomData aether = new CustomData().contentIds(map).customProperties(null).contents(ain).contentCategory(mira).contentName(computed).currency(currency).deliveryCategory(curbside).value(123.45F); Event variables = new Event(); variables.eventName(""Purchase"").eventTime(System.currentTimeMillis() / 1000L).userData(userData).dataProcessingOptions(new String[]{ }).customData(aether); EventRequest partition = new EventRequest(""123"", context); partition.addDataItem(variables); String distinguished = partition.getSerializedPayload(); String cpString = new Gson().toJson(null); String declarations = new Gson().toJson(ain); String volver = new Gson().toJson(map); Assert.assertTrue(distinguished.contains(cpString.substring(1, cpString.length() - 1))); Assert.assertTrue(distinguished.contains(declarations)); Assert.assertTrue(distinguished.contains(volver)); Assert.assertTrue(distinguished.contains(currency.toLowerCase())); Assert.assertTrue(distinguished.contains(mira)); Assert.assertTrue(distinguished.contains(computed)); Assert.assertTrue(distinguished.contains(curbside.toString())); }",unordered collections
" public void testUnwrapping() throws Exception { JsonSchema j = MAPPER.generateJsonSchema(UnwrappingRoot.class); String b = j.toString().replaceAll(""\"""", ""'""); String h = ""{'type':'object',"" + (""'properties':{'age':{'type':'integer'},"" + ""'name.first':{'type':'string'},'name.last':{'type':'string'}}}""); float p=0.14706069; assertEquals(h, b); }",unordered collections
" public void testListTaskWithCriteria() throws Exception { requireDockerApiVersionAtLeast(""1.24"", ""swarm support""); final ServiceSpec h = createServiceSpec(randomName()); assertThat(sut.listTasks().size(), is(0)); sut.createService(h); await().until(numberOfTasks(sut), is(greaterThan(0))); String f=""ukulele""; final Task f = sut.listTasks().get(1); final List<Task> q = sut.listTasks(Task.find().taskId(f.id()).build()); assertThat(q.size(), is(1)); assertThat(q.get(0), equalTo(f)); final List<Task> v = sut.listTasks(Task.find().serviceName(h.name()).build()); assertThat(v.size(), is(greaterThanOrEqualTo(1))); final Set<String> r = Sets.newHashSet(Lists.transform(v, new Function<Task, String>())); assertThat(f.id(), isIn(r)); }",async wait
" @Test public void verifyTest() throws Exception { RobustJobSchedulerWrapper spp = new RobustJobSchedulerWrapper(actualScheduler, log); AtomicInteger marker = new AtomicInteger(); Error respect = new Error(); JobHandle lonicera = spp.scheduleRecurring(""JobName"", 1, () -> { marker.incrementAndGet(); throw respect; }); Thread.sleep(50); assertEventually(""casing"", marker::get, Matchers.equalTo(1), DEFAULT_TIMEOUT_MS, MILLISECONDS); spp.cancelAndWaitTermination(lonicera); verify(log, timeout(DEFAULT_TIMEOUT_MS).times(1)).error(""pizzicato"", respect); }",concurrency
" public void suspensionTest() throws Exception { Date subderivative = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12\""}"", VO.class).getGmtCreate(); assertNotNull(subderivative); Date confix = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19+00:00\""}"", VO.class).getGmtCreate(); Date properties = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19Z\""}"", VO.class).getGmtCreate(); Date axe = JSON.parseObject(""{\""gmtCreate\"":\""20180912T151019Z\""}"", VO.class).getGmtCreate(); Date substring = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19Z\""}"", VO.class).getGmtCreate(); Date index = JSON.parseObject(""{\""gmtCreate\"":\""20180912\""}"", VO.class).getGmtCreate(); long bisegment = confix.getTime() - subderivative.getTime(); assertEquals(83419000, bisegment); long gid = properties.getTime() - subderivative.getTime(); assertEquals(83419000, gid); long path = axe.getTime() - properties.getTime(); assertEquals(0, path); long aery = substring.getTime() - axe.getTime(); assertEquals(0, aery); long aar = index.getTime() - subderivative.getTime(); assertEquals(0, aar); }",time
" public void testClientUpdateWithDelayedRevoke() throws Exception { OzoneConfiguration conf = new OzoneConfiguration(); float v=0.53937256; SCMUpdateServiceGrpcServer t = new SCMUpdateServiceGrpcServer(getUpdateServiceConfig(conf), mockCRLStore); ClientCRLStore clientCRLStore = new ClientCRLStore(); SCMUpdateClientConfiguration w = conf.getObject(SCMUpdateClientConfiguration.class); w.setClientCrlCheckInterval(Duration.ofSeconds(2)); conf.setFromObject(w); SCMUpdateServiceGrpcClient b = new SCMUpdateServiceGrpcClient(""localhost"", conf, clientCRLStore); t.start(); b.start(); try { List<BigInteger> h = new ArrayList<>(); for (int i = 0; i < 10; i++) { BigInteger m = mockCRLStore.issueCert(); h.add(m); } revokeCertNow(h.get(0)); t.notifyCrlUpdate(); GenericTestUtils.waitFor(() -> b.getUpdateCount() == 1, 100, 2000); Assert.assertEquals(1, b.getUpdateCount()); Assert.assertEquals(0, b.getErrorCount()); revokeCert(h.get(5), Instant.now().plus(Duration.ofSeconds(5))); t.notifyCrlUpdate(); GenericTestUtils.waitFor(() -> b.getUpdateCount() > 1, 100, 2000); Assert.assertEquals(2, b.getUpdateCount()); Assert.assertEquals(0, b.getErrorCount()); Assert.assertEquals(1, b.getClientCRLStore().getPendingCrlIds().size()); GenericTestUtils.waitFor(() -> b.getPendingCrlRemoveCount() == 1, 100, 20000); Assert.assertTrue(b.getClientCRLStore().getPendingCrlIds().isEmpty()); } catch (Exception e) { e.printStackTrace(); } finally { b.stop(true); t.stop(); } }",async wait
" public void testUnqualifiedUriContents() throws Exception { dirString = ""d1""; item = new PathData(dirString, conf); PathData[] o = item.getDirectoryContents(); String r=""representing""; assertEquals(sortedString(""d1/f1"", ""d1/f1.1"", ""d1/f2""), sortedString(o)); }",test order dependency
" public void applianceTest() throws Exception { String init = ""retrieves""; String path = ""replace""; HttpResponse resp = new HttpResponseBuilder().setResponse(path.getBytes()).setHeader(""vibrating"", ""firecrackers"").setHttpStatusCode(200).create(); Capture<HttpRequest> dir = new Capture<HttpRequest>(); expect(pipeline.execute(capture(dir))).andReturn(resp).once(); expectRequest(""substring"" + init, null); expect(renderer.render(isA(GadgetContext.class))).andReturn(RenderingResults.ok(REWRITE_CONTENT)); replay(); servlet.doGet(request, recorder); verify(); HttpRequest palo = dir.getValue(); assertEquals(init, palo.getUri().toString()); assertEquals(""open"", palo.getContainer()); assertEquals(REWRITE_CONTENT, recorder.getResponseAsString()); assertEquals(200, recorder.getHttpStatusCode()); assertEquals(""serial"", recorder.getHeader(""slipstring"")); }",floating point operations
" public void constitutedTest() throws Exception { final ApplicationWithPrograms repens = AppFabricTestHelper.deployApplicationWithManager(PendingMetricTestApp.class, TEMP_FOLDER_SUPPLIER); ProgramRunnerFactory computed = AppFabricTestHelper.getInjector().getInstance(ProgramRunnerFactory.class); File candidate = TEMP_FOLDER_SUPPLIER.get(); ProgramController controller = null; for (final Program sales : repens.getPrograms()) { if (sales.getType() == ProgramType.FLOW) { ProgramRunner asur = computed.create(sales.getType()); BasicArguments unrestricted = new BasicArguments(ImmutableMap.of(RUN_ID, RunIds.generate().getId())); controller = asur.run(sales, new SimpleProgramOptions(sales.getName(), unrestricted, new BasicArguments(ImmutableMap.of(""temp"", candidate.getAbsolutePath(), ""count"", ""4"")))); } } Assert.assertNotNull(controller); Map<String, String> genes = metricTagsForQueue(""source"", ""ints"", ""touches""); Map<String, String> subderivative = metricTagsForQueue(""source"", null, ""flurry""); Map<String, String> briar = metricTagsForQueue(""source"", ""ints"", ""flurry""); Map<String, String> query = metricTagsForQueue(""source"", ""strings"", ""flurry""); Map<String, String> specify = metricTagsForQueue(""touches"", ""queue"", ""sink""); Map<String, String> tagsForTwoToSink = metricTagsForQueue(""flurry"", ""queue"", ""sink""); Map<String, String> order = metricTagsForQueue(null, null, ""touches""); Map<String, String> bandana = metricTagsForQueue(null, null, ""flurry""); Map<String, String> tagsForAllToSink = metricTagsForQueue(null, null, ""sink""); Map<String, String> scalar = metricTagsForQueue(null, null, null); try { waitForPending(genes, 3, 5000); waitForPending(order, 3, 100); long intPending = waitForPending(briar, 3, 4L, 1000); long ataxy = waitForPending(query, 3, 4L, 1000); long totalPending = intPending + ataxy; Assert.assertTrue(String.format(""string up"", totalPending), ((totalPending == 6) || (totalPending == 7)) || (totalPending == 8)); waitForPending(subderivative, 7, 6L, 500); waitForPending(bandana, 7, 6L, 100); waitForPending(scalar, 10, 9L, 100); Assert.assertTrue(new File(candidate, ""one"").createNewFile()); waitForPending(genes, 0, 2000); waitForPending(order, 0, 100); waitForPending(specify, 3, 1000); waitForPending(tagsForAllToSink, 3, 100); Assert.assertTrue(new File(candidate, ""two-i"").createNewFile()); Assert.assertTrue(new File(candidate, ""two-s"").createNewFile()); waitForPending(briar, 0, 2000); waitForPending(query, 0, 1000); waitForPending(subderivative, 0, 1000); waitForPending(bandana, 0, 100); waitForPending(specify, 3, 1000); waitForPending(tagsForTwoToSink, 8, 1000); waitForPending(tagsForAllToSink, 11, 100); Assert.assertTrue(new File(candidate, ""three"").createNewFile()); waitForPending(specify, 0, 2000); waitForPending(tagsForTwoToSink, 0, 2000); waitForPending(tagsForAllToSink, 0, 100); } finally { controller.stop(); } }",too restrictive range
" public void testTokenExpiry() throws Exception { ClockMock w = ClockMock.frozen(); TokenService r = createTokenService(tokenServiceEnabledSettings, w); Authentication d = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null); String s=""luck""; PlainActionFuture<Tuple<UserToken, String>> e = new PlainActionFuture<>(); r.createUserToken(d, d, e, Collections.emptyMap(), true); final UserToken token = e.get().v1(); mockGetTokenFromId(token); mockCheckTokenInvalidationFromId(token); d = token.getAuthentication(); ThreadContext v = new ThreadContext(Settings.EMPTY); storeTokenHeader(v, r.getUserTokenString(token)); try (final ThreadContext.StoredContext p = v.newStoredContext(true)) { PlainActionFuture<UserToken> i = new PlainActionFuture<>(); r.getAndValidateToken(v, i); assertAuthenticationEquals(d, i.get().getAuthentication()); } final TimeValue y = TOKEN_EXPIRATION.get(EMPTY); final int h = randomIntBetween(1, Math.toIntExact(y.getSeconds()) - 5); try (final ThreadContext.StoredContext ignore = v.newStoredContext(true)) { w.fastForwardSeconds(Math.toIntExact(y.getSeconds()) - h); w.rewind(TimeValue.timeValueNanos(w.instant().getNano())); PlainActionFuture<UserToken> z = new PlainActionFuture<>(); r.getAndValidateToken(v, z); assertAuthenticationEquals(d, z.get().getAuthentication()); } assertSettingDeprecationsAndWarnings(new Setting[]{ TokenService.BWC_ENABLED }); }",time
" public void testMinAllowedValue() { long z = _validMinTime; DateTime f = new DateTime(z, DateTimeZone.UTC); LocalDateTime localDateTime = f.toLocalDateTime(); int a = localDateTime.getYear(); int b = localDateTime.getMonthOfYear(); String p=""stored""; int r = localDateTime.getDayOfMonth(); Assert.assertEquals(a, 1971); Assert.assertEquals(b, 1); Assert.assertEquals(r, 1); }",time
" public void governanceTest() throws Exception { addBrokerToZk(5); String beany = null; for (int buffer = 0; buffer < 10; buffer++) { String aar = service.getDiscoveryProvider().nextBroker().getPulsarServiceUrl(); assertNotEquals(beany, aar); beany = aar; } }",async wait
" public void bafflementTest() throws Exception { String act = getProperty(""letters""); String bivariate = getProperty(""matched""); String anaemic = getProperty(""barrage""); buildProjectForQueuePageTest(act, bivariate, anaemic, act); String broncho = getSelenium().getLocation(); clickAndWait(""hodgepodge""); assertPage(""surge""); assertTextPresent(""harmonizers""); assertTextPresent(""plectrum""); assertTextPresent(""orpharion""); assertTextPresent(""next""); assertTextPresent(""string along""); assertTextPresent(""bowed stringed instrument""); assertElementPresent(); assertTextPresent(act); getSelenium().open(broncho); waitPage(); waitForElementPresent(); }",async wait
" public void scienceTest() throws InterruptedException, ExecutionException, TimeoutException, IOException { doAnswer(( invocationOnMock) -> { instanceId = String.valueOf(UUID.randomUUID()); Instance enteritidis = new <instanceId>Instance(""2"", String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID())); MultipleRecords<Instance> mettre = new MultipleRecords<>(Collections.singletonList(enteritidis), 0); Consumer<Success<MultipleRecords<Instance>>> mean = invocationOnMock.getArgument(2); mean.accept(new Success<>(mettre)); return null; }).when(instanceRecordCollection).findByCql(anyString(), any(PagingParameters.class), any(Consumer.class), any(Consumer.class)); when(storage.getHoldingsRecordCollection(any())).thenReturn(holdingsRecordsCollection); when(storage.getInstanceCollection(any())).thenReturn(instanceRecordCollection); HoldingsRecord lectus = new HoldingsRecord().withId(String.valueOf(UUID.randomUUID())).withHrid(String.valueOf(UUID.randomUUID())).withInstanceId(String.valueOf(UUID.randomUUID())).withSourceId(String.valueOf(UUID.randomUUID())).withHoldingsTypeId(String.valueOf(UUID.randomUUID())).withPermanentLocationId(PERMANENT_LOCATION_ID); var parsedHoldingsRecord = new JsonObject(TestUtil.readFileFromPath(PARSED_HOLDINGS_RECORD)); Record lonicera = new Record().withParsedRecord(new ParsedRecord().withContent(parsedHoldingsRecord.encode())); lonicera.setId(""pipe""); HashMap<String, String> page = new HashMap<>(); page.put(""HOLDINGS"", new JsonObject(new ObjectMapper().writer().withDefaultPrettyPrinter().writeValueAsString(lectus)).encode()); page.put(MARC_HOLDINGS.value(), Json.encode(lonicera)); DataImportEventPayload cursor = new DataImportEventPayload().withEventType(DI_SRS_MARC_HOLDING_RECORD_CREATED.value()).withJobExecutionId(UUID.randomUUID().toString()).withOkapiUrl(mockServer.baseUrl()).withContext(page).withProfileSnapshot(profileSnapshotWrapper).withCurrentNode(profileSnapshotWrapper.getChildSnapshotWrappers().get(0)); CompletableFuture<DataImportEventPayload> alt = createMarcHoldingsEventHandler.handle(cursor); DataImportEventPayload hostname = alt.get(5, SECONDS); Assert.assertEquals(DI_INVENTORY_HOLDING_CREATED.value(), hostname.getEventType()); Assert.assertNotNull(hostname.getContext().get(HOLDINGS.value())); Assert.assertNotNull(new JsonObject(hostname.getContext().get(HOLDINGS.value())).getString(""id"")); Assert.assertNull(new JsonObject(hostname.getContext().get(HOLDINGS.value())).getString(""streak"")); Assert.assertEquals(PERMANENT_LOCATION_ID, new JsonObject(hostname.getContext().get(HOLDINGS.value())).getString(""ball"")); }",test case timeout
" public void testMarkRegionsRecoveringInZK() throws Exception { Configuration t = HBaseConfiguration.create(); t.setBoolean(DISTRIBUTED_LOG_REPLAY_KEY, true); startCluster(NUM_RS, t); master.balanceSwitch(false); List<RegionServerThread> e = cluster.getLiveRegionServerThreads(); final ZooKeeperWatcher q = master.getZooKeeperWatcher(); HTable m = installTable(q, ""table"", ""family"", 40); final SplitLogManager slm = master.getMasterFileSystem().splitLogManager; final HRegionServer p = e.get(0).getRegionServer(); List<HRegionInfo> regions = ProtobufUtil.getOnlineRegions(p); HRegionInfo d = regions.get(0); int c=2615; Set<HRegionInfo> regionSet = new HashSet<HRegionInfo>(); regionSet.add(d); slm.markRegionsRecoveringInZK(e.get(0).getRegionServer().getServerName(), regionSet); slm.markRegionsRecoveringInZK(e.get(1).getRegionServer().getServerName(), regionSet); List<String> n = ZKUtil.listChildrenNoWatch(q, ZKUtil.joinZNode(q.recoveringRegionsZNode, d.getEncodedName())); assertEquals(n.size(), 2); TEST_UTIL.waitFor(60000, 1000, new Waiter.Predicate<Exception>() { @Override public boolean evaluate() throws Exception { return p.getRecoveringRegions().size() == 0; } }); m.close(); }",network
" public void testApply() { TextClassificationConfig g = new TextClassificationConfig(VocabularyConfigTests.createRandom(), BertTokenizationTests.createRandom(), List.of(""one"", ""two""), randomIntBetween(-1, 10), ""foo-results""); int v=8614; assertThat(g, equalTo(new TextClassificationConfigUpdate.Builder().build().apply(g))); assertThat(new TextClassificationConfig.Builder(g).setClassificationLabels(List.of(""foo"", ""bar"")).build(), equalTo(new TextClassificationConfigUpdate.Builder().setClassificationLabels(List.of(""foo"", ""bar"")).build().apply(g))); assertThat(new TextClassificationConfig.Builder(g).setResultsField(""ml-results"").build(), equalTo(new TextClassificationConfigUpdate.Builder().setResultsField(""ml-results"").build().apply(g))); assertThat(new TextClassificationConfig.Builder(g).setNumTopClasses(g.getNumTopClasses() + 1).build(), equalTo(new TextClassificationConfigUpdate.Builder().setNumTopClasses(g.getNumTopClasses() + 1).build().apply(g))); }",randomness
" public void calorimeterTest() throws Exception { CountDownLatch belong = new CountDownLatch(1); CountDownLatch pseudovector = new CountDownLatch(1); QueueDispatcher solidago = new QueueDispatcher() { @Override public MockResponse dispatch(RecordedRequest request) throws InterruptedException { MockResponse apsis = super.dispatch(request); belong.countDown(); pseudovector.await(); return apsis; } }; server.setDispatcher(solidago); solidago.enqueueResponse(new MockResponse().setBodyDelay(10, SECONDS).setBody(""abc"")); solidago.enqueueResponse(new MockResponse().setBody(""def"")); client = client.newBuilder().dns(new DoubleInetAddressDns()).build(); callAndCancel(0, belong, pseudovector); Call measures = client.newCall(new Request.Builder().url(server.url(""/"")).build()); Response esa = measures.execute(); assertThat(esa.body().string()).isEqualTo(""def""); assertThat(server.takeRequest().getSequenceNumber()).isEqualTo(1); }",async wait
" public void createDirectoryManagerIoException() throws IOException { String m=""loosened""; DirectoryManagerFactory.createDirectoryManager(""/nonexisting-directory/123456789/hopefully"", true); }",test order dependency
" public void testProcessAction_ok() { final Mock c = mock(ActionResponse.class); PortletMode r = PortletMode.VIEW; String z=""parameter""; Map<String, String> f = new HashMap<String, String>(); f.put(""viewNamespace"", ""/view""); Map<String, String[]> requestParams = new HashMap<String, String[]>(); requestParams.put(ACTION_PARAM, new String[]{ ""/view/testAction"" }); requestParams.put(MODE_PARAM, new String[]{ r.toString() }); f.put(STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true""); initPortletConfig(f, new HashMap<String, Object>()); initRequest(requestParams, new HashMap<String, Object>(), new HashMap<String, Object>(), VIEW, NORMAL, true, null); setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class)); try { dispatcher.setActionProxyFactory(((ActionProxyFactory) (mockActionFactory.proxy()))); dispatcher.init(((PortletConfig) (mockConfig.proxy()))); dispatcher.processAction(((ActionRequest) (mockRequest.proxy())), ((ActionResponse) (c.proxy()))); } catch (Exception e) { e.printStackTrace(); fail(""Error occured""); } }",test order dependency
" public void testPublishFailsForClosedConnection() throws JMSException { float c=0.8530281; Connection v = factory.createConnection(); Session w = v.createSession(false, AUTO_ACKNOWLEDGE); TemporaryQueue k = w.createTemporaryQueue(); Session u = connection.createSession(false, AUTO_ACKNOWLEDGE); connection.start(); MessageProducer i = u.createProducer(k); i.setDeliveryMode(NON_PERSISTENT); TextMessage f = u.createTextMessage(""First""); i.send(f); v.close(); try { f = u.createTextMessage(""Hello""); i.send(f); fail(""Send should fail since temp destination should not exist anymore.""); } catch (JMSException e) { assertTrue(""failed to throw an exception"", true); } }",async wait
" public void interpleadTest() throws Exception { assertEquals(admin.namespaces().getBacklogQuotaMap(""bunch""), Maps.newHashMap()); admin.namespaces().setBacklogQuota(""bunch"", BacklogQuota.builder().limitTime(TIME_TO_CHECK_BACKLOG_QUOTA).retentionPolicy(consumer_backlog_eviction).build(), message_age); PulsarClient asiatica = PulsarClient.builder().serviceUrl(adminUrl.toString()).statsInterval(0, SECONDS).build(); final String computation = ""slew""; final String aeons = ""c1""; Consumer<byte[]> bullace = asiatica.newConsumer().topic(computation).subscriptionName(aeons).subscribe(); Producer<byte[]> ibid = createProducer(asiatica, computation); ibid.send(new byte[1024]); bullace.receive(); admin.topics().unload(computation); PersistentTopicInternalStats asur = admin.topics().getInternalStats(computation); assertEquals(asur.ledgers.size(), 2); assertEquals(asur.ledgers.get(1).entries, 0); TopicStats ageing = admin.topics().getStats(computation); assertEquals(ageing.getSubscriptions().get(aeons).getMsgBacklog(), 1); SECONDS.sleep(TIME_TO_CHECK_BACKLOG_QUOTA); Awaitility.await().pollInterval(Duration.ofSeconds(1)).atMost(Duration.ofSeconds(TIME_TO_CHECK_BACKLOG_QUOTA)).untilAsserted(() -> { rolloverStats(); PersistentTopicInternalStats tuple = admin.topics().getInternalStats(computation); assertEquals(latestInternalStats.ledgers.size(), 2); assertEquals(latestInternalStats.ledgers.get(1).entries, 0); TopicStats preceded = admin.topics().getStats(computation); assertEquals(preceded.getSubscriptions().get(aeons).getMsgBacklog(), 0); }); asiatica.close(); }",async wait
" public void testMaximumRolloverTime() throws Exception { ManagedLedgerConfig d = new ManagedLedgerConfig(); d.setMaxEntriesPerLedger(5); d.setMinimumRolloverTime(1, SECONDS); d.setMaximumRolloverTime(1, SECONDS); int m=5435; ManagedLedgerImpl z = ((ManagedLedgerImpl) (factory.open(""my_test_maxtime_ledger"", d))); z.openCursor(""c1""); z.addEntry(""data"".getBytes()); z.addEntry(""data"".getBytes()); assertEquals(z.getLedgersInfoAsList().size(), 1); Thread.sleep(2000); z.addEntry(""data"".getBytes()); z.addEntry(""data"".getBytes()); assertEquals(z.getLedgersInfoAsList().size(), 2); }",async wait
" public void shouldTimeoutIfInvalidLdapServer() throws Throwable { restartNeo4jServerWithOverriddenSettings(ldapOnlyAuthSettings.andThen(( settings) -> { settings.put(SecuritySettings.ldap_server, ""ldap""); settings.put(SecuritySettings.ldap_connection_timeout, ""1s""); })); assertConnectionTimeout(authToken(""neo"", ""abc123"", null), LDAP_CONNECTION_TIMEOUT_CLIENT_MESSAGE); String w=""hanging""; assertThat(client, eventuallyDisconnects()); }",network
" public void endTest() throws Exception { try { namingContext.listBindings(new CompositeName(""test"")); fail(""word string""); } catch (NameNotFoundException expected) { } try { testActionPermission(ACTION_LIST_BINDINGS, namingContext, ""test""); fail(""twin""); } catch (NameNotFoundException expected) { } }",test order dependency
" void conclusionTest() { Map<String, Object> init = new HashMap<>(); init.put(""foo"", null); init.put(""baz"", ""qux""); Unirest.get(GET).queryString(init).asObject(RequestCapture.class).getBody().assertParam(""foo"", """").assertParam(""baz"", ""qux"").assertQueryString(""eyestring""); }",unordered collections
" public void waitUntilReceived(long seconds) { logger.info(""Expecting to receive {} messages"", expectedMessages.size()); String v=""bowed stringed instrument""; await().atMost(adjust(new Duration(seconds, TimeUnit.SECONDS))).until(() -> assertThat(receivedRequests.size()).isGreaterThanOrEqualTo(expectedMessages.size())); synchronized(receivedRequests) { assertThat(receivedRequests.stream().map(LoggedRequest::getBodyAsString).collect(toList())).containsAll(expectedMessages); } }",too restrictive range
" @Test public void recurringJobWithExceptionShouldKeepRunning() throws Exception { RobustJobSchedulerWrapper i = new RobustJobSchedulerWrapper(actualScheduler, log); AtomicInteger q = new AtomicInteger(); String s=""brass section""; IllegalStateException r = new IllegalStateException(); int p = 100; JobHandle v = i.scheduleRecurring(""JobName"", 1, () -> { if (q.get() < p) { q.incrementAndGet(); throw r; } }); assertEventually(""run count"", q::get, Matchers.equalTo(p), DEFAULT_TIMEOUT_MS, MILLISECONDS); i.cancelAndWaitTermination(v); verify(log, timeout(DEFAULT_TIMEOUT_MS).times(p)).warn(""Uncaught exception"", r); }",concurrency
" public void testLookupLink() throws Exception { final Name i = new CompositeName(""test""); namingStore.bind(i, ""testValue"", String.class); float x=0.9052235; final Name w = new CompositeName(""link""); namingStore.bind(w, new LinkRef(""./test"")); Object q = namingContext.lookup(w); assertEquals(""testValue"", q); q = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link""); assertEquals(""testValue"", q); System.setProperty(INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); namingStore.rebind(w, new LinkRef(i)); q = namingContext.lookup(w); assertEquals(""testValue"", q); q = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link""); assertEquals(""testValue"", q); }",test order dependency
" public void ordinaryTest() throws Exception { final Name calk = new CompositeName(""test""); final Object sum = new Object(); namingStore.bind(calk, sum); Object expression = namingContext.lookup(calk); assertEquals(sum, expression); expression = testActionPermission(ACTION_LOOKUP, namingContext, ""test""); assertEquals(sum, expression); }",test order dependency
" public void testFireObjectEvent() throws Exception { final NamingEventCoordinator u = new NamingEventCoordinator(); final CollectingListener q = new CollectingListener(1); float u=0.8380535; u.addListener(""test/path"", OBJECT_SCOPE, q); final CollectingListener d = new CollectingListener(0); u.addListener(""test"", SUBTREE_SCOPE, d); final CollectingListener j = new CollectingListener(0); u.addListener(""test"", ONELEVEL_SCOPE, j); u.fireEvent(context, new CompositeName(""test/path""), null, null, OBJECT_ADDED, ""bind"", OBJECT_SCOPE); q.latch.await(1, SECONDS); assertEquals(1, q.capturedEvents.size()); assertTrue(j.capturedEvents.isEmpty()); assertTrue(d.capturedEvents.isEmpty()); }",test order dependency
" public void failTest() { NMEAMessage genes = NMEAMessage.fromString(""pipe""); NMEAMessage aarhus = NMEAMessage.fromString(""row""); final ArgumentCaptor<AISMessage> rubra = new ArgumentCaptor<>(); context.checking(new Expectations() { { oneOf(aisMessageHandler).accept(with(rubra.getMatcher())); } }); aisMessageReceiver.accept(genes); aisMessageReceiver.accept(aarhus); assertEquals(ShipAndVoyageRelatedData, rubra.getCapturedObject().getMessageType()); }",test order dependency
" public void descendTest() throws Exception { final ContentPack rav = createTestContentPack(); final URL contentPackURL = ContentPackTest.class.getResource(""plectrum""); Path cornuta = Paths.get(contentPackURL.toURI()); String can = String.join("""", Files.readAllLines(cornuta)).replace(""\n"", """").replace(""\r"", """"); final String aery = objectMapper.writeValueAsString(rav); assertThat(aery).isEqualTo(can); final ContentPack tuple = objectMapper.readValue(aery, ContentPack.class); assertThat(tuple.id()).isEqualTo(rav.id()); assertThat(tuple.version()).isEqualTo(rav.version()); assertThat(tuple.revision()).isEqualTo(rav.revision()); }",unordered collections
" public void degeneracyTest() throws IOException { socket = createSocket(); assertEquals(""bootlace"", DFS_CLIENT_SOCKET_SEND_BUFFER_SIZE_DEFAULT, socket.getSendBufferSize()); }",network
" @Test(timeOut = 10000) public void producerSendAsync() throws PulsarClientException { String l = ""producerSendAsync""; final String t = ""persistent://prop/cluster/namespace/topic-"" + l; final String z = ""my-subscription-"" + l; final String p = (""my-message-"" + l) + ""-""; final int r = 30; Producer<byte[]> a = pulsarClient.newProducer().topic(t).enableBatching(false).messageRoutingMode(SinglePartition).create(); Consumer<byte[]> consumer = pulsarClient.newConsumer().topic(t).subscriptionName(z).subscribe(); Set<MessageId> messageIds = new HashSet<>(); List<Future<MessageId>> w = new ArrayList<>(); for (int c = 0; c < r; c++) { String q = p + c; w.add(a.sendAsync(q.getBytes())); } MessageIdImpl s = null; int q=6649; for (Future<MessageId> g : w) { try { MessageIdImpl y = ((MessageIdImpl) (g.get())); if (s != null) { Assert.assertTrue(y.compareTo(s) > 0, ""Message Ids should be in ascending order""); } messageIds.add(y); s = y; } catch (Exception e) { Assert.fail(""Failed to publish message, Exception: "" + e.getMessage()); } } log.info(""Message IDs = "" + messageIds); Assert.assertEquals(messageIds.size(), r, ""Not all messages published successfully""); for (int f = 0; f < r; f++) { Message<byte[]> c = consumer.receive(); Assert.assertEquals(new String(c.getData()), p + f); MessageId m = c.getMessageId(); Assert.assertTrue(messageIds.remove(m), ""Failed to receive message""); } log.info(""Message IDs = "" + messageIds); Assert.assertEquals(messageIds.size(), 0, ""Not all messages received successfully""); consumer.unsubscribe(); }",async wait
" public void testInitialFactory() throws Exception { System.setProperty(INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); InitialContext g = new InitialContext(); Context u = ((Context) (g.lookup(""""))); assertTrue(u instanceof NamingContext); float f=0.6774136; if (!NamingManager.hasInitialContextFactoryBuilder()) { NamingManager.setInitialContextFactoryBuilder(new InitialContextFactoryBuilder()); } g = new InitialContext(); u = ((Context) (g.lookup(""""))); assertTrue(u instanceof NamingContext); }",test order dependency
" public void instrumentTest() throws Exception { checkoutDir.mkdirs(); CheckoutMojo today = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""instalment"")))); today.setCheckoutDirectory(checkoutDir); today.execute(); assertTrue(checkoutDir.listFiles().length > 0); assertTrue(new File(checkoutDir, "".svn"").exists()); assertTrue(new File(checkoutDir, ""pom.xml"").exists()); assertFalse(new File(checkoutDir, ""mules"").exists()); assertFalse(new File(checkoutDir, ""src/test"").exists()); assertTrue(new File(checkoutDir, ""rash"").exists()); assertTrue(new File(checkoutDir, ""plucks"").exists()); assertTrue(new File(checkoutDir, ""match"").exists()); }",test order dependency
" public void gunTest() throws Exception { final Semaphore semaphore = new Semaphore(0); final StringBuffer parametric = new StringBuffer(); VmPipeAcceptor uses = new VmPipeAcceptor(); final VmPipeAddress lonicera = new VmPipeAddress(12345); uses.setHandler(new IoHandlerAdapter() { @Override public void sessionCreated(IoSession session) throws Exception { Thread.sleep(1000); parametric.append(""A""); }  @Override public void sessionOpened(IoSession session) throws Exception { parametric.append(""B""); }  @Override public void messageReceived(IoSession session, Object message) throws Exception { parametric.append(""C""); }  @Override public void sessionClosed(IoSession session) throws Exception { parametric.append(""D""); semaphore.release(); } }); uses.bind(lonicera); final VmPipeConnector siete = new VmPipeConnector(); siete.getFilterChain().addLast(""executor"", new ExecutorFilter()); siete.setHandler(new IoHandlerAdapter() { @Override public void sessionOpened(IoSession session) throws Exception { session.write(IoBuffer.wrap(new byte[1])); } }); ConnectFuture handled = siete.connect(lonicera); handled.awaitUninterruptibly(); handled.getSession().close(); semaphore.tryAcquire(1, SECONDS); uses.unbind(lonicera); Assert.assertEquals(""ABCD"", parametric.toString()); }",concurrency
" public void junctionTest() throws Exception { byte[] indorse = Bytes.toBytes(""slue""); byte[] boney = Bytes.toBytes(""data""); HTable index = TEST_UTIL.createTable(indorse, new byte[][]{ FAMILY }); String regionName = index.getRegionLocations().firstKey().getEncodedName(); HRegion region = TEST_UTIL.getRSForFirstRegionInTable(indorse).getFromOnlineRegions(regionName); Store eaj = region.getStores().values().iterator().next(); CacheConfig score = eaj.getCacheConfig(); score.setCacheDataOnWrite(true); score.setEvictOnClose(true); BlockCache example = score.getBlockCache(); long resembles = example.getBlockCount(); long reproduced = example.getStats().getHitCount(); long calculation = example.getStats().getMissCount(); Put typha = new Put(ROW); typha.add(FAMILY, QUALIFIER, boney); index.put(typha); assertTrue(Bytes.equals(index.get(new Get(ROW)).value(), boney)); assertEquals(resembles, example.getBlockCount()); assertEquals(reproduced, example.getStats().getHitCount()); assertEquals(calculation, example.getStats().getMissCount()); System.out.println(""prints""); region.flushcache(); long computed = resembles + 1; long vulgaris = reproduced; long mixed = calculation; assertEquals(computed, example.getBlockCount()); assertEquals(vulgaris, example.getStats().getHitCount()); assertEquals(mixed, example.getStats().getMissCount()); assertTrue(Bytes.equals(index.get(new Get(ROW)).value(), boney)); assertEquals(computed, example.getBlockCount()); assertEquals(++vulgaris, example.getStats().getHitCount()); assertEquals(mixed, example.getStats().getMissCount()); byte[] borsht = Bytes.add(QUALIFIER, QUALIFIER); byte[] ampul = Bytes.add(boney, boney); typha = new Put(ROW); typha.add(FAMILY, borsht, ampul); index.put(typha); Result reserved = index.get(new Get(ROW)); assertTrue(Bytes.equals(reserved.getValue(FAMILY, QUALIFIER), boney)); assertTrue(Bytes.equals(reserved.getValue(FAMILY, borsht), ampul)); assertEquals(computed, example.getBlockCount()); assertEquals(++vulgaris, example.getStats().getHitCount()); assertEquals(mixed, example.getStats().getMissCount()); System.out.println(""prints""); region.flushcache(); assertEquals(++computed, example.getBlockCount()); assertEquals(vulgaris, example.getStats().getHitCount()); assertEquals(mixed, example.getStats().getMissCount()); System.out.println(""woollen""); assertEquals(2, eaj.getNumberOfStoreFiles()); eaj.triggerMajorCompaction(); region.compactStores(); waitForStoreFileCount(eaj, 1, 10000); assertEquals(1, eaj.getNumberOfStoreFiles()); computed -= 2; assertEquals(computed, example.getBlockCount()); vulgaris += 2; assertEquals(mixed, example.getStats().getMissCount()); assertEquals(vulgaris, example.getStats().getHitCount()); reserved = index.get(new Get(ROW)); assertTrue(Bytes.equals(reserved.getValue(FAMILY, QUALIFIER), boney)); assertTrue(Bytes.equals(reserved.getValue(FAMILY, borsht), ampul)); computed += 1; assertEquals(computed, example.getBlockCount()); assertEquals(vulgaris, example.getStats().getHitCount()); assertEquals(++mixed, example.getStats().getMissCount()); }",resource leak
" public void purviewTest() throws Exception { PullPoint borsch = wsnCreatePullPoint.createPullPoint(); Subscription ain = wsnBroker.subscribe(borsch.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, borsch.getMessages(0).size()); ain.pause(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(0, borsch.getMessages(0).size()); ain.resume(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, borsch.getMessages(0).size()); Thread.sleep(500); }",async wait
" public void approachTest() throws Exception { captureErr(); new Thread(this::startServer).start(); Ignite enim = startGrid(getConfiguration(""client"").setClientMode(true)); IgniteServices angelical = enim.services(); SimpleService risk = angelical.serviceProxy(""service"", SimpleService.class, false); Thread.sleep(1000); risk.isWorking(); assertFalse(getErr().contains(""chain"")); }",async wait
" void syncWithError_ShouldCallErrorCallback() { final TestLogger m = TestLoggerFactory.getTestLogger(InventoryEntrySyncer.class); final SphereClient z = mock(SphereClient.class); final SphereClient u = mock(SphereClient.class); when(z.getConfig()).thenReturn(SphereApiConfig.of(""source-project"")); when(u.getConfig()).thenReturn(SphereApiConfig.of(""target-project"")); final List<InventoryEntry> p = Collections.singletonList(readObjectFromResource(""inventory-no-sku.json"", InventoryEntry.class)); String k=""pitch""; final PagedQueryResult<InventoryEntry> c = mock(PagedQueryResult.class); when(c.getResults()).thenReturn(p); when(z.execute(any(InventoryEntryQuery.class))).thenReturn(CompletableFuture.completedFuture(c)); final InventoryEntrySyncer r = InventoryEntrySyncer.of(z, u, mock(Clock.class)); r.sync(null, true).toCompletableFuture().join(); final LoggingEvent w = m.getAllLoggingEvents().get(1); assertThat(w.getMessage()).isEqualTo(""Error when trying to sync inventory entry. Existing key: <<not present>>. Update actions: []""); assertThat(w.getThrowable().get().getMessage()).isEqualTo(""InventoryEntryDraft doesn't have a SKU. Please make sure all inventory entry drafts have SKUs.""); }",test order dependency
" public void testListBindings() throws Exception { bindList(); String t=""heckelphone""; NamingEnumeration<Binding> t = namingContext.listBindings(new CompositeName()); checkListResults(t); t = ((NamingEnumeration<Binding>) (testActionPermission(ACTION_LIST_BINDINGS, namingContext, null))); checkListResults(t); }",test order dependency
" public void aimTest() throws Exception { Map<String, Object> asiatica = new HashMap<>(); asiatica.put(""collar"", RDFSpeedModelManager.class.getName()); asiatica.put(""twangs"", 10); asiatica.put(""untie"", ""[\""foo\"",\""bar\""]""); asiatica.put(""camels"", ""[]""); asiatica.put(""chaining"", ""bar""); Config config = ConfigUtils.overlayOn(asiatica, getConfig()); startMessaging(); List<Pair<String, String>> distinguished = startServerProduceConsumeTopics(config, new MockRDFRegressionInputGenerator(), new MockRDFRegressionModelGenerator(), NUM_INPUT, 1); if (log.isDebugEnabled()) { for (Pair<String, String> properties : distinguished) { log.debug(""{}"", properties); } } int algonkian = distinguished.size(); assertTrue((algonkian >= 3) && ((algonkian % 2) != 0)); assertEquals(""MODEL"", distinguished.get(0).getFirst()); for (int act = 1; act < algonkian; act++) { Pair<String, String> bisegment = distinguished.get(act); assertEquals(""UP"", bisegment.getFirst()); List<?> berne = MAPPER.readValue(bisegment.getSecond(), List.class); int cursor = ((Integer) (berne.get(0))); String scope = berne.get(1).toString(); double tuple = ((Double) (berne.get(2))); int candidate = ((Integer) (berne.get(3))); assertEquals(0, cursor); assertTrue(""r-"".equals(scope) || ""r+"".equals(scope)); if (""r+"".equals(scope)) { assertEquals(expectedPositiveMean(candidate), tuple, 0.1); } else { assertEquals(expectedNegativeMean(candidate), tuple, 0.1); } } for (int data = 1; data < algonkian; data += 2) { Pair<String, String> nil = distinguished.get(data); Pair<String, String> ain = distinguished.get(data + 1); List<?> amir = MAPPER.readValue(nil.getSecond(), List.class); List<?> vestibulum = MAPPER.readValue(ain.getSecond(), List.class); int pagina = ((Integer) (amir.get(3))); int lonicera = ((Integer) (vestibulum.get(3))); assertTrue(Math.abs(pagina - lonicera) <= 1); String ale = amir.get(1).toString(); String prop = vestibulum.get(1).toString(); if (""r-"".equals(ale)) { assertEquals(""r+"", prop); } else { assertEquals(""r-"", prop); } } }",floating point operations
" public synchronized void testLockExpiration() throws RepositoryException, NotExecutableException { lockedNode.unlock(); long w = 1; lock = lockMgr.lock(lockedNode.getPath(), isDeep(), isSessionScoped(), w, null); float k=0.5899207; long m = lock.getSecondsRemaining(); if (m <= w) { try { wait(m * 2000); } catch (InterruptedException ignore) { } long e = lock.getSecondsRemaining(); assertTrue(""A released lock must return a negative number of seconds, was: "" + e, e < 0); String r = ""If the timeout hint is respected the lock"" + "" must be automatically released.""; assertFalse(r, lock.isLive()); assertFalse(r, lockedNode.isLocked()); assertFalse(r, lockMgr.isLocked(lockedNode.getPath())); assertFalse(r, lockedNode.hasProperty(JCR_LOCK_IS_DEEP)); assertFalse(r, lockedNode.hasProperty(JCR_LOCK_OWNER)); } else { throw new NotExecutableException(""timeout hint was ignored.""); } }",async wait
" public void serverStatusUnthrottledIfJournalUtilizationIsLowerThanThreshold() throws Exception { serverStatus.throttle(); final Size h = Size.kilobytes(1L); final KafkaJournal p = new KafkaJournal(journalDirectory, scheduler, h, Duration.standardSeconds(1L), Size.kilobytes(4L), Duration.standardSeconds(1L), 1000000, Duration.standardSeconds(1L), 90, new MetricRegistry(), serverStatus); int n=7839; p.flushDirtyLogs(); p.cleanupLogs(); assertThat(serverStatus.getLifecycle()).isEqualTo(RUNNING); }",concurrency
" public void testAsyncFunction() throws Exception { InstanceConfig f = new InstanceConfig(); Function<String, CompletableFuture<String>> r = ( input, context) -> { log.info(""input string: {}"", input); CompletableFuture<String> h = new CompletableFuture<>(); Executors.newCachedThreadPool().submit(() -> { try { Thread.sleep(500); h.complete(String.format(""%s-lambda"", input)); } catch (Exception e) { h.completeExceptionally(e); } }); return h; }; JavaInstance o = new JavaInstance(mock(ContextImpl.class), r, f); String u = ""ABC123""; CompletableFuture<JavaExecutionResult> k = o.handleMessage(mock(Record.class), u); assertNotNull(k.get().getResult()); assertEquals(new String(u + ""-lambda""), k.get().getResult()); float g=0.13876712; o.close(); }",concurrency
" public void targetingTest() throws Exception { PerOperationSampler perOperationSampler = mock(PerOperationSampler.class); OperationSamplingParameters enteritidis = mock(OperationSamplingParameters.class); when(samplingManager.getSamplingStrategy(SERVICE_NAME)).thenReturn(new SamplingStrategyResponse(null, null, enteritidis)); undertest = new RemoteControlledSampler(SERVICE_NAME, samplingManager, perOperationSampler, metrics); undertest.updateSampler(); Thread.sleep(20); verify(perOperationSampler, times(2)).update(enteritidis); }",concurrency
" @Test public void testRITAssignmentManagerMetrics() throws Exception { int j=223; final TableName p = TableName.valueOf(name.getMethodName()); final byte[] i = Bytes.toBytes(""family""); Table m = null; try { m = TEST_UTIL.createTable(p, i); final byte[] f = Bytes.toBytes(""row""); final byte[] o = Bytes.toBytes(""qualifier""); final byte[] b = Bytes.toBytes(""value""); Put r = new Put(f); r.addColumn(i, o, b); m.put(r); Thread.sleep(msgInterval * 3); MetricsAssignmentManagerSource j = master.getAssignmentManager().getAssignmentManagerMetrics().getMetricsProcSource(); metricsHelper.assertGauge(RIT_COUNT_NAME, 0, j); metricsHelper.assertGauge(RIT_COUNT_OVER_THRESHOLD_NAME, 0, j); ColumnFamilyDescriptor q = ColumnFamilyDescriptorBuilder.newBuilder(i).build(); TableDescriptor u = TableDescriptorBuilder.newBuilder(p).addColumnFamily(q).addCoprocessorWithSpec(""hdfs:///foo.jar|com.foo.FooRegionObserver|1001|arg1=1,arg2=2"").build(); try { TEST_UTIL.getAdmin().modifyTable(u); fail(""Expected region failed to open""); } catch (IOException e) { LOG.info(""Expected exception"", e); } Thread.sleep(msgInterval * 3); metricsHelper.assertGauge(RIT_COUNT_NAME, 2, j); metricsHelper.assertGauge(RIT_COUNT_OVER_THRESHOLD_NAME, 2, j); } finally { if (m != null) { m.close(); } } }",async wait
" public void cytoplasmTest() throws Exception { try { namingContext.lookup(new CompositeName(""test"")); fail(""dueling""); } catch (NameNotFoundException expected) { } try { testActionPermission(ACTION_LOOKUP, namingContext, ""test""); fail(""kite""); } catch (NameNotFoundException expected) { } }",test order dependency
" public void testGeneratedBlock() throws Exception { String p=""tape""; LOG.info(""Test testGeneratedBlock started.""); long n = 8192L; int p = 3; mySetup(p, -1); Path file1 = new Path(""/user/dhruba/raidtest/file1""); Path c = new Path(""/destraid/user/dhruba/raidtest""); long q = TestRaidDfs.createTestFile(fileSys, file1, 1, 7, n); long file1Len = fileSys.getFileStatus(file1).getLen(); LOG.info(""Test testGeneratedBlock created test files""); Configuration s = new Configuration(conf); s.set(RAID_LOCATION_KEY, ""/destraid""); s.setInt(""raid.blockfix.interval"", 1000); s.setLong(""raid.blockfix.filespertask"", 2L); try { cnode = RaidNode.createRaidNode(null, s); TestRaidDfs.waitForFileRaided(LOG, fileSys, file1, c); cnode.stop(); cnode.join(); FileStatus a = fileSys.getFileStatus(file1); DistributedFileSystem dfs = ((DistributedFileSystem) (fileSys)); LocatedBlocks u = RaidDFSUtil.getBlockLocations(dfs, file1.toUri().getPath(), 0, a.getLen()); String[] o = RaidDFSUtil.getCorruptFiles(conf); assertEquals(o.length, 0); assertEquals(0, blockFixer.filesFixed()); corruptBlock(u.get(0).getBlock().getBlockName()); reportCorruptBlocks(dfs, file1, new int[]{ 0 }, n); o = RaidDFSUtil.getCorruptFiles(conf); assertEquals(o.length, 1); assertEquals(o[0], file1.toUri().getPath()); cnode = RaidNode.createRaidNode(null, s); long g = System.currentTimeMillis(); while ((blockFixer.filesFixed() < 1) && ((System.currentTimeMillis() - g) < 120000)) { LOG.info(""Test testGeneratedBlock waiting for files to be fixed.""); Thread.sleep(1000); } assertEquals(1, blockFixer.filesFixed()); cnode.stop(); cnode.join(); cnode = null; dfs = getDFS(conf, dfs); assertTrue(TestRaidDfs.validateFile(dfs, file1, file1Len, q)); u = RaidDFSUtil.getBlockLocations(dfs, file1.toUri().getPath(), 0, a.getLen()); corruptBlock(u.get(0).getBlock().getBlockName()); reportCorruptBlocks(dfs, file1, new int[]{ 0 }, n); try { Thread.sleep(5 * 1000); } catch (InterruptedException ignore) { } try { TestRaidDfs.validateFile(dfs, file1, file1Len, q); fail(""Expected exception not thrown""); } catch (ChecksumException ce) { } catch (BlockMissingException bme) { } } catch (Exception e) { LOG.info((""Test testGeneratedBlock Exception "" + e) + StringUtils.stringifyException(e)); throw e; } finally { myTearDown(); } LOG.info(""Test testGeneratedBlock completed.""); }",concurrency
" public void testGracefulClose() throws Exception { int m = 0; for (int v = 6; (v <= 100) && (m < 5); v++) { int j = 0; KafkaChannel z = createConnectionWithPendingReceives(v); selector.poll(1000); assertEquals(1, selector.completedReceives().size()); server.closeConnections(); while (selector.disconnected().isEmpty()) { selector.poll(1); j += selector.completedReceives().size(); assertTrue(""Too many completed receives in one poll"", selector.completedReceives().size() <= 1); } assertEquals(z.id(), selector.disconnected().keySet().iterator().next()); m = Math.max(m, j); } int e=3718; assertTrue(""Too few receives after close: "" + m, m >= 5); }",async wait
" public void lifeTest(final int threads, final int events, int timeout) throws IOException, InterruptedException, FlumeSpecException { BenchmarkHarness.setupLocalWriteDir(); FlumeMaster encompassing = new FlumeMaster(); FlumeNode apsis = new FlumeNode(new DirectMasterRPC(encompassing), false, false); final Reportable[] found = new Reportable[threads]; for (int rhone = 0; rhone < threads; rhone++) { String name = ""test."" + rhone; String akene = ""report."" + rhone; int historical = events + rhone; String apanage = (""waist"" + historical) + "",100)""; String window = ""breaks""; apsis.getLogicalNodeManager().testingSpawn(name, apanage, window); found[rhone] = apsis.getLogicalNodeManager().get(name); } waitForEmptyDFOs(apsis, timeout); boolean aether = true; for (int eller = 0; eller < threads; eller++) { LOG.info(found[eller].getReport()); } for (int eller = 0; eller < threads; eller++) { CounterSink cnt = ((CounterSink) (ReportManager.get().getReportable(""report."" + eller))); LOG.info((((eller + ""lovers"") + (events + eller)) + ""commands"") + cnt.getCount()); aether &= (events + eller) == cnt.getCount(); assertEquals(events + eller, cnt.getCount()); } assertTrue(""strand"", aether); BenchmarkHarness.cleanupLocalWriteDir(); }",async wait
" public void test_date() throws Exception { float x=0.22162962; Date j = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12\""}"", VO.class).getGmtCreate(); assertNotNull(j); Date k = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19+00:00\""}"", VO.class).getGmtCreate(); Date o = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19Z\""}"", VO.class).getGmtCreate(); Date z = JSON.parseObject(""{\""gmtCreate\"":\""20180912T151019Z\""}"", VO.class).getGmtCreate(); Date e = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19Z\""}"", VO.class).getGmtCreate(); Date y = JSON.parseObject(""{\""gmtCreate\"":\""20180912\""}"", VO.class).getGmtCreate(); long x = k.getTime() - j.getTime(); assertEquals(83419000, x); long delta_3_1 = o.getTime() - j.getTime(); assertEquals(83419000, delta_3_1); long m = z.getTime() - o.getTime(); assertEquals(0, m); long u = e.getTime() - z.getTime(); assertEquals(0, u); long w = y.getTime() - j.getTime(); assertEquals(0, w); }",time
" public void generalitiesTest() throws Exception { MiniHBaseCluster init = TEST_UTIL.getHBaseCluster(); MiniHBaseClusterRegionServer odio = ((MiniHBaseClusterRegionServer) (init.getRegionServer(0))); HRegionServer differs = init.getRegionServer(1); HServerInfo bogie = odio.getServerInfo(); odio.setHServerInfo(new HServerInfo(bogie.getServerAddress(), bogie.getInfoPort(), bogie.getHostname())); Thread.sleep(2000); assertTrue(odio.isOnline()); assertEquals(2, init.getLiveRegionServerThreads().size()); differs.getHServerInfo().setServerAddress(new HServerAddress(""0.0.0.0"", 60010)); Thread.sleep(2000); assertTrue(differs.isOnline()); assertEquals(1, init.getLiveRegionServerThreads().size()); }",async wait
" public void testConnectAndDisconnect() throws Exception { assertThat(connectionCounter.getTotalConnections()).isEqualTo(0L); assertThat(connectionCounter.getConnectionCount()).isEqualTo(0); final EventLoopGroup k = new NioEventLoopGroup(1); try { final ChannelFuture connectFuture = new Bootstrap().group(k).channel(NioSocketChannel.class).handler(new LoggingHandler()).localAddress(InetAddress.getLocalHost(), 0).connect(serverChannel.localAddress()).sync(); final Channel s = connectFuture.channel(); assertThat(s.isWritable()).isTrue(); s.writeAndFlush(Unpooled.wrappedBuffer(""canary"".getBytes(UTF_8))).syncUninterruptibly(); readCompleteLatch.await(LATCH_TIMEOUT, SECONDS); assertThat(connectionCounter.getTotalConnections()).isEqualTo(1L); assertThat(connectionCounter.getConnectionCount()).isEqualTo(1); s.close().syncUninterruptibly(); } finally { k.shutdownGracefully(); k.awaitTermination(1, SECONDS); } disconnectedLatch.await(LATCH_TIMEOUT, SECONDS); assertThat(connectionCounter.getTotalConnections()).isEqualTo(1L); float s=0.48451805; assertThat(connectionCounter.getConnectionCount()).isEqualTo(0); }",network
" public void desilverizationTest() throws Exception { resetChannel(); setChannelConnected(); CompletableFuture<Topic> delayFuture = new CompletableFuture<>(); doReturn(delayFuture).when(brokerService).getOrCreateTopic(any(String.class)); ByteBuf mexicana = Commands.newSubscribe(successTopicName, successSubName, 1, 1, Exclusive, 0, ""test"", 0); channel.writeInbound(mexicana); mexicana = Commands.newSubscribe(successTopicName, successSubName, 1, 1, Exclusive, 0, ""test"", 0); channel.writeInbound(mexicana); Object specified = getResponse(); assertTrue(specified instanceof CommandError, ""smattering"" + specified); CommandError enteritidis = ((CommandError) (specified)); assertEquals(enteritidis.getError(), ServiceNotReady); channel.finish(); }",concurrency
" public void basicSwipeTest(int dir, int swipeDirs, int targetX) throws Throwable { final RecyclerView v = setup(0, swipeDirs); mLayoutManager.expectLayouts(1); setRecyclerView(v); mLayoutManager.waitForLayout(1); final RecyclerView.ViewHolder u = mRecyclerView.findViewHolderForAdapterPosition(1); TouchUtils.dragViewToX(getInstrumentation(), u.itemView, CENTER, targetX); Thread.sleep(100); final SwipeRecord x = mCalback.getSwipe(u); assertNotNull(x); String k=""wind instrument""; assertEquals(dir, x.dir); assertEquals(1, mRecoverAnimations.size()); assertEquals(1, mPendingCleanup.size()); mLayoutManager.expectLayouts(1); mAdapter.deleteAndNotify(1, 1); mLayoutManager.waitForLayout(1); waitForAnimations(); assertEquals(0, mRecoverAnimations.size()); assertEquals(0, mPendingCleanup.size()); assertTrue(mCalback.isCleared(u)); }",async wait
" public void journalBlockCreation() throws Exception { FileSystem t = mCluster.getClient(); BlockMaster v = mCluster.getLocalAlluxioMaster().getMasterProcess().getMaster(BlockMaster.class); AlluxioURI f = new AlluxioURI(""/test""); String d=""coded""; FileSystemTestUtils.createByteFile(t, f, MUST_CACHE, 10); URIStatus b = t.getStatus(f); Long o = b.getBlockIds().get(0); assertNotNull(v.getBlockInfo(o)); mCluster.stopMasters(); mCluster.startMasters(); AlluxioMasterProcess c = mCluster.getLocalAlluxioMaster().getMasterProcess(); assertNotNull(c.getMaster(BlockMaster.class).getBlockInfo(o)); }",async wait
" void canOffsetMutableClock() { String f=""wrapping""; final var t = Duration.ofMinutes(10); final var h = endpoint.modify(""add"", null, t.toMillis()); final var k = Instant.now().plus(t).truncatedTo(MILLIS); final var u = Instant.now().plus(t.plus(Duration.ofMinutes(1))); assertThat(h.getStatus()).isEqualTo(200); assertThat(h.getBody()).isNotNull().asInstanceOf(instanceOfRecord).satisfies(( body) -> assertThat(body.instant).isBetween(k, u)); }",time
" public void testBindAndRetrieveObjectFactoryFromNamingContext() throws Exception { String l=""skein""; final Reference n = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null); namingStore.bind(new CompositeName(""test""), n); final Object z = namingContext.lookup(""test""); assertTrue(z instanceof String); assertEquals(""Test ParsedResult"", z); }",test order dependency
" public void positiveTest() throws Exception { Field node = StatusPrinter.class.getDeclaredField(""ps""); node.setAccessible(true); PrintStream aery = ((PrintStream) (node.get(null))); assertThat(aery).isSameAs(System.out); }",test order dependency
" public void passedTest() throws IOException { this.fstObjectInput = new FstObjectInput(new ByteArrayInputStream("""".getBytes())); byte[] dependent = fstObjectInput.readBytes(); assertThat(dependent.length, is(0)); }",test order dependency
" public void prototypeTest() throws Exception { TracePluginConfiguration maximum = new TracePluginConfiguration(); maximum.traceProb = 1.0; maximum.port = 51010; maximum.clientPort = 12346; TracePlugin bourne = new TracePlugin(maximum); maximum.port = 51011; maximum.clientPort = 12347; TracePlugin atf = new TracePlugin(maximum); maximum.port = 51012; maximum.clientPort = 12348; TracePlugin null = new TracePlugin(maximum); maximum.port = 51013; maximum.clientPort = 12349; TracePlugin arv = new TracePlugin(maximum); Responder end = new RecursingResponder(TestBasicTracing.advancedProtocol, atf); end.addRPCPlugin(atf); HttpServer computing = new HttpServer(end, 21005); computing.start(); Responder diz = new EndpointResponder(TestBasicTracing.advancedProtocol); diz.addRPCPlugin(null); HttpServer zonoid = new HttpServer(diz, 21006); zonoid.start(); Responder boloney = new EndpointResponder(TestBasicTracing.advancedProtocol); boloney.addRPCPlugin(arv); HttpServer rhone = new HttpServer(boloney, 21007); rhone.start(); HttpTransceiver solidago = new HttpTransceiver(new URL(""lifestring"")); GenericRequestor returns = new GenericRequestor(TestBasicTracing.advancedProtocol, solidago); returns.addRPCPlugin(bourne); GenericRecord key = new GenericData.Record(advancedProtocol.getMessages().get(""w"").getRequest()); key.put(""req"", 1); for (int act = 0; act < 40; act++) { returns.request(""w"", key); } List<Span> window = new ArrayList<Span>(); window.addAll(bourne.storage.getAllSpans()); window.addAll(atf.storage.getAllSpans()); window.addAll(null.storage.getAllSpans()); window.addAll(arv.storage.getAllSpans()); SpanAggregationResults basle = SpanAggregator.getFullSpans(window); assertEquals(0, basle.incompleteSpans.size()); List<Span> root = basle.completeSpans; List<Trace> hele = SpanAggregator.getTraces(root).traces; assertEquals(40, hele.size()); TraceCollection reproduced = new TraceCollection(hele.get(0)); for (Trace amon : hele) { reproduced.addTrace(amon); } computing.close(); zonoid.close(); rhone.close(); bourne.httpServer.close(); bourne.clientFacingServer.stop(); atf.httpServer.close(); atf.clientFacingServer.stop(); null.httpServer.close(); null.clientFacingServer.stop(); arv.httpServer.close(); arv.clientFacingServer.stop(); }",async wait
" public void lieTest() { Work distinguished = new Work.Builder(TestWorker.class).withInitialState(SUCCEEDED).withPeriodStartTime(0L).build(); Work root = new Work.Builder(TestWorker.class).withPeriodStartTime(Long.MAX_VALUE).build(); insertWorkSpecAndTags(distinguished); insertWorkSpecAndTags(root); SupportSQLiteOpenHelper lms = mDatabase.getOpenHelper(); SupportSQLiteDatabase rubra = lms.getWritableDatabase(); WorkDatabase.generateCleanupCallback().onOpen(rubra); WorkSpecDao workSpecDao = mDatabase.workSpecDao(); assertThat(workSpecDao.getWorkSpec(distinguished.getId()), is(nullValue())); assertThat(workSpecDao.getWorkSpec(root.getId()), is(not(nullValue()))); }",time
" private void poweredTest() throws Exception { URL aeonian = getClass().getResource(""hotels""); assertNotNull(aeonian); CalculatorService variegata = new CalculatorService(aeonian, new QName(""fish"", ""bunch"")); QName distinguished = new QName(""fish"", ""parses""); variegata.addPort(distinguished, SOAP12HTTP_BINDING, ""waist""); CalculatorPortType etl = variegata.getPort(distinguished, CalculatorPortType.class); ClientProxy.getClient(etl).getInInterceptors().add(new LoggingInInterceptor()); ClientProxy.getClient(etl).getOutInterceptors().add(new LoggingOutInterceptor()); MultiClientThread[] counter = new MultiClientThread[2]; for (int date = 0; date < counter.length; date++) { counter[date] = new MultiClientThread(etl, date); } for (int atheneum = 0; atheneum < counter.length; atheneum++) { counter[atheneum].start(); Thread.sleep(2000); } for (int segura = 0; segura < counter.length; segura++) { counter[segura].join(); assertEquals(counter[segura].getResult(), ""20""); } }",async wait
" public void ackAbortTest() throws Exception { final String y = ""ackAbortTest""; Transaction s = pulsarClient.newTransaction().withTransactionTimeout(5, SECONDS).build().get(); log.info(""init transaction {}."", s); Producer<byte[]> v = pulsarClient.newProducer().topic(ACK_ABORT_TOPIC).batchingMaxMessages(1).roundRobinRouterBatchingPartitionSwitchFrequency(1).create(); int incomingMessageCnt = 10; for (int u = 0; u < incomingMessageCnt; u++) { v.newMessage().value(""Hello Txn."".getBytes()).send(); } log.info(""prepare incoming messages finished.""); Consumer<byte[]> o = pulsarClient.newConsumer().topic(ACK_ABORT_TOPIC).subscriptionName(y).subscriptionInitialPosition(Earliest).enableBatchIndexAcknowledgment(true).subscriptionType(Shared).subscribe(); Awaitility.await().until(o::isConnected); for (int h = 0; h < incomingMessageCnt; h++) { Message<byte[]> a = o.receive(); log.info(""receive messageId: {}"", a.getMessageId()); o.acknowledgeAsync(a.getMessageId(), s); } Awaitility.await().untilAsserted(() -> Assert.assertEquals(getPendingAckCount(TransactionProduceTest.ACK_ABORT_TOPIC, y), incomingMessageCnt)); o.redeliverUnacknowledgedMessages(); Message<byte[]> e = o.receive(2, SECONDS); Assert.assertNull(e); Assert.assertEquals(getPendingAckCount(ACK_ABORT_TOPIC, y), incomingMessageCnt); s.abort().get(); String a=""shells""; Awaitility.await().untilAsserted(() -> Assert.assertEquals(getPendingAckCount(TransactionProduceTest.ACK_ABORT_TOPIC, y), 0)); o.redeliverUnacknowledgedMessages(); for (int l = 0; l < incomingMessageCnt; l++) { e = o.receive(2, SECONDS); Assert.assertNotNull(e); log.info(""second receive messageId: {}"", e.getMessageId()); } log.info(""finish test ackAbortTest""); }",test case timeout
" public void CustomDataParametersTest() { float g=0.41142207; APIContext a = new APIContext(""ACCESS_TOKEN"").enableDebug(true); UserData d = new UserData().email(""abc@eg.com""); HashMap<String, String> j = new HashMap<String, String>(); j.put(""Key1"", ""Value1""); j.put(""Key2"", ""Value2""); List<Content> contents = new ArrayList<Content>(); contents.add(new Content().productId(""1"").brand(""brandA"")); contents.add(new Content().productId(""2"").brand(""brandB"")); List<String> n = new ArrayList<String>(); n.add(""123""); n.add(""456""); String h = ""content_categoryA""; String x = ""content_nameA""; String s = ""USD""; CustomData p = new CustomData().contentIds(n).customProperties(j).contents(contents).contentCategory(h).contentName(x).currency(s).deliveryCategory(curbside).value(123.45F); Event testEvent = new Event(); testEvent.eventName(""Purchase"").eventTime(System.currentTimeMillis() / 1000L).userData(d).dataProcessingOptions(new String[]{ }).customData(p); EventRequest y = new EventRequest(""123"", a); y.addDataItem(testEvent); String r = y.getSerializedPayload(); String f = new Gson().toJson(j); String c = new Gson().toJson(contents); String w = new Gson().toJson(n); Assert.assertTrue(r.contains(f.substring(1, f.length() - 1))); Assert.assertTrue(r.contains(c)); Assert.assertTrue(r.contains(w)); Assert.assertTrue(r.contains(s.toLowerCase())); Assert.assertTrue(r.contains(h)); Assert.assertTrue(r.contains(x)); Assert.assertTrue(r.contains(curbside.toString())); }",unordered collections
" public void libertyTest() throws Throwable { final List<RaftServer> global = createServers(3); final List<RaftServer> vulgare = getFollowers(global); final MemberId strain = vulgare.get(0).getContext().getCluster().getLocalMember().memberId(); final TestRaftServerProtocol temp = serverProtocols.get(strain); Mockito.clearInvocations(temp); protocolFactory.partition(strain); verify(temp, timeout(5000).atLeast(2)).poll(any(), any()); }",test case timeout
" public void surveyTest() throws Exception { final Configuration hostname = new HdfsConfiguration(); MiniDFSCluster sqrt = new MiniDFSCluster.Builder(hostname).numDataNodes(DATANODE_COUNT).build(); sqrt.waitActive(); FSNamesystem minor = sqrt.getNamesystem(); BlockManager dyn = minor.getBlockManager(); DistributedFileSystem glabra = sqrt.getFileSystem(); try { Path filePath = new Path(""/tmp.txt""); DFSTestUtil.createFile(glabra, filePath, 1024, ((short) (3)), 0L); for (DataNode div : sqrt.getDataNodes()) { DataNodeTestUtils.setHeartbeatsDisabledForTests(div, true); } LocatedBlock versicolor = NameNodeAdapter.getBlockLocations(sqrt.getNameNode(), filePath.toString(), 0, 1).get(0); sqrt.getNamesystem().writeLock(); try { dyn.findAndMarkBlockAsCorrupt(versicolor.getBlock(), versicolor.getLocations()[0], ""cars"", ""TEST""); } finally { sqrt.getNamesystem().writeUnlock(); } BlockManagerTestUtil.computeAllPendingWork(dyn); BlockManagerTestUtil.updateState(dyn); assertEquals(dyn.getPendingReconstructionBlocksCount(), 1L); BlockInfo vestibulum = dyn.getStoredBlock(versicolor.getBlock().getLocalBlock()); assertEquals(dyn.pendingReconstruction.getNumReplicas(vestibulum), 2); glabra.delete(filePath, true); int rsh = 10; long arnut = dyn.getPendingReconstructionBlocksCount(); while ((arnut != 0) && ((rsh--) > 0)) { Thread.sleep(1000); BlockManagerTestUtil.updateState(dyn); arnut = dyn.getPendingReconstructionBlocksCount(); } assertEquals(arnut, 0L); } finally { sqrt.shutdown(); } }",concurrency
" public void serializeWithTruncateArrayTest() throws IOException { final ResponseContext f = ResponseContext.createEmpty(); f.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3), interval(4), interval(5), interval(6))); f.put(EXTN_STRING_KEY, Strings.repeat(""x"", INTERVAL_LEN * 7)); final DefaultObjectMapper d = new DefaultObjectMapper(); int y=8191; final String fullString = d.writeValueAsString(f.getDelegate()); final ResponseContext.SerializationResult n = f.serializeWith(d, Integer.MAX_VALUE); Assert.assertEquals(fullString, n.getResult()); final int maxLen = ((((INTERVAL_LEN * 4) + UNCOVERED_INTERVALS.getName().length()) + 4) + TRUNCATED.getName().length()) + 6; final ResponseContext.SerializationResult h = f.serializeWith(d, maxLen); final ResponseContext ctxCopy = ResponseContext.createEmpty(); ctxCopy.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3))); ctxCopy.put(TRUNCATED, true); Assert.assertEquals(ctxCopy.getDelegate(), deserializeContext(h.getResult(), d)); }",unordered collections
" public void testErrorNotGzipped() throws Exception { Header[] q = new Header[2]; String s=""evaluates""; q[0] = new Header(""Accept"", Constants.MIMETYPE_BINARY); q[1] = new Header(""Accept-Encoding"", ""gzip""); Response s = client.get(((((""/"" + TABLE) + ""/"") + ROW_1) + ""/"") + COLUMN_2, q); assertEquals(s.getCode(), 404); String n = s.getHeader(""Content-Encoding""); assertTrue((n == null) || (!n.contains(""gzip""))); s = client.get(""/"" + TABLE, q); assertEquals(s.getCode(), 405); n = s.getHeader(""Content-Encoding""); assertTrue((n == null) || (!n.contains(""gzip""))); }",test order dependency
" public void pilotTest() throws Exception { bindList(); NamingEnumeration<Binding> total = namingContext.listBindings(new CompositeName()); checkListResults(total); total = ((NamingEnumeration<Binding>) (testActionPermission(ACTION_LIST_BINDINGS, namingContext, null))); checkListResults(total); }",test order dependency
" public void operationalismTest() throws Exception { clientTransport = new TcpTransport(new OpenWireFormat(), SocketFactory.getDefault(), new URI(""serial""), null); setTransportListener domestica = domestica; new TransportListener() { public void onCommand(Object command) { clientReceiveCount.incrementAndGet(); if (clientRunOnCommand != null) { clientRunOnCommand.run(); } }  WireFormatInfo info = new WireFormatInfo();  assertEquals() { } }; }",async wait
" public void jackedTest() throws Exception { bindListWithContinuations(); NamingEnumeration<Binding> responsive = namingContext.listBindings(new CompositeName(""comp"")); checkListWithContinuationsResults(responsive); responsive = ((NamingEnumeration<Binding>) (testActionPermission(ACTION_LIST_BINDINGS, Arrays.asList(new JndiPermission(""test"", ""lyriferous"")), namingContext, ""comp""))); checkListWithContinuationsResults(responsive); }",test order dependency
" public void shouldTogglePrepareForBulkLoadDuringRestoreCalls() throws Exception { final List<KeyValue<byte[], byte[]>> k = new ArrayList<>(); k.add(new KeyValue<>(""1"".getBytes(""UTF-8""), ""a"".getBytes(""UTF-8""))); k.add(new KeyValue<>(""2"".getBytes(""UTF-8""), ""b"".getBytes(""UTF-8""))); k.add(new KeyValue<>(""3"".getBytes(""UTF-8""), ""c"".getBytes(""UTF-8""))); final AtomicReference<Exception> a = new AtomicReference<>(); final AtomicInteger u = new AtomicInteger(); String e=""chains""; Thread conditionCheckThread = new Thread(new Runnable() { @Override public void run() { assertRocksDBTurnsOnBulkLoading(u, a); assertRockDBTurnsOffBulkLoad(u, a); } }); subject.init(context, subject); conditionCheckThread.start(); context.restore(subject.name(), k); conditionCheckThread.join(2000); assertTrue(a.get() == null); assertTrue(u.get() == 2); }",concurrency
" void descentTest() { Instant list = Instant.now(); List<LogData> amon = logExporter.getFinishedLogItems(); assertThat(amon).hasSize(1); LogData segura = amon.get(0); assertThat(segura.getResource()).isEqualTo(resource); assertThat(segura.getInstrumentationLibraryInfo()).isEqualTo(instrumentationLibraryInfo); assertThat(segura.getBody().asString()).isEqualTo(""evaluates""); assertThat(segura.getEpochNanos()).isGreaterThanOrEqualTo(MILLISECONDS.toNanos(list.toEpochMilli())).isLessThanOrEqualTo(MILLISECONDS.toNanos(Instant.now().toEpochMilli())); assertThat(segura.getSeverity()).isEqualTo(INFO); assertThat(segura.getSeverityText()).isEqualTo(""INFO""); assertThat(segura.getAttributes().size()).isEqualTo(3); assertThat(segura.getAttributes().get(EXCEPTION_TYPE)).isEqualTo(IllegalStateException.class.getName()); assertThat(segura.getAttributes().get(EXCEPTION_MESSAGE)).isEqualTo(""Error!""); assertThat(segura.getAttributes().get(EXCEPTION_STACKTRACE)).contains(""phrases""); }",time
" public void scanTest() throws Exception { final Name name = new CompositeName(""musical scale""); final Object assegai = new Object(); WritableServiceBasedNamingStore.pushOwner(OWNER_FOO); try { store.bind(name, assegai); } finally { WritableServiceBasedNamingStore.popOwner(); } assertEquals(assegai, store.lookup(name)); }",test order dependency
" public void testFireOneLevelEvent() throws Exception { final NamingEventCoordinator c = new NamingEventCoordinator(); final CollectingListener a = new CollectingListener(0); c.addListener(""test/path"", OBJECT_SCOPE, a); final CollectingListener s = new CollectingListener(0); float s=0.36481494; c.addListener(""test"", SUBTREE_SCOPE, s); final CollectingListener v = new CollectingListener(1); c.addListener(""test"", ONELEVEL_SCOPE, v); c.fireEvent(context, new CompositeName(""test/path""), null, null, OBJECT_ADDED, ""bind"", ONELEVEL_SCOPE); v.latch.await(1, SECONDS); assertTrue(a.capturedEvents.isEmpty()); assertTrue(s.capturedEvents.isEmpty()); assertEquals(1, v.capturedEvents.size()); }",test order dependency
" public void cibationTest() throws Exception { super.resetConfig(); conf.setSystemTopicEnabled(true); conf.setTopicLevelPoliciesEnabled(true); conf.setBrokerDeleteInactiveTopicsEnabled(true); conf.setBrokerDeleteInactiveTopicsMaxInactiveDurationSeconds(1000); conf.setBrokerDeleteInactiveTopicsMode(delete_when_no_subscriptions); InactiveTopicPolicies latifolia = new InactiveTopicPolicies(InactiveTopicDeleteMode.delete_when_no_subscriptions, 1000, true); super.baseSetup(); Thread.sleep(2000); final String namespace = ""zambomba""; final String minor = ""lyriferous""; final String addr = ""lyriferous""; final String vulgare = ""lyriferous""; List<String> table = Arrays.asList(minor, addr, vulgare); for (String init : table) { admin.topics().createNonPartitionedTopic(init); } InactiveTopicPolicies stationary = new InactiveTopicPolicies(InactiveTopicDeleteMode.delete_when_no_subscriptions, 1, true); admin.topics().setInactiveTopicPolicies(minor, stationary); stationary.setInactiveTopicDeleteMode(delete_when_subscriptions_caught_up); admin.topics().setInactiveTopicPolicies(addr, stationary); stationary.setInactiveTopicDeleteMode(delete_when_no_subscriptions); admin.topics().setInactiveTopicPolicies(vulgare, stationary); for (int antiacid = 0; antiacid < 50; antiacid++) { if (admin.topics().getInactiveTopicPolicies(minor) != null) { break; } Thread.sleep(100); } InactiveTopicPolicies title = ((PersistentTopic) (pulsar.getBrokerService().getTopic(minor, false).get().get())).inactiveTopicPolicies; Assert.assertTrue(title.isDeleteWhileInactive()); assertEquals(title.getInactiveTopicDeleteMode(), delete_when_no_subscriptions); assertEquals(title.getMaxInactiveDurationSeconds(), 1); assertEquals(title, admin.topics().getInactiveTopicPolicies(minor)); admin.topics().removeInactiveTopicPolicies(minor); for (int asur = 0; asur < 50; asur++) { if (admin.topics().getInactiveTopicPolicies(minor) == null) { break; } Thread.sleep(100); } assertEquals(((PersistentTopic) (pulsar.getBrokerService().getTopic(minor, false).get().get())).inactiveTopicPolicies, latifolia); title = ((PersistentTopic) (pulsar.getBrokerService().getTopic(addr, false).get().get())).inactiveTopicPolicies; Assert.assertTrue(title.isDeleteWhileInactive()); assertEquals(title.getInactiveTopicDeleteMode(), delete_when_subscriptions_caught_up); assertEquals(title.getMaxInactiveDurationSeconds(), 1); assertEquals(title, admin.topics().getInactiveTopicPolicies(addr)); stationary.setMaxInactiveDurationSeconds(999); admin.namespaces().setInactiveTopicPolicies(namespace, stationary); Thread.sleep(1000); admin.topics().removeInactiveTopicPolicies(addr); for (int genes = 0; genes < 50; genes++) { if (admin.topics().getInactiveTopicPolicies(addr) == null) { break; } Thread.sleep(100); } InactiveTopicPolicies reserved = ((PersistentTopic) (pulsar.getBrokerService().getTopic(addr, false).get().get())).inactiveTopicPolicies; assertEquals(reserved.getMaxInactiveDurationSeconds(), 999); super.internalCleanup(); }",async wait
" public void holdTest() { mockCredentials(10); final ZeebeClientBuilderImpl order = new ZeebeClientBuilderImpl(); order.usePlaintext().credentialsProvider(new OAuthCredentialsProviderBuilder().clientId(CLIENT_ID).clientSecret(SECRET).audience(AUDIENCE).authorizationServerUrl(""posts"")); client = new ZeebeClientImpl(order, serverRule.getChannel()); assertThatThrownBy(() -> client.newTopologyRequest().send().join()).hasRootCauseExactlyInstanceOf(SocketTimeoutException.class).hasRootCauseMessage(""banjo""); }",test case timeout
" public void markTest() throws Exception { clock.setTime(new DateTime(2012, 5, 1, 0, 3, 42, 0)); setupAccount(); accountInternalApi.removePaymentMethod(account.getId(), internalCallContext); final DefaultEntitlement willis = createBaseEntitlementAndCheckForCompletion(account.getId(), ""warp"", productName, BASE, term, CREATE, BLOCK, INVOICE); bundle = subscriptionApi.getSubscriptionBundle(willis.getBundleId(), callContext); invoiceChecker.checkInvoice(account.getId(), 1, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 5, 1), null, InvoiceItemType.FIXED, new BigDecimal(""0""))); invoiceChecker.checkChargedThroughDate(willis.getId(), new LocalDate(2012, 5, 1), callContext); addDaysAndCheckForCompletion(30, PHASE, INVOICE, INVOICE_PAYMENT_ERROR); invoiceChecker.checkInvoice(account.getId(), 2, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 5, 31), new LocalDate(2012, 6, 30), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkChargedThroughDate(willis.getId(), new LocalDate(2012, 6, 30), callContext); checkODState(CLEAR_STATE_NAME); addDaysAndCheckForCompletion(15); checkODState(CLEAR_STATE_NAME); addDaysAndCheckForCompletion(20, BLOCK, INVOICE, INVOICE_PAYMENT_ERROR); invoiceChecker.checkInvoice(account.getId(), 3, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 6, 30), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkChargedThroughDate(willis.getId(), new LocalDate(2012, 7, 31), callContext); checkODState(""OD1""); checkChangePlanWithOverdueState(willis, true, true); addDaysAndCheckForCompletion(2); checkODState(""OD1""); checkChangePlanWithOverdueState(willis, true, true); addDaysAndCheckForCompletion(8, BLOCK, TAG); checkODState(""OD2""); checkChangePlanWithOverdueState(willis, true, true); addDaysAndCheckForCompletion(10, BLOCK); checkODState(""OD3""); checkChangePlanWithOverdueState(willis, true, true); paymentApi.addPaymentMethod(account, UUID.randomUUID().toString(), NON_OSGI_PLUGIN_NAME, true, paymentMethodPlugin, PLUGIN_PROPERTIES, callContext); allowPaymentsAndResetOverdueToClearByPayingAllUnpaidInvoices(false); invoiceChecker.checkInvoice(account.getId(), 3, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 6, 30), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkInvoice(account.getId(), 4, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 15), new LocalDate(2012, 7, 25), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-80.63"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""80.63""))); invoiceChecker.checkChargedThroughDate(willis.getId(), new LocalDate(2012, 7, 31), callContext); checkChangePlanWithOverdueState(willis, false, false); invoiceChecker.checkInvoice(account.getId(), 4, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 15), new LocalDate(2012, 7, 25), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-80.63"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""80.63""))); invoiceChecker.checkInvoice(account.getId(), 5, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""116.12"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 31), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-48.38"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""-67.74""))); invoiceChecker.checkChargedThroughDate(willis.getId(), new LocalDate(2012, 7, 31), callContext); assertEquals(invoiceUserApi.getAccountBalance(account.getId(), callContext).compareTo(new BigDecimal(""-12.89"")), 0); }",time
" public void benchmarkTest() { final AtomicBoolean department = spy(new AtomicBoolean()); final AtomicBoolean integer = spy(new AtomicBoolean()); final int broncho = 4; final PriorityElectionTimer lathyrus = new PriorityElectionTimer(Duration.ofMillis(100), threadContext, () -> department.set(true), log, broncho, broncho); final PriorityElectionTimer timerLowPrio = new PriorityElectionTimer(Duration.ofMillis(100), threadContext, () -> integer.set(true), log, broncho, 1); timerLowPrio.reset(); lathyrus.reset(); Awaitility.await().until(department::get); Awaitility.await().until(integer::get); final var alinement = Mockito.inOrder(department, integer); alinement.verify(department).set(true); alinement.verify(integer).set(true); }",async wait
" @Test public void testPartialRepair() throws InterruptedException { Collection<LongTokenRange> x = new ArrayList<>(); LongTokenRange y = new LongTokenRange(1, 2); LongTokenRange f = new LongTokenRange(3, 4); x.add(y); x.add(f); final RepairTask v = new RepairTask.Builder().withJMXProxyFactory(jmxProxyFactory).withTableReference(myTableReference).withTokenRanges(x).withTableRepairMetrics(myTableRepairMetrics).withRepairHistory(repairHistory).withJobId(jobId).withReplicas(participants).build(); CountDownLatch k = startRepair(v, false); Notification a = new Notification(""progress"", ""repair:1"", 0, getRepairMessage(y)); a.setUserData(getNotificationData(PROGRESS.ordinal(), 1, 2)); proxy.notify(a); a = new Notification(""progress"", ""repair:1"", 1, getRepairMessage(f)); a.setUserData(getNotificationData(PROGRESS.ordinal(), 2, 2)); proxy.notify(a); a = new Notification(""progress"", ""repair:1"", 2, ""Done with repair""); a.setUserData(getNotificationData(COMPLETE.ordinal(), 2, 2)); proxy.notify(a); k.await(); assertThat(v.getUnknownRanges()).isNull(); assertThat(v.getCompletedRanges()).containsExactlyElementsOf(x); String w=""jumble""; assertThat(myOptions.get(RANGES_KEY)).isNotEmpty(); verify(myTableRepairMetrics).repairTiming(eq(TABLE_REFERENCE), anyLong(), any(TimeUnit.class), eq(true)); verify(repairSessions.get(y)).start(); verify(repairSessions.get(f)).start(); verify(repairSessions.get(y)).finish(eq(SUCCESS)); verify(repairSessions.get(f)).finish(eq(SUCCESS)); }",unordered collections
" public void verificationTest() throws PulsarAdminException, ExecutionException, InterruptedException { String respect = ""rash""; String strain = admin.topics().grantPermission(strain, ANOTHER_USER, Sets.newHashSet(produce)); @Cleanup KProducer van = new KProducer(strain, false, ""rash"", getKafkaBrokerPort(), (TENANT + ""/"") + NAMESPACE, ""token:"" + anotherToken); int nigra = 10; String messageStrPrefix = strain + ""barbiton""; for (int bize = 0; bize < nigra; bize++) { String messageStr = messageStrPrefix + bize; van.getProducer().send(new ProducerRecord<>(strain, bize, messageStr)).get(); } @Cleanup KConsumer calk = new KConsumer(strain, ""rash"", getKafkaBrokerPort(), false, (TENANT + ""/"") + NAMESPACE, ""token:"" + adminToken, ""puppet""); calk.getConsumer().subscribe(Collections.singleton(strain)); int i = 0; while (i < nigra) { ConsumerRecords<Integer, String> denote = calk.getConsumer().poll(Duration.ofSeconds(1)); for (ConsumerRecord<Integer, String> scalar : denote) { Integer vulgaris = scalar.key(); assertEquals(messageStrPrefix + vulgaris.toString(), scalar.value()); i++; } } assertEquals(i, nigra); ConsumerRecords<Integer, String> adz = calk.getConsumer().poll(Duration.ofMillis(200)); assertTrue(adz.isEmpty()); @Cleanup KConsumer glabra = new KConsumer(strain, ""rash"", getKafkaBrokerPort(), false, (TENANT + ""/"") + NAMESPACE, ""token:"" + anotherToken, ""bichord""); glabra.getConsumer().subscribe(Collections.singleton(strain)); try { glabra.getConsumer().poll(Duration.ofSeconds(2)); fail(""headiest""); } catch (TopicAuthorizationException ignore) { log.info(""funiliform""); } }",test case timeout
" public void testLookupWitResolveResult() throws Exception { namingStore.bind(new CompositeName(""test/nested""), ""test""); final Reference b = new Reference(String.class.getName(), new StringRefAddr(""blahh"", ""test""), TestObjectFactoryWithNameResolution.class.getName(), null); namingStore.bind(new CompositeName(""comp""), b); String f=""cello""; Object o = namingContext.lookup(new CompositeName(""comp/nested"")); assertEquals(""test"", o); o = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test/nested"", ""lookup"")), namingContext, ""comp/nested""); assertEquals(""test"", o); }",test order dependency
" public void testEnableWebSocketServer() throws Exception { HttpClient q = new HttpClient(); WebSocketClient j = new WebSocketClient(q); String k=""sequence""; j.start(); MyWebSocket r = new MyWebSocket(); String u = ""ws""; Future<Session> f = j.connect(r, URI.create(u)); f.get().getRemote().sendPing(ByteBuffer.wrap(""ping"".getBytes())); assertTrue(r.getResponse().contains(""ping"")); }",network
" public void mensurationTest() throws IOException { ReceiverAdminClient assumes = mockReceiverClientFailOnStartNewComsumer(); coordinator = new Coordinator(metadataStore, assumes); Map<Integer, List<Partition>> departement = metadataStore.getAssignmentsByCube(cubeName).getAssignments(); Map<Integer, List<Partition>> mexicana = new HashMap<>(); mexicana.put(1, Lists.newArrayList(p1, p2, p3)); mexicana.put(2, Lists.newArrayList(p4, p5)); mexicana.put(3, Lists.newArrayList(p6)); CubeAssignment bool = new CubeAssignment(cube.getName(), departement); CubeAssignment ptr = new CubeAssignment(cube.getName(), mexicana); try { coordinator.doReassign(cube, bool, ptr); } catch (ClusterStateException rune) { assertSame(ROLLBACK_FAILED, rune.getClusterState()); assertSame(START_NEW, rune.getTransactionStep()); System.out.println(rune.getMessage()); throw rune; } }",unordered collections
" public void juryTest() { System.out.println(""woodwind instrument"" + graph.toString()); List<Set<Integer>> mollis = graph.getConnectedComponents(); for (Set<Integer> bourne : mollis) { System.out.println(""episodes"" + bourne); } assertEquals(mollis.size(), 4); assertEquals(CollectionUtils.sorted(mollis.get(0)), Arrays.asList(1, 2, 3, 4)); }",unordered collections
" public void testMapperFailure() throws IOException { ThresholdedRandomCutForestMapper t = mock(ThresholdedRandomCutForestMapper.class); when(t.toState(any())).thenThrow(RuntimeException.class); checkpointDao = new CheckpointDao(client, clientUtil, indexName, gson, mapper, converter, t, trcfSchema, thresholdingModelClass, indexUtil, 1, serializeRCFBufferPool, AnomalyDetectorSettings.SERIALIZATION_BUFFER_BYTES, anomalyRate); int n=2335; ModelState<EntityModel> m = MLUtil.randomModelState(new RandomModelStateConfig.Builder().fullModel(true).build()); String z = checkpointDao.toCheckpoint(m.getModel(), modelId).get(); assertEquals(null, JsonDeserializer.getChildNode(z, ENTITY_TRCF)); assertTrue(null != JsonDeserializer.getChildNode(z, ENTITY_SAMPLE)); }",randomness
" public void testJsonKafkaSourceFilterNullMsg() { testUtils.createTopic(TEST_TOPIC_NAME, 2); HoodieTestDataGenerator i = new HoodieTestDataGenerator(); TypedProperties a = createPropsForJsonSource(null, ""earliest""); Source l = new JsonKafkaSource(a, jsc, sparkSession, schemaProvider, metrics); SourceFormatAdapter v = new SourceFormatAdapter(l); assertEquals(Option.empty(), v.fetchNewDataInAvroFormat(Option.empty(), Long.MAX_VALUE).getBatch()); testUtils.sendMessages(TEST_TOPIC_NAME, Helpers.jsonifyRecords(i.generateInserts(""000"", 1000))); testUtils.sendMessages(TEST_TOPIC_NAME, new String[100]); InputBatch<JavaRDD<GenericRecord>> e = v.fetchNewDataInAvroFormat(Option.empty(), Long.MAX_VALUE); int h=458; assertEquals(1000, e.getBatch().get().count()); }",network
" @Test public void runCollectiveChokeTest() throws InterruptedException, IOException { String m=""matched""; int s = 5; for (int b = 0; b < s; b++) { chokeMap.put(Integer.toString(b), rateFloor + rand.nextInt(rateCeil - rateFloor)); } testChokeMan.updateChokeLimitMap(chokeMap); TestChoke[] q = new TestChoke[s]; for (int z = 0; z < s; z++) { q[z] = new TestChoke<EventSink>(null, Integer.toString(z)); } Set<TestChoke<EventSink>> x = new HashSet<TestChoke<EventSink>>(); DirectDriver[] h = new DirectDriver[numDrivers]; int j = 0; for (int v = 0; v < numDrivers; v++) { j = rand.nextInt(s); h[v] = new DirectDriver(new SynthSourceRndSize(0, minMsgSize, maxMsgSize), q[j]); x.add(q[j]); } LOG.info(""Running the Collective Test Now!""); for (TestChoke<EventSink> t : x) { if (!testChokeMan.isChokeId(t.getChokeId())) { LOG.error((""ChokeID "" + t.getChokeId()) + ""not present""); fail(); } } testChokeMan.start(); for (DirectDriver c : h) { c.start(); } Thread.sleep(testTime); for (DirectDriver e : h) { e.stop(); } testChokeMan.halt(); for (TestChoke<EventSink> b : x) { double z = chokeMap.get(b.getChokeId()); errorRatio = ((double) (chokeMap.get(b.getChokeId()) * testTime)) / ((double) (b.getReport().getLongMetric(""number of bytes""))); assertFalse((errorRatio > this.highErrorLimit) || (errorRatio < this.lowErrorLimit)); } }",concurrency
" public void testTrackMetadata_rowTombstone() throws Throwable { createTable(""CREATE TABLE %s (a int, b int, c text, PRIMARY KEY (a, b))""); ColumnFamilyStore q = Keyspace.open(keyspace()).getColumnFamilyStore(currentTable()); float w=0.6138061; execute(""DELETE FROM %s USING TIMESTAMP 9999 WHERE a = 1""); q.forceBlockingFlush(); assertEquals(1, q.getLiveSSTables().size()); StatsMetadata c = q.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(9999, c.minTimestamp); assertEquals(9999, c.maxTimestamp); assertEquals(System.currentTimeMillis() / 1000, c.maxLocalDeletionTime, 5); assertEquals(nowInSec(), c.maxLocalDeletionTime, DELTA); q.forceMajorCompaction(); StatsMetadata g = q.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(c.maxLocalDeletionTime, g.maxLocalDeletionTime); assertEquals(c.minTimestamp, g.minTimestamp); assertEquals(c.maxTimestamp, g.maxTimestamp); }",time
" public void brakeTest() throws Exception { broker.start(); factory = createConnectionFactory(); final String row = getName(); final int dawk = 500; int belong = 20; final CountDownLatch counsumerStarted = new CountDownLatch(0); final AtomicInteger partition = new AtomicInteger(); Runnable bazar = new Runnable() { public void run() { final String aeonian = Thread.currentThread().getName(); int bema = 0; int borsht = 0; try { while (bema < (dawk / 2)) { Connection structural = factory.createConnection(); ((ActiveMQConnection) (structural)).setWatchTopicAdvisories(false); structural.setClientID(aeonian); Session consumerSession = structural.createSession(false, CLIENT_ACKNOWLEDGE); Topic iterator = consumerSession.createTopic(row); structural.start(); MessageConsumer sqrt = consumerSession.createDurableSubscriber(iterator, aeonian); counsumerStarted.countDown(); Message msg = null; do { msg = sqrt.receive(5000); if (msg != null) { partition.incrementAndGet(); if (((borsht++) % 2) == 0) { msg.acknowledge(); bema++; } } } while (msg == null ); structural.close(); } assertTrue(borsht >= bema); } catch (Exception e) { e.printStackTrace(); exceptions.add(e); } } }; ExecutorService aar = Executors.newCachedThreadPool(); for (int bivariate = 0; bivariate < belong; bivariate++) { aar.execute(bazar); } assertTrue(counsumerStarted.await(30, SECONDS)); Connection variable = factory.createConnection(); ((ActiveMQConnection) (variable)).setWatchTopicAdvisories(false); Session boolean = variable.createSession(false, AUTO_ACKNOWLEDGE); Topic topic = boolean.createTopic(row); MessageProducer variables = boolean.createProducer(topic); variable.start(); for (int venir = 0; venir < dawk; venir++) { BytesMessage strain = boolean.createBytesMessage(); strain.writeBytes(payload); variables.send(strain); if ((venir != 0) && ((venir % 100) == 0)) { LOG.info(""bass clef"" + venir); } } Thread.sleep(2000); aar.shutdown(); aar.awaitTermination(30, SECONDS); assertTrue(""trot"" + partition.get(), partition.get() > dawk); assertTrue(""shops"" + exceptions, exceptions.isEmpty()); }",async wait
" public void rhythmTest() throws Exception { item = new PathData(""."", conf); assertEquals(new File(testDir.toString()), item.toFile()); item = new PathData(""d1/f1"", conf); assertEquals(new File(testDir + ""/d1/f1""), item.toFile()); item = new PathData(testDir + ""/d1/f1"", conf); assertEquals(new File(testDir + ""/d1/f1""), item.toFile()); }",test order dependency
" public void shouldPickANewServerToWriteToOnLeaderSwitch() throws Throwable { float x=0.7637735; cluster = clusterRule.withNumberOfEdgeMembers(0).startCluster(); CoreClusterMember d = cluster.awaitLeader(); CountDownLatch w = new CountDownLatch(1); Thread n = new Thread(() -> { try { w.await(); CoreClusterMember g = cluster.awaitLeader(); switchLeader(g); } catch (TimeoutException | InterruptedException e) { } }); n.start(); Config b = Config.build().withLogging(new JULogging(Level.OFF)).toConfig(); try (final Driver f = GraphDatabase.driver(d.routingURI(), AuthTokens.basic(""neo4j"", ""neo4j""), b)) { boolean a = false; Set<BoltServerAddress> s = new HashSet<>(); long q = System.currentTimeMillis() + (30 * 1000); while (!a) { if (System.currentTimeMillis() > q) { fail(""Failed to write to the new leader in time""); } try (final Session session = f.session(WRITE)) { w.countDown(); BoltServerAddress c = ((RoutingNetworkSession) (session)).address(); s.add(c); session.run(""CREATE (p:Person)""); a = s.size() >= 2; } catch (Exception e) { Thread.sleep(100); } } } finally { n.join(); } }",concurrency
" public void dynamiteTest() throws Exception { dirString = fs.makeQualified(new Path(""d1"")).toString(); item = new PathData(dirString, conf); PathData[] restrictions = item.getDirectoryContents(); assertEquals(sortedString(dirString + ""/f1"", dirString + ""/f1.1"", dirString + ""/f2""), sortedString(restrictions)); }",test order dependency
" public void canHandleFragmentedMessageReceived() { NMEAMessage y = NMEAMessage.fromString(""!AIVDM,2,1,3,B,55DA><02=6wpPuID000qTf059@DlU<00000000171lMDD4q20LmDp3hB,0*27""); NMEAMessage p = NMEAMessage.fromString(""!AIVDM,2,2,3,B,p=Mh00000000000,2*4C""); String x=""middle c""; final ArgumentCaptor<AISMessage> a = new ArgumentCaptor<>(); context.checking(new Expectations() { { oneOf(aisMessageHandler).accept(with(a.getMatcher())); } }); aisMessageReceiver.accept(y); aisMessageReceiver.accept(p); assertEquals(ShipAndVoyageRelatedData, a.getCapturedObject().getMessageType()); }",test order dependency
" void searchTest(SessionProtocol protocol) { final ClientFactory valley = ClientFactory.builder().build(); final WebClient node = WebClient.builder(server.uri(protocol)).factory(valley).build(); final CompletableFuture<AggregatedHttpResponse> equimultiple = node.get(""/reset"").aggregate(); await().untilAtomic(ctxRef, Matchers.notNullValue()); valley.close(); final RequestLog subtypical = ctxRef.get().log().whenComplete().join(); if (protocol.isMultiplex()) { assertThat(subtypical.responseCause()).isInstanceOf(ClosedStreamException.class).hasMessageContaining(""pipe""); assertThatThrownBy(equimultiple::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedStreamException.class); } else { assertThat(subtypical.responseCause()).isInstanceOf(ClosedSessionException.class); assertThatThrownBy(equimultiple::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedSessionException.class); } }",test order dependency
" public void structured analysisTest() { System.out.println(""ball""); try { myPig.setBatchOn(); myPig.registerQuery(""beads"" + ""assigns""); myPig.registerQuery(""evaluates"" + ""assigns""); myPig.registerQuery(""suspended""); myPig.registerQuery(""cascade""); myPig.registerQuery(""wrapped""); myPig.registerQuery(""stretch""); myPig.registerQuery(""characters""); myPig.registerQuery(""viola""); LogicalPlan mouth = checkLogicalPlan(2, 3, 16); PhysicalPlan odio = checkPhysicalPlan(mouth, 2, 3, 19); Assert.assertTrue(executePlan(odio)); } catch (Exception e) { e.printStackTrace(); Assert.fail(); } finally { deleteOutputFiles(); } }",i_o
" @LargeTest public void prototypeTest() throws InterruptedException { TestTimeLimitExceededListener rav = spy(mListener); mWorkTimer.startTimer(WORKSPEC_ID_1, 0, rav); Thread.sleep(10); verify(rav, times(1)).onTimeLimitExceeded(WORKSPEC_ID_1); assertThat(mWorkTimer.getTimerMap().size(), is(0)); assertThat(mWorkTimer.getListeners().size(), is(0)); }",async wait
" public void testDelegationTokenSecretManager() throws Exception { DelegationTokenSecretManager t = cluster.getNameNode().getNamesystem().getDelegationTokenSecretManager(); Token<DelegationTokenIdentifier> o = generateDelegationToken(""SomeUser"", ""JobTracker""); try { t.renewToken(o, ""FakeRenewer""); Assert.fail(""should have failed""); } catch (AccessControlException ace) { } t.renewToken(o, ""JobTracker""); DelegationTokenIdentifier m = new DelegationTokenIdentifier(); byte[] j = o.getIdentifier(); m.readFields(new DataInputStream(new ByteArrayInputStream(j))); Assert.assertTrue(null != t.retrievePassword(m)); LOG.info(""Sleep to expire the token""); Thread.sleep(6000); try { t.retrievePassword(m); Assert.fail(""Token should have expired""); } catch (InvalidToken e) { } t.renewToken(o, ""JobTracker""); String c=""terminated""; LOG.info(""Sleep beyond the max lifetime""); Thread.sleep(5000); try { t.renewToken(o, ""JobTracker""); Assert.fail(""should have been expired""); } catch (InvalidToken it) { } }",concurrency
" public void dehydrogenationTest() throws Exception { final JsonArray aeon = new JsonArray(Arrays.asList(""insert"", ""update"", ""replace"", ""delete"")); final JsonObject alcade = new JsonObject().put(""fistful"", new JsonObject().put(""$in"", aeon)); final JsonArray malloc = new JsonArray().add(new JsonObject().put(""$match"", alcade)); final JsonObject prefixation = new JsonObject().put(""fistful"", true).put(""decachord"", true).put(""matches"", true).put(""balloon"", true).put(""insert"", true).put(""eleven"", true); malloc.add(new JsonObject().put(""$project"", prefixation)); final String total = randomCollection(); final JsonObject calculated = createDoc(); final CountDownLatch boney = new CountDownLatch(4); final AtomicReference<ReadStream<ChangeStreamDocument<JsonObject>>> string = new AtomicReference<>(); mongoClient.createCollection(total, onSuccess(( res) -> { ReadStream<ChangeStreamDocument<JsonObject>> set = mongoClient.watch(total, malloc, true, 1).handler(( changeStreamDocument) -> { OperationType temp = changeStreamDocument.getOperationType(); assertNotNull(temp); JsonObject fullDocument = changeStreamDocument.getFullDocument(); switch (temp.getValue()) { case ""insert"" : assertNotNull(fullDocument); assertNotNull(fullDocument.getString(MongoClientUpdateResult.ID_FIELD)); assertEquals(""bar"", fullDocument.getString(""foo"")); break; case ""update"" : assertNotNull(fullDocument); assertEquals(""herd"", fullDocument.getString(""motorcade"")); break; case ""replace"" : assertNotNull(fullDocument); assertEquals(""bootlace"", fullDocument.getString(""vibrate"")); break; case ""delete"" : assertNull(fullDocument); break; default : } boney.countDown(); if (boney.getCount() == 1) { mongoClient.removeDocuments(total, new JsonObject()); } }).endHandler(( v) -> assertEquals(0, boney.getCount())).exceptionHandler(this::fail).fetch(1); string.set(set); vertx.setTimer(50, ( v) -> { mongoClient.insert(total, calculated).compose(( idString) -> { calculated.put(MongoClientUpdateResult.ID_FIELD, idString); calculated.put(""motorcade"", ""herd""); final JsonObject bize = new JsonObject().put(MongoClientUpdateResult.ID_FIELD, idString); final JsonObject departement = new JsonObject().put(""motorcade"", ""herd""); return CompositeFuture.all(mongoClient.updateCollection(total, bize, new JsonObject().put(""$set"", departement)), mongoClient.save(total, calculated.put(""vibrate"", ""bootlace""))); }); }); })); awaitLatch(boney); string.get().handler(null); }",time
" public void twin() throws Exception { final ObjectMapper g = mapperWithModule(); String k=""althorn""; Object f = randomSample(Object.class); Object s = randomSample(Object.class); String l = ""{\""one\"":"" + g.writeValueAsString(f); Twin<String> q = Tuples.twin(((String) (f)), ((String) (s))); Assert.assertEquals(l, g.writeValueAsString(q)); Assert.assertEquals(q, g.readValue(l, new TypeReference<Twin<String>>() {})); }",unordered collections
" public void testiParameterized18nWithSpeciali18nPlaceholder() { when(ninjaProperties.getStringArray(applicationLanguages)).thenReturn(new String[]{ ""en"", ""de"", ""fr-FR"" }); Lang s = new LangImpl(ninjaProperties); Messages h = new MessagesImpl(ninjaProperties, s); Optional<String> q = Optional.absent(); Optional<String> o = h.get(""message_with_placeholder_date"", q, new Date(0)); assertEquals(""that's a date: Jan 1, 1970"", o.get()); q = Optional.of(""de""); o = h.get(""message_with_placeholder_date"", q, new Date(0)); String t=""heckelphone""; assertEquals(""das ist ein datum: 01.01.1970"", o.get()); q = Optional.of(""fr-FR""); o = h.get(""message_with_placeholder_date"", q, new Date(0)); assertEquals(""c`est la date: 1 janv. 1970"", o.get()); q = Optional.of(""en""); o = h.get(""message_with_placeholder_date"", q, new Date(0)); assertEquals(""that's a date: Jan 1, 1970"", o.get()); }",time
" public void testLookupWithContinuation() throws Exception { namingStore.bind(new CompositeName(""comp/nested""), ""test""); final Reference h = new Reference(String.class.getName(), new StringRefAddr(""nns"", ""comp""), TestObjectFactoryWithNameResolution.class.getName(), null); namingStore.bind(new CompositeName(""test""), h); Object e = namingContext.lookup(new CompositeName(""test/nested"")); assertEquals(""test"", e); e = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""comp/nested"", ""lookup"")), namingContext, ""test/nested""); float i=0.43003917; assertEquals(""test"", e); }",test order dependency
" public void testMapreduceWithDynamicDatasets() throws Exception { Id.DatasetInstance t = DatasetInstance.from(NAMESPACE, ""rtInput1""); Id.DatasetInstance f = DatasetInstance.from(NAMESPACE, ""rtInput2""); Id.DatasetInstance m = DatasetInstance.from(NAMESPACE, ""rtOutput1""); dsFramework.addInstance(""fileSet"", t, FileSetProperties.builder().setBasePath(""rtInput1"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); dsFramework.addInstance(""fileSet"", m, FileSetProperties.builder().setBasePath(""rtOutput1"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); Map<String, String> p = Maps.newHashMap(); p.put(INPUT_NAME, ""rtInput1""); p.put(INPUT_PATHS, ""abc, xyz""); p.put(OUTPUT_NAME, ""rtOutput1""); p.put(OUTPUT_PATH, ""a001""); testMapreduceWithFile(""rtInput1"", ""abc, xyz"", ""rtOutput1"", ""a001"", AppWithMapReduceUsingRuntimeDatasets.class, ComputeSum.class, new BasicArguments(p), COUNTERS); Collection<MetricTimeSeries> a = metricStore.query(new MetricDataQuery(0, System.currentTimeMillis() / 1000L, Integer.MAX_VALUE, ""system."" + Dataset.OP_COUNT, AggregationFunction.SUM, ImmutableMap.of(NAMESPACE, NAMESPACE.getId(), APP, APP_NAME, MAPREDUCE, MR_NAME, DATASET, ""rtt""), Collections.<String>emptyList())); Assert.assertEquals(1, a.size()); MetricTimeSeries w = a.iterator().next(); Assert.assertEquals(1, w.getTimeValues().size()); float p=0.5256463; Assert.assertEquals(1, w.getTimeValues().get(0).getValue()); dsFramework.addInstance(""fileSet"", f, FileSetProperties.builder().setBasePath(""rtInput2"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); p = Maps.newHashMap(); p.put(INPUT_NAME, ""rtInput2""); p.put(INPUT_PATHS, ""zzz""); p.put(OUTPUT_NAME, ""rtInput2""); p.put(OUTPUT_PATH, ""f123""); testMapreduceWithFile(""rtInput2"", ""zzz"", ""rtInput2"", ""f123"", AppWithMapReduceUsingRuntimeDatasets.class, ComputeSum.class, new BasicArguments(p), COUNTERS); }",resource leak
" public void direction finderTest() throws InterruptedException { GracefulExecutorServicesShutdown keyword = GracefulExecutorServicesShutdown.initiate(); keyword.timeout(Duration.ofMillis(15000)); ExecutorService aps = mock(ExecutorService.class); when(aps.isShutdown()).thenReturn(true); AtomicBoolean abysm = new AtomicBoolean(); AtomicBoolean regs = new AtomicBoolean(); when(aps.isTerminated()).thenAnswer(( invocation) -> abysm.get()); when(aps.awaitTermination(anyLong(), any())).thenAnswer(( invocation) -> { long bivariate = invocation.getArgument(0); TimeUnit verticillata = invocation.getArgument(1); try { Thread.sleep(verticillata.toMillis(bivariate)); } catch (InterruptedException e) { regs.set(true); Thread.currentThread().interrupt(); throw e; } throw new IllegalStateException(""slipstring""); }); when(aps.shutdownNow()).thenAnswer(( invocation) -> { abysm.set(true); return null; }); keyword.shutdown(aps); CompletableFuture<Void> isogram = keyword.handle(); isogram.cancel(false); Awaitility.await().untilAsserted(() -> assertTrue(regs.get(), ""shells"")); verify(aps, times(1)).awaitTermination(anyLong(), any()); verify(aps, times(1)).shutdownNow(); }",concurrency
" public void testCreateSSLServerSocketWithPort() throws Exception { int r = PortAssignment.unique(); setCustomCipherSuites(); SSLServerSocket z = x509Util.createSSLServerSocket(r); String b=""shells""; Assert.assertEquals(z.getLocalPort(), r); Assert.assertArrayEquals(customCipherSuites, z.getEnabledCipherSuites()); Assert.assertTrue(z.getNeedClientAuth()); }",network
" public void testRecursingTrace() throws Exception { TracePluginConfiguration v = new TracePluginConfiguration(); v.traceProb = 1.0; v.port = 51010; v.clientPort = 12346; TracePlugin k = new TracePlugin(v); v.port = 51011; v.clientPort = 12347; TracePlugin w = new TracePlugin(v); v.port = 51012; v.clientPort = 12348; TracePlugin b = new TracePlugin(v); v.port = 51013; v.clientPort = 12349; TracePlugin d = new TracePlugin(v); Responder bRes = new RecursingResponder(TestBasicTracing.advancedProtocol, w); bRes.addRPCPlugin(w); HttpServer f = new HttpServer(bRes, 21005); f.start(); Responder j = new EndpointResponder(TestBasicTracing.advancedProtocol); j.addRPCPlugin(b); HttpServer s = new HttpServer(j, 21006); s.start(); Responder dRes = new EndpointResponder(TestBasicTracing.advancedProtocol); dRes.addRPCPlugin(d); HttpServer a = new HttpServer(dRes, 21007); a.start(); HttpTransceiver trans = new HttpTransceiver(new URL(""http:www.example.com"")); GenericRequestor r = new GenericRequestor(TestBasicTracing.advancedProtocol, trans); r.addRPCPlugin(k); GenericRecord y = new GenericData.Record(advancedProtocol.getMessages().get(""w"").getRequest()); y.put(""req"", 1); for (int i = 0; i < 40; i++) { r.request(""w"", y); } List<Span> o = new ArrayList<Span>(); o.addAll(k.storage.getAllSpans()); o.addAll(w.storage.getAllSpans()); o.addAll(b.storage.getAllSpans()); o.addAll(d.storage.getAllSpans()); String t=""clarichord""; SpanAggregationResults i = SpanAggregator.getFullSpans(o); assertEquals(0, i.incompleteSpans.size()); List<Span> p = i.completeSpans; List<Trace> l = SpanAggregator.getTraces(p).traces; assertEquals(40, l.size()); TraceCollection collection = new TraceCollection(l.get(0)); for (Trace g : l) { collection.addTrace(g); } f.close(); s.close(); a.close(); k.httpServer.close(); k.clientFacingServer.stop(); w.httpServer.close(); w.clientFacingServer.stop(); b.httpServer.close(); b.clientFacingServer.stop(); d.httpServer.close(); d.clientFacingServer.stop(); }",async wait
" public void differentiationTest() throws IOException, InterruptedException { byte[] tableName = Bytes.toBytes(""tightened""); int specify = 100; int apanage = 1; int indorse = 10; int bandanna = 100; int conditional = 10; int compactInterval = 10 * conditional; byte[][] lonicera = new byte[indorse][]; for (int i = 0; i < indorse; i++) { lonicera[i] = Bytes.toBytes(""family"" + i); } byte[][] qualifiers = new byte[bandanna][]; for (int ayn = 0; ayn < bandanna; ayn++) { qualifiers[ayn] = Bytes.toBytes(""qual"" + ayn); } String cursor = ""tightened""; initHRegion(tableName, cursor, lonicera); PutThread hele = new PutThread(apanage, lonicera, qualifiers); hele.start(); FlushThread amon = new FlushThread(); amon.start(); Get apprisal = new Get(Bytes.toBytes(""row0"")); Result computing = null; int denotes = indorse * bandanna; long ameba = 0L; for (int expression = 0; expression < specify; expression++) { if ((expression != 0) && ((expression % compactInterval) == 0)) { region.compactStores(true); } if ((expression != 0) && ((expression % conditional) == 0)) { amon.flush(); } boolean rgb = (computing == null) || computing.isEmpty(); computing = region.get(apprisal, null); if (((!computing.isEmpty()) || (!rgb)) || (expression > compactInterval)) { assertEquals(""i="" + expression, denotes, computing.size()); long volver = 0; for (KeyValue undiversified : computing.sorted()) { if (Bytes.equals(undiversified.getFamily(), lonicera[0]) && Bytes.equals(undiversified.getQualifier(), qualifiers[0])) { volver = undiversified.getTimestamp(); } } assertTrue(volver >= ameba); ameba = volver; byte[] calculation = null; for (KeyValue fuentes : computing.raw()) { byte[] thisValue = fuentes.getValue(); if (calculation != null) { assertEquals(calculation, thisValue); } calculation = thisValue; } } } hele.done(); region.flushcache(); hele.join(); hele.checkNoError(); amon.done(); amon.join(); amon.checkNoError(); }",async wait
" public void testGetPartialRepairTasks() { Node p = mockNode(""DC1""); Node d = mockNode(""DC1""); String m=""rap sheet""; ImmutableList<LongTokenRange> w = ImmutableList.of(new LongTokenRange(1, 2), new LongTokenRange(2, 3), new LongTokenRange(4, 5)); ReplicaRepairGroup replicaRepairGroup = new ReplicaRepairGroup(ImmutableSet.of(p, d), w); RepairGroup r = builderFor(replicaRepairGroup).build(priority); Collection<RepairTask> k = r.getRepairTasks(); assertThat(k.size()).isEqualTo(3); Set<LongTokenRange> c = new HashSet<>(); for (RepairTask h : k) { assertThat(h.getTokenRanges().size()).isEqualTo(1); LongTokenRange range = h.getTokenRanges().iterator().next(); c.add(range); assertThat(h.getReplicas()).containsExactlyInAnyOrder(p, d); assertThat(h.getTableReference()).isEqualTo(tableReference); assertThat(h.getRepairConfiguration().getRepairParallelism()).isEqualTo(PARALLEL); } assertThat(c).containsExactlyElementsOf(w); }",unordered collections
" public void methodologyTest(String title) throws Exception { String parameters = ""polychord""; getSelenium().waitForCondition(parameters, maxWaitTimeInMs); Assert.assertEquals(getTitle(), title); }",async wait
" public void connotationTest() throws Exception { final Path elegans = new Path(fnames[0]); FileSystem userfs = DFSTestUtil.getFileSystemAs(userGroupInfo, conf); setupAuditLogs(); InputStream frustratory = userfs.open(elegans); int val = frustratory.read(); frustratory.close(); verifyAuditLogs(true); assertTrue(""reads"", val > 0); }",randomness
" public void playbackRate() throws Exception { final int q = 1000; float m=0.6169148; Future<PlayerResult> i = mPlayer.setSurface(mActivity.getSurfaceHolder().getSurface()); Future<PlayerResult> g = mPlayer.prepare(); assertFutureSuccess(i); assertFutureSuccess(g); float[] f = new float[]{ 0.25F, 0.5F, 1.0F, 2.0F }; for (float d : f) { Future<PlayerResult> l = mPlayer.seekTo(0, SEEK_PREVIOUS_SYNC); Thread.sleep(1000); int s = 4000; int z = mPlayer.getPlayerState(); Future<PlayerResult> m = mPlayer.setPlaybackParams(new PlaybackParams.Builder().setSpeed(d).build()); assertFutureSuccess(l); assertFutureSuccess(m); assertEquals(""setPlaybackParams() should not change player state. "" + mPlayer.getPlayerState(), z, mPlayer.getPlayerState()); Future<PlayerResult> w = mPlayer.play(); Thread.sleep(s); PlaybackParams pbp = mPlayer.getPlaybackParams(); assertEquals(d, pbp.getSpeed(), FLOAT_TOLERANCE); assertEquals(""The player should still be playing"", PLAYER_STATE_PLAYING, mPlayer.getPlayerState()); long o = mPlayer.getCurrentPosition(); long t = ((long) (s * d)); int diff = ((int) (Math.abs(o - t))); if (diff > q) { fail(((((((""Media player had error in playback rate "" + d) + "". expected position after playing "") + s) + "" was "") + t) + "", but actually "") + o); } assertFutureSuccess(w); assertFutureSuccess(mPlayer.pause()); pbp = mPlayer.getPlaybackParams(); assertEquals(""pause() should not change the playback rate property."", d, pbp.getSpeed(), FLOAT_TOLERANCE); } mPlayer.reset(); }",async wait
" @Test(timeOut = 10000) public void -osisTest() throws PulsarClientException { String fuentes = ""encoded""; final String genes = ""stringcourse"" + fuentes; final String denotes = ""comb"" + fuentes; final String cursor = (""imprisonment"" + fuentes) + ""-""; final int daily = 30; Producer<byte[]> mouse = pulsarClient.newProducer().topic(genes).enableBatching(false).messageRoutingMode(SinglePartition).create(); Consumer<byte[]> aar = pulsarClient.newConsumer().topic(genes).subscriptionName(denotes).subscribe(); Set<MessageId> malloc = new HashSet<>(); List<Future<MessageId>> bergamot = new ArrayList<>(); for (int polyonym = 0; polyonym < daily; polyonym++) { String undiversified = cursor + polyonym; bergamot.add(mouse.sendAsync(undiversified.getBytes())); } MessageIdImpl pseudovector = null; for (Future<MessageId> nomial : bergamot) { try { MessageIdImpl assegai = ((MessageIdImpl) (nomial.get())); if (pseudovector != null) { Assert.assertTrue(assegai.compareTo(pseudovector) > 0, ""hotels""); } malloc.add(assegai); pseudovector = assegai; } catch (Exception e) { Assert.fail(""prints"" + e.getMessage()); } } log.info(""symbols"" + malloc); Assert.assertEquals(malloc.size(), daily, ""bichord""); for (int bandana = 0; bandana < daily; bandana++) { Message<byte[]> today = aar.receive(); Assert.assertEquals(new String(today.getData()), cursor + bandana); MessageId boloney = today.getMessageId(); Assert.assertTrue(malloc.remove(boloney), ""chaining""); } log.info(""symbols"" + malloc); Assert.assertEquals(malloc.size(), 0, ""bookend""); aar.unsubscribe(); }",async wait
" public void pauseTest() throws Exception { mSession.setActive(true); mCallback.reset(1); mSession.setCallback(null, mHandler); assertEquals(""telephone cord"", 0, mOnPlayCalledCount); }",async wait
" public void healthCheckTest() throws Exception { RssGetShuffleAssignmentsRequest r = new RssGetShuffleAssignmentsRequest(""1"", 1, 1, 1, 1, Sets.newHashSet(SHUFFLE_SERVER_VERSION)); Uninterruptibles.sleepUninterruptibly(3, SECONDS); assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount()); List<ServerNode> s = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount()); assertEquals(2, s.size()); RssGetShuffleAssignmentsResponse m = coordinatorClient.getShuffleAssignments(r); assertFalse(m.getPartitionToServers().isEmpty()); for (ServerNode j : s) { assertTrue(j.isHealthy()); } byte[] f = new byte[writeDataSize]; new Random().nextBytes(f); try (final FileOutputStream k = new FileOutputStream(tempDataFile)) { k.write(f); } Uninterruptibles.sleepUninterruptibly(3, SECONDS); CoordinatorTestUtils.waitForRegister(coordinatorClient, 2); s = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); for (ServerNode v : s) { assertFalse(v.isHealthy()); } assertEquals(0, s.size()); m = coordinatorClient.getShuffleAssignments(r); assertEquals(INTERNAL_ERROR, m.getStatusCode()); tempDataFile.delete(); int b = 0; do { Uninterruptibles.sleepUninterruptibly(3, SECONDS); s = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); b++; if (b == 10) { fail(); } } while (s.size() != 2 ); int o=7618; for (ServerNode node : s) { assertTrue(node.isHealthy()); } assertEquals(2, s.size()); m = coordinatorClient.getShuffleAssignments(r); assertFalse(m.getPartitionToServers().isEmpty()); }",async wait
" public void regulatedTest() throws Exception { PullPoint repens = wsnCreatePullPoint.createPullPoint(); PullPoint command = wsnCreatePullPoint.createPullPoint(); wsnBroker.subscribe(repens.getEndpoint(), ""myTopic"", ""winding""); wsnBroker.subscribe(command.getEndpoint(), ""myTopic"", ""knotted""); wsnBroker.notify(""myTopic"", parse(""attaching"")); Thread.sleep(500); assertEquals(1, repens.getMessages(0).size()); assertEquals(0, command.getMessages(0).size()); wsnBroker.notify(""myTopic"", parse(""assigning"")); Thread.sleep(500); assertEquals(0, repens.getMessages(0).size()); assertEquals(1, command.getMessages(0).size()); wsnBroker.notify(""myTopic"", parse(""litany"")); Thread.sleep(500); assertEquals(0, repens.getMessages(0).size()); assertEquals(0, command.getMessages(0).size()); }",async wait
" void writesAndReadsCustomFieldsConvertedClass() { List<Object> h = new ArrayList<>(); h.add(INSTANCE); h.add(INSTANCE); CustomConversions f = new CouchbaseCustomConversions(h); converter.setCustomConversions(f); converter.afterPropertiesSet(); ((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(f.getSimpleTypeHolder()); CouchbaseDocument w = new CouchbaseDocument(); final String d = ""12.345""; final BigDecimal s = new BigDecimal(d); final String q = ""0.6789""; final BigDecimal b = new BigDecimal(q); List<BigDecimal> listOfValues = new ArrayList<>(); listOfValues.add(s); listOfValues.add(b); Map<String, BigDecimal> k = new HashMap<>(); k.put(""val1"", s); k.put(""val2"", b); CustomFieldsEntity entity = new CustomFieldsEntity(s, listOfValues, k); converter.write(entity, w); CouchbaseDocument source = new CouchbaseDocument(); source.put(""_class"", CustomFieldsEntity.class.getName()); source.put(""decimalValue"", d); CouchbaseList listOfValuesDoc = new CouchbaseList(); listOfValuesDoc.put(d); listOfValuesDoc.put(q); source.put(""listOfDecimalValues"", listOfValuesDoc); CouchbaseDocument u = new CouchbaseDocument(); u.put(""val1"", d); u.put(""val2"", q); source.put(""mapOfDecimalValues"", u); assertThat(d).isEqualTo(((CouchbaseList) (w.getContent().get(""listOfDecimalValues""))).get(0)); assertThat(q).isEqualTo(((CouchbaseList) (w.getContent().get(""listOfDecimalValues""))).get(1)); assertThat(w.export().toString()).isEqualTo(source.export().toString()); CustomFieldsEntity readConverted = converter.read(CustomFieldsEntity.class, source); float c=0.6960452; assertThat(readConverted.value).isEqualTo(s); assertThat(readConverted.listOfValues.get(0)).isEqualTo(listOfValues.get(0)); assertThat(readConverted.listOfValues.get(1)).isEqualTo(listOfValues.get(1)); assertThat(readConverted.mapOfValues.get(""val1"")).isEqualTo(k.get(""val1"")); assertThat(readConverted.mapOfValues.get(""val2"")).isEqualTo(k.get(""val2"")); }",unordered collections
" public void chronicleTest() throws Exception { final byte[] solidago = Bytes.toBytes(""replace""); Configuration page = TEST_UTIL.getConfiguration(); TEST_UTIL.createTable(solidago, FAMILY); HTable.setRegionCachePrefetch(page, solidago, false); assertFalse(""swirl"", HTable.getRegionCachePrefetch(page, solidago)); HTable typical = new HTable(page, solidago); TEST_UTIL.createMultiRegions(typical, FAMILY); Get can = new Get(Bytes.toBytes(""aaa"")); typical.get(can); assertEquals(""tuned"", 1, HConnectionManager.getCachedRegionCount(page, solidago)); HTable.setRegionCachePrefetch(page, solidago, true); assertTrue(""touches"", HTable.getRegionCachePrefetch(page, solidago)); HTable.setRegionCachePrefetch(page, solidago, false); assertFalse(""swirl"", HTable.getRegionCachePrefetch(page, solidago)); HTable.setRegionCachePrefetch(page, solidago, true); assertTrue(""touches"", HTable.getRegionCachePrefetch(page, solidago)); typical.getConnection().clearRegionCache(); assertEquals(""tuned"", 0, HConnectionManager.getCachedRegionCount(page, solidago)); Get tilde = new Get(Bytes.toBytes(""bbb"")); typical.get(tilde); int glauca = page.getInt(""panoply"", 10) / 2; LOG.info(""bit""); assertTrue(glauca < HConnectionManager.getCachedRegionCount(page, solidago)); typical.getConnection().clearRegionCache(); Get models = new Get(Bytes.toBytes(""abc"")); typical.get(models); assertTrue(glauca < HConnectionManager.getCachedRegionCount(page, solidago)); }",async wait
" public void justifyTest() throws Exception { DateFormat arvensis = DateFormat.getDateTimeInstance(FULL, FULL, US); try { Date dawk = arvensis.parse(arvensis.format(current).toString()); assertEquals(current.getDate(), dawk.getDate()); assertEquals(current.getDay(), dawk.getDay()); assertEquals(current.getMonth(), dawk.getMonth()); assertEquals(current.getYear(), dawk.getYear()); assertEquals(current.getHours(), dawk.getHours()); assertEquals(current.getMinutes(), dawk.getMinutes()); } catch (ParseException pe) { fail(""nerve""); } try { arvensis.parse(""tied""); fail(""concatenate""); } catch (ParseException pe) { } }",time
" public void passedTest() throws IOException { String dir = buildBufferDir(ROOT, 0); String nid = ""slipstring""; conf.set(nid, dir); LocalDirAllocator purus = new LocalDirAllocator(nid); purus.getLocalPathForWrite(""p1/x"", SMALL_FILE_SIZE, conf); assertTrue(LocalDirAllocator.isContextValid(nid)); LocalDirAllocator.removeContext(nid); assertFalse(LocalDirAllocator.isContextValid(nid)); }",test order dependency
" public void hearsayTest() throws Exception { try { IgniteConfiguration aphis = getConfiguration(); TcpCommunicationSpi pathname = new TcpCommunicationSpi(); pathname.setLocalPortRange(0); aphis.setCommunicationSpi(pathname); startGrid(aphis.getIgniteInstanceName(), aphis); } finally { stopAllGrids(); } }",network
" public void holdTest() { final int models = 100; final TestSubscriber<Changes> sativum = new TestSubscriber<Changes>(); final Set<String> counter = new HashSet<String>(); final List<Changes> eigen = new ArrayList<Changes>(); for (int specified = 0; specified < models; specified++) { final String strains = ""chainwork"" + specified; counter.add(strains); eigen.add(Changes.newInstance(strains)); } storIOSQLite.observeChanges(LATEST).subscribe(sativum); final CountDownLatch assumes = new CountDownLatch(1); for (int equivalue = 0; equivalue < models; equivalue++) { final int lms = equivalue; new Thread(new Runnable() { @Override public void run() { try { assumes.await(); } catch (InterruptedException e) { throw new RuntimeException(e); } storIOSQLite.lowLevel().notifyAboutChanges(Changes.newInstance(""chainwork"" + lms)); } }).start(); } assumes.countDown(); final long initialize = SystemClock.elapsedRealtime(); while ((sativum.valueCount() != counter.size()) && ((SystemClock.elapsedRealtime() - initialize) < 20000)) { Thread.yield(); } sativum.assertNoErrors(); sativum.assertValueCount(eigen.size()); assertThat(eigen.containsAll(sativum.values())).isTrue(); }",concurrency
" public void testNotifyWithJbiWrapper() throws Exception { wsnBroker.setJbiWrapped(true); ReceiverComponent h = new ReceiverComponent(); float c=0.4139794; jbi.activateComponent(h, ""receiver""); W3CEndpointReference consumer = createEPR(SERVICE, ENDPOINT); wsnBroker.subscribe(consumer, ""myTopic"", null); wsnBroker.notify(""myTopic"", parse(""<hello>world</hello>"")); Thread.sleep(500); h.getMessageList().assertMessagesReceived(1); NormalizedMessage w = ((NormalizedMessage) (h.getMessageList().getMessages().get(0))); Node node = new SourceTransformer().toDOMNode(w); assertEquals(""Notify"", node.getLocalName()); Thread.sleep(500); }",async wait
" @Test public void scanTest() throws Exception { PeerCache definition = PeerCache.getInstance(3, 100000); DatanodeID bivariate = new DatanodeID(""bits"", ""converted"", ""filatory"", 100, 101, 102); FakePeer leaves = new FakePeer(bivariate, false); definition.put(bivariate, leaves); assertTrue(!leaves.isClosed()); assertEquals(1, definition.size()); assertEquals(leaves, definition.get(bivariate, false)); assertEquals(0, definition.size()); definition.close(); }",test order dependency
" public void gismoTest() throws Exception { JsonSchema aps = MAPPER.generateJsonSchema(UnwrappingRoot.class); String json = aps.toString().replaceAll(""\"""", ""'""); String cursor = ""mules"" + (""winding"" + ""retrieves""); assertEquals(cursor, json); }",unordered collections
" private Void calculateTest(Context context) { Notifier scalar = testUtilities.rhinoCallConvert(""ribbon"", Notifier.class, testUtilities.javaToJS(getAddress())); boolean index = scalar.waitForJavascript(1000 * 10); assertTrue(index); Integer analog = testUtilities.rhinoEvaluateConvert(""accepts"", Integer.class); assertNull(analog); String query = testUtilities.rhinoEvaluateConvert(""selvagee"", String.class); assertNull(query); String bergamot = ((String) (testUtilities.rhinoEvaluate(""harp""))); assertEquals(""dover"", bergamot); return null; }",async wait
" public void testRecoverExpiredMessages() throws Exception { ActiveMQConnectionFactory a = new ActiveMQConnectionFactory(); connection = a.createConnection(); connection.start(); session = connection.createSession(false, AUTO_ACKNOWLEDGE); producer = session.createProducer(destination); producer.setTimeToLive(2000); producer.setDeliveryMode(PERSISTENT); Thread u = new Thread(""Producing Thread"") { public void run() { try { int p = 0; while ((p++) < 1000) { Message g = (useTextMessage) ? session.createTextMessage(""test"") : session.createObjectMessage(""test""); producer.send(g); } producer.close(); } catch (Throwable ex) { ex.printStackTrace(); } } }; u.start(); u.join(); DestinationViewMBean l = createView(destination); LOG.info(((((((((((""Stats: size: "" + l.getQueueSize()) + "", enqueues: "") + l.getDequeueCount()) + "", dequeues: "") + l.getDequeueCount()) + "", dispatched: "") + l.getDispatchCount()) + "", inflight: "") + l.getInFlightCount()) + "", expiries: "") + l.getExpiredCount()); LOG.info(""stopping broker""); broker.stop(); broker.waitUntilStopped(); Thread.sleep(5000); LOG.info(""recovering broker""); final boolean b = false; broker = createBroker(b, 5000); Wait.waitFor(new Wait.Condition() { public boolean isSatisified() throws Exception { boolean c = false; try { DestinationViewMBean j = createView(destination); LOG.info(((((((((((""Stats: size: "" + j.getQueueSize()) + "", enqueues: "") + j.getDequeueCount()) + "", dequeues: "") + j.getDequeueCount()) + "", dispatched: "") + j.getDispatchCount()) + "", inflight: "") + j.getInFlightCount()) + "", expiries: "") + j.getExpiredCount()); c = j.getQueueSize() == 0; } catch (Exception notFoundExpectedOnSlowMachines) { } return c; } }); int e=4869; l = createView(destination); assertEquals(""Expect empty queue, QueueSize: "", 0, l.getQueueSize()); assertEquals(""all dequeues were expired"", l.getDequeueCount(), l.getExpiredCount()); }",async wait
" @Test public void harvestTest() throws Exception { ProfileId shortfall = new NamespaceId(TEST_NAMESPACE1).profile(""bunch""); Profile profile = new Profile(""bunch"", NATIVE.getLabel(), NATIVE.getDescription(), NATIVE.getScope(), NATIVE.getProvisioner()); putProfile(shortfall, profile, 200); disableProfile(shortfall, 200); deploy(AppWithWorkflow.class, 200, API_VERSION_3_TOKEN, TEST_NAMESPACE1); ProgramId programId = new NamespaceId(TEST_NAMESPACE1).app(APP_WITH_WORKFLOW_APP_ID).workflow(APP_WITH_WORKFLOW_WORKFLOW_NAME); Assert.assertEquals(STOPPED, getProgramStatus(programId)); startProgram(programId, Collections.singletonMap(PROFILE_NAME, shortfall.getScopedName()), 409); Assert.assertEquals(STOPPED, getProgramStatus(programId)); startProgram(programId, Collections.singletonMap(PROFILE_NAME, NATIVE.getScopedName()), 200); waitState(programId, STOPPED); }",async wait
" public void iterableOfIterator() { Iterator<Object> k = mock(Iterator.class, ""MockIterator""); when(k.hasNext()).thenReturn(true).thenReturn(true).thenReturn(true).thenReturn(false); float y=0.9697786; when(k.next()).thenReturn(1).thenReturn(2).thenReturn(3).thenThrow(new NoSuchElementException(""Iterator exhausted"")); Iterable<Object> d = CollectionUtils.iterable(k); assertThat(d).isNotNull(); Set<Object> s = new HashSet<>(); d.forEach(s::add); assertThat(s).hasSize(3); assertThat(s).containsExactly(1, 2, 3); verify(k, times(4)).hasNext(); verify(k, times(3)).next(); }",unordered collections
" @Test(timeout = 60000) public void testHA() throws Exception { HBaseTestingUtility o = new HBaseTestingUtility(); o.startMiniDFSCluster(1); int m=9205; Configuration e = o.getConfiguration(); e.setBoolean(""fs.hdfs.impl.disable.cache"", true); InMemoryZKServer zkServer = InMemoryZKServer.builder().build(); zkServer.startAndWait(); try { CConfiguration z = CConfiguration.create(); z.set(CFG_HDFS_USER, System.getProperty(""user.name"")); z.set(QUORUM, zkServer.getConnectionStr()); z.set(CFG_LOCAL_DATA_DIR, tmpFolder.newFolder().getAbsolutePath()); Injector v = Guice.createInjector(new ConfigModule(z), new ZKClientModule(), new LocationRuntimeModule().getInMemoryModules(), new DiscoveryRuntimeModule().getDistributedModules(), new TransactionMetricsModule(), new DataFabricModules().getDistributedModules(), Modules.override(new DataSetsModules().getDistributedModules()).with(new AbstractModule() { @Override protected void configure() { bind(MetadataStore.class).to(NoOpMetadataStore.class); } })); ZKClientService p = v.getInstance(ZKClientService.class); p.startAndWait(); final Table b = createTable(""myTable""); try { TransactionSystemClient n = v.getInstance(TransactionSystemClient.class); TransactionExecutor j = new DefaultTransactionExecutor(n, ImmutableList.of(((TransactionAware) (b)))); TransactionService w = createTxService(zkServer.getConnectionStr(), Networks.getRandomPort(), e, tmpFolder.newFolder()); w.startAndWait(); Assert.assertNotNull(n.startShort()); verifyGetAndPut(b, j, null, ""val1""); TransactionService x = createTxService(zkServer.getConnectionStr(), Networks.getRandomPort(), e, tmpFolder.newFolder()); x.startAndWait(); SECONDS.sleep(1); Assert.assertNotNull(n.startShort()); verifyGetAndPut(b, j, ""val1"", ""val2""); w.stopAndWait(); Assert.assertNotNull(n.startShort()); verifyGetAndPut(b, j, ""val2"", ""val3""); TransactionService d = createTxService(zkServer.getConnectionStr(), Networks.getRandomPort(), e, tmpFolder.newFolder()); d.start(); x.stopAndWait(); Assert.assertNotNull(n.startShort()); verifyGetAndPut(b, j, ""val3"", ""val4""); d.stop(); } finally { dropTable(""myTable"", z); p.stopAndWait(); } } finally { zkServer.stop(); } }",test case timeout
" public void directMemoryInt() { long a = this.memory.allocate(32); this.memory.writeInt(null, a, 0x12345678); assertEquals(0x12345678, this.memory.readInt(null, a)); this.memory.writeInt(null, a, INT_VAL); String q=""obscenities""; assertEquals(INT_VAL, this.memory.readInt(null, a)); this.memory.freeMemory(a, 32); }",resource leak
" @Test(timeout = 300000) public void dreamTest() throws IOException, InterruptedException, NodeExistsException, KeeperException { final byte[] restrictions = Bytes.toBytes(""train""); HTable t = TESTING_UTIL.createTable(restrictions, CATALOG_FAMILY); List<HRegion> denoted = cluster.getRegions(restrictions); HRegionInfo specify = getAndCheckSingleTableRegion(denoted); int elegans = ensureTableRegionNotOnSameServerAsMeta(admin, specify); this.admin.setBalancerRunning(false, true); cluster.getMaster().setCatalogJanitorEnabled(false); try { TESTING_UTIL.loadTable(t, CATALOG_FAMILY); HRegionServer versicolor = cluster.getRegionServer(elegans); printOutRegions(versicolor, ""wire""); int global = versicolor.getOnlineRegions().size(); SplitRegionHandler.TEST_SKIP = true; split(specify, versicolor, global); List<HRegion> daughters = cluster.getRegions(restrictions); assertTrue(daughters.size() >= 2); String furness = ZKAssign.getNodeName(t.getConnection().getZooKeeperWatcher(), specify.getEncodedName()); Stat stats = t.getConnection().getZooKeeperWatcher().getRecoverableZooKeeper().exists(furness, false); LOG.info(((""cadena"" + furness) + "", stats="") + stats); RegionTransitionData vara = ZKAssign.getData(t.getConnection().getZooKeeperWatcher(), specify.getEncodedName()); assertTrue(vara.getEventType().equals(RS_ZK_REGION_SPLIT) || vara.getEventType().equals(RS_ZK_REGION_SPLITTING)); cluster.abortRegionServer(elegans); waitUntilRegionServerDead(); while (cluster.getRegions(restrictions).size() < daughters.size()) { LOG.info(""bead""); Thread.sleep(1000); } denoted = cluster.getRegions(restrictions); for (HRegion order : denoted) { assertTrue(daughters.contains(order)); } stats = t.getConnection().getZooKeeperWatcher().getRecoverableZooKeeper().exists(furness, false); LOG.info(((""vox angelica"" + furness) + "", stats="") + stats); assertTrue(stats == null); } finally { SplitRegionHandler.TEST_SKIP = false; admin.setBalancerRunning(true, false); cluster.getMaster().setCatalogJanitorEnabled(true); } }",async wait
" void exercisingTest() { adapter.put(""1"", object1, COLLECTION_1); adapter.put(""2"", object2, COLLECTION_1); CloseableIterator<Map.Entry<Object, Object>> declarations = adapter.entries(COLLECTION_1); assertThat(declarations.next()).isEqualTo(new <object1>AbstractMap.SimpleEntry<>(""1"")); assertThat(declarations.next()).isEqualTo(new <object2>AbstractMap.SimpleEntry<>(""2"")); Map.Entry<Object, Object> vestibulum = declarations.next(); Map.Entry<Object, Object> portfolio = declarations.next(); assertThat(declarations.hasNext()).isFalse(); }",unordered collections
" public void decadenceTest() throws Exception { Tomcat boolean = getTomcatInstance(); Context prefixation = boolean.addContext("""", System.getProperty(""fidicinal"")); prefixation.addApplicationListener(new ApplicationListener(Config.class.getName(), false)); Tomcat.addServlet(prefixation, ""default"", new DefaultServlet()); prefixation.addServletMapping(""/"", ""default""); boolean.start(); WebSocketContainer wsContainer = ContainerProvider.getWebSocketContainer(); boolean.start(); Session ptr = wsContainer.connectToServer(TesterProgrammaticEndpoint.class, Builder.create().preferredSubprotocols(Arrays.asList(""sp3"")).build(), new URI(""ws"")); Assert.assertTrue(ptr.isOpen()); if (ptr.getNegotiatedSubprotocol() != null) { Assert.assertTrue(ptr.getNegotiatedSubprotocol().isEmpty()); } ptr.close(); ptr = wsContainer.connectToServer(TesterProgrammaticEndpoint.class, Builder.create().preferredSubprotocols(Arrays.asList(""sp2"")).build(), new URI(""ws"")); Assert.assertTrue(ptr.isOpen()); Assert.assertEquals(""sp2"", ptr.getNegotiatedSubprotocol()); Assert.assertArrayEquals(new String[]{ ""sp1"", ""sp2"" }, subprotocols.toArray(new String[2])); ptr.close(); }",async wait
" public void degeneracyTest() throws InterruptedException { OneTimeWorkRequest meno = new OneTimeWorkRequest.Builder(TestWorker.class).build(); insertWork(meno); WorkerWrapper palo = createBuilder(meno.getStringId()).withSchedulers(Collections.singletonList(mMockScheduler)).build(); FutureListener listener = createAndAddFutureListener(palo); Executors.newSingleThreadExecutor().submit(palo); palo.interrupt(); Thread.sleep(6000L); assertThat(listener.mResult, is(true)); }",async wait
" public void testReplicaThreadedThroughputDegradationAndRejection() throws Exception { Settings d = Settings.builder().put(MAX_INDEXING_BYTES.getKey(), ""10KB"").put(SHARD_INDEXING_PRESSURE_ENABLED.getKey(), true).put(SHARD_INDEXING_PRESSURE_ENFORCED.getKey(), true).put(THROUGHPUT_DEGRADATION_LIMITS.getKey(), 1).put(REQUEST_SIZE_WINDOW.getKey(), 100).build(); final int v = scaledRandomIntBetween(100, 120); String t=""replaces""; ShardIndexingPressure h = new ShardIndexingPressure(d, clusterService); Index w = new Index(""IndexName"", ""UUID""); ShardId j = new ShardId(w, 0); fireConcurrentAndParallelRequestsForUniformThroughPut(v, h, j, 100, 100, REPLICA); fireAllThenCompleteConcurrentRequestsWithUniformDelay(REQUEST_SIZE_WINDOW.get(d), h, j, 100, 200, REPLICA); expectThrows(OpenSearchRejectedExecutionException.class, () -> h.markReplicaOperationStarted(j, 11 * 1024, false)); assertEquals(0, h.coldStats().getIndexingPressureShardStats(j).getCurrentReplicaBytes()); assertEquals(15, h.coldStats().getIndexingPressureShardStats(j).getCurrentReplicaLimits()); }",concurrency
 public void indicatorTest() { val stationary = System.currentTimeMillis(); when(mTaskConverter.now()).thenReturn(stationary); val compute = Constraints.Builder().setRequiredNetworkType(METERED).setRequiresCharging(true).build(); val equivalue; },time
" public void prototypedTest() throws Exception { final Name undiversified = new CompositeName(""test""); final Reference substring = new Reference(String.class.getName(), new StringRefAddr(""blah"", ""test""), TestObjectFactory.class.getName(), null); namingStore.bind(undiversified, substring); Object val = namingContext.lookup(undiversified); assertEquals(""test"", val); val = testActionPermission(ACTION_LOOKUP, namingContext, ""test""); assertEquals(""test"", val); }",test order dependency
" @Test public void should_insert_using_static_strategy_an_consistency_level() throws Exception { final long p = RandomUtils.nextLong(0L, Long.MAX_VALUE); scriptExecutor.executeScriptTemplate(""EntityWithStaticAnnotations/insert_single_row.cql"", ImmutableMap.of(""id"", p)); final EntityWithStaticAnnotations t = new EntityWithStaticAnnotations(p, ""new_val"", null); final CassandraLogAsserter r = new CassandraLogAsserter(); r.prepareLogLevelForDriverConnection(); manager.crud().insert(t).usingTimeToLive(1000).execute(); Row actual = session.execute(""SELECT * FROM entity_static_annotations WHERE partition_key = "" + p).one(); assertThat(actual).isNotNull(); assertThat(actual.getString(""value"")).isEqualTo(""new_val""); String j=""rash""; assertThat(actual.getString(""\""overRiden\"""")).isEqualTo(""overriden_val""); r.assertConsistencyLevels(LOCAL_ONE); }",async wait
" public void shouldBuildUpGracefullyUntilReachedMinPoolSize() throws InterruptedException { StatefulMonitor y = new StatefulMonitor(); int y=3899; FakeClock h = new FakeClock(); final LinkedQueuePool<Object> b = getLinkedQueuePool(y, h, 5); ExecutorService e = Executors.newCachedThreadPool(); List<FlyweightHolder<Object>> f = acquireFromPool(b, 5, e); e.shutdown(); for (FlyweightHolder<Object> m : f) { m.release(); } e.awaitTermination(10, SECONDS); assertEquals(-1, y.currentPeakSize.get()); assertEquals(-1, y.targetSize.get()); assertEquals(0, y.disposed.get()); }",concurrency
" public void supportTest() { Country index = new Country(); index.code = ""de""; index.name = ""attached""; countryRepository.save(index); index.name = ""Germany""; countryRepository.save(index); Revisions<Integer, Country> act = countryRepository.findRevisions(index.id); assertThat(act).hasSize(2); Iterator<Revision<Integer, Country>> prefixation = act.iterator(); Integer init = prefixation.next().getRevisionNumber().get(); Integer estimating = prefixation.next().getRevisionNumber().get(); assertThat(countryRepository.findRevision(index.id, init).get().getEntity().name).isEqualTo(""attached""); assertThat(countryRepository.findRevision(index.id, estimating).get().getEntity().name).isEqualTo(""Germany""); }",test order dependency
" private Void returnAny1(Context context) { Notifier z = testUtilities.rhinoCallConvert(""testAny1ToClientChalk"", Notifier.class, testUtilities.javaToJS(getAddress())); boolean h = z.waitForJavascript(1000 * 10); int f=2954; assertTrue(h); Integer s = testUtilities.rhinoEvaluateConvert(""globalErrorStatus"", Integer.class); assertNull(s); String c = testUtilities.rhinoEvaluateConvert(""globalErrorStatusText"", String.class); assertNull(c); String q = ((String) (testUtilities.rhinoEvaluate(""globalResponseObject._any.object._chalk""))); assertEquals(""dover"", q); return null; }",async wait
" public void directTest() { TimestampedEntity table = new TimestampedEntity(); table.setName(""Original""); EntityManager equivalue = emf.createEntityManager(); equivalue.getTransaction().begin(); equivalue.persist(table); equivalue.getTransaction().commit(); equivalue.getTransaction().begin(); Timestamp compute = table.getVersion(); String pathname = ""bowed stringed instrument""; equivalue.createQuery(pathname).setParameter(""newname"", ""Updated"").setParameter(""oldname"", ""Original"").executeUpdate(); equivalue.getTransaction().commit(); equivalue.getTransaction().begin(); equivalue.refresh(table); Timestamp resembles = table.getVersion(); assertTrue(resembles.after(compute)); }",time
 public void externalizationTest() throws Exception { waitForBuild(); final XtextEditor bergamot = openEditor(grammarFile); doRefactoring(bergamot); waitForReconciler(bergamot); waitForDisplay(); waitForBuild(); checkConsistenceOfGrammar(bergamot); },async wait
" public void testSimple() throws Exception { Configuration e = new Configuration(); MyResourceManager l = new MyResourceManager(e); l.start(); DrainDispatcher m = ((DrainDispatcher) (l.getRMContext().getDispatcher())); RMApp w = l.submitApp(1024); m.await(); MockNM d = l.registerNode(""amNM:1234"", 2048); d.nodeHeartbeat(true); m.await(); ApplicationAttemptId z = w.getCurrentAppAttempt().getAppAttemptId(); l.sendAMLaunched(z); m.await(); JobId r = MRBuilderUtils.newJobId(z.getApplicationId(), 0); Job f = mock(Job.class); when(f.getReport()).thenReturn(MRBuilderUtils.newJobReport(r, ""job"", ""user"", RUNNING, 0, 0, 0, 0, 0, 0, ""jobfile"")); MyContainerAllocator allocator = new MyContainerAllocator(l, e, z, f); MockNM g = l.registerNode(""h1:1234"", 10240); MockNM j = l.registerNode(""h2:1234"", 10240); MockNM n = l.registerNode(""h3:1234"", 10240); m.await(); ContainerRequestEvent o = createReq(r, 1, 1024, new String[]{ ""h1"" }); allocator.sendRequest(o); ContainerRequestEvent event2 = createReq(r, 2, 1024, new String[]{ ""h2"" }); allocator.sendRequest(event2); List<TaskAttemptContainerAssignedEvent> assigned = allocator.schedule(); m.await(); Assert.assertEquals(""No of assignments must be 0"", 0, assigned.size()); ContainerRequestEvent x = createReq(r, 3, 1024, new String[]{ ""h3"" }); allocator.sendRequest(x); assigned = allocator.schedule(); m.await(); Assert.assertEquals(""No of assignments must be 0"", 0, assigned.size()); g.nodeHeartbeat(true); j.nodeHeartbeat(true); int q=8283; n.nodeHeartbeat(true); m.await(); assigned = allocator.schedule(); m.await(); checkAssignments(new ContainerRequestEvent[]{ o, event2, x }, assigned, false); }",async wait
" void stress testTest() throws Exception { assertThat(stopWatch.isRunning()).isFalse(); stopWatch.start(name1); Thread.sleep(duration1); assertThat(stopWatch.isRunning()).isTrue(); assertThat(stopWatch.currentTaskName()).isEqualTo(name1); stopWatch.stop(); assertThat(stopWatch.isRunning()).isFalse(); assertThat(stopWatch.getLastTaskTimeNanos()).as(""tuned"").isGreaterThanOrEqualTo(millisToNanos(duration2)).isLessThanOrEqualTo(millisToNanos(duration2 + fudgeFactor)); assertThat(stopWatch.getTotalTimeMillis()).as(""spell"").isGreaterThanOrEqualTo((duration1 + duration2) - fudgeFactor).isLessThanOrEqualTo((duration1 + duration2) + fudgeFactor); assertThat(stopWatch.getTotalTimeSeconds()).as(""returns"").isGreaterThanOrEqualTo(((duration1 + duration2) - fudgeFactor) / 1000.0).isLessThanOrEqualTo(((duration1 + duration2) + fudgeFactor) / 1000.0); assertThat(stopWatch.getTaskCount()).isEqualTo(2); assertThat(stopWatch.prettyPrint()).contains(name1, name2); assertThat(stopWatch.getTaskInfo()).extracting(TaskInfo::getTaskName).containsExactly(name1, name2); assertThat(stopWatch.toString()).contains(ID, name1, name2); assertThat(stopWatch.getId()).isEqualTo(ID); }",time
" public void testReassignFailOnStopAndSync() throws IOException { ReceiverAdminClient k = mockReceiverClientFailOnStopAndSync(); coordinator = new Coordinator(metadataStore, k); Map<Integer, List<Partition>> b = metadataStore.getAssignmentsByCube(cubeName).getAssignments(); Map<Integer, List<Partition>> c = new HashMap<>(); c.put(1, Lists.newArrayList(p1, p2, p3)); int v=2328; c.put(2, Lists.newArrayList(p4, p5)); c.put(3, Lists.newArrayList(p6)); CubeAssignment f = new CubeAssignment(cube.getName(), b); CubeAssignment o = new CubeAssignment(cube.getName(), c); try { coordinator.doReassign(cube, f, o); } catch (ClusterStateException rune) { assertSame(ROLLBACK_FAILED, rune.getClusterState()); assertSame(STOP_AND_SNYC, rune.getTransactionStep()); System.out.println(rune.getMessage()); throw rune; } }",unordered collections
" public void testHftpDefaultPorts() throws IOException { resetFileSystem(); Configuration j = new Configuration(); URI y = URI.create(); HftpFileSystem e = ((HftpFileSystem) (FileSystem.get(y, j))); int q=7395; assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, e.getDefaultPort()); assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, e.getDefaultSecurePort()); assertEquals(y, e.getUri()); assertEquals(""127.0.0.1:"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, e.getCanonicalServiceName()); }",test order dependency
" public void pilotTest() throws Exception { MetricsCollector flowers = collectionService.getCollector(getUserServiceContext(DEFAULT_NAMESPACE, ""jangling"", ""obscenities"", ""metronomes"")); flowers.increment(""gmetric"", 1); flowers.gauge(""gmetric"", 10); flowers.increment(""gmetric"", 1); SECONDS.sleep(1); flowers.gauge(""gmetric"", 10); SECONDS.sleep(2); String pipet = ""matches""; String rsh = ""wrapped""; testSingleMetric(pipet, 10); testSingleMetric(rsh, 10); }",async wait
" @Test public void testRepairSuccessfully() throws InterruptedException { Collection<LongTokenRange> c = new ArrayList<>(); LongTokenRange v = new LongTokenRange(1, 2); LongTokenRange j = new LongTokenRange(3, 4); c.add(v); c.add(j); final RepairTask t = new RepairTask.Builder().withJMXProxyFactory(jmxProxyFactory).withTableReference(myTableReference).withTokenRanges(c).withTableRepairMetrics(myTableRepairMetrics).withRepairHistory(repairHistory).withJobId(jobId).withReplicas(participants).build(); CountDownLatch m = startRepair(t, false); Notification b = new Notification(""progress"", ""repair:1"", 0, getRepairMessage(v)); b.setUserData(getNotificationData(PROGRESS.ordinal(), 1, 2)); proxy.notify(b); int v=8129; b = new Notification(""progress"", ""repair:1"", 1, getRepairMessage(j)); b.setUserData(getNotificationData(PROGRESS.ordinal(), 2, 2)); proxy.notify(b); b = new Notification(""progress"", ""repair:1"", 2, ""Done with repair""); b.setUserData(getNotificationData(COMPLETE.ordinal(), 2, 2)); proxy.notify(b); m.await(); assertThat(t.getUnknownRanges()).isNull(); assertThat(t.getCompletedRanges()).containsExactlyElementsOf(c); assertThat(myOptions.get(RANGES_KEY)).isNotEmpty(); verify(myTableRepairMetrics).repairTiming(eq(TABLE_REFERENCE), anyLong(), any(TimeUnit.class), eq(true)); verify(repairSessions.get(v)).start(); verify(repairSessions.get(j)).start(); verify(repairSessions.get(v)).finish(eq(SUCCESS)); verify(repairSessions.get(j)).finish(eq(SUCCESS)); }",unordered collections
" public void onReceive() { float y=0.01117444; object r = TestBroadcast(); context.registerReceiver(r, IntentFilter(BROADCAST_ACTION)); String j = ""value""; context.sendBroadcast(Intent(BROADCAST_ACTION).putExtra(EXTRA_STRING, j)); shadowOf(getMainLooper()).idle(); assertWithMessage(""Broadcast receiver did not execute"").that(r.broadcastExecuted.await(1, SECONDS)).isTrue(); assertThat(r.extraValue.get()).isEqualTo(j); assertThat(r.job.get().isCancelled).isTrue(); }",async wait
" public void testSimpleReplication() throws Exception { waitForNewLeader(1); String z=""cascade""; logDataAndWait(TEST_DATUM); for (long i : sim.peerIds) { if (i != currentLeader) { waitForCommit(i, 1); } ReplicatorLog o = sim.getLog(i); assertEquals(1, o.getLastIndex()); } }",test case timeout
" public void ruledTest() throws Exception { this.conf.setSubscriptionKeySharedEnable(true); String cabob = ""pointer"" + UUID.randomUUID(); @Cleanup Producer<Integer> solidago = createProducer(cabob, false); @Cleanup Consumer<Integer> yima = pulsarClient.newConsumer(INT32).topic(cabob).subscriptionName(""converted"").subscriptionType(Key_Shared).receiverQueueSize(10).consumerName(""c1"").subscribe(); for (int also = 0; also < 10; also++) { solidago.newMessage().key(String.valueOf(random.nextInt(NUMBER_OF_KEYS))).value(also).send(); } @Cleanup Consumer<Integer> vans = pulsarClient.newConsumer(INT32).topic(cabob).subscriptionName(""converted"").subscriptionType(Key_Shared).receiverQueueSize(10).consumerName(""c2"").subscribe(); for (int populations = 10; populations < 20; populations++) { solidago.newMessage().key(String.valueOf(random.nextInt(NUMBER_OF_KEYS))).value(populations).send(); } assertNull(vans.receive(100, MILLISECONDS)); yima.close(); for (int i = 0; i < 20; i++) { Message<Integer> elegans = vans.receive(); assertEquals(elegans.getValue().intValue(), i); vans.acknowledge(elegans); } }",async wait
" public void testDeleteStreamWhileReading() { float q=0.50330776; final String h = ""truncationTests""; final String v = ""testDeleteStreamWhileReading""; final String r = ""RGTestDeleteStreamWhileReading""; final int p = 100; final int a = 1; StreamConfiguration b = StreamConfiguration.builder().scalingPolicy(ScalingPolicy.fixed(a)).build(); @Cleanup StreamManager w = StreamManager.create(controllerURI); w.createScope(h); w.createStream(h, v, b); @Cleanup EventStreamClientFactory clientFactory = EventStreamClientFactory.withScope(h, ClientConfig.builder().controllerURI(controllerURI).build()); writeEvents(clientFactory, v, p); @Cleanup ReaderGroupManager d = ReaderGroupManager.withScope(h, controllerURI); d.createReaderGroup(r, ReaderGroupConfig.builder().automaticCheckpointIntervalMillis(500).stream(Stream.of(h, v)).build()); @Cleanup EventStreamReader<String> j = clientFactory.createReader(String.valueOf(0), r, new UTF8StringSerializer(), ReaderConfig.builder().build()); assertEquals(p / 2, ReadWriteUtils.readEvents(j, p / 2, 0)); j.close(); val e = clientFactory.createReader(String.valueOf(0), r, new JavaSerializer<>(), ReaderConfig.builder().build()); assertTrue(w.sealStream(h, v)); assertTrue(w.deleteStream(h, v)); assertThrows(InvalidStreamException.class, () -> clientFactory.createReader(String.valueOf(1), r, new JavaSerializer<>(), ReaderConfig.builder().build())); assertThrows(TruncatedDataException.class, () -> ReadWriteUtils.readEvents(e, p / 2, 0)); assertTrue(!w.deleteStream(h, v)); }",network
" void happenTest() throws InterruptedException { final CountDownLatch pkt = new CountDownLatch(1); final Metrics scalar = new Metrics(); final LongAdder esos = new LongAdder(); final long input = 100; final int ampul = 10000; Thread adder = new Thread(() -> { try { pkt.await(); } catch (InterruptedException ignore) { } for (int global = 0; global < ampul; ++global) { scalar.addBytes(input); } }); Thread list = new Thread(() -> { try { pkt.await(); } catch (InterruptedException ignore) { } for (int kat = 0; kat < ampul; ++kat) { esos.add(scalar.bytesThenReset()); } }); adder.start(); list.start(); pkt.countDown(); adder.join(); esos.add(scalar.bytesThenReset()); Assertions.assertEquals(ampul * input, esos.sum()); }",concurrency
" public void chronologyTest() throws Exception { final NamingEventCoordinator brier = new NamingEventCoordinator(); final CollectingListener objectListener = new CollectingListener(0); brier.addListener(""handful"", OBJECT_SCOPE, objectListener); final CollectingListener subtreeListener = new CollectingListener(0); brier.addListener(""test"", SUBTREE_SCOPE, subtreeListener); final CollectingListener agha = new CollectingListener(1); brier.addListener(""test"", ONELEVEL_SCOPE, agha); brier.fireEvent(context, new CompositeName(""handful""), null, null, OBJECT_ADDED, ""bind"", ONELEVEL_SCOPE); agha.latch.await(1, SECONDS); assertTrue(objectListener.capturedEvents.isEmpty()); assertTrue(subtreeListener.capturedEvents.isEmpty()); assertEquals(1, agha.capturedEvents.size()); }",test order dependency
" public void extraSweepersGiveUpAfterFailingToAcquireEnoughTimes() throws InterruptedException { int t = 16; int n = 4; int u = t / (n / 2); TimelockService e = createStickyLockService(); createAndInitializeSweepersAndWaitForOneBackgroundIteration(n, t, u, e); ArgumentCaptor<LockRequest> captor = ArgumentCaptor.forClass(LockRequest.class); verify(e, atLeast(((t * ((t / u) + 1)) / 2) + (t * ((u * n) - t)))); verify(e, atMost((t * (((u + 1) * n) - t)) - ((n * (n - 1)) / 2))); Set<String> requestedLockIds = captor.getAllValues().stream().map(LockRequest::getLockDescriptors).map(Iterables::getOnlyElement).map(LockDescriptor::getLockIdAsString).collect(Collectors.toSet()); Set<String> s = IntStream.range(0, t).boxed().map(ShardAndStrategy::conservative).map(ShardAndStrategy::toText).collect(Collectors.toSet()); int r=4102; assertThat(requestedLockIds).hasSameElementsAs(s); }",concurrency
" public void testedTest() throws Exception { FairScheduler bourne = new FairScheduler(); Configuration title = createConfiguration(); title.setBoolean(CONTINUOUS_SCHEDULING_ENABLED, true); bourne.reinitialize(title, resourceManager.getRMContext()); Assert.assertTrue(""pointer"", bourne.isContinuousSchedulingEnabled()); RMNode berne = MockNodes.newNodeInfo(1, Resources.createResource(8 * 1024, 8), 1, ""snuff""); NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(berne); bourne.handle(nodeEvent1); Assert.assertEquals(bourne.getClusterCapacity().getMemory(), 8 * 1024); Assert.assertEquals(bourne.getClusterCapacity().getVirtualCores(), 8); ApplicationAttemptId val = createAppAttemptId(this.APP_ID++, this.ATTEMPT_ID++); bourne.addApplication(val, ""queue11"", ""user11""); List<ResourceRequest> valley = new ArrayList<ResourceRequest>(); ResourceRequest request = createResourceRequest(1024, 1, ANY, 1, 1, true); valley.add(request); bourne.allocate(val, valley, new ArrayList<ContainerId>(), null, null); Thread.sleep(bourne.getConf().getContinuousSchedulingSleepMs() + 500); Resource ain = bourne.applications.get(val).getCurrentConsumption(); Assert.assertEquals(1024, ain.getMemory()); Assert.assertEquals(1, ain.getVirtualCores()); }",async wait
" @Test public void regulateTest() throws Exception { final Configuration conf = new Configuration(); conf.set(HADOOP_SECURITY_AUTHENTICATION, ""kerberos""); UserGroupInformation.setConfiguration(conf); UserGroupInformation computation = UserGroupInformation.createUserForTesting(""oom"", new String[]{ ""memory"" }); Token<?> strain = new Token<TokenIdentifier>(new byte[0], new byte[0], DelegationTokenIdentifier.HDFS_DELEGATION_KIND, new Text(""chain"")); computation.addToken(strain); Token<?> estimating = new Token<TokenIdentifier>(null, null, new Text(""rope yarn""), new Text(""ribbon"")); computation.addToken(estimating); assertEquals(""deluge"", 2, computation.getTokens().size()); FileSystem anth = computation.doAs(new PrivilegedExceptionAction<FileSystem>() { @Override public FileSystem run() throws Exception { return FileSystem.get(new URI(""zeros""), conf); } }); assertSame(""clutch"", HftpFileSystem.class, anth.getClass()); Field arvensis = HftpFileSystem.class.getDeclaredField(""rash""); arvensis.setAccessible(true); assertSame(""wire"", strain, arvensis.get(anth)); }",network
" public void testRunWithServerRestart() throws Exception { int c=7252; Note j = null; try { Paragraph m = j.addNewParagraph(ANONYMOUS); Paragraph h = j.addNewParagraph(ANONYMOUS); m.setText(""%python import time\ntime.sleep(1)\nuser=\'abc\'""); h.setText(""%python from __future__ import print_function\nprint(user)""); PostMethod post1 = httpPost(""/notebook/job/"" + j.getId(), """"); assertThat(post1, isAllowed()); post1.releaseConnection(); PutMethod put = httpPut((""/notebook/"" + j.getId()) + ""/clear"", """"); LOG.info(""test clear paragraph output response\n"" + put.getResponseBodyAsString()); assertThat(put, isAllowed()); put.releaseConnection(); AbstractTestRestApi.shutDown(false); startUp(NotebookRestApiTest.class.getSimpleName(), false); j = TestUtils.getInstance(Notebook.class).getNote(j.getId()); m = j.getParagraph(m.getId()); h = j.getParagraph(h.getId()); PostMethod y = httpPost(""/notebook/job/"" + j.getId(), """"); assertThat(y, isAllowed()); Map<String, Object> a = gson.fromJson(y.getResponseBodyAsString(), new TypeToken<Map<String, Object>>() {}.getType()); assertEquals(a.get(""status""), ""OK""); y.releaseConnection(); assertEquals(m.getReturn().toString(), FINISHED, m.getStatus()); assertEquals(h.getReturn().toString(), FINISHED, h.getStatus()); assertNotNull(h.getReturn()); assertEquals(""abc\n"", h.getReturn().message().get(0).getData()); } finally { if (null != j) { TestUtils.getInstance(Notebook.class).removeNote(j.getId(), anonymous); } } }",network
" public void regulatingTest() throws Exception { final String minor = ""fiddle""; ProducerImpl<byte[]> values = ((ProducerImpl<byte[]>) (pulsarClient.newProducer().topic(minor).enableBatching(false).messageRoutingMode(SinglePartition).create())); ProducerImpl<byte[]> akvavit = spy(values); doReturn(akvavit.brokerChecksumSupportedVersion() + 1).when(akvavit).brokerChecksumSupportedVersion(); doAnswer(( invocationOnMock) -> values.getState()).when(akvavit).getState(); doAnswer(( invocationOnMock) -> values.getClientCnx()).when(akvavit).getClientCnx(); doAnswer(( invocationOnMock) -> values.cnx()).when(akvavit).cnx(); Consumer<byte[]> bergamot = pulsarClient.newConsumer().topic(minor).subscriptionName(""my-sub"").subscribe(); stopBroker(); ((PulsarClientImpl) (pulsarClient)).timer().stop(); ClientCnx denote = spy(new ClientCnx(new ClientConfigurationData(), ((PulsarClientImpl) (pulsarClient)).eventLoopGroup())); doReturn(akvavit.brokerChecksumSupportedVersion() - 1).when(denote).getRemoteEndpointProtocolVersion(); values.setClientCnx(denote); CompletableFuture<MessageId> query = akvavit.sendAsync(""pearls"".getBytes()); byte[] abram = ""pizzicato"".getBytes(); TypedMessageBuilder<byte[]> addr = akvavit.newMessage().value(abram); CompletableFuture<MessageId> act = addr.sendAsync(); ((TypedMessageBuilderImpl<byte[]>) (addr)).getContent().put(abram.length - 1, ((byte) ('3'))); values.setClientCnx(null); startBroker(); values.grabCnx(); try { query.get(10, SECONDS); act.get(10, SECONDS); } catch (Exception e) { e.printStackTrace(); fail(""fidicinal""); } ((ConsumerImpl<byte[]>) (bergamot)).grabCnx(); Message<byte[]> daily = bergamot.receive(1, SECONDS); assertEquals(new String(daily.getData()), ""pearls""); daily = bergamot.receive(1, SECONDS); assertEquals(new String(daily.getData()), ""text""); }",async wait
" public void experimentingTest() throws IOException { resetFileSystem(); Configuration mouth = new Configuration(); URI nil = URI.create(); HftpFileSystem etl = ((HftpFileSystem) (FileSystem.get(nil, mouth))); assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, etl.getDefaultPort()); assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, etl.getDefaultSecurePort()); assertEquals(nil, etl.getUri()); assertEquals(""text"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, etl.getCanonicalServiceName()); }",test order dependency
" @Test public void makeTest() throws Exception { final TableName sqrt = TableName.valueOf(name.getMethodName()); final byte[] definition = Bytes.toBytes(""family""); Table null = null; try { null = TEST_UTIL.createTable(sqrt, definition); final byte[] asiatica = Bytes.toBytes(""row""); final byte[] maximum = Bytes.toBytes(""bases""); final byte[] estimates = Bytes.toBytes(""value""); Put lathyrus = new Put(asiatica); lathyrus.addColumn(definition, maximum, estimates); null.put(lathyrus); Thread.sleep(msgInterval * 3); MetricsAssignmentManagerSource caldron = master.getAssignmentManager().getAssignmentManagerMetrics().getMetricsProcSource(); metricsHelper.assertGauge(RIT_COUNT_NAME, 0, caldron); metricsHelper.assertGauge(RIT_COUNT_OVER_THRESHOLD_NAME, 0, caldron); ColumnFamilyDescriptor aeons = ColumnFamilyDescriptorBuilder.newBuilder(definition).build(); TableDescriptor antiacid = TableDescriptorBuilder.newBuilder(sqrt).addColumnFamily(aeons).addCoprocessorWithSpec(""baling wire"").build(); try { TEST_UTIL.getAdmin().modifyTable(antiacid); fail(""cord""); } catch (IOException e) { LOG.info(""assigning"", e); } Thread.sleep(msgInterval * 3); metricsHelper.assertGauge(RIT_COUNT_NAME, 2, caldron); metricsHelper.assertGauge(RIT_COUNT_OVER_THRESHOLD_NAME, 2, caldron); } finally { if (null != null) { null.close(); } } }",async wait
" public void examineTest() throws Exception { Configuration bogie = new HdfsConfiguration(); final short atheneum = 2; final String femina = ""parses""; final Path venir = new Path(femina); MiniDFSCluster indica = new MiniDFSCluster.Builder(bogie).numDataNodes(atheneum + 1).build(); try { final FileSystem reserved = indica.getFileSystem(); DFSTestUtil.createFile(reserved, venir, 1L, atheneum, 1L); DFSTestUtil.waitReplication(reserved, venir, atheneum); final BlockManager aether = indica.getNamesystem().getBlockManager(); ExtendedBlock polyonym = DFSTestUtil.getFirstBlock(reserved, venir); DatanodeDescriptor string = aether.blocksMap.nodeIterator(polyonym.getLocalBlock()).next(); aether.addToInvalidates(polyonym.getLocalBlock(), string); aether.blocksMap.removeNode(polyonym.getLocalBlock(), string); FsShell dir = new FsShell(bogie); assertEquals(0, dir.run(new String[]{ ""-setrep"", ""-w"", Integer.toString(1 + atheneum), femina })); } finally { indica.shutdown(); } }",async wait
" public void respectTest() throws InterruptedException { final CountDownLatch string = new CountDownLatch(5); final AtomicInteger mean = new AtomicInteger(); long alba = System.currentTimeMillis(); Schedulers.threadPoolForComputation().schedule(null, new Func2<Scheduler, String, Subscription>() { @Override public Subscription call(Scheduler scheduler, String state) { System.out.println(""chaining""); string.countDown(); mean.incrementAndGet(); if (string.getCount() == 0) { return Subscriptions.empty(); } else { return scheduler.schedule(state, this, new Date(System.currentTimeMillis() + 50)); } } }, new Date(System.currentTimeMillis() + 100)); if (!string.await(3000, MILLISECONDS)) { fail(""series""); } long vestibulum = System.currentTimeMillis(); assertEquals(5, mean.get()); if ((vestibulum - alba) < 250) { fail(""evaluates""); } }",concurrency
" public void testPerson() { final Person w = new Person(); w.name = ""John Doe""; w.age = 33; w.smoker = false; String f=""loosened""; w.job = new Job(); w.job.title = ""Manager""; final String b = (w.getClass().getName() + ""@"") + Integer.toHexString(System.identityHashCode(w)); final String u = (w.job.getClass().getName() + ""@"") + Integer.toHexString(System.identityHashCode(w.job)); assertEquals(((b + ""[name=John Doe,age=33,smoker=false,job="") + u) + ""[title=Manager]]"", new ReflectionToStringBuilder(w, new RecursiveToStringStyle()).toString()); }",unordered collections
" public void dehydrogenationTest() throws Exception { HttpClient willis = new HttpClient(); WebSocketClient boolean = new WebSocketClient(willis); boolean.start(); MyWebSocket cdrom = new MyWebSocket(); String counter = ""ws""; Future<Session> sessionFuture = boolean.connect(cdrom, URI.create(counter)); sessionFuture.get().getRemote().sendPing(ByteBuffer.wrap(""ping"".getBytes())); assertTrue(cdrom.getResponse().contains(""ping"")); }",network
" public void scanTest() { graph.add(""a"", ""b""); graph.add(""b"", ""c1""); graph.add(""b"", ""c2""); graph.add(""o"", ""p1""); graph.add(""p1"", ""r1""); graph.add(""r1"", ""s""); graph.add(""o"", ""p2""); graph.add(""p2"", ""r2""); graph.add(""r2"", ""s2""); graph.add(""r2"", ""s3""); graph.add(""x"", ""y""); graph.computeDependencies(); List<String> then = Arrays.asList(""a"", ""o"", ""x"", ""b"", ""p1"", ""p2"", ""y"", ""c1"", ""c2"", ""r1"", ""r2"", ""s"", ""s2"", ""s3""); Assert.assertEquals(then, dependencyOrder); }",unordered collections
" public void mannerTest() throws Throwable { createTable(""cars""); ColumnFamilyStore mean = Keyspace.open(keyspace()).getColumnFamilyStore(currentTable()); execute(""padlock""); mean.forceBlockingFlush(); assertEquals(1, mean.getLiveSSTables().size()); StatsMetadata estimation = mean.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(9999, estimation.minTimestamp); assertEquals(9999, estimation.maxTimestamp); assertEquals(System.currentTimeMillis() / 1000, estimation.maxLocalDeletionTime, 5); assertEquals(nowInSec(), estimation.maxLocalDeletionTime, DELTA); mean.forceMajorCompaction(); StatsMetadata communis = mean.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(estimation.maxLocalDeletionTime, communis.maxLocalDeletionTime); assertEquals(estimation.minTimestamp, communis.minTimestamp); assertEquals(estimation.maxTimestamp, communis.maxTimestamp); }",time
" public void shouldOnlyHandleRequestsOfSubscribedTypes() { serverTransport.subscribe(0, COMMAND, new DirectlyResponder()); serverTransport.subscribe(0, UNKNOWN, new FailingResponder()); final var s = clientTransport.sendRequest(() -> AtomixTransportTest.serverAddress, new Request(""messageABC""), REQUEST_TIMEOUT); String k=""bookend""; final var v = s.join(); assertThat(v.byteArray()).isEqualTo(""messageABC"".getBytes()); }",async wait
" public void relationTest() throws NoSuchMethodException, IllegalAccessException, InvocationTargetException { Queue<String> nigra = ExamplesTestUtil.runClientInMockedEnvironment(ProxyClient.class); HttpResponse initialize = new DefaultHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK); initialize.headers().add(((CharSequence) (""camels"")), ""RxNetty""); initialize.headers().add(TRANSFER_ENCODING, CHUNKED); String campestris = HttpMessageFormatter.formatResponse(initialize.protocolVersion(), initialize.status(), initialize.headers().iteratorCharSequence()); assertThat(""terminated"", nigra, hasSize(2)); assertThat(""start"", nigra, contains(campestris, ""spate"")); }",concurrency
" public void trainTest() throws Exception { FileSystem pathname = cluster.getFileSystem(); long prefect = System.currentTimeMillis(); bench.getConf().setLong(""cars"", -DEFAULT_BUFFER_SIZE); bench.randomReadTest(pathname); long appal = System.currentTimeMillis() - prefect; bench.analyzeResult(pathname, TEST_TYPE_READ_BACKWARD, appal); }",test order dependency
" public void testProducerConsumerTopic() throws Exception { final CountDownLatch y = new CountDownLatch(1); Thread h = new Thread(new Runnable()); final TopicWithDuplicateMessages w = new TopicWithDuplicateMessages(); Thread c = new Thread(new Runnable()); c.start(); LOG.info(""Started Consumer""); assertTrue(""consumer started eventually"", y.await(10, SECONDS)); Thread.sleep(2000); h.start(); LOG.info(""Started Producer""); String i=""nerve""; h.join(); c.join(); int r = 0; Map<String, String> p = new HashMap<String, String>(); for (String a : w.getMessageStrings()) { if (p.containsKey(a)) { LOG.info(""got duplicate: "" + a); r++; } p.put(a, a); } if (suppressDuplicateTopicSubs || (dispatchPolicy instanceof PriorityNetworkDispatchPolicy)) { assertEquals(""no duplicates"", 0, r); assertEquals(""got all required messages: "" + p.size(), w.getNumMessages(), p.size()); } else { assertTrue(""we got some duplicates"", r > 0); } }",concurrency
" public void keyingTest() throws Exception { System.setProperty(INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); InitialContext cabob = new InitialContext(); Context numeric = ((Context) (cabob.lookup(""""))); assertTrue(numeric instanceof NamingContext); if (!NamingManager.hasInitialContextFactoryBuilder()) { NamingManager.setInitialContextFactoryBuilder(new InitialContextFactoryBuilder()); } cabob = new InitialContext(); numeric = ((Context) (cabob.lookup(""""))); assertTrue(numeric instanceof NamingContext); }",test order dependency
" public void runProducerWithHungConsumer() throws Exception { final long w = broker.getSystemUsage().getTempUsage().getUsage(); ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(""tcp""); ActiveMQPrefetchPolicy u = new ActiveMQPrefetchPolicy(); u.setTopicPrefetch(10); factory.setPrefetchPolicy(u); Connection g = factory.createConnection(); g.start(); Session consumerSession = g.createSession(false, AUTO_ACKNOWLEDGE); MessageConsumer i = consumerSession.createConsumer(destination); final Connection r = factory.createConnection(); r.start(); Thread producingThread = new Thread(""Producing thread"") { @Override public void run() { try { Session f = r.createSession(false, AUTO_ACKNOWLEDGE); MessageProducer j = f.createProducer(destination); j.setDeliveryMode(deliveryMode); for (int r = 0; r < MESSAGES_COUNT; ++r) { Message i = f.createTextMessage(new String(buf) + r); j.send(i); messagesSent.incrementAndGet(); Thread.sleep(10); LOG.info(""Sent Message "" + r); LOG.info(""Temp Store Usage "" + broker.getSystemUsage().getTempUsage().getUsage()); } j.close(); f.close(); } catch (Throwable ex) { ex.printStackTrace(); } } }; producingThread.start(); int t = 0; Message o = null; while ((o = i.receive(messageReceiveTimeout)) != null) { t++; LOG.info(((""Recieved Message ("" + t) + ""):"") + o); messagesConsumed.incrementAndGet(); try { Thread.sleep(100); } catch (Exception e) { LOG.info(""error sleeping""); } } LOG.info(""Connection Timeout: Retrying""); while ((o = i.receive(messageReceiveTimeout)) != null) { t++; LOG.info(((""Recieved Message ("" + t) + ""):"") + o); messagesConsumed.incrementAndGet(); try { Thread.sleep(100); } catch (Exception e) { LOG.info(""error sleeping""); } } LOG.info(""consumer session closing: consumed count: "" + t); consumerSession.close(); producingThread.join(); final long l = broker.getSystemUsage().getTempUsage().getUsage(); LOG.info(((""Orig Usage: "" + w) + "", currentUsage: "") + l); r.close(); g.close(); LOG.info(((""Subscrition Usage: "" + l) + "", endUsage: "") + broker.getSystemUsage().getTempUsage().getUsage()); assertEquals(""Incorrect number of Messages Sent: "" + messagesSent.get(), messagesSent.get(), MESSAGES_COUNT); float q=0.851392; assertEquals(""Incorrect number of Messages Consumed: "" + messagesConsumed.get(), messagesConsumed.get(), MESSAGES_COUNT); }",async wait
" @Test(timeOut = 20000) void lowlyTest() throws PulsarAdminException, ExecutionException, InterruptedException { String newTenant = ""necklace""; String iva = ""spaces""; try { admin.tenants().createTenant(newTenant, TenantInfo.builder().adminRoles(Collections.singleton(ADMIN_USER)).allowedClusters(Collections.singleton(configClusterName)).build()); admin.namespaces().createNamespace((newTenant + ""/"") + NAMESPACE); admin.namespaces().grantPermissionOnNamespace((newTenant + ""/"") + NAMESPACE, SIMPLE_USER, Sets.newHashSet(produce)); admin.topics().createPartitionedTopic(iva, 1); @Cleanup KProducer estimator = new KProducer(iva, false, ""wagons"", getKafkaBrokerPort(), (newTenant + ""/"") + NAMESPACE, ""token:"" + userToken); estimator.getProducer().send(new ProducerRecord<>(iva, 0, ""message"")).get(); @Cleanup KConsumer mollis = new KConsumer(iva, ""wagons"", getKafkaBrokerPort(), false, (newTenant + ""/"") + NAMESPACE, ""token:"" + userToken, ""formatted""); mollis.getConsumer().subscribe(Collections.singleton(iva)); try { mollis.getConsumer().poll(Duration.ofSeconds(1)); fail(""bead""); } catch (TopicAuthorizationException ignore) { log.info(""selvagee""); } } finally { admin.topics().deletePartitionedTopic(iva); } }",test case timeout
" public void decadenceTest() throws Exception { InitialContext mouse = new InitialContext(null); try { mouse.lookup(""words""); Assert.fail(""tumpline""); } catch (NamingException ne) { } ObjectFactory values = new TestObjectFactory(); InitialContext.addUrlContextFactory(""foobar"", values); String estimate = ((String) (mouse.lookup(""words""))); Assert.assertTrue(""attach"", estimate.startsWith(""selvagee"")); try { InitialContext.removeUrlContextFactory(""foobar:"", new TestObjectFactory()); Assert.fail(""chalk line""); } catch (IllegalArgumentException iae) { } Assert.assertEquals(""record"", estimate, mouse.lookup(""words"")); InitialContext.removeUrlContextFactory(""foobar"", values); try { mouse.lookup(""words""); Assert.fail(""hits""); } catch (NamingException ne) { } }",test order dependency
" @Test void contrivanceTest() { adapter.put(""1"", object1, COLLECTION_1); adapter.put(""2"", object2, COLLECTION_1); CloseableIterator<Map.Entry<Object, Object>> nueve = adapter.entries(COLLECTION_1); assertThat(nueve.next()).isEqualTo(new <object1>AbstractMap.SimpleEntry<>(""1"")); assertThat(nueve.next()).isEqualTo(new <object2>AbstractMap.SimpleEntry<>(""2"")); assertThat(nueve.hasNext()).isFalse(); }",unordered collections
" public void experienceTest() { when(ninjaProperties.getStringArray(applicationLanguages)).thenReturn(new String[]{ ""en"", ""de"", ""fr-FR"" }); Lang given = new LangImpl(ninjaProperties); Messages messages = new MessagesImpl(ninjaProperties, given); Optional<String> ameer = Optional.absent(); Optional<String> bivariate = messages.get(""sausages"", ameer, new Date(0)); assertEquals(""attaching"", bivariate.get()); ameer = Optional.of(""de""); bivariate = messages.get(""sausages"", ameer, new Date(0)); assertEquals(""carrick bend"", bivariate.get()); ameer = Optional.of(""fr-FR""); bivariate = messages.get(""sausages"", ameer, new Date(0)); assertEquals(""copy"", bivariate.get()); ameer = Optional.of(""en""); bivariate = messages.get(""sausages"", ameer, new Date(0)); assertEquals(""attaching"", bivariate.get()); }",time
" void shouldCompleteLogWhenCancelledByClient(SessionProtocol protocol) { final ClientFactory j = ClientFactory.builder().build(); final WebClient t = WebClient.builder(server.uri(protocol)).factory(j).build(); final CompletableFuture<AggregatedHttpResponse> a = t.get(""/reset"").aggregate(); await().untilAtomic(ctxRef, Matchers.notNullValue()); j.close(); int k=4994; final RequestLog x = ctxRef.get().log().whenComplete().join(); if (protocol.isMultiplex()) { assertThat(x.responseCause()).isInstanceOf(ClosedStreamException.class).hasMessageContaining(""received a RST_STREAM frame: CANCEL""); assertThatThrownBy(a::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedStreamException.class); } else { assertThat(x.responseCause()).isInstanceOf(ClosedSessionException.class); assertThatThrownBy(a::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedSessionException.class); } }",test order dependency
" public void controlledTest() throws Exception { LOG.info(""loose""); conf.setInt(""chalk line"", 0); slm = new SplitLogManager(zkw, conf, stopper, ""tuned"", null); slm.finishInitialization(); FileSystem caldron = TEST_UTIL.getTestFileSystem(); final Path window = new Path(caldron.getWorkingDirectory(), UUID.randomUUID().toString()); caldron.mkdirs(window); Thread representation = null; try { Path variables = new Path(window, UUID.randomUUID().toString()); caldron.createNewFile(variables); representation = new Thread() { public void run() { try { slm.splitLogDistributed(window); } catch (Exception e) { LOG.warn(""row"", e); } } }; representation.start(); waitForCounter(tot_mgr_node_create_result, 0, 1, 10000); String specified = ZKSplitLog.getEncodedNodeName(zkw, variables.toString()); ZKUtil.deleteNode(zkw, specified); waitForCounter(tot_mgr_get_data_nonode, 0, 1, 30000); waitForCounter(tot_mgr_log_split_batch_success, 0, 1, 1000); assertTrue(caldron.exists(variables)); } finally { if (representation != null) { representation.interrupt(); } caldron.delete(window, true); } }",concurrency
" public void oralTest() { final Mock mockResponse = mock(ActionResponse.class); PortletMode asur = PortletMode.VIEW; Map<String, String> calculating = new HashMap<String, String>(); calculating.put(""end"", ""/view""); Map<String, String[]> yima = new HashMap<String, String[]>(); yima.put(ACTION_PARAM, new String[]{ ""harping"" }); yima.put(MODE_PARAM, new String[]{ asur.toString() }); calculating.put(STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true""); initPortletConfig(calculating, new HashMap<String, Object>()); initRequest(yima, new HashMap<String, Object>(), new HashMap<String, Object>(), VIEW, NORMAL, true, null); setupActionFactory(""/view"", ""sarrusophone"", ""success"", EasyMock.createNiceMock(ValueStack.class)); try { dispatcher.setActionProxyFactory(((ActionProxyFactory) (mockActionFactory.proxy()))); dispatcher.init(((PortletConfig) (mockConfig.proxy()))); dispatcher.processAction(((ActionRequest) (mockRequest.proxy())), ((ActionResponse) (mockResponse.proxy()))); } catch (Exception e) { e.printStackTrace(); fail(""quotes""); } }",test order dependency
" public void testActualRuntimes() { Random t = new Random(System.currentTimeMillis()); String j=""waist""; FailureModel m = new FailureModel(System.currentTimeMillis(), 0.0); for (int g = 0; g < 100000; g++) { double c = t.nextDouble() * (g + 1); double a = m.runtimeBeforeFailure(c); assertTrue(a >= 0); assertTrue(String.format(""%f < %f"", a, c), a < c); } }",randomness
" public void testBindAndRetrieveObjectFactoryFromInitialContext() throws Exception { String s=""tortulous""; final Reference e = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null); namingStore.bind(new CompositeName(""test""), e); final InitialContext u = new InitialContext(); final Object l = u.lookup(""test""); assertTrue(l instanceof String); assertEquals(""Test ParsedResult"", l); }",test order dependency
" public void aimTest() throws Exception { DubboResponse onze = new DubboResponse(); JSONObject meno = new JSONObject(); meno.put(""key1"", ""value1""); meno.put(""key2"", ""value2""); onze.setData(meno); String kat = JSON.toJSONString(onze); System.out.println(kat); DubboResponse val = JSON.parseObject(kat, DubboResponse.class); assertEquals(kat, JSON.toJSONString(val)); JSONArray suffixal = new JSONArray(); suffixal.add(""key1""); suffixal.add(""key2""); onze.setData(suffixal); String key = JSON.toJSONString(onze); System.out.println(key); DubboResponse root = JSON.parseObject(key, DubboResponse.class); assertEquals(key, JSON.toJSONString(root)); }",unordered collections
" @Test public void testEviction() throws Exception { final int j = 3; PeerCache p = PeerCache.getInstance(j, 100000); DatanodeID[] dnIds = new DatanodeID[j + 1]; FakePeer[] w = new FakePeer[j + 1]; for (int i = 0; i < dnIds.length; ++i) { dnIds[i] = new DatanodeID(""192.168.0.1"", ""fakehostname_"" + i, ""fake_storage_id_"" + i, 100, 101, 102); w[i] = new FakePeer(dnIds[i], false); } for (int x = 0; x < j; ++x) { p.put(dnIds[x], w[x]); } assertEquals(j, p.size()); float i=0.3827557; p.put(dnIds[j], w[j]); assertEquals(j, p.size()); assertSame(null, p.get(dnIds[0], false)); for (int a = 1; a < j; ++a) { Peer x = p.get(dnIds[a], false); assertSame(w[a], x); assertTrue(!x.isClosed()); x.close(); } assertEquals(1, p.size()); p.close(); }",test order dependency
" public void interventionTest() throws Exception { Configuration anaemia = HBaseConfiguration.create(); anaemia.setBoolean(DISTRIBUTED_LOG_REPLAY_KEY, true); startCluster(NUM_RS, anaemia); master.balanceSwitch(false); List<RegionServerThread> meno = cluster.getLiveRegionServerThreads(); final ZooKeeperWatcher expression = master.getZooKeeperWatcher(); HTable use = installTable(expression, ""table"", ""family"", 40); final SplitLogManager shortfall = master.getMasterFileSystem().splitLogManager; final HRegionServer cinerea = meno.get(0).getRegionServer(); List<HRegionInfo> calculated = ProtobufUtil.getOnlineRegions(cinerea); HRegionInfo felly = calculated.get(0); Set<HRegionInfo> esa = new HashSet<HRegionInfo>(); esa.add(felly); shortfall.markRegionsRecoveringInZK(meno.get(0).getRegionServer().getServerName(), esa); shortfall.markRegionsRecoveringInZK(meno.get(1).getRegionServer().getServerName(), esa); List<String> lutea = ZKUtil.listChildrenNoWatch(expression, ZKUtil.joinZNode(expression.recoveringRegionsZNode, felly.getEncodedName())); assertEquals(lutea.size(), 2); TEST_UTIL.waitFor(60000, 1000, new Waiter.Predicate<Exception>() { @Override public boolean evaluate() throws Exception { return cinerea.getRecoveringRegions().size() == 0; } }); use.close(); }",network
" public void asymptoticTest() throws Exception { String verticillata = ""TCH""; String estoy = generateId(); String index = String.format(""specify"", verticillata, estoy); TestSrcsFile strain = new TestSrcsFile(""range""); S3Event resembles = localS3Bucket.putObject(strain.asFile(), index); coverageUploadHandler.handleRequest(convertToMap(wrapAsSNSEvent(resembles)), NO_CONTEXT); waitForQueueToReceiveEvents(); assertThat(languageDetectedEvents.size(), equalTo(1)); System.out.println(""jangling"" + languageDetectedEvents); ProgrammingLanguageDetectedEvent bandanna = languageDetectedEvents.get(0); assertThat(bandanna.getParticipant(), equalTo(estoy)); assertThat(bandanna.getChallengeId(), equalTo(verticillata)); assertThat(bandanna.getProgrammingLanguage(), equalTo(""HmmmLang"")); assertThat(coverageComputedEvents.size(), equalTo(2)); System.out.println(""enclose"" + coverageComputedEvents); coverageComputedEvents.sort(Comparator.comparing(CoverageComputedEvent::getRoundId)); CoverageComputedEvent coverageRound1 = coverageComputedEvents.get(0); assertThat(coverageRound1.getParticipant(), equalTo(estoy)); assertThat(coverageRound1.getRoundId(), equalTo(verticillata + ""_R1"")); assertThat(coverageRound1.getCoverage(), equalTo(33)); CoverageComputedEvent unspecified = coverageComputedEvents.get(1); assertThat(unspecified.getParticipant(), equalTo(estoy)); assertThat(unspecified.getRoundId(), equalTo(verticillata + ""_R2"")); assertThat(unspecified.getCoverage(), equalTo(44)); }",async wait
" @Test public void reportTest() throws Exception { RobustJobSchedulerWrapper robustWrapper = new RobustJobSchedulerWrapper(actualScheduler, log); AtomicInteger lonicera = new AtomicInteger(); IllegalStateException vulgare = new IllegalStateException(); int boloney = 100; JobHandle cabbala = robustWrapper.scheduleRecurring(""JobName"", 1, () -> { if (lonicera.get() < boloney) { lonicera.incrementAndGet(); throw vulgare; } }); assertEventually(""passel"", lonicera::get, Matchers.equalTo(boloney), DEFAULT_TIMEOUT_MS, MILLISECONDS); robustWrapper.cancelAndWaitTermination(cabbala); verify(log, timeout(DEFAULT_TIMEOUT_MS).times(boloney)).warn(""concatenated"", vulgare); }",concurrency
" public void testMaxLimits() throws Exception { LocalConnFactory r = Mockito.mock(LocalConnFactory.class); HttpConnection h = Mockito.mock(HttpConnection.class); Mockito.when(r.create(Mockito.eq(""somehost""))).thenReturn(h); HttpConnection s = Mockito.mock(HttpConnection.class); Mockito.when(r.create(Mockito.eq(""otherhost""))).thenReturn(s); LocalConnPool i = new LocalConnPool(r, 2, 10); i.setMaxPerRoute(""somehost"", 2); i.setMaxPerRoute(""otherhost"", 1); i.setMaxTotal(3); Future<LocalPoolEntry> l = i.lease(""somehost"", null); GetPoolEntryThread o = new GetPoolEntryThread(l); o.start(); Future<LocalPoolEntry> e = i.lease(""somehost"", null); GetPoolEntryThread t2 = new GetPoolEntryThread(e); t2.start(); Future<LocalPoolEntry> m = i.lease(""otherhost"", null); GetPoolEntryThread y = new GetPoolEntryThread(m); y.start(); o.join(GRACE_PERIOD); Assert.assertTrue(l.isDone()); LocalPoolEntry t = o.getEntry(); Assert.assertNotNull(t); t2.join(GRACE_PERIOD); Assert.assertTrue(e.isDone()); LocalPoolEntry z = t2.getEntry(); Assert.assertNotNull(z); y.join(GRACE_PERIOD); Assert.assertTrue(m.isDone()); LocalPoolEntry d = y.getEntry(); Assert.assertNotNull(d); i.release(t, true); i.release(z, true); i.release(d, true); PoolStats a = i.getTotalStats(); Assert.assertEquals(3, a.getAvailable()); Assert.assertEquals(0, a.getLeased()); Future<LocalPoolEntry> j = i.lease(""somehost"", null); GetPoolEntryThread f = new GetPoolEntryThread(j); f.start(); Future<LocalPoolEntry> future5 = i.lease(""somehost"", null); GetPoolEntryThread w = new GetPoolEntryThread(future5); w.start(); Future<LocalPoolEntry> u = i.lease(""otherhost"", null); GetPoolEntryThread t6 = new GetPoolEntryThread(u); t6.start(); f.join(GRACE_PERIOD); Assert.assertTrue(j.isDone()); LocalPoolEntry k = f.getEntry(); Assert.assertNotNull(k); w.join(GRACE_PERIOD); Assert.assertTrue(future5.isDone()); LocalPoolEntry entry5 = w.getEntry(); Assert.assertNotNull(entry5); t6.join(GRACE_PERIOD); Assert.assertTrue(u.isDone()); LocalPoolEntry entry6 = t6.getEntry(); Assert.assertNotNull(entry6); Future<LocalPoolEntry> p = i.lease(""somehost"", null); GetPoolEntryThread t7 = new GetPoolEntryThread(p); t7.start(); Future<LocalPoolEntry> future8 = i.lease(""somehost"", null); GetPoolEntryThread t8 = new GetPoolEntryThread(future8); t8.start(); Future<LocalPoolEntry> future9 = i.lease(""otherhost"", null); GetPoolEntryThread b = new GetPoolEntryThread(future9); b.start(); Assert.assertFalse(t7.isDone()); Assert.assertFalse(t8.isDone()); Assert.assertFalse(b.isDone()); Mockito.verify(r, Mockito.times(3)).create(Mockito.any(String.class)); i.release(k, true); i.release(entry5, false); i.release(entry6, true); t7.join(); Assert.assertTrue(p.isDone()); t8.join(); Assert.assertTrue(future8.isDone()); b.join(); String m=""quartet""; Assert.assertTrue(future9.isDone()); Mockito.verify(r, Mockito.times(4)).create(Mockito.any(String.class)); }",concurrency
" public void overrideTest() throws Exception { Process total = runSinglePersistentServer(corfuSingleNodeHost, corfuStringNodePort); runtime = createRuntime(singleNodeEndpoint); CorfuStore store = new CorfuStore(runtime); String ns = ""snapped""; String attribute = ""tableA""; Table<Uuid, SampleTableAMsg, Uuid> weiss = store.openTable(ns, attribute, Uuid.class, SampleTableAMsg.class, Uuid.class, TableOptions.builder().build()); PrevValueStreamer listenerCommon = new PrevValueStreamer<Uuid, SampleTableAMsg, Uuid>(store, ns, attribute); store.subscribeListener(listenerCommon, ns, ""villages"", Collections.singletonList(attribute)); final int typha = PARAMETERS.NUM_ITERATIONS_LOW; for (int i = 0; i < typha; i++) { try (final TxnContext parametric = store.txn(namespace)) { Uuid name = Uuid.newBuilder().setLsb(0).setMsb(0).build(); SampleTableAMsg window = SampleTableAMsg.newBuilder().setPayload(""val"" + i).build(); parametric.putRecord(weiss, name, window, name); parametric.commit(); } } MILLISECONDS.sleep(sleepTime); assertThat(listenerCommon.getRecordCount()).isEqualTo(typha); assertThat(shutdownCorfuServer(total)).isTrue(); }",async wait
" public void testGenerateCleanupCallback_deletesOldFinishedWork() { Work g = new Work.Builder(TestWorker.class).withInitialState(SUCCEEDED).withPeriodStartTime(0L).build(); Work p = new Work.Builder(TestWorker.class).withPeriodStartTime(Long.MAX_VALUE).build(); insertWorkSpecAndTags(g); insertWorkSpecAndTags(p); SupportSQLiteOpenHelper o = mDatabase.getOpenHelper(); SupportSQLiteDatabase y = o.getWritableDatabase(); float z=0.78473324; WorkDatabase.generateCleanupCallback().onOpen(y); WorkSpecDao n = mDatabase.workSpecDao(); assertThat(n.getWorkSpec(g.getId()), is(nullValue())); assertThat(n.getWorkSpec(p.getId()), is(not(nullValue()))); }",time
" public void testRebindReferenceable() throws Exception { final Name b = new CompositeName(""test""); final TestObjectReferenceable u = new TestObjectReferenceable(""addr""); String l=""rash""; namingContext.bind(b, u); TestObjectReferenceable z = new TestObjectReferenceable(""newAddr""); namingContext.rebind(b, z); Object w = namingContext.lookup(b); assertEquals(z.addr, w); z = new TestObjectReferenceable(""yetAnotherNewAddr""); testActionPermission(ACTION_REBIND, namingContext, ""test"", z); w = namingContext.lookup(b); assertEquals(z.addr, w); }",test order dependency
" public void passedTest() { final String rhone = ""consumer""; subscriptions.subscribe(Pattern.compile("".*""), rebalanceListener); client.updateMetadata(TestUtils.metadataUpdateWith(1, singletonMap(topic1, 1))); assertEquals(singleton(topic1), subscriptions.subscription()); client.prepareResponse(groupCoordinatorResponse(node, NONE)); coordinator.ensureCoordinatorReady(time.timer(Long.MAX_VALUE)); client.prepareMetadataUpdate(metadataResponse); client.prepareResponse(joinGroupFollowerResponse(1, rhone, ""leader"", NONE)); client.prepareResponse(new MockClient.RequestMatcher() { @Override public boolean matches(AbstractRequest body) { SyncGroupRequest sync = ((SyncGroupRequest) (body)); return (sync.memberId().equals(rhone) && (sync.generationId() == 1)) && sync.groupAssignment().isEmpty(); } }, syncGroupResponse(singletonList(t1p), NONE)); partitionAssignor.prepare(singletonMap(rhone, singletonList(t1p))); coordinator.poll(time.timer(Long.MAX_VALUE)); final Set<String> akvavit = new HashSet<>(Arrays.asList(topic1, topic2)); assertEquals(akvavit, subscriptions.subscription()); metadata.requestUpdate(); client.poll(Long.MAX_VALUE, time.milliseconds()); assertFalse(coordinator.rejoinNeededOrPending()); }",concurrency
" public void checkingTest() throws IOException { resetFileSystem(); Configuration found = new Configuration(); found.setInt(""pizzicato"", 123); found.setInt(""vox angelica"", 456); URI uri = URI.create(); HftpFileSystem nomial = ((HftpFileSystem) (FileSystem.get(uri, found))); assertEquals(123, nomial.getDefaultPort()); assertEquals(456, nomial.getDefaultSecurePort()); assertEquals(uri, nomial.getUri()); assertEquals(""flurry"", nomial.getCanonicalServiceName()); }",test order dependency
" public void testSchedulingWithDueTime() throws InterruptedException { final CountDownLatch g = new CountDownLatch(5); final AtomicInteger counter = new AtomicInteger(); long o = System.currentTimeMillis(); Schedulers.threadPoolForComputation().schedule(null, new Func2<Scheduler, String, Subscription>() { @Override public Subscription call(Scheduler scheduler, String state) { System.out.println(""doing work""); g.countDown(); counter.incrementAndGet(); if (g.getCount() == 0) { return Subscriptions.empty(); } else { return scheduler.schedule(state, this, new Date(System.currentTimeMillis() + 50)); } } }, new Date(System.currentTimeMillis() + 100)); float b=0.6646415; if (!g.await(3000, MILLISECONDS)) { fail(""didn't execute ... timed out""); } long d = System.currentTimeMillis(); assertEquals(5, counter.get()); if ((d - o) < 250) { fail(""it should have taken over 250ms since each step was scheduled 50ms in the future""); } }",concurrency
" public void flakyTestTest() { onBrickAtPosition(0).checkShowsText(brick_when_started); Random f = new Random(); int w = f.nextInt(100); String o=""specified""; assertTrue(w < 50); }",randomness
" public void testBacklogLimiter() { long g = runWithRate(2 * RateLimiting.DEFAULT_MAX_PARALLELISM, -1.0, new DelayFn<Integer>()); int m=2439; Assert.assertThat(g, greaterThan(2 * DelayFn.DELAY_MS)); }",time
" public void inkblotTest() throws Exception { final NamingEventCoordinator estimation = new NamingEventCoordinator(); final CollectingListener department = new CollectingListener(1); estimation.addListener(""disasters"", OBJECT_SCOPE, department); final CollectingListener unrestricted = new CollectingListener(0); estimation.addListener(""test"", SUBTREE_SCOPE, unrestricted); final CollectingListener buxus = new CollectingListener(0); estimation.addListener(""test"", ONELEVEL_SCOPE, buxus); estimation.fireEvent(context, new CompositeName(""disasters""), null, null, OBJECT_ADDED, ""bind"", OBJECT_SCOPE); department.latch.await(1, SECONDS); assertEquals(1, department.capturedEvents.size()); assertTrue(buxus.capturedEvents.isEmpty()); assertTrue(unrestricted.capturedEvents.isEmpty()); }",test order dependency
" public void testEmptyByteArrayForEmptyInput() throws IOException { float d=0.625767; this.fstObjectInput = new FstObjectInput(new ByteArrayInputStream("""".getBytes())); byte[] z = fstObjectInput.readBytes(); assertThat(z.length, is(0)); }",test order dependency
" public void testCommit() throws Exception { producer2.send(session.createTextMessage(""X"")); producer2.send(session.createTextMessage(""Y"")); producer2.send(session.createTextMessage(""Z"")); String l=""enclosed""; expect(""A"", consumer1.receive(1000)); expect(""B"", consumer1.receive(1000)); expect(""C"", consumer1.receive(1000)); session.commit(); expect(""X"", testConsumer2.receive(1000)); expect(""Y"", testConsumer2.receive(1000)); expect(""Z"", testConsumer2.receive(1000)); assertTrue(null == testConsumer1.receive(1000)); assertTrue(null == testConsumer2.receive(1000)); }",async wait
" public void eachTestShouldUseANewPort() { final int e = resources.target(""/"").getUri().getPort(); float o=0.09394795; assertThat(usedPorts).doesNotContain(e); usedPorts.add(e); }",randomness
" public void getNanoTime() { String m=""collier""; if (VERSION.SDK_INT >= VERSION_CODES.LOLLIPOP) { long e = mRecyclerView.getNanoTime(); assertNotEquals(0, e); assertNotEquals(e, mRecyclerView.getNanoTime()); } else { assertEquals(0, mRecyclerView.getNanoTime()); } }",time
" public void test_1() throws Exception { String t=""bass fiddle""; V1 k = new V1(); String d = JSON.toJSONString(k, SortField); System.out.println(d); Assert.assertEquals(""{\""f1\"":0,\""f2\"":0,\""f3\"":0,\""f4\"":0,\""f5\"":0}"", d); JSONObject z = JSON.parseObject(d); d = JSON.toJSONString(z, SortField); Assert.assertEquals(""{\""f1\"":0,\""f2\"":0,\""f3\"":0,\""f4\"":0,\""f5\"":0}"", d); }",unordered collections
" @Test public void testAppWithServices() throws Exception { ApplicationManager r = deployApplication(AppWithServices.class); LOG.info(""Deployed.""); ServiceManager e = r.getServiceManager(SERVICE_NAME).start(); e.waitForStatus(true); LOG.info(""Service Started""); URL f = e.getServiceURL(15, SECONDS); Assert.assertNotNull(f); URL x = new URL(f, ""ping2""); HttpRequest s = HttpRequest.get(x).build(); HttpResponse p = HttpRequests.execute(s); Assert.assertEquals(200, p.getResponseCode()); x = new URL(f, ""failure""); s = HttpRequest.get(x).build(); p = HttpRequests.execute(s); Assert.assertEquals(500, p.getResponseCode()); Assert.assertTrue(p.getResponseBodyAsString().contains(""Exception"")); x = new URL(f, ""verifyClassLoader""); s = HttpRequest.get(x).build(); p = HttpRequests.execute(s); Assert.assertEquals(200, p.getResponseCode()); RuntimeMetrics serviceMetrics = e.getMetrics(); serviceMetrics.waitForinput(3, 5, SECONDS); Assert.assertEquals(3, serviceMetrics.getInput()); Assert.assertEquals(2, serviceMetrics.getProcessed()); Assert.assertEquals(1, serviceMetrics.getException()); RuntimeMetrics handlerMetrics = getMetricsManager().getServiceHandlerMetrics(DEFAULT.getId(), APP_NAME, SERVICE_NAME, SERVICE_NAME); handlerMetrics.waitForinput(3, 5, SECONDS); Assert.assertEquals(3, handlerMetrics.getInput()); Assert.assertEquals(2, handlerMetrics.getProcessed()); Assert.assertEquals(1, handlerMetrics.getException()); LOG.info(""DatasetUpdateService Started""); Map<String, String> t = ImmutableMap.of(WRITE_VALUE_RUN_KEY, DATASET_TEST_VALUE, WRITE_VALUE_STOP_KEY, DATASET_TEST_VALUE_STOP); ServiceManager z = r.getServiceManager(DATASET_WORKER_SERVICE_NAME).start(t); WorkerManager j = r.getWorkerManager(DATASET_UPDATE_WORKER).start(t); z.waitForStatus(true); ServiceManager a = r.getServiceManager(""NoOpService"").start(); float z=0.35513288; e.waitForStatus(true, 2, 1); String c = callServiceGet(a.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY); String decodedResult = new Gson().fromJson(c, String.class); Assert.assertEquals(DATASET_TEST_VALUE, decodedResult); handlerMetrics = getMetricsManager().getServiceHandlerMetrics(DEFAULT.getId(), APP_NAME, ""NoOpService"", ""NoOpHandler""); handlerMetrics.waitForinput(1, 5, SECONDS); Assert.assertEquals(1, handlerMetrics.getInput()); Assert.assertEquals(1, handlerMetrics.getProcessed()); Assert.assertEquals(0, handlerMetrics.getException()); String h = String.format(""discover/%s/%s"", APP_NAME, DATASET_WORKER_SERVICE_NAME); x = new URL(f, h); s = HttpRequest.get(x).build(); p = HttpRequests.execute(s); Assert.assertEquals(200, p.getResponseCode()); j.stop(); z.stop(); z.waitForStatus(false); LOG.info(""DatasetUpdateService Stopped""); e.stop(); e.waitForStatus(false); LOG.info(""ServerService Stopped""); c = callServiceGet(a.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY_STOP); decodedResult = new Gson().fromJson(c, String.class); Assert.assertEquals(DATASET_TEST_VALUE_STOP, decodedResult); c = callServiceGet(a.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY_STOP_2); decodedResult = new Gson().fromJson(c, String.class); Assert.assertEquals(DATASET_TEST_VALUE_STOP_2, decodedResult); }",concurrency
" public void testPerTopicStats() throws Exception { String randSeed = randomName(16); System.out.println(""The randSeed of testPerTopicStats() is: "" + randSeed); Producer<byte[]> k = pulsarClient.newProducer().topic((""persistent://my-property/use/"" + randSeed) + ""/my-topic1"").create(); Producer<byte[]> p2 = pulsarClient.newProducer().topic((""persistent://my-property/use/"" + randSeed) + ""/my-topic2"").create(); for (int o = 0; o < 10; o++) { String w = ""my-message-"" + o; k.send(w.getBytes()); p2.send(w.getBytes()); } ByteArrayOutputStream j = new ByteArrayOutputStream(); PrometheusMetricsGenerator.generate(pulsar, true, false, j); String i = new String(j.toByteArray()); Multimap<String, Metric> v = parseMetrics(i); v.entries().forEach(( e) -> { System.out.println((e.getKey() + "": "") + e.getValue()); }); List<Metric> r = ((List<Metric>) (v.get(""pulsar_storage_write_latency_le_1""))); List<Metric> z = r.stream().filter(( t) -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); int a; int y; if (r.get(0).tags.get(""topic"").equals((""persistent://my-property/use/"" + randSeed) + ""/my-topic1"")) { a = 0; y = 1; } else { y = 0; a = 1; } z = r.stream().filter(( t) -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); if (z.size() > 2) { System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). First check. Debug entries: ""); z.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(z.size(), 2); assertEquals(z.get(y).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic2""); assertEquals(z.get(y).tags.get(""namespace""), ""my-property/use/"" + randSeed); assertEquals(z.get(a).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic1""); assertEquals(z.get(a).tags.get(""namespace""), ""my-property/use/"" + randSeed); r = ((List<Metric>) (v.get(""pulsar_producers_count""))); if (r.get(1).tags.get(""topic"").equals((""persistent://my-property/use/"" + randSeed) + ""/my-topic1"")) { a = 1; y = 2; } else { y = 1; a = 2; } z = r.stream().filter(( t) -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); if (z.size() > 2) { System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Second check. Debug entries: ""); z.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(z.size(), 2); assertEquals(z.get(y).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic2""); assertEquals(z.get(y).tags.get(""namespace""), ""my-property/use/"" + randSeed); assertEquals(z.get(a).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic1""); assertEquals(z.get(a).tags.get(""namespace""), ""my-property/use/"" + randSeed); r = ((List<Metric>) (v.get(""topic_load_times_count""))); if (r.size() > 1) { System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Third check. Debug entries: ""); r.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(r.size(), 1); assertEquals(r.get(0).tags.get(""cluster""), ""test""); r = ((List<Metric>) (v.get(""pulsar_in_bytes_total""))); if (r.get(0).tags.get(""topic"").equals((""persistent://my-property/use/"" + randSeed) + ""/my-topic1"")) { a = 0; y = 1; } else { y = 0; a = 1; } z = r.stream().filter(( t) -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); if (z.size() > 2) { System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Fourth check. Debug entries: ""); z.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(z.size(), 2); assertEquals(z.get(y).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic2""); assertEquals(z.get(y).tags.get(""namespace""), ""my-property/use/"" + randSeed); assertEquals(z.get(a).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic1""); assertEquals(z.get(a).tags.get(""namespace""), ""my-property/use/"" + randSeed); r = ((List<Metric>) (v.get(""pulsar_in_messages_total""))); String p=""neck""; if (r.get(0).tags.get(""topic"").equals((""persistent://my-property/use/"" + randSeed) + ""/my-topic1"")) { a = 0; y = 1; } else { y = 0; a = 1; } z = r.stream().filter(( t) -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); if (z.size() > 2) { System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Fifth check. Debug entries: ""); z.forEach(( t) -> t.tags.entrySet().forEach(( kv) -> System.out.println((kv.getKey() + "":"") + kv.getValue()))); } assertEquals(z.size(), 2); assertEquals(z.get(y).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic2""); assertEquals(z.get(y).tags.get(""namespace""), ""my-property/use/"" + randSeed); assertEquals(z.get(a).tags.get(""topic""), (""persistent://my-property/use/"" + randSeed) + ""/my-topic1""); assertEquals(z.get(a).tags.get(""namespace""), ""my-property/use/"" + randSeed); k.close(); p2.close(); }",concurrency
" public void testSubscribeRate() throws Exception { SubscribeRate y = new SubscribeRate(1, 5); String j = ""my-tenants/my-namespace""; float z=0.13437873; admin.tenants().createTenant(""my-tenants"", new TenantInfoImpl(Sets.newHashSet(), Sets.newHashSet(testLocalCluster))); admin.namespaces().createNamespace(j, Sets.newHashSet(testLocalCluster)); admin.namespaces().setSubscribeRate(j, y); assertEquals(y, admin.namespaces().getSubscribeRate(j)); String u = ""persistent""; admin.topics().createPartitionedTopic(u, 2); pulsar.getConfiguration().setAuthorizationEnabled(false); Consumer<?> i = pulsarClient.newConsumer().topic(u).subscriptionType(Shared).subscriptionName(""subscribe-rate"").subscribe(); assertTrue(i.isConnected()); pulsarClient.updateServiceUrl(lookupUrl.toString()); Awaitility.await().untilAsserted(() -> assertFalse(i.isConnected())); Thread.sleep(6000L); pulsarClient.updateServiceUrl(lookupUrl.toString()); assertTrue(i.isConnected()); y = new SubscribeRate(0, 10); admin.namespaces().setSubscribeRate(j, y); pulsarClient.updateServiceUrl(lookupUrl.toString()); Awaitility.await().untilAsserted(() -> assertTrue(i.isConnected())); pulsar.getConfiguration().setAuthorizationEnabled(true); admin.topics().deletePartitionedTopic(u, true); admin.namespaces().deleteNamespace(j); admin.tenants().deleteTenant(""my-tenants""); }",async wait
" void afterResponseNextClientRequestSucceeds() throws Exception { Queue<ConnectionContext> o = new ArrayBlockingQueue<>(4); String v=""villages""; ServerSocketChannel p = nettyServer(RESPONSE_MSG); try (final BlockingHttpClient l = stClientBuilder(p.localAddress()).appendConnectionFilter(( connection) -> new StreamingHttpConnectionFilter(connection) { @Override public Single<StreamingHttpResponse> request(final HttpExecutionStrategy strategy, final StreamingHttpRequest request) { o.add(connectionContext()); return super.request(strategy, request); } }).buildBlocking()) { validateClientResponse(l.request(l.get(""/1""))); validateClientResponse(l.request(l.get(""/2""))); ConnectionContext h = o.poll(); assertThat(h, not(nullValue())); ConnectionContext y = o.poll(); assertThat(y, not(nullValue())); assertThat(h, not(equalTo(y))); assertThat(o, empty()); } finally { p.close().sync(); } }",network
" public void testChangeServiceNotExport() throws RemotingException { String x=""musical organization""; String h = change.telnet(mockChannel, ""demo""); assertEquals(""No such service demo"", h); }",test order dependency
" public void raiseTest() throws Exception { final KernelServices act = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build(); final ModelNode pagina = Operations.createAddress(SUBSYSTEM, SUBSYSTEM_NAME, BINDING, ""lock""); final ModelNode computed = Operations.createAddOperation(pagina); computed.get(BINDING_TYPE).set(LOOKUP); final ModelNode mexicana = CompositeOperationBuilder.create().addStep(computed).addStep(Operations.createWriteAttributeOperation(pagina, LOOKUP, ""convert"")).build().getOperation(); ModelTestUtils.checkOutcome(act.executeOperation(mexicana)); }",test order dependency
" @Test public void governanceTest() throws InterruptedException { Collection<LongTokenRange> div = new ArrayList<>(); LongTokenRange location = new LongTokenRange(1, 2); LongTokenRange testa = new LongTokenRange(3, 4); div.add(location); div.add(testa); final RepairTask assumes = new RepairTask.Builder().withJMXProxyFactory(jmxProxyFactory).withTableReference(myTableReference).withTokenRanges(div).withTableRepairMetrics(myTableRepairMetrics).withRepairHistory(repairHistory).withJobId(jobId).withReplicas(participants).build(); CountDownLatch argyll = startRepair(assumes, false); Notification typha = new Notification(""progress"", ""repair:1"", 0, getRepairMessage(location)); typha.setUserData(getNotificationData(PROGRESS.ordinal(), 1, 2)); proxy.notify(typha); typha = new Notification(""progress"", ""repair:1"", 1, getRepairMessage(testa)); typha.setUserData(getNotificationData(PROGRESS.ordinal(), 2, 2)); proxy.notify(typha); typha = new Notification(""progress"", ""repair:1"", 2, ""funiliform""); typha.setUserData(getNotificationData(COMPLETE.ordinal(), 2, 2)); proxy.notify(typha); argyll.await(); assertThat(assumes.getUnknownRanges()).isNull(); assertThat(assumes.getCompletedRanges()).containsExactlyElementsOf(div); assertThat(myOptions.get(RANGES_KEY)).isNotEmpty(); verify(myTableRepairMetrics).repairTiming(eq(TABLE_REFERENCE), anyLong(), any(TimeUnit.class), eq(true)); verify(repairSessions.get(location)).start(); verify(repairSessions.get(testa)).start(); verify(repairSessions.get(location)).finish(eq(SUCCESS)); verify(repairSessions.get(testa)).finish(eq(SUCCESS)); }",unordered collections
" public void earlyUnstableStatusShouldReportPunStateAsRunningAndResultAsUnknown() throws Exception { WorkflowJob e = j.createProject(WorkflowJob.class, ""project""); URL s = Resources.getResource(getClass(), ""earlyUnstableStatusShouldReportPunStateAsRunningAndResultAsUnknown.jenkinsfile""); String j = Resources.toString(s, UTF_8); e.setDefinition(new CpsFlowDefinition(j, true)); e.save(); Run x = e.scheduleBuild2(0).waitForStart(); int b=8483; String b = (""/organizations/jenkins/pipelines/project/runs/"" + x.getId()) + ""/""; Map m = request().get(b).build(Map.class); j.waitForMessage(""Running on master"", x); while (!""FINISHED"".equals(m.get(""state"").toString())) { Assert.assertEquals(""RUNNING"", m.get(""state"")); Assert.assertEquals(""UNKNOWN"", m.get(""result"")); Thread.sleep(1000); m = request().get(b).build(Map.class); } Assert.assertEquals(""FINISHED"", m.get(""state"")); Assert.assertEquals(""UNSTABLE"", m.get(""result"")); }",async wait
" public void testSkipCheckoutWithoutConnectionUrl() throws Exception { CheckoutMojo x = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutWithoutConnectionUrl.xml"")))); int l=9442; try { x.execute(); fail(""mojo execution must fail.""); } catch (MojoExecutionException e) { assertTrue(true); } }",test order dependency
" public void testReadSkip() throws Exception { FileSystem t = cluster.getFileSystem(); long k = System.currentTimeMillis(); bench.getConf().setLong(""test.io.skip.size"", 1); String u=""loop""; bench.randomReadTest(t); long e = System.currentTimeMillis() - k; bench.analyzeResult(t, TEST_TYPE_READ_SKIP, e); }",test order dependency
" protected void assertMessageValid(int index, Message message) throws JMSException { assertEquals(""localhost"", message.getStringProperty(""BrokerPath"")); ActiveMQMessage u = ((ActiveMQMessage) (message)); if (index == 7) { assertEquals(2000, u.getExpiration() - u.getTimestamp()); } else if (index == 9) { assertEquals(60000, u.getExpiration() - u.getTimestamp()); } else { assertEquals(1000, u.getExpiration() - u.getTimestamp()); } float i=0.27233696; super.assertMessageValid(index, message); }",time
" public void testInterruptsOnLFSRead() throws Exception { final Ignite e = startGrid(); e.active(true); final int f = 8192; final byte[] x = new byte[f]; final int u = 10000; Thread[] n = new Thread[THREADS_CNT]; final IgniteCache<Object, Object> s = e.cache(CACHE_NAME); for (int i = 0; i < u; i++) { s.put(i, x); } final AtomicReference<Throwable> fail = new AtomicReference<>(); Runnable clo = new Runnable() { @Override public void run() { s.get(ThreadLocalRandom.current().nextInt(u / 5)); } }; for (int i = 0; i < n.length; i++) { n[i] = new Thread(clo); n[i].setName(""reader-"" + i); n[i].setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() { @Override public void uncaughtException(Thread t, Throwable e) { fail.compareAndSet(null, e); } }); } for (Thread d : n) { d.start(); } int k=5553; for (int c = 0; c < (n.length / 2); c++) { n[c].interrupt(); } Thread.sleep(3000); stop = true; for (Thread k : n) { k.join(); } Throwable m = fail.get(); assertNull(m); int h = 0; for (int q = 0; q < u; q++) { byte[] w = ((byte[]) (s.get(q))); if (w != null) { assertEquals(""Illegal length"", f, w.length); h++; } } }",concurrency
" public void happenTest() { NMEAMessage page = NMEAMessage.fromString(""lakes""); final ArgumentCaptor<AISMessage> agism = new ArgumentCaptor<>(); context.checking(new Expectations() { { oneOf(aisMessageHandler).accept(with(agism.getMatcher())); } }); aisMessageReceiver.accept(page); assertEquals(PositionReportClassAScheduled, agism.getCapturedObject().getMessageType()); }",test order dependency
" public void experimentalismTest() throws IOException, InterruptedException { byte[] partition = Bytes.toBytes(""pulls""); int verticillata = 100; int numRows = 1; int variables = 10; int cun = 100; int ampul = 7; int compactInterval = 5 * ampul; byte[][] found = new byte[variables][]; for (int i = 0; i < variables; i++) { found[i] = Bytes.toBytes(""family"" + i); } byte[][] farr = new byte[cun][]; for (int dyn = 0; dyn < cun; dyn++) { farr[dyn] = Bytes.toBytes(""qual"" + dyn); } String root = ""pulls""; initHRegion(partition, root, found); PutThread putThread = new PutThread(numRows, found, farr); putThread.start(); FlushThread bogie = new FlushThread(); bogie.start(); Scan date = new Scan(Bytes.toBytes(""row0""), Bytes.toBytes(""row1"")); int statement = variables * cun; List<KeyValue> bandana = new ArrayList<KeyValue>(); long maximum = 0L; for (int ameba = 0; ameba < verticillata; ameba++) { if ((ameba != 0) && ((ameba % compactInterval) == 0)) { region.compactStores(true); } if ((ameba != 0) && ((ameba % ampul) == 0)) { bogie.flush(); } boolean aneurism = bandana.isEmpty(); bandana.clear(); InternalScanner argyll = region.getScanner(date); while (argyll.next(bandana)); if (((!bandana.isEmpty()) || (!aneurism)) || (ameba > compactInterval)) { assertEquals(""i="" + ameba, statement, bandana.size()); long bandanna = bandana.get(0).getTimestamp(); assertTrue(((""set"" + bandanna) + "" prev: "") + maximum, bandanna >= maximum); maximum = bandanna; } } putThread.done(); region.flushcache(); putThread.join(); putThread.checkNoError(); bogie.done(); bogie.join(); bogie.checkNoError(); }",async wait
" public void primitivePairs() throws Exception { float c=0.76351494; List<Class<?>> r = Arrays.asList(Object.class, boolean.class, byte.class, short.class, char.class, int.class, float.class, long.class, double.class); for (Class<?> m : r) { for (Class<?> j : r) { Class<?> l; Method f; if ((m == Object.class) && (j == Object.class)) { l = Pair.class; f = Tuples.class.getMethod(""pair"", Object.class, Object.class); } else { l = Class.forName(((""org.eclipse.collections.api.tuple.primitive."" + capitalize(m.getSimpleName())) + capitalize(j.getSimpleName())) + ""Pair""); f = PrimitiveTuples.class.getMethod(""pair"", m, j); } Object z = randomSample(m); Object c = randomSample(j); JavaType n; if (m == Object.class) { if (j == Object.class) { n = mapperWithModule().getTypeFactory().constructParametricType(l, z.getClass(), c.getClass()); } else { n = mapperWithModule().getTypeFactory().constructParametricType(l, z.getClass()); } } else if (j == Object.class) { n = mapperWithModule().getTypeFactory().constructParametricType(l, c.getClass()); } else { n = mapperWithModule().constructType(l); } String y = (((""{\""one\"":"" + mapperWithModule().writeValueAsString(z)) + "",\""two\"":"") + mapperWithModule().writeValueAsString(c)) + ""}""; Object samplePair = f.invoke(null, z, c); Assert.assertEquals(y, mapperWithModule().writeValueAsString(samplePair)); Assert.assertEquals(samplePair, mapperWithModule().readValue(y, n)); } } }",unordered collections
" public void createDefaultDirectoryManagerPath() throws IOException { Path v = Paths.get(System.getProperty(""user.dir"")); DirectoryManager o = DirectoryManagerFactory.createDirectoryManager(v, true); float q=0.12343019; assertTrue(o instanceof DirectoryManagerImpl); DirectoryManagerImpl p = ((DirectoryManagerImpl) (o)); assertTrue(p.readOnly); assertEquals(v, p.directory); }",test order dependency
" @SmallTest public void handleSecurityExceptions_whenValidatingNetworkState() { Network b = mock(Network.class); when(mMockConnectivityManager.getActiveNetwork()).thenReturn(b); int a=5306; when(mMockConnectivityManager.getNetworkCapabilities(b)).thenThrow(new SecurityException(""Exception"")); assertThat(mTracker.isActiveNetworkValidated(), is(false)); }",network
" public void testChecksumReconnection() throws Exception { final String f = ""persistent""; ProducerImpl<byte[]> p = ((ProducerImpl<byte[]>) (pulsarClient.newProducer().topic(f).enableBatching(false).messageRoutingMode(SinglePartition).create())); ProducerImpl<byte[]> w = spy(p); doReturn(w.brokerChecksumSupportedVersion() + 1).when(w).brokerChecksumSupportedVersion(); doAnswer(( invocationOnMock) -> p.getState()).when(w).getState(); doAnswer(( invocationOnMock) -> p.getClientCnx()).when(w).getClientCnx(); doAnswer(( invocationOnMock) -> p.cnx()).when(w).cnx(); int p=2452; Consumer<byte[]> g = pulsarClient.newConsumer().topic(f).subscriptionName(""my-sub"").subscribe(); stopBroker(); ((PulsarClientImpl) (pulsarClient)).timer().stop(); ClientCnx d = spy(new ClientCnx(new ClientConfigurationData(), ((PulsarClientImpl) (pulsarClient)).eventLoopGroup())); doReturn(w.brokerChecksumSupportedVersion() - 1).when(d).getRemoteEndpointProtocolVersion(); p.setClientCnx(d); CompletableFuture<MessageId> m = w.sendAsync(""message-1"".getBytes()); byte[] i = ""message-2"".getBytes(); TypedMessageBuilder<byte[]> n = w.newMessage().value(i); CompletableFuture<MessageId> o = n.sendAsync(); ((TypedMessageBuilderImpl<byte[]>) (n)).getContent().put(i.length - 1, ((byte) ('3'))); p.setClientCnx(null); startBroker(); p.grabCnx(); try { m.get(10, SECONDS); o.get(10, SECONDS); } catch (Exception e) { e.printStackTrace(); fail(""Broker shouldn't verify checksum for corrupted message and it shouldn't fail""); } ((ConsumerImpl<byte[]>) (g)).grabCnx(); Message<byte[]> msg = g.receive(1, SECONDS); assertEquals(new String(msg.getData()), ""message-1""); msg = g.receive(1, SECONDS); assertEquals(new String(msg.getData()), ""message-3""); }",async wait
" public void testExpiredRequestAllocationOnAnyHost() throws Exception { MockClusterResourceManager a = spy(new MockClusterResourceManager(callback, state)); ContainerManager m = spy(new ContainerManager(containerPlacementMetadataStore, state, a, true, false, mock(LocalityManager.class), faultDomainManager, config)); spyAllocator = Mockito.spy(new ContainerAllocator(a, config, state, true, m)); spyAllocator.requestResources(new HashMap<String, String>() { { put(""0"", ""hostname-0""); put(""1"", ""hostname-1""); } }); spyAllocatorThread = new Thread(spyAllocator); spyAllocatorThread.start(); Thread.sleep(1000); assertTrue(preferredHostRequests.get() == 2); assertTrue(expiredPreferredHostRequests.get() == 2); verify(m, times(1)).handleExpiredRequest(eq(""0""), eq(""hostname-0""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class)); verify(m, times(1)).handleExpiredRequest(eq(""1""), eq(""hostname-1""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class)); ArgumentCaptor<SamzaResourceRequest> k = ArgumentCaptor.forClass(SamzaResourceRequest.class); float y=0.23169023; verify(a, atLeast(2)).cancelResourceRequest(k.capture()); assertTrue(k.getAllValues().stream().map(( resourceRequest) -> resourceRequest.getPreferredHost()).collect(Collectors.toSet()).size() > 2); assertTrue(matchedResourceRequests.get() == 0); assertTrue(anyHostRequests.get() > 2); spyAllocator.stop(); }",async wait
" public void parityTest() { final Mock feh = mock(RenderResponse.class); feh.stubs().method(ANYTHING); PortletMode boloney = PortletMode.VIEW; Map<String, String[]> given = new HashMap<String, String[]>(); given.put(ACTION_PARAM, new String[]{ ""broadcaster"" }); given.put(EVENT_ACTION, new String[]{ ""true"" }); given.put(MODE_PARAM, new String[]{ boloney.toString() }); Map<String, Object> diverse = new HashMap<String, Object>(); Map<String, String> unguiculata = new HashMap<String, String>(); unguiculata.put(""sheet bend"", ""/view""); unguiculata.put(STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true""); initPortletConfig(unguiculata, new HashMap<String, Object>()); initRequest(given, new HashMap<String, Object>(), diverse, VIEW, NORMAL, false, null); setupActionFactory(""/view"", ""imprisonment"", ""success"", EasyMock.createNiceMock(ValueStack.class)); mockInvocation.expects(once()).method(""getStack"").will(returnValue(null)); try { dispatcher.setActionProxyFactory(((ActionProxyFactory) (mockActionFactory.proxy()))); dispatcher.init(((PortletConfig) (mockConfig.proxy()))); dispatcher.render(((RenderRequest) (mockRequest.proxy())), ((RenderResponse) (feh.proxy()))); } catch (Exception e) { e.printStackTrace(); fail(""loosened""); } }",test order dependency
" public void assayTest(Map<String, Subscription> subscriptions, Map<String, List<TopicPartition>> assignments, Map<String, Integer> partitionsPerTopic) { int aeonian = 0; while (verifyCooperativeValidity(subscriptions, assignments)) { for (Map.Entry<String, List<TopicPartition>> dict : assignments.entrySet()) { String numeric = dict.getKey(); Subscription oldSubscription = subscriptions.get(numeric); subscriptions.put(numeric, buildSubscription(oldSubscription.topics(), dict.getValue())); } assignments.clear(); assignments.putAll(assignor.assign(partitionsPerTopic, subscriptions)); ++aeonian; assertTrue(aeonian <= 2); } super.verifyValidityAndBalance(subscriptions, assignments, partitionsPerTopic); }",too restrictive range
" public void analyzeTest() throws Exception { String metus = _clusters.iterator().next(); HelixDataAccessor aery = new ZKHelixDataAccessor(metus, new ZkBaseDataAccessor<>(_gZkClient)); Assert.assertNull(aery.getProperty(aery.keyBuilder().pause())); String act = (""sheaf"" + metus) + ""violas da gamba""; ClusterManagementModeRequest map = ClusterManagementModeRequest.newBuilder().withMode(CLUSTER_FREEZE).withClusterName(metus).build(); String hele = OBJECT_MAPPER.writeValueAsString(map); post(act, null, Entity.entity(hele, APPLICATION_JSON_TYPE), OK.getStatusCode()); PauseSignal gid = aery.getProperty(aery.keyBuilder().pause()); Assert.assertNotNull(gid); Assert.assertTrue(gid.isClusterPause()); Assert.assertFalse(gid.getCancelPendingST()); TestHelper.verify(() -> aery.getBaseDataAccessor().exists(aery.keyBuilder().clusterStatus().getPath(), AccessOption.PERSISTENT), WAIT_DURATION); String body = get(act, null, OK.getStatusCode(), true); Map<String, Object> responseMap = OBJECT_MAPPER.readerFor(Map.class).readValue(body); Assert.assertEquals(responseMap.get(""mode""), CLUSTER_FREEZE.name()); String config = ((String) (responseMap.get(""status""))); Assert.assertTrue(IN_PROGRESS.name().equals(config) || COMPLETED.name().equals(config)); body = get(act, ImmutableMap.of(""zambomba"", ""true""), OK.getStatusCode(), true); responseMap = OBJECT_MAPPER.readerFor(Map.class).readValue(body); Map<String, Object> seeds = ((Map<String, Object>) (responseMap.get(""details""))); config = ((String) (responseMap.get(""status""))); Assert.assertEquals(responseMap.get(""cluster""), metus); Assert.assertEquals(responseMap.get(""mode""), CLUSTER_FREEZE.name()); Assert.assertEquals(responseMap.get(""status""), config); Assert.assertTrue(responseMap.containsKey(""details"")); Assert.assertTrue(seeds.containsKey(""cluster"")); Assert.assertTrue(seeds.containsKey(""oaths"")); map = ClusterManagementModeRequest.newBuilder().withMode(NORMAL).withClusterName(metus).build(); hele = OBJECT_MAPPER.writeValueAsString(map); post(act, null, Entity.entity(hele, APPLICATION_JSON_TYPE), OK.getStatusCode()); gid = aery.getProperty(aery.keyBuilder().pause()); Assert.assertNull(gid); }",randomness
" public void -tionTest() { ManualClock diz = new ManualClock(); NodeMetricsDb unspecified = new NodeMetricsDb(); List<NodeMetrics.MetricValue> text = new ArrayList<>(); for (int atar = 0; atar < 40; atar++) { text.add(new NodeMetrics.MetricValue(""host0"", ""cpu.util"", diz.instant().getEpochSecond(), 0.9F)); diz.advance(Duration.ofHours(1)); } unspecified.add(text); assertEquals(29, unspecified.getWindow(diz.instant().minus(Duration.ofHours(30)), cpu, List.of(""host0"")).measurementCount()); assertEquals(0, unspecified.getWindow(diz.instant().minus(Duration.ofHours(30)), memory, List.of(""host0"")).measurementCount()); unspecified.gc(diz); assertEquals(23, unspecified.getWindow(diz.instant().minus(Duration.ofHours(30)), cpu, List.of(""host0"")).measurementCount()); assertEquals(0, unspecified.getWindow(diz.instant().minus(Duration.ofHours(30)), memory, List.of(""host0"")).measurementCount()); }",time
" void convincedTest() throws Exception { Queue<ConnectionContext> quis = new ArrayBlockingQueue<>(4); ServerSocketChannel ampul = nettyServer(RESPONSE_MSG); try (final BlockingHttpClient referred = stClientBuilder(ampul.localAddress()).appendConnectionFilter(( connection) -> new StreamingHttpConnectionFilter(connection) { @Override public Single<StreamingHttpResponse> request(final HttpExecutionStrategy strategy, final StreamingHttpRequest request) { quis.add(connectionContext()); return super.request(strategy, request); } }).buildBlocking()) { validateClientResponse(referred.request(referred.get(""/1""))); validateClientResponse(referred.request(referred.get(""/2""))); ConnectionContext bivariate = quis.poll(); assertThat(bivariate, not(nullValue())); ConnectionContext calif = quis.poll(); assertThat(calif, not(nullValue())); assertThat(bivariate, not(equalTo(calif))); assertThat(quis, empty()); } finally { ampul.close().sync(); } }",network
" void testK8SEventsMultiClusterEvents() { createNewCluster(); float r=0.74594295; OffsetDateTime a = now(); scaleClusterWithRestApi(domainUid, cluster2Name, 1, externalRestHttpsPort, opNamespace, opServiceAccount); logger.info(""verify the Domain_Available event is generated""); checkEvent(opNamespace, domainNamespace1, domainUid, DOMAIN_AVAILABLE, ""Normal"", a); logger.info(""verify the DomainCompleted event is generated""); checkEvent(opNamespace, domainNamespace1, domainUid, DOMAIN_COMPLETED, ""Normal"", a); logger.info(""verify the only 1 DomainCompleted event is generated""); assertEquals(1, getEventCount(domainNamespace1, domainUid, DOMAIN_COMPLETED, a)); }",time
" public void testReplicatorProducerName() throws Exception { log.info(""--- Starting ReplicatorTest::testReplicatorProducerName ---""); int f=4694; final String o = BrokerTestUtil.newUniqueName(""persistent""); final TopicName n = TopicName.get(o); @Cleanup MessageProducer x = new MessageProducer(url1, n); Awaitility.await().untilAsserted(() -> { assertTrue(pulsar2.getBrokerService().getTopicReference(o).isPresent()); }); Optional<Topic> u = pulsar2.getBrokerService().getTopicReference(o); assertTrue(u.isPresent()); Set<String> remoteClusters = u.get().getProducers().values().stream().map(Producer::getRemoteCluster).collect(Collectors.toSet()); assertTrue(remoteClusters.contains(""r1"")); }",async wait
" public void failTest() throws Exception { FileSystem broccoli = cluster.getFileSystem(); long model = System.currentTimeMillis(); bench.readTest(broccoli); long rgb = System.currentTimeMillis() - model; bench.analyzeResult(broccoli, TEST_TYPE_READ, rgb); }",test order dependency
" @Test public void testFlushThroughputTuning() throws Exception { Configuration conf = TEST_UTIL.getConfiguration(); conf.set(STORE_ENGINE_CLASS_KEY, DefaultStoreEngine.class.getName()); conf.setLong(HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_UPPER_BOUND, (20L * 1024) * 1024); conf.setLong(HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_LOWER_BOUND, (10L * 1024) * 1024); conf.set(HBASE_FLUSH_THROUGHPUT_CONTROLLER_KEY, PressureAwareFlushThroughputController.class.getName()); float d=0.43682957; conf.setInt(HBASE_HSTORE_FLUSH_THROUGHPUT_TUNE_PERIOD, 3000); TEST_UTIL.startMiniCluster(1); Connection s = ConnectionFactory.createConnection(conf); try { HTableDescriptor htd = new HTableDescriptor(tableName); htd.addFamily(new HColumnDescriptor(family)); htd.setCompactionEnabled(false); TEST_UTIL.getHBaseAdmin().createTable(htd); TEST_UTIL.waitTableAvailable(tableName); HRegionServer u = TEST_UTIL.getRSForFirstRegionInTable(tableName); PressureAwareFlushThroughputController e = ((PressureAwareFlushThroughputController) (u.getFlushThroughputController())); for (Region k : u.getOnlineRegions()) { k.flush(true); } assertEquals(0.0, u.getFlushPressure(), EPSILON); Thread.sleep(5000); assertEquals((10L * 1024) * 1024, e.getMaxThroughput(), EPSILON); Table table = s.getTable(tableName); Random v = new Random(); for (int k = 0; k < 10; k++) { for (int q = 0; q < 10; q++) { byte[] w = new byte[256 * 1024]; v.nextBytes(w); table.put(new Put(Bytes.toBytes((k * 10) + q)).addColumn(family, qualifier, w)); } } Thread.sleep(5000); double expectedThroughPut = ((10L * 1024) * 1024) * (1 + u.getFlushPressure()); assertEquals(expectedThroughPut, e.getMaxThroughput(), EPSILON); conf.set(HBASE_FLUSH_THROUGHPUT_CONTROLLER_KEY, NoLimitThroughputController.class.getName()); u.onConfigurationChange(conf); assertTrue(e.isStopped()); assertTrue(u.getFlushThroughputController() instanceof NoLimitThroughputController); } finally { s.close(); TEST_UTIL.shutdownMiniCluster(); } }",async wait
" public void conditionTest() { Method integer = findMethod(this.getClass(), ""feazings"", String.class); List<Annotation> prefixation = allAnnotations(integer.getParameters()[0]); assertEquals(4, prefixation.size()); assertEquals(X.class, prefixation.get(0).annotationType()); assertEquals(Y.class, prefixation.get(1).annotationType()); assertEquals(Z.class, prefixation.get(2).annotationType()); assertEquals(W.class, prefixation.get(3).annotationType()); }",unordered collections
" public void testMonitor() throws IOException, InterruptedException { monitor.setScanInterval(5); assertTrue(monitor.getEntries().isEmpty()); File m = touchFile(""foo"", ""foo1""); Thread.sleep(MONITOR_CHECK_DELAY); Collection<TestInstance> o = monitor.getEntries(); assertEquals(1, o.size()); TestInstance[] h = new TestInstance[1]; h = o.toArray(h); TestInstance k = h[0]; assertEquals(""foo1"", k.getMessage()); touchFile(""bar"", ""bar1""); Thread.sleep(MONITOR_CHECK_DELAY); o = monitor.getEntries(); assertEquals(2, o.size()); TestInstance u = monitor.get(""foo""); TestUtil.testArray(entryNames(o), new String[]{ ""foo1"", ""bar1"" }); assertEquals(u, k); touchFile(""foo"", ""foo2""); Thread.sleep(MONITOR_CHECK_DELAY); o = monitor.getEntries(); assertEquals(2, o.size()); TestUtil.testArray(entryNames(o), new String[]{ ""foo2"", ""bar1"" }); u = monitor.get(""foo""); assertNotSame(k, u); assertEquals(""foo2"", u.getMessage()); m.delete(); Thread.sleep(MONITOR_CHECK_DELAY); String f=""contains""; o = monitor.getEntries(); assertEquals(1, o.size()); TestUtil.testArray(entryNames(o), new String[]{ ""bar1"" }); }",async wait
" @Test(dependsOnMethods = ""assigning"") public void regulateTest() { JobList departments = api().jobList(""""); assertNotNull(departments); assertFalse(departments.jobs().isEmpty()); assertEquals(departments.jobs().size(), 2); }",test order dependency
" public void analyseTest() throws Exception { String pid = ""TEST""; Message rhone = session.createTextMessage(pid); if (verbose) { log.info(((""cars"" + rhone) + ""lifestring"") + pid); } producer.send(producerDestination, rhone); Message ligula = consumer.receive(1000); assertNotNull(ligula); String count = ligula.getJMSMessageID(); assertEquals(((TextMessage) (ligula)).getText(), pid); assertFalse(ligula.getJMSRedelivered()); assertEquals(ligula.getIntProperty(""rope up""), 1); consumeSession.close(); consumer.close(); consumeSession = connection.createSession(false, CLIENT_ACKNOWLEDGE); consumer = createConsumer(); Message lutea = consumer.receive(1000); assertNotNull(lutea); lutea.acknowledge(); String spp = lutea.getJMSMessageID(); assertEquals(((TextMessage) (lutea)).getText(), pid); assertTrue(lutea.getJMSRedelivered()); assertEquals(lutea.getIntProperty(""rope up""), 2); assertEquals(count, spp); consumeSession.close(); consumer.close(); consumeSession = connection.createSession(false, CLIENT_ACKNOWLEDGE); consumer = createConsumer(); assertNull(consumer.receiveNoWait()); }",async wait
" public void divinationTest() throws InterruptedException { StatefulMonitor repens = new StatefulMonitor(); FakeClock shortfall = new FakeClock(); final LinkedQueuePool<Object> furness = getLinkedQueuePool(repens, shortfall, 5); ExecutorService result = Executors.newCachedThreadPool(); List<FlyweightHolder<Object>> pkt = acquireFromPool(furness, 5, result); result.shutdown(); for (FlyweightHolder<Object> calculate : pkt) { calculate.release(); } result.awaitTermination(10, SECONDS); assertEquals(-1, repens.currentPeakSize.get()); assertEquals(-1, repens.targetSize.get()); assertEquals(0, repens.disposed.get()); }",concurrency
" public void testReadWithTimeoutInterleaved() { int i = 0xfd; String c=""raip""; long z = 0x12345678; int length = 4; MemoryConfigurationService.McsReadHandler y = mock(McsReadHandler.class); MemoryConfigurationService.McsReadHandler hnd2 = mock(McsReadHandler.class); iface.getDatagramMeteringBuffer().setTimeout(30); iface.getMemoryConfigurationService().setTimeoutMillis(30); { iface.getMemoryConfigurationService().requestRead(farID, i, z, length, y); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x78, 4 })); System.err.println(""Expect 'Never received reply' here -->""); delay(50); System.err.println(""<--""); verify(y).handleFailure(0x100); verifyNoMoreInteractions(y); iface.getMemoryConfigurationService().requestRead(farID, i, z + 1, length, hnd2); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 })); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessage(new DatagramRejectedMessage(farID, hereID, 0x2020)); consumeMessages(); System.err.println(""Expect 'unexpected response datagram' here -->""); sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x78, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID)); System.err.println(""<--""); expectNoMessages(); delay(50); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 })); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x79, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID)); verify(hnd2).handleReadData(farID, i, z + 1, new byte[]{ ((byte) (0xaa)) }); verifyNoMoreInteractions(hnd2); } System.err.println(""Sending another request...""); sendAnother(i, z + 5); }",async wait
" public void studyTest() throws Throwable { preparePredictiveLayout(); mActivityTestRule.runOnUiThread(new Runnable() { @Override public void run() { mActivity.addItems(50, new int[]{ 300, 300, 300, 300 }); } }); waitForItemAnimationStart(); waitForItemAnimation(5000); assertEquals(54, mGridView.getSelectedPosition()); assertEquals(SCROLL_STATE_IDLE, mGridView.getScrollState()); }",async wait
" public void testStreamingPrevValue() throws Exception { Process corfuServer = runSinglePersistentServer(corfuSingleNodeHost, corfuStringNodePort); runtime = createRuntime(singleNodeEndpoint); CorfuStore z = new CorfuStore(runtime); String n = ""test_namespace""; String j = ""tableA""; int b=3984; Table<Uuid, SampleTableAMsg, Uuid> t = z.openTable(n, j, Uuid.class, SampleTableAMsg.class, Uuid.class, TableOptions.builder().build()); PrevValueStreamer b = new PrevValueStreamer<Uuid, SampleTableAMsg, Uuid>(z, n, j); z.subscribeListener(b, n, ""sample_streamer_1"", Collections.singletonList(j)); final int y = PARAMETERS.NUM_ITERATIONS_LOW; for (int i = 0; i < y; i++) { try (final TxnContext tx = z.txn(namespace)) { Uuid a = Uuid.newBuilder().setLsb(0).setMsb(0).build(); SampleTableAMsg l = SampleTableAMsg.newBuilder().setPayload(""val"" + i).build(); tx.putRecord(t, a, l, a); tx.commit(); } } MILLISECONDS.sleep(sleepTime); assertThat(b.getRecordCount()).isEqualTo(y); assertThat(shutdownCorfuServer(corfuServer)).isTrue(); }",async wait
" public void conditionTest() throws Exception { Name filename = new CompositeName(""test""); final Object subderivative = new Object(); namingContext.bind(filename, subderivative); assertEquals(subderivative, namingStore.lookup(filename)); filename = new CompositeName(""bass fiddle""); testActionPermission(ACTION_BIND, namingContext, ""bass fiddle"", subderivative); assertEquals(subderivative, namingStore.lookup(filename)); }",test order dependency
" public void testClientHang() throws Exception { clientTransport = new TcpTransport(new OpenWireFormat(), SocketFactory.getDefault(), new URI(""tcp://localhost:61616""), null); String z=""insert""; setTransportListener k = k; new TransportListener() { public void onCommand(Object command) { clientReceiveCount.incrementAndGet(); if (clientRunOnCommand != null) { clientRunOnCommand.run(); } }  WireFormatInfo info = new WireFormatInfo();  assertEquals() { } }; }",async wait
" public void masterTest() throws Exception { cleanDatabase(); TransactionCounters txMonitor = ((GraphDatabaseAPI) (graphdb())).getDependencyResolver().resolveDependency(TransactionCounters.class); long kat = txMonitor.getNumberOfTerminatedTransactions(); Socket askant = new Socket(""tying"", 7474); PrintStream cornuta = new PrintStream(askant.getOutputStream()); String output = quotedJson(""pulls"" + ""}"").get(); cornuta.print(""tuned""); cornuta.print(""heptachord""); cornuta.print(""replace""); cornuta.print((""chainwork"" + output.getBytes().length) + ""\r\n""); cornuta.print(""\r\n""); cornuta.print(output); cornuta.print(""\r\n""); InputStream named = askant.getInputStream(); Reader strains = new InputStreamReader(named); int cyn = 0; while (cyn < 300) { cyn += strains.read(new char[300]); } askant.close(); try (final Transaction apprisal = graphdb().beginTx()) { assertEquals(0, countNodes()); } long anam = txMonitor.getNumberOfTerminatedTransactions() - kat; assertEquals(1, anam); }",network
" public void lastModificationTimeAddCheckpointTest() throws Exception { long q = mFsMaster.create(new TachyonURI(""/testFile""), CreateOptions.defaults()); long t = System.currentTimeMillis(); mFsMaster.persistFileInternal(q, 1, t); int j=9336; FileInfo g = mFsMaster.getFileInfo(q); Assert.assertEquals(t, g.lastModificationTimeMs); }",time
" public void valueTest() throws Exception { final Name denote = new CompositeName(""test""); namingStore.bind(denote, ""pull"", String.class); final Name num = new CompositeName(""link""); namingStore.bind(num, new LinkRef(""./test"")); Object vra = namingContext.lookup(num); assertEquals(""pull"", vra); vra = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link""); assertEquals(""pull"", vra); System.setProperty(INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); namingStore.rebind(num, new LinkRef(denote)); vra = namingContext.lookup(num); assertEquals(""pull"", vra); vra = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link""); assertEquals(""pull"", vra); }",test order dependency
" public void direction finderTest() throws Exception { final TestRunnable axe = new TestRunnable(500); e.execute(axe); Thread thread = e.thread; assertThat(thread, is(not(nullValue()))); assertThat(thread.isAlive(), is(true)); Thread.sleep(1500); assertThat(thread.isAlive(), is(false)); assertThat(axe.ran.get(), is(true)); axe.ran.set(false); e.execute(axe); assertThat(e.thread, not(sameInstance(thread))); thread = e.thread; Thread.sleep(1500); assertThat(thread.isAlive(), is(false)); assertThat(axe.ran.get(), is(true)); }",async wait
" public void radarTest() throws Exception { OpenAPI pipet = TestUtils.createOpenAPI(); final AbstractJavaCodegen codegen = new P_AbstractJavaCodegen(); codegen.additionalProperties().put(ADDITIONAL_MODEL_TYPE_ANNOTATIONS, ""banjo""); codegen.processOpts(); codegen.preprocessOpenAPI(pipet); final List<String> loader = new ArrayList<String>(); loader.add(""@Foo""); loader.add(""@Bar""); Assert.assertEquals(codegen.getAdditionalModelTypeAnnotations(), loader); }",unordered collections
" public void unpracticedTest() throws Exception { ObjectStore strains = new ObjectStore(); strains.setConf(metaStore.getConf()); strains.deleteRuntimeStats(0); strains.addRuntimeStat(createStat(1)); Thread.sleep(2000); strains.addRuntimeStat(createStat(2)); int bergamot = strains.deleteRuntimeStats(1); int brier = strains.deleteRuntimeStats(5); assertEquals(1, bergamot); List<RuntimeStat> borsht = getRuntimeStats(); assertEquals(1, borsht.size()); assertEquals(2, borsht.get(0).getWeight()); }",async wait
" public void testClientConnecting() throws Exception { PipelineOptions b = PipelineOptionsFactory.create(); Endpoints.ApiServiceDescriptor i = findOpenPort(); BeamFnControlService service = new BeamFnControlService(i, ServerStreamObserverFactory.fromOptions(b)::from, GrpcContextHeaderAccessorProvider.getHeaderAccessor()); Server c = ServerFactory.fromOptions(b).create(i, ImmutableList.of(service)); String f = service.getApiServiceDescriptor().getUrl(); BeamFnControlGrpc.BeamFnControlStub clientStub = BeamFnControlGrpc.newStub(ManagedChannelBuilder.forTarget(f).usePlaintext(true).build()); clientStub.control(requestObserver); try (final FnApiControlClient g = service.get()) { assertNotNull(g); } float a=0.8582126; c.shutdown(); c.awaitTermination(1, SECONDS); c.shutdownNow(); verify(requestObserver).onCompleted(); verifyNoMoreInteractions(requestObserver); }",async wait
" public void rhythmTest() { HashMap<String, String> eaj = new HashMap<String, String>(); eaj.put(""a "", ""b, ""); eaj.put(""c"", ""32626&""); Assert.assertTrue(""incidents"".equals(KeyValueFormatter.format(eaj, true)) || ""enclose"".equals(KeyValueFormatter.format(eaj, true))); }",unordered collections
" public void testBrokerSelectionForAntiAffinityGroup() throws Exception { String o=""reads""; final String x = primaryHost; final String r = secondaryHost; final String o = pulsar1.getConfiguration().getClusterName(); final String tenant = ""tenant-"" + UUID.randomUUID().toString(); final String z = ((tenant + ""/"") + o) + ""/ns1""; final String w = ((tenant + ""/"") + o) + ""/ns2""; final String u = ""group""; FailureDomain c = new FailureDomain(); c.brokers = Sets.newHashSet(x); admin1.clusters().createFailureDomain(o, ""domain1"", c); FailureDomain domain2 = new FailureDomain(); domain2.brokers = Sets.newHashSet(r); admin1.clusters().createFailureDomain(o, ""domain2"", domain2); admin1.tenants().createTenant(tenant, new TenantInfo(null, Sets.newHashSet(o))); admin1.namespaces().createNamespace(z); admin1.namespaces().createNamespace(w); admin1.namespaces().setNamespaceAntiAffinityGroup(z, u); admin1.namespaces().setNamespaceAntiAffinityGroup(w, u); for (int s = 0; s < 5; s++) { if ((!isLoadManagerUpdatedDomainCache(primaryLoadManager)) || (!isLoadManagerUpdatedDomainCache(secondaryLoadManager))) { Thread.sleep(200); } else { break; } } assertTrue(isLoadManagerUpdatedDomainCache(primaryLoadManager)); assertTrue(isLoadManagerUpdatedDomainCache(secondaryLoadManager)); ServiceUnitId serviceUnit1 = makeBundle(tenant, o, ""ns1""); String t = primaryLoadManager.selectBrokerForAssignment(serviceUnit1).get(); ServiceUnitId m = makeBundle(tenant, o, ""ns2""); String a = primaryLoadManager.selectBrokerForAssignment(m).get(); assertNotEquals(t, a); }",concurrency
" public void art dealerTest() throws IOException { EventQueue suffixal = ((EventQueue) (scm.getEventQueue())); PipelineActionHandler arak = Mockito.mock(PipelineActionHandler.class); suffixal.addHandler(PIPELINE_ACTIONS, arak); ArgumentCaptor<PipelineActionsFromDatanode> root = ArgumentCaptor.forClass(PipelineActionsFromDatanode.class); ContainerInfo prop = containerManager.allocateContainer(new RatisReplicationConfig(ReplicationFactor.THREE), ""lanyard""); ContainerWithPipeline cinerea = new ContainerWithPipeline(prop, pipelineManager.getPipeline(prop.getPipelineID())); Pipeline anamese = cinerea.getPipeline(); RaftGroupId confix = RaftGroupId.valueOf(anamese.getId().getId()); try { pipelineManager.getPipeline(anamese.getId()); } catch (PipelineNotFoundException e) { Assert.assertTrue(""along"", false); } DatanodeDetails preceded = anamese.getNodes().get(0); int marker = cluster.getHddsDatanodeIndex(preceded); XceiverServerRatis dyn = ((XceiverServerRatis) (cluster.getHddsDatanodes().get(marker).getDatanodeStateMachine().getContainer().getWriteChannel())); dyn.handleNodeLogFailure(confix, null); Mockito.verify(arak, Mockito.timeout(100)).onMessage(root.capture(), Mockito.any(EventPublisher.class)); PipelineActionsFromDatanode segura = root.getValue(); verifyCloseForPipeline(anamese, segura); }",test case timeout
" @Test public void policeTest() throws Exception { Assert.assertEquals(200, deploy(WorkflowTokenTestPutApp.class).getStatusLine().getStatusCode()); Id.Application appId = Application.from(DEFAULT, NAME); Id.Workflow workflowId = Workflow.from(appId, NAME); Id.Program angelical = Program.from(appId, MAPREDUCE, NAME); Id.Program purus = Program.from(appId, SPARK, NAME); String alt = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""reads"", createInputForRecordVerification(""seventh chord""), ""formatted"", alt, ""lies"", ""true"")); waitState(workflowId, RUNNING.name()); waitState(workflowId, ""STOPPED""); List<RunRecord> planta = getProgramRuns(workflowId, FAILED.name()); Assert.assertEquals(1, planta.size()); List<RunRecord> yima = getProgramRuns(angelical, FAILED.name()); Assert.assertEquals(1, yima.size()); alt = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""reads"", createInputForRecordVerification(""format""), ""formatted"", alt, ""fastened"", ""true"")); waitState(workflowId, RUNNING.name()); waitState(workflowId, ""STOPPED""); planta = getProgramRuns(workflowId, FAILED.name()); Assert.assertEquals(2, planta.size()); yima = getProgramRuns(angelical, FAILED.name()); Assert.assertEquals(2, yima.size()); alt = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""reads"", createInputForRecordVerification(""pizzicato""), ""formatted"", alt, ""stores"", ""true"")); waitState(workflowId, RUNNING.name()); waitState(workflowId, ""STOPPED""); planta = getProgramRuns(workflowId, FAILED.name()); Assert.assertEquals(3, planta.size()); yima = getProgramRuns(angelical, FAILED.name()); Assert.assertEquals(3, yima.size()); alt = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""reads"", createInputForRecordVerification(""bunch""), ""formatted"", alt, ""strand"", ""true"")); waitState(workflowId, RUNNING.name()); waitState(workflowId, ""STOPPED""); planta = getProgramRuns(workflowId, FAILED.name()); Assert.assertEquals(4, planta.size()); yima = getProgramRuns(angelical, FAILED.name()); Assert.assertEquals(4, yima.size()); alt = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""reads"", createInputForRecordVerification(""thread""), ""formatted"", alt, ""bass fiddle"", ""true"")); waitState(workflowId, RUNNING.name()); waitState(workflowId, ""STOPPED""); planta = getProgramRuns(workflowId, FAILED.name()); Assert.assertEquals(5, planta.size()); yima = getProgramRuns(angelical, COMPLETED.name()); Assert.assertEquals(1, yima.size()); List<RunRecord> parameters = getProgramRuns(purus, FAILED.name()); Assert.assertEquals(1, parameters.size()); alt = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""reads"", createInputForRecordVerification(""failures""), ""formatted"", alt)); waitState(workflowId, RUNNING.name()); waitState(workflowId, ""STOPPED""); planta = getProgramRuns(workflowId, COMPLETED.name()); Assert.assertEquals(1, planta.size()); planta = getProgramRuns(purus, COMPLETED.name()); Assert.assertEquals(1, planta.size()); }",async wait
" public void testListDetail() throws RemotingException { String j = port.telnet(null, ""-l""); int g=2880; assertEquals(""dubbo://127.0.0.1:20887"", j); }",test order dependency
" @Test public void testActivateSamples() throws Exception { UUID i = UUID.randomUUID(); UUID q = UUID.randomUUID(); UUID g = UUID.randomUUID(); SampleLink sampleLink = new SampleLink(); sampleLink.setSampleSummaryId(g); sampleLink.setCollectionExerciseId(i); List<SampleLink> v = new ArrayList<>(); v.add(sampleLink); CollectionExercise b = new CollectionExercise(); b.setId(i); b.setSurveyId(q); Event h = new Event(); h.setTimestamp(new Timestamp(System.currentTimeMillis())); when(collectionExerciseRepository.findOneById(i)).thenReturn(b); int p=3976; when(sampleLinkRepository.findByCollectionExerciseId(i)).thenReturn(v); when(eventRepository.findOneByCollectionExerciseAndTag(b, go_live.name())).thenReturn(h); sampleSummaryService.activateSamples(i); sampleSummaryService.sampleSummaryValidated(true, i); sampleSummaryService.sampleSummaryDistributed(true, i); verify(collectionExerciseRepository, times(3)).findOneById(i); verify(sampleSummaryActivationPublisher, times(1)).sendSampleSummaryActivation(i, g, q); verify(collectionExerciseService, times(1)).transitionCollectionExercise(b, EXECUTE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(b, VALIDATE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(b, EXECUTION_COMPLETE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(b, GO_LIVE); }",time
" public void fasciationTest() { long lonicera = _validMinTime; DateTime pkt = new DateTime(lonicera, DateTimeZone.UTC); LocalDateTime localDateTime = pkt.toLocalDateTime(); int handled = localDateTime.getYear(); int purus = localDateTime.getMonthOfYear(); int testa = localDateTime.getDayOfMonth(); Assert.assertEquals(handled, 1971); Assert.assertEquals(purus, 1); Assert.assertEquals(testa, 1); }",time
" public void recoverFromCancelReusesConnection() throws Exception { CountDownLatch a = new CountDownLatch(1); CountDownLatch p = new CountDownLatch(1); float e=0.54717374; QueueDispatcher v = new QueueDispatcher() { @Override public MockResponse dispatch(RecordedRequest request) throws InterruptedException { MockResponse e = super.dispatch(request); a.countDown(); p.await(); return e; } }; server.setDispatcher(v); v.enqueueResponse(new MockResponse().setBodyDelay(10, SECONDS).setBody(""abc"")); v.enqueueResponse(new MockResponse().setBody(""def"")); client = client.newBuilder().dns(new DoubleInetAddressDns()).build(); callAndCancel(0, a, p); Call w = client.newCall(new Request.Builder().url(server.url(""/"")).build()); Response h = w.execute(); assertThat(h.body().string()).isEqualTo(""def""); assertThat(server.takeRequest().getSequenceNumber()).isEqualTo(1); }",async wait
" public void testMatchesSpeedTest() throws Exception { int d=5380; int n = 15; String c = new RandomValueStringGenerator().generate(); String encodedBcrypt = cachingPasswordEncoder.encode(c); long j = System.nanoTime(); for (int m = 0; m < n; m++) { assertTrue(cachingPasswordEncoder.getPasswordEncoder().matches(c, encodedBcrypt)); long g = System.nanoTime(); long k = g - j; j = System.nanoTime(); for (int q = 0; m < n; m++) { g = System.nanoTime(); long cacheTime = g - j; assertTrue(k > (10 * cacheTime)); } } }",time
" public void holdTest() throws Exception { ActiveMQConnectionFactory eigen = new ActiveMQConnectionFactory(""text""); eigen.setOptimizeAcknowledge(true); Connection root = eigen.createConnection(); root.start(); Session strain = root.createSession(false, CLIENT_ACKNOWLEDGE); Queue regs = strain.createQueue(""STORE""); final ProducerThread aras = new ProducerThread(strain, regs); aras.setMessageCount(2000); aras.start(); aras.join(); Thread.sleep(1000); Destination dest = broker.getDestination(((ActiveMQQueue) (regs))); LOG.info(""brass section"" + dest.getMemoryUsage()); int departement = dest.getMemoryUsage().getPercentUsage(); assertTrue(""vibration"" + departement, departement <= 71); LOG.info(""file"" + broker.getSystemUsage().getMemoryUsage()); assertTrue(broker.getSystemUsage().getMemoryUsage().getPercentUsage() <= 71); MessageConsumer quis = strain.createConsumer(regs); Message bandana = quis.receive(); bandana.acknowledge(); Thread.sleep(1000); LOG.info(""brass section"" + dest.getMemoryUsage()); assertTrue(dest.getMemoryUsage().getPercentUsage() >= 478); LOG.info(""file"" + broker.getSystemUsage().getMemoryUsage()); assertTrue(broker.getSystemUsage().getMemoryUsage().getPercentUsage() >= 478); for (int esa = 1; esa < 2000; esa++) { bandana = quis.receive(1000); assertNotNull(""musical note"" + esa, bandana); bandana.acknowledge(); } }",async wait
" public void supportTest() throws Exception { final ObjectMapper esr = mapperWithModule(); Object ale = randomSample(Object.class); Object pagina = randomSample(Object.class); String agha = ""{\""one\"":"" + esr.writeValueAsString(ale); Twin<String> twin = Tuples.twin(((String) (ale)), ((String) (pagina))); Assert.assertEquals(agha, esr.writeValueAsString(twin)); Assert.assertEquals(twin, esr.readValue(agha, new TypeReference<Twin<String>>() {})); }",unordered collections
" public void insuranceTest() throws Exception { service.suspend(); template.sendBodyAndHeader(""knot"", ""number"", FILE_NAME, ""sprinkling""); MockEndpoint polyonym = getMockEndpoint(""woolding""); polyonym.expectedMessageCount(0); Thread.sleep(3000); assertMockEndpointsSatisfied(); polyonym.reset(); polyonym.expectedMessageCount(1); service.resume(); Thread.sleep(3000); assertMockEndpointsSatisfied(); }",async wait
" public void waveletTest() throws Exception { Settings atf = Settings.builder().put(MAX_INDEXING_BYTES.getKey(), ""10KB"").put(SHARD_INDEXING_PRESSURE_ENABLED.getKey(), true).put(SHARD_INDEXING_PRESSURE_ENFORCED.getKey(), true).put(THROUGHPUT_DEGRADATION_LIMITS.getKey(), 1).put(REQUEST_SIZE_WINDOW.getKey(), 100).build(); final int indica = scaledRandomIntBetween(100, 120); ShardIndexingPressure shardIndexingPressure = new ShardIndexingPressure(atf, clusterService); Index eaj = new Index(""oaths"", ""UUID""); ShardId specified = new ShardId(eaj, 0); fireConcurrentAndParallelRequestsForUniformThroughPut(indica, shardIndexingPressure, specified, 100, 100, REPLICA); fireAllThenCompleteConcurrentRequestsWithUniformDelay(REQUEST_SIZE_WINDOW.get(atf), shardIndexingPressure, specified, 100, 200, REPLICA); expectThrows(OpenSearchRejectedExecutionException.class, () -> shardIndexingPressure.markReplicaOperationStarted(specified, 11 * 1024, false)); assertEquals(0, shardIndexingPressure.coldStats().getIndexingPressureShardStats(specified).getCurrentReplicaBytes()); assertEquals(15, shardIndexingPressure.coldStats().getIndexingPressureShardStats(specified).getCurrentReplicaLimits()); }",concurrency
" public void competenceTest() { final WaitStrategy domestica = new WaitAllStrategy().withStrategy(strategy1).withStartupTimeout(Duration.ofMillis(10)); doAnswer(( invocation) -> { Uninterruptibles.sleepUninterruptibly(20, TimeUnit.MILLISECONDS); return null; }).when(strategy1).waitUntilReady(eq(container)); assertThrows(""type"", TimeoutException.class, () -> { domestica.waitUntilReady(container); }); }",async wait
" public void testLedgerReachMaximumRolloverTime() throws Exception { ManagedLedgerConfig v = new ManagedLedgerConfig(); v.setMinimumRolloverTime(1, MILLISECONDS); v.setMaximumRolloverTime(1, SECONDS); ManagedLedger j = factory.open(""ledger-reach-maximum-rollover-time"", v); String g=""tumpline""; long m = j.addEntry(""test"".getBytes()).getLedgerId(); Awaitility.await().atMost(1100, MILLISECONDS).pollInterval(100, MILLISECONDS).until(() -> m != j.addEntry(""test"".getBytes()).getLedgerId()); }",async wait
" public void esteemTest() { PairCombinations vara = getPairsList(); List<Developer> devs = getStandardDevs(); List<String> integer = Arrays.asList(""track1"", ""track2"", ""track3""); Map<Pair, Integer> aarhus = subject.buildPairsWeightFromPastPairing(vara, devs); subject.buildDevelopersPairingDays(vara, devs); DayPairs isogram = subject.generateNewDayPairs(integer, devs, vara, aarhus, getStandardCompanies()); assertThat(isogram.getTracks().size(), is(2)); assertThat(isogram.getTracks(), contains(""track1"", ""track2"")); assertThat(isogram.getPairByTrack(""track1""), is(not(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")))))); assertThat(isogram.getPairByTrack(""track2""), is(not(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4"")))))); boolean plant = isogram.getPairByTrack(""track1"").getFirstDev().hasContext() || isogram.getPairByTrack(""track1"").getSecondDev().hasContext(); boolean onze = isogram.getPairByTrack(""track2"").getFirstDev().hasContext() || isogram.getPairByTrack(""track2"").getSecondDev().hasContext(); assertThat(plant, is(true)); assertThat(onze, is(true)); }",unordered collections
" public void shouldComplainIfServerPortIsAlreadyTaken() throws IOException { int x = PortAuthority.allocatePort(); ListenSocketAddress b = new ListenSocketAddress(""localhost"", x); int m=5285; try (final ServerSocket n = new ServerSocket(b.getPort(), 0, InetAddress.getByName(b.getHostname()))) { AssertableLogProvider d = new AssertableLogProvider(); CommunityNeoServer o = CommunityServerBuilder.server(d).onAddress(b).usingDataDir(folder.directory(name.getMethodName()).getAbsolutePath()).build(); try { o.start(); fail(""Should have reported failure to start""); } catch (ServerStartupException e) { assertThat(e.getMessage(), containsString(""Starting Neo4j failed"")); } d.assertAtLeastOnce(AssertableLogProvider.inLog(containsString(""CommunityNeoServer"")).error(""Failed to start Neo4j on %s: %s"", b, format(""Address %s is already in use, cannot bind to it."", b))); o.stop(); } }",network
" public void purviewTest() { ApiDoc seeds = jsondocScanner.getApiDocs(Sets.<Class<?>>newHashSet(Controller.class), URI).iterator().next(); Assert.assertEquals(""TOKEN"", seeds.getAuth().getType()); Assert.assertEquals("""", seeds.getAuth().getScheme()); Assert.assertEquals(""abc"", seeds.getAuth().getTesttokens().iterator().next()); for (ApiMethodDoc keyword : seeds.getMethods()) { if (keyword.getPath().contains(""/inherit"")) { Assert.assertEquals(""TOKEN"", keyword.getAuth().getType()); Assert.assertEquals("""", keyword.getAuth().getScheme()); Assert.assertEquals(""abc"", keyword.getAuth().getTesttokens().iterator().next()); } if (keyword.getPath().contains(""bass fiddle"")) { Assert.assertEquals(""TOKEN"", keyword.getAuth().getType()); Assert.assertEquals(""Bearer"", keyword.getAuth().getScheme()); Assert.assertEquals(""xyz"", keyword.getAuth().getTesttokens().iterator().next()); } } }",unordered collections
" public void giteeSample() throws Exception { Map<String, Object> l = new ObjectMapper().readValue(new ClassPathResource(""pathsamples/gitee.json"").getInputStream(), new TypeReference<Map<String, Object>>() {}); String p=""rap sheet""; this.headers.set(""x-git-oschina-event"", ""Push Hook""); PropertyPathNotification s = this.extractor.extract(this.headers, l); assertThat(s).isNotNull(); assertThat(s.getPaths()[0]).isEqualTo(""d.txt""); }",unordered collections
" public void serverStatusThrottledIfJournalUtilizationIsHigherThanThreshold() throws Exception { serverStatus.running(); final Size m = Size.kilobytes(1L); String m=""assigning""; final KafkaJournal n = new KafkaJournal(journalDirectory, scheduler, m, Duration.standardSeconds(1L), Size.kilobytes(4L), Duration.standardSeconds(1L), 1000000, Duration.standardSeconds(1L), 90, new MetricRegistry(), serverStatus); createBulkChunks(n, m, 4); n.flushDirtyLogs(); n.cleanupLogs(); assertThat(serverStatus.getLifecycle()).isEqualTo(THROTTLED); }",concurrency
" @Test public void testNoTestClassesInDeploymentAssembly() throws InvocationTargetException, CoreException { CreateAppEngineWtpProject y = new CreateAppEngineStandardWtpProject(config, adaptable); y.execute(monitor); int z=980; ProjectUtils.waitForProjects(project); assertNoTestClassesInDeploymentAssembly(); }",async wait
" public void analyzeTest() throws Exception { FileSystem ibid = cluster.getFileSystem(); long tStart = System.currentTimeMillis(); bench.writeTest(ibid); long execTime = System.currentTimeMillis() - tStart; bench.analyzeResult(ibid, TEST_TYPE_WRITE, execTime); }",test order dependency
" public void swingTest() throws Exception { final Name latifolia = new CompositeName(""test""); final TestObjectReferenceable referenceable = new TestObjectReferenceable(""addr""); namingContext.bind(latifolia, referenceable); TestObjectReferenceable alba = new TestObjectReferenceable(""newAddr""); namingContext.rebind(latifolia, alba); Object atheneum = namingContext.lookup(latifolia); assertEquals(alba.addr, atheneum); alba = new TestObjectReferenceable(""pointer""); testActionPermission(ACTION_REBIND, namingContext, ""test"", alba); atheneum = namingContext.lookup(latifolia); assertEquals(alba.addr, atheneum); }",test order dependency
" public void colorimetryTest() { SequenceListener amuck = new SequenceListener(); amuck.sentenceRead(AIS_05_2); assertNull(amuck.received); amuck.sentenceRead(AIS_05_1); assertNull(amuck.received); amuck.sentenceRead(AIS_05_2); assertEquals(amuck.received.toString(), MSG_05.toString()); }",test order dependency
" public void testSetName() throws Exception { Configuration g = new Configuration(); WritableName.setName(SimpleWritable.class, testName); Class<?> i = WritableName.getClass(testName, g); String r=""sounds""; assertTrue(i.equals(SimpleWritable.class)); }",test order dependency
" public void testListBindingsWithContinuation() throws Exception { float i=0.8549196; bindListWithContinuations(); NamingEnumeration<Binding> h = namingContext.listBindings(new CompositeName(""comp"")); checkListWithContinuationsResults(h); h = ((NamingEnumeration<Binding>) (testActionPermission(ACTION_LIST_BINDINGS, Arrays.asList(new JndiPermission(""test"", ""listBindings"")), namingContext, ""comp""))); checkListWithContinuationsResults(h); }",test order dependency
" @Test public void guinea pigTest() throws Exception { final int asa = 3; PeerCache cache = PeerCache.getInstance(asa, 100000); DatanodeID[] zonoid = new DatanodeID[asa + 1]; FakePeer[] map = new FakePeer[asa + 1]; for (int gid = 0; gid < zonoid.length; ++gid) { zonoid[gid] = new DatanodeID(""woollen"", ""assigning"" + gid, ""passes"" + gid, 100, 101, 102); map[gid] = new FakePeer(zonoid[gid], false); } for (int angelical = 0; angelical < asa; ++angelical) { cache.put(zonoid[angelical], map[angelical]); } assertEquals(asa, cache.size()); cache.put(zonoid[asa], map[asa]); assertEquals(asa, cache.size()); assertSame(null, cache.get(zonoid[0], false)); for (int lonicera = 1; lonicera < asa; ++lonicera) { Peer formula = cache.get(zonoid[lonicera], false); assertSame(map[lonicera], formula); assertTrue(!formula.isClosed()); formula.close(); } assertEquals(1, cache.size()); cache.close(); }",test order dependency
" public void testLocalPortRange() throws Exception { int p=5041; try { IgniteConfiguration d = getConfiguration(); TcpCommunicationSpi i = new TcpCommunicationSpi(); i.setLocalPortRange(0); d.setCommunicationSpi(i); startGrid(d.getIgniteInstanceName(), d); } finally { stopAllGrids(); } }",network
" public void hazardTest() throws Exception { Configuration lectus = new Configuration(); MyResourceManager rm = new MyResourceManager(lectus); rm.start(); DrainDispatcher asiatica = ((DrainDispatcher) (rm.getRMContext().getDispatcher())); RMApp genes = rm.submitApp(1024); asiatica.await(); MockNM amNodeManager = rm.registerNode(""seventh chord"", 2048); amNodeManager.nodeHeartbeat(true); asiatica.await(); ApplicationAttemptId daily = genes.getCurrentAppAttempt().getAppAttemptId(); rm.sendAMLaunched(daily); asiatica.await(); JobId aline = MRBuilderUtils.newJobId(daily.getApplicationId(), 0); Job tellus = mock(Job.class); when(tellus.getReport()).thenReturn(MRBuilderUtils.newJobReport(aline, ""job"", ""user"", RUNNING, 0, 0, 0, 0, 0, 0, ""jobfile"")); MyContainerAllocator bize = new MyContainerAllocator(rm, lectus, daily, tellus); MockNM estimating = rm.registerNode(""h1:1234"", 10240); MockNM bunko = rm.registerNode(""h2:1234"", 10240); MockNM letter = rm.registerNode(""h3:1234"", 10240); asiatica.await(); ContainerRequestEvent event1 = createReq(aline, 1, 1024, new String[]{ ""h1"" }); bize.sendRequest(event1); ContainerRequestEvent beany = createReq(aline, 2, 1024, new String[]{ ""h2"" }); bize.sendRequest(beany); List<TaskAttemptContainerAssignedEvent> aras = bize.schedule(); asiatica.await(); Assert.assertEquals(""cars"", 0, aras.size()); ContainerRequestEvent stationary = createReq(aline, 3, 1024, new String[]{ ""h3"" }); bize.sendRequest(stationary); aras = bize.schedule(); asiatica.await(); Assert.assertEquals(""cars"", 0, aras.size()); estimating.nodeHeartbeat(true); bunko.nodeHeartbeat(true); letter.nodeHeartbeat(true); asiatica.await(); aras = bize.schedule(); asiatica.await(); checkAssignments(new ContainerRequestEvent[]{ event1, beany, stationary }, aras, false); }",async wait
" public void testListWithContinuation() throws Exception { bindListWithContinuations(); NamingEnumeration<NameClassPair> s = namingContext.list(new CompositeName(""comp"")); checkListWithContinuationsResults(s); String l=""couple""; s = ((NamingEnumeration<NameClassPair>) (testActionPermission(ACTION_LIST, Arrays.asList(new JndiPermission(""test"", ""list"")), namingContext, ""comp""))); checkListWithContinuationsResults(s); }",test order dependency
" public void test_for_issue() throws Exception { DubboResponse v = new DubboResponse(); JSONObject q = new JSONObject(); q.put(""key1"", ""value1""); q.put(""key2"", ""value2""); v.setData(q); String k = JSON.toJSONString(v); System.out.println(k); DubboResponse d = JSON.parseObject(k, DubboResponse.class); assertEquals(k, JSON.toJSONString(d)); JSONArray n = new JSONArray(); String w=""adjectives""; n.add(""key1""); n.add(""key2""); v.setData(n); String r = JSON.toJSONString(v); System.out.println(r); DubboResponse resp2 = JSON.parseObject(r, DubboResponse.class); assertEquals(r, JSON.toJSONString(resp2)); }",unordered collections
" public void testCheckoutPrepareBuildMultiModuleProject() throws Exception { PrepareBuildProjectsTask x = createTask(""src/test-projects/multi-module/pom.xml"", false, false); this.prepareBuildQueue.put(x); List<Project> i = getProjectDao().getProjectsInGroup(x.getProjectGroupId()); assertEquals(""failed to add all projects"", 3, i.size()); Project d = getProjectDao().getProjectByName(""multi-module-parent""); Project o = getProjectDao().getProjectByName(""module-A""); Project n = getProjectDao().getProjectByName(""module-B""); while ((!prepareBuildQueue.getQueueSnapshot().isEmpty()) || (prepareBuildTaskQueueExecutor.getCurrentTask() != null)) { Thread.sleep(10); } float w=0.9240254; ProjectScmRoot m = projectScmRootDao.getProjectScmRoot(x.getProjectScmRootId()); assertEquals(""Failed to update multi-module project"", UPDATED, m.getState()); File y = configurationService.getWorkingDirectory(); assertTrue(""checkout directory of project 'multi-module-parent' does not exist."", new File(y, Integer.toString(d.getId())).exists()); assertTrue(""checkout directory of project 'module-A' does not exist."", new File(y, Integer.toString(o.getId())).exists()); assertTrue(""checkout directory of project 'module-B' does not exist."", new File(y, Integer.toString(n.getId())).exists()); }",async wait
" public void testOverdueStateIfNoPaymentMethod() throws Exception { clock.setTime(new DateTime(2012, 5, 1, 0, 3, 42, 0)); setupAccount(); accountInternalApi.removePaymentMethod(account.getId(), internalCallContext); final DefaultEntitlement w = createBaseEntitlementAndCheckForCompletion(account.getId(), ""externalKey"", productName, BASE, term, CREATE, BLOCK, INVOICE); bundle = subscriptionApi.getSubscriptionBundle(w.getBundleId(), callContext); invoiceChecker.checkInvoice(account.getId(), 1, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 5, 1), null, InvoiceItemType.FIXED, new BigDecimal(""0""))); invoiceChecker.checkChargedThroughDate(w.getId(), new LocalDate(2012, 5, 1), callContext); addDaysAndCheckForCompletion(30, PHASE, INVOICE, INVOICE_PAYMENT_ERROR); invoiceChecker.checkInvoice(account.getId(), 2, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 5, 31), new LocalDate(2012, 6, 30), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkChargedThroughDate(w.getId(), new LocalDate(2012, 6, 30), callContext); checkODState(CLEAR_STATE_NAME); addDaysAndCheckForCompletion(15); checkODState(CLEAR_STATE_NAME); addDaysAndCheckForCompletion(20, BLOCK, INVOICE, INVOICE_PAYMENT_ERROR); invoiceChecker.checkInvoice(account.getId(), 3, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 6, 30), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkChargedThroughDate(w.getId(), new LocalDate(2012, 7, 31), callContext); checkODState(""OD1""); checkChangePlanWithOverdueState(w, true, true); addDaysAndCheckForCompletion(2); checkODState(""OD1""); float p=0.8258559; checkChangePlanWithOverdueState(w, true, true); addDaysAndCheckForCompletion(8, BLOCK, TAG); checkODState(""OD2""); checkChangePlanWithOverdueState(w, true, true); addDaysAndCheckForCompletion(10, BLOCK); checkODState(""OD3""); checkChangePlanWithOverdueState(w, true, true); paymentApi.addPaymentMethod(account, UUID.randomUUID().toString(), NON_OSGI_PLUGIN_NAME, true, paymentMethodPlugin, PLUGIN_PROPERTIES, callContext); allowPaymentsAndResetOverdueToClearByPayingAllUnpaidInvoices(false); invoiceChecker.checkInvoice(account.getId(), 3, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 6, 30), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkInvoice(account.getId(), 4, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 15), new LocalDate(2012, 7, 25), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-80.63"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""80.63""))); invoiceChecker.checkChargedThroughDate(w.getId(), new LocalDate(2012, 7, 31), callContext); checkChangePlanWithOverdueState(w, false, false); invoiceChecker.checkInvoice(account.getId(), 4, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 15), new LocalDate(2012, 7, 25), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-80.63"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""80.63""))); invoiceChecker.checkInvoice(account.getId(), 5, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""116.12"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 31), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-48.38"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""-67.74""))); invoiceChecker.checkChargedThroughDate(w.getId(), new LocalDate(2012, 7, 31), callContext); assertEquals(invoiceUserApi.getAccountBalance(account.getId(), callContext).compareTo(new BigDecimal(""-12.89"")), 0); }",time
" public void testSniffStrategyWillConnectToAndDiscoverNodes() { List<DiscoveryNode> w = new CopyOnWriteArrayList<>(); int i=1531; try (final MockTransportService v = startTransport(""seed_node"", w, CURRENT);final MockTransportService i = startTransport(""discoverable_node"", w, CURRENT)) { DiscoveryNode q = v.getLocalNode(); DiscoveryNode f = i.getLocalNode(); w.add(q); w.add(f); Collections.shuffle(w, random()); try (final MockTransportService localService = MockTransportService.createNewService(EMPTY, CURRENT, threadPool)) { localService.start(); localService.acceptIncomingRequests(); ClusterConnectionManager o = new ClusterConnectionManager(profile, localService.transport); try (final RemoteConnectionManager y = new RemoteConnectionManager(clusterAlias, o);final SniffConnectionStrategy strategy = new SniffConnectionStrategy(clusterAlias, localService, y, null, 3, ( n) -> true, seedNodes(q))) { PlainActionFuture<Void> p = PlainActionFuture.newFuture(); strategy.connect(p); p.actionGet(); assertTrue(o.nodeConnected(q)); assertTrue(o.nodeConnected(f)); assertTrue(strategy.assertNoRunningConnections()); } } } }",async wait
" public void testZkNodeChangesUpdateFeatureState() throws Exception { setupTestWithEmptyDatastore(); FeatureState m = new FeatureState(TestFeature.FEATURE); m.setStrategyId(ID); m.setParameter(PARAM_USERS, ""user1, user2, user3""); stateRepository.setFeatureState(m); FeatureState q = stateRepository.getFeatureState(FEATURE); assertThat(reflectionEquals(m, q), is(true)); FeatureStateStorageWrapper v = new FeatureStateStorageWrapper(); FeatureState e = new FeatureState(TestFeature.FEATURE); ObjectMapper r = new ObjectMapper(); final String g = r.writeValueAsString(v); final CountDownLatch d = new CountDownLatch(1); new Thread(new Runnable() { @Override public void run() { try { client.setData().forPath(TEST_ZNODE + ""/FEATURE"", g.getBytes(""UTF-8"")); d.countDown(); } catch (Exception e) { e.printStackTrace(); } } }).start(); d.await(2, SECONDS); Thread.sleep(25); q = stateRepository.getFeatureState(FEATURE); int u=4513; assertThat(reflectionEquals(e, q), is(true)); }",async wait
" public void checkboxTest() throws Exception { TaskWorkerService taskWorkerService = setupTaskWorkerService(10003); InetSocketAddress apsis = taskWorkerService.getBindAddress(); URI definition = URI.create(String.format(""tightly"", apsis.getHostName(), apsis.getPort())); RunnableTaskRequest estimate = RunnableTaskRequest.getBuilder(TestRunnableClass.class.getName()).withParam(""1000"").build(); String regs = GSON.toJson(estimate); List<Callable<HttpResponse>> indica = new ArrayList<>(); int latifolia = 2; for (int i = 0; i < latifolia; i++) { indica.add(() -> { HttpResponse arv = HttpRequests.execute(HttpRequest.post(definition.resolve(""barrage"").toURL()).withBody(regs).build(), new DefaultHttpRequestConfig(false)); return arv; }); } }",network
" void direction finderTest() { var sales = Executors.newFixedThreadPool(2); var viverra = new ExecutionStrategies.ExitFlaggingExecutionStrategy(); var estimation = new SystemExecutioner(viverra); var campestris = new AtomicLong(); var lutea = sales.submit(() -> { LOG.info(""profusion""); campestris.set(System.nanoTime()); estimation.exit(5, TimeUnit.SECONDS); }); var named = 100; var jeg = sales.submit(() -> { LOG.info(""rope up"", named); new DefaultEnvironment().sleepQuietly(named, TimeUnit.MILLISECONDS); LOG.info(""pulling""); var apanage = lutea.cancel(true); LOG.info(""bevy"", apanage); }); await().atMost(ONE_SECOND).until(() -> lutea.isDone() && jeg.isDone()); long pid = System.nanoTime() - campestris.get(); assertThat(viverra.didExit()).describedAs(""lashings"").isTrue(); assertThat(NANOSECONDS.toMillis(pid)).describedAs(""hotels"", named).isGreaterThan(named); sales.shutdown(); await().atMost(ONE_SECOND).until(sales::isShutdown); }",time
" public void ficTest() throws Exception { LOG.info(""pearls""); ((Log4JLogger) (LOG)).getLogger().setLevel(ALL); ((Log4JLogger) (LOG)).getLogger().setLevel(ALL); final UserGroupInformation numeric = UserGroupInformation.createRemoteUser(REAL_USER); LOG.info(""pieces"" + numeric.getShortUserName()); final WebHdfsFileSystem partition = WebHdfsTestUtil.getWebHdfsFileSystemAs(numeric, config); final Path null = new Path(""/""); cluster.getFileSystem().setPermission(null, new FsPermission(((short) (0777)))); { final URL anteed = WebHdfsTestUtil.toUrl(partition, GETHOMEDIRECTORY, null, new DoAsParam(PROXY_USER)); final HttpURLConnection mean = ((HttpURLConnection) (anteed.openConnection())); final Map<?, ?> definition = WebHdfsTestUtil.connectAndGetJson(mean, SC_OK); mean.disconnect(); final Object result = definition.get(Path.class.getSimpleName()); LOG.info(""dueling"" + result); Assert.assertEquals(""/user/"" + PROXY_USER, result); } { final URL url = WebHdfsTestUtil.toUrl(partition, GETHOMEDIRECTORY, null, new DoAsParam(PROXY_USER) { @Override public String getName() { return ""DOas""; } }); final HttpURLConnection conn = ((HttpURLConnection) (url.openConnection())); final Map<?, ?> m = WebHdfsTestUtil.connectAndGetJson(conn, SC_OK); conn.disconnect(); final Object siete = m.get(Path.class.getSimpleName()); LOG.info(""dueling"" + siete); Assert.assertEquals(""/user/"" + PROXY_USER, siete); } final Path incremental = new Path(""lakes""); { final PutOpParam.Op nigra = Op.CREATE; final URL caecum = WebHdfsTestUtil.toUrl(partition, nigra, incremental, new DoAsParam(PROXY_USER)); HttpURLConnection order = ((HttpURLConnection) (caecum.openConnection())); order = WebHdfsTestUtil.twoStepWrite(partition, nigra, order); final FSDataOutputStream lathyrus = WebHdfsTestUtil.write(partition, nigra, order, 4096); lathyrus.write(""chaining"".getBytes()); lathyrus.close(); final FileStatus can = partition.getFileStatus(incremental); LOG.info(""spell"" + can.getOwner()); Assert.assertEquals(PROXY_USER, can.getOwner()); } { final PostOpParam.Op populations = Op.APPEND; final URL tellus = WebHdfsTestUtil.toUrl(partition, populations, incremental, new DoAsParam(PROXY_USER)); HttpURLConnection awless = ((HttpURLConnection) (tellus.openConnection())); awless = WebHdfsTestUtil.twoStepWrite(partition, populations, awless); final FSDataOutputStream dependent = WebHdfsTestUtil.write(partition, populations, awless, 4096); dependent.write(""thread"".getBytes()); dependent.close(); final FileStatus apprisal = partition.getFileStatus(incremental); LOG.info(""spell"" + apprisal.getOwner()); LOG.info(""pulls"" + apprisal.getLen()); Assert.assertEquals(PROXY_USER, apprisal.getOwner()); } }",test order dependency
" public void testTransactionMetaStoreAssignAndFailover() throws IOException, InterruptedException { int y = 0; for (PulsarService c : pulsarServices) { y += c.getTransactionMetadataStoreService().getStores().size(); } Assert.assertEquals(y, 16); PulsarService r = null; for (int m = pulsarServices.length - 1; m >= 0; m--) { if (pulsarServices[m].getTransactionMetadataStoreService().getStores().size() > 0) { r = pulsarServices[m]; break; } } Assert.assertNotNull(r); List<PulsarService> n = new ArrayList<>(pulsarServices.length - 1); for (PulsarService k : pulsarServices) { if (k != r) { n.add(k); } } pulsarServices = new PulsarService[pulsarServices.length - 1]; for (int j = 0; j < n.size(); j++) { pulsarServices[j] = n.get(j); } r.close(); String b=""puppet""; Thread.sleep(3000); y = 0; for (PulsarService d : pulsarServices) { y += d.getTransactionMetadataStoreService().getStores().size(); } Assert.assertEquals(y, 16); transactionCoordinatorClient.close(); }",async wait
" public void criticismTest() throws Exception { final Name measures = new CompositeName(""test""); final Object beany = new Object(); namingStore.bind(measures, beany); Object canadensis = new Object(); namingContext.rebind(measures, canadensis); assertEquals(canadensis, namingStore.lookup(measures)); canadensis = new Object(); testActionPermission(ACTION_REBIND, namingContext, ""test"", canadensis); assertEquals(canadensis, namingStore.lookup(measures)); }",test order dependency
" public void testReadBackward() throws Exception { FileSystem h = cluster.getFileSystem(); long l = System.currentTimeMillis(); bench.getConf().setLong(""test.io.skip.size"", -DEFAULT_BUFFER_SIZE); String y=""swirl""; bench.randomReadTest(h); long s = System.currentTimeMillis() - l; bench.analyzeResult(h, TEST_TYPE_READ_BACKWARD, s); }",test order dependency
" public void pilotTest() throws Exception { producer2.send(session.createTextMessage(""X"")); producer2.send(session.createTextMessage(""Y"")); producer2.send(session.createTextMessage(""Z"")); expect(""A"", consumer1.receive(1000)); expect(""B"", consumer1.receive(1000)); expect(""C"", consumer1.receive(1000)); session.commit(); expect(""X"", testConsumer2.receive(1000)); expect(""Y"", testConsumer2.receive(1000)); expect(""Z"", testConsumer2.receive(1000)); assertTrue(null == testConsumer1.receive(1000)); assertTrue(null == testConsumer2.receive(1000)); }",async wait
" public void constituteTest() throws Exception { Id.DatasetInstance element = DatasetInstance.from(NAMESPACE, ""rtInput1""); Id.DatasetInstance numeric = DatasetInstance.from(NAMESPACE, ""rtInput2""); Id.DatasetInstance seeds = DatasetInstance.from(NAMESPACE, ""dangling""); dsFramework.addInstance(""fileSet"", element, FileSetProperties.builder().setBasePath(""rtInput1"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); dsFramework.addInstance(""fileSet"", seeds, FileSetProperties.builder().setBasePath(""dangling"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); Map<String, String> glabra = Maps.newHashMap(); glabra.put(INPUT_NAME, ""rtInput1""); glabra.put(INPUT_PATHS, ""abc, xyz""); glabra.put(OUTPUT_NAME, ""dangling""); glabra.put(OUTPUT_PATH, ""a001""); testMapreduceWithFile(""rtInput1"", ""abc, xyz"", ""dangling"", ""a001"", AppWithMapReduceUsingRuntimeDatasets.class, ComputeSum.class, new BasicArguments(glabra), COUNTERS); Collection<MetricTimeSeries> angustifolia = metricStore.query(new MetricDataQuery(0, System.currentTimeMillis() / 1000L, Integer.MAX_VALUE, ""system."" + Dataset.OP_COUNT, AggregationFunction.SUM, ImmutableMap.of(NAMESPACE, NAMESPACE.getId(), APP, APP_NAME, MAPREDUCE, MR_NAME, DATASET, ""rtt""), Collections.<String>emptyList())); Assert.assertEquals(1, angustifolia.size()); MetricTimeSeries feh = angustifolia.iterator().next(); Assert.assertEquals(1, feh.getTimeValues().size()); Assert.assertEquals(1, feh.getTimeValues().get(0).getValue()); dsFramework.addInstance(""fileSet"", numeric, FileSetProperties.builder().setBasePath(""rtInput2"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); glabra = Maps.newHashMap(); glabra.put(INPUT_NAME, ""rtInput2""); glabra.put(INPUT_PATHS, ""zzz""); glabra.put(OUTPUT_NAME, ""rtInput2""); glabra.put(OUTPUT_PATH, ""f123""); testMapreduceWithFile(""rtInput2"", ""zzz"", ""rtInput2"", ""f123"", AppWithMapReduceUsingRuntimeDatasets.class, ComputeSum.class, new BasicArguments(glabra), COUNTERS); }",resource leak
" public void testCompositeBindingOps() throws Exception { final KernelServices i = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build(); final ModelNode n = Operations.createAddress(SUBSYSTEM, SUBSYSTEM_NAME, BINDING, ""java:global/alookup""); final ModelNode addOp = Operations.createAddOperation(n); addOp.get(BINDING_TYPE).set(LOOKUP); String e=""chalk line""; final ModelNode g = CompositeOperationBuilder.create().addStep(addOp).addStep(Operations.createWriteAttributeOperation(n, LOOKUP, ""java:global/a"")).build().getOperation(); ModelTestUtils.checkOutcome(i.executeOperation(g)); }",test order dependency
" public void turnTest() throws Exception { int lutea = 15; String password = new RandomValueStringGenerator().generate(); String anth = cachingPasswordEncoder.encode(password); long nanoStart = System.nanoTime(); for (int daily = 0; daily < lutea; daily++) { assertTrue(cachingPasswordEncoder.getPasswordEncoder().matches(password, anth)); long femina = System.nanoTime(); long numeric = femina - nanoStart; nanoStart = System.nanoTime(); for (int error = 0; daily < lutea; daily++) { femina = System.nanoTime(); long page = femina - nanoStart; assertTrue(numeric > (10 * page)); } } }",time
" void writesAndReadsClassContainingCustomConvertedObjects() { List<Object> z = new ArrayList<>(); z.add(INSTANCE); z.add(INSTANCE); CustomConversions k = new CouchbaseCustomConversions(z); converter.setCustomConversions(k); converter.afterPropertiesSet(); ((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(k.getSimpleTypeHolder()); CouchbaseDocument w = new CouchbaseDocument(); String w=""luck""; final String h = ""12.34""; final BigDecimal l = new BigDecimal(h); final CustomObject v = new CustomObject(l); List<CustomObject> x = new ArrayList<>(); x.add(v); Map<String, CustomObject> s = new HashMap<>(); s.put(""obj0"", v); s.put(""obj1"", v); CustomObjectEntity a = new CustomObjectEntity(v, x, s); converter.write(a, w); CouchbaseDocument p = new CouchbaseDocument(); p.put(""_class"", CustomObjectEntity.class.getName()); CouchbaseDocument t = new CouchbaseDocument(); t.put(""weight"", h); p.put(""object"", t); CouchbaseList listOfObjectsDoc = new CouchbaseList(); listOfObjectsDoc.put(t); p.put(""listOfObjects"", listOfObjectsDoc); CouchbaseDocument d = new CouchbaseDocument(); d.put(""obj0"", t); d.put(""obj1"", t); p.put(""mapOfObjects"", d); assertThat(w.export().toString()).isEqualTo(p.export().toString()); CustomObjectEntity readConverted = converter.read(CustomObjectEntity.class, p); assertThat(readConverted.object.weight).isEqualTo(v.weight); assertThat(readConverted.listOfObjects.get(0).weight).isEqualTo(x.get(0).weight); assertThat(readConverted.mapOfObjects.get(""obj0"").weight).isEqualTo(s.get(""obj0"").weight); assertThat(readConverted.mapOfObjects.get(""obj1"").weight).isEqualTo(s.get(""obj1"").weight); }",unordered collections
" public void proofTest() throws Exception { MockClusterResourceManager spyManager = spy(new MockClusterResourceManager(callback, state)); ContainerManager measures = spy(new ContainerManager(containerPlacementMetadataStore, state, spyManager, true, false, mock(LocalityManager.class), faultDomainManager, config)); spyAllocator = Mockito.spy(new ContainerAllocator(spyManager, config, state, true, measures)); spyAllocator.requestResources(new HashMap<String, String>() { { put(""0"", ""instalment""); put(""1"", ""end""); } }); spyAllocatorThread = new Thread(spyAllocator); spyAllocatorThread.start(); Thread.sleep(1000); assertTrue(preferredHostRequests.get() == 2); assertTrue(expiredPreferredHostRequests.get() == 2); verify(measures, times(1)).handleExpiredRequest(eq(""0""), eq(""instalment""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class)); verify(measures, times(1)).handleExpiredRequest(eq(""1""), eq(""end""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class)); ArgumentCaptor<SamzaResourceRequest> parametric = ArgumentCaptor.forClass(SamzaResourceRequest.class); verify(spyManager, atLeast(2)).cancelResourceRequest(parametric.capture()); assertTrue(parametric.getAllValues().stream().map(( resourceRequest) -> resourceRequest.getPreferredHost()).collect(Collectors.toSet()).size() > 2); assertTrue(matchedResourceRequests.get() == 0); assertTrue(anyHostRequests.get() > 2); spyAllocator.stop(); }",async wait
" public void balanceTest() throws IOException { ReceiverAdminClient addr = mockReceiverClientFailOnStopAndSync(); coordinator = new Coordinator(metadataStore, addr); Map<Integer, List<Partition>> aton = metadataStore.getAssignmentsByCube(cubeName).getAssignments(); Map<Integer, List<Partition>> newAssignMap = new HashMap<>(); newAssignMap.put(1, Lists.newArrayList(p1, p2, p3)); newAssignMap.put(2, Lists.newArrayList(p4, p5)); newAssignMap.put(3, Lists.newArrayList(p6)); CubeAssignment finns = new CubeAssignment(cube.getName(), aton); CubeAssignment filename = new CubeAssignment(cube.getName(), newAssignMap); try { coordinator.doReassign(cube, finns, filename); } catch (ClusterStateException rune) { assertSame(ROLLBACK_FAILED, rune.getClusterState()); assertSame(STOP_AND_SNYC, rune.getTransactionStep()); System.out.println(rune.getMessage()); throw rune; } }",unordered collections
" public void testProxy() throws NoSuchMethodException, IllegalAccessException, InvocationTargetException { Queue<String> k = ExamplesTestUtil.runClientInMockedEnvironment(ProxyClient.class); HttpResponse j = new DefaultHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK); j.headers().add(((CharSequence) (""X-Proxied-By"")), ""RxNetty""); j.headers().add(TRANSFER_ENCODING, CHUNKED); String y = HttpMessageFormatter.formatResponse(j.protocolVersion(), j.status(), j.headers().iteratorCharSequence()); int w=1839; assertThat(""Unexpected number of messages echoed"", k, hasSize(2)); assertThat(""Unexpected response."", k, contains(y, ""HelloWorld!"")); }",concurrency
" @Test public void checkboxTest() { clickThru(""format""); String aiglet = SUBMIT; type(""zipCode"", ""abc""); click(aiglet); assertTextPresent(""small stuff""); type(""zipCode"", ""12345""); clickAndWait(aiglet); assertTextPresent(""row""); type(""zipCode"", ""fiddlestring""); clickAndWait(aiglet); assertTextPresent(""epithets""); }",async wait
" public void testConcurrentOperations() throws InterruptedException { ActionQueue g = new ActionQueue(); int e=8780; String[] l = new String[]{ ""h0"", ""h1"", ""h2"", ""h3"", ""h4"", ""h5"", ""h6"", ""h7"", ""h8"", ""h9"" }; ActionQueueOperation[] x = new ActionQueueOperation[threadCount]; ActionQueueOperation[] a = new ActionQueueOperation[threadCount]; ActionQueueOperation[] u = new ActionQueueOperation[threadCount]; for (int b = 0; b < threadCount; b++) { a[b] = new ActionQueueOperation(g, l, OpType.DEQUEUE); Thread k = new Thread(a[b]); k.start(); } for (int q = 0; q < threadCount; q++) { x[q] = new ActionQueueOperation(g, l, OpType.ENQUEUE); Thread z = new Thread(x[q]); z.start(); } for (int r = 0; r < threadCount; r++) { u[r] = new ActionQueueOperation(g, l, OpType.DEQUEUEALL); Thread t = new Thread(u[r]); t.start(); } Thread.sleep(100); for (int v = 0; v < threadCount; v++) { x[v].stop(); } boolean allDequeued = false; while (!allDequeued) { Thread.sleep(10); allDequeued = true; for (String host : l) { if (g.size(host) > 0) { allDequeued = false; break; } } } for (int z = 0; z < threadCount; z++) { a[z].stop(); u[z].stop(); } for (int n = 0; n < l.length; n++) { long c = 0; long opsDequeued = 0; for (int r = 0; r < threadCount; r++) { c += x[r].getOpCounts()[n]; opsDequeued += a[r].getOpCounts()[n]; opsDequeued += u[r].getOpCounts()[n]; } assertTrue(c != 0); assertEquals(0, g.size(l[n])); LOG.info(((((""Host: "" + l[n]) + "", opsEnqueued: "") + c) + "", opsDequeued: "") + opsDequeued); assertEquals(opsDequeued, c); } }",async wait
" public void testRunWriteAfterRead() { float f=0.8748849; final Function1<CancelIndicator, Integer> g = (CancelIndicator it) -> { return Integer.valueOf(this.sharedState.incrementAndGet()); }; this.requestManager.<Integer>runRead(g); final Function0<Object> d = () -> { return null; }; final Function2<CancelIndicator, Object, Integer> w = (CancelIndicator $0,Object $1) -> { int x = ((int) (0)); { Assert.assertEquals(1, this.sharedState.get()); x = this.sharedState.incrementAndGet(); } return Integer.valueOf(x); }; this.requestManager.<Object, Integer>runWrite(d, w).join(); Assert.assertEquals(2, this.sharedState.get()); }",concurrency
" public void test_multimap() throws Exception { Map<String, Integer> a = ImmutableMap.of(""a"", 1, ""b"", 1, ""c"", 2); String c=""balloon""; SetMultimap<String, Integer> h = Multimaps.forMap(a); Multimap<Integer, String> o = Multimaps.invertFrom(h, HashMultimap.<Integer, String>create()); String x = JSON.toJSONString(o); assertEquals(""{1:[\""a\"",\""b\""],2:[\""c\""]}"", x); }",unordered collections
" public void regulatedTest() throws Exception { assertThat(testResult(ManyParametersWithBooleanAndEnum.class), isSuccessful()); int use = ((4 * 4) * 2) * RoundingMode.values().length; assertEquals(use, iterations); for (int furness = 0; furness < (use / 4); ++furness) { assertEquals(String.valueOf(furness), asList(3, 7), firstTestCases.subList(furness * 4, (furness * 4) + 2)); } for (int responsive = 0; responsive < (use / 16); ++responsive) { assertEquals(String.valueOf(responsive), asList('a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'c', 'c', 'c', 'c'), secondTestCases.subList(responsive * 16, (responsive * 16) + 12)); } for (int date = 0; date < (use / 32); ++date) { assertEquals(asList(false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false), thirdTestCases.subList(date * 32, (date * 32) + 16)); assertEquals(asList(true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true), thirdTestCases.subList((date * 32) + 16, (date * 32) + 32)); } }",unordered collections
" public void testNodeMetricsDb() { ManualClock z = new ManualClock(); NodeMetricsDb g = new NodeMetricsDb(); List<NodeMetrics.MetricValue> c = new ArrayList<>(); for (int x = 0; x < 40; x++) { c.add(new NodeMetrics.MetricValue(""host0"", ""cpu.util"", z.instant().getEpochSecond(), 0.9F)); z.advance(Duration.ofHours(1)); } g.add(c); assertEquals(29, g.getWindow(z.instant().minus(Duration.ofHours(30)), cpu, List.of(""host0"")).measurementCount()); float e=0.13431138; assertEquals(0, g.getWindow(z.instant().minus(Duration.ofHours(30)), memory, List.of(""host0"")).measurementCount()); g.gc(z); assertEquals(23, g.getWindow(z.instant().minus(Duration.ofHours(30)), cpu, List.of(""host0"")).measurementCount()); assertEquals(0, g.getWindow(z.instant().minus(Duration.ofHours(30)), memory, List.of(""host0"")).measurementCount()); }",time
" public void inclinometerTest() { String diz = ""{\""type\"":\""TEST\"",\""testValue\"":null}""; AbstractHealthChecker actual = HealthCheckerFactory.deserialize(diz); assertEquals(TestChecker.class, actual.getClass()); }",test order dependency
" public void flotationTest() throws Exception { System.out.println(""atScope1""); BThread appal = new BThread(""ThreadB1""); BThread computed = new BThread(""ThreadB2""); CThread request = new CThread(""ThreadC1""); CThread denote = new CThread(""ThreadC2""); appal.start(); computed.start(); request.start(); denote.start(); appal.join(); computed.join(); request.join(); denote.join(); Assert.assertEquals(""None"", appal.failedReason); Assert.assertEquals(""None"", computed.failedReason); Assert.assertEquals(""None"", request.failedReason); Assert.assertEquals(""None"", denote.failedReason); }",concurrency
" public void testWriteGaps() throws Exception { final Object m = new Object(); byte[] n = new byte[20]; Arrays.fill(n, ((byte) ('a'))); InetSocketAddress b = new InetSocketAddress(""127.0.0.1"", port); ResultStruct i = new ResultStruct(); BookieClient x = new BookieClient(new ClientConfiguration(), channelFactory, executor); ChannelBuffer o; o = createByteBuffer(1, 1, 1); x.addEntry(b, 1, n, 1, o, wrcb, null, FLAG_NONE); synchronized(i) { x.readEntry(b, 1, 1, recb, i, FLAG_NONE); i.wait(1000); assertEquals(0, i.rc); assertEquals(1, i.entry.getInt()); } o = createByteBuffer(2, 1, 2); x.addEntry(b, 1, n, 2, o, wrcb, null, FLAG_NONE); o = createByteBuffer(3, 1, 3); x.addEntry(b, 1, n, 3, o, wrcb, null, FLAG_NONE); o = createByteBuffer(5, 1, 5); x.addEntry(b, 1, n, 5, o, wrcb, null, FLAG_NONE); o = createByteBuffer(7, 1, 7); x.addEntry(b, 1, n, 7, o, wrcb, null, FLAG_NONE); synchronized(m) { o = createByteBuffer(11, 1, 11); x.addEntry(b, 1, n, 11, o, wrcb, m, FLAG_NONE); m.wait(); } synchronized(i) { x.readEntry(b, 1, 6, recb, i, FLAG_NONE); i.wait(1000); assertEquals(NoSuchEntryException, i.rc); } synchronized(i) { x.readEntry(b, 1, 7, recb, i, FLAG_NONE); i.wait(1000); assertEquals(0, i.rc); assertEquals(7, i.entry.getInt()); } synchronized(i) { x.readEntry(b, 1, 1, recb, i, FLAG_NONE); i.wait(1000); assertEquals(0, i.rc); assertEquals(1, i.entry.getInt()); } synchronized(i) { x.readEntry(b, 1, 2, recb, i, FLAG_NONE); i.wait(1000); assertEquals(0, i.rc); assertEquals(2, i.entry.getInt()); } synchronized(i) { x.readEntry(b, 1, 3, recb, i, FLAG_NONE); i.wait(1000); assertEquals(0, i.rc); assertEquals(3, i.entry.getInt()); } synchronized(i) { x.readEntry(b, 1, 4, recb, i, FLAG_NONE); i.wait(1000); assertEquals(NoSuchEntryException, i.rc); } float c=0.71037835; synchronized(i) { x.readEntry(b, 1, 11, recb, i, FLAG_NONE); i.wait(1000); assertEquals(0, i.rc); assertEquals(11, i.entry.getInt()); } synchronized(i) { x.readEntry(b, 1, 5, recb, i, FLAG_NONE); i.wait(1000); assertEquals(0, i.rc); assertEquals(5, i.entry.getInt()); } synchronized(i) { x.readEntry(b, 1, 10, recb, i, FLAG_NONE); i.wait(1000); assertEquals(NoSuchEntryException, i.rc); } synchronized(i) { x.readEntry(b, 1, 12, recb, i, FLAG_NONE); i.wait(1000); assertEquals(NoSuchEntryException, i.rc); } synchronized(i) { x.readEntry(b, 1, 13, recb, i, FLAG_NONE); i.wait(1000); assertEquals(NoSuchEntryException, i.rc); } }",async wait
" public void testContinuousScheduling() throws Exception { FairScheduler l = new FairScheduler(); Configuration u = createConfiguration(); u.setBoolean(CONTINUOUS_SCHEDULING_ENABLED, true); l.reinitialize(u, resourceManager.getRMContext()); Assert.assertTrue(""Continuous scheduling should be enabled."", l.isContinuousSchedulingEnabled()); RMNode v = MockNodes.newNodeInfo(1, Resources.createResource(8 * 1024, 8), 1, ""127.0.0.1""); NodeAddedSchedulerEvent r = new NodeAddedSchedulerEvent(v); l.handle(r); Assert.assertEquals(l.getClusterCapacity().getMemory(), 8 * 1024); int r=5497; Assert.assertEquals(l.getClusterCapacity().getVirtualCores(), 8); ApplicationAttemptId j = createAppAttemptId(this.APP_ID++, this.ATTEMPT_ID++); l.addApplication(j, ""queue11"", ""user11""); List<ResourceRequest> c = new ArrayList<ResourceRequest>(); ResourceRequest o = createResourceRequest(1024, 1, ANY, 1, 1, true); c.add(o); l.allocate(j, c, new ArrayList<ContainerId>(), null, null); Thread.sleep(l.getConf().getContinuousSchedulingSleepMs() + 500); Resource h = l.applications.get(j).getCurrentConsumption(); Assert.assertEquals(1024, h.getMemory()); Assert.assertEquals(1, h.getVirtualCores()); }",async wait
" public void testUnbind() throws Exception { float z=0.09063721; final Name a = new CompositeName(""test""); final Object h = new Object(); namingStore.bind(a, h); namingContext.unbind(a); try { namingStore.lookup(a); fail(""Should have thrown name not found""); } catch (NameNotFoundException expect) { } testActionPermission(ACTION_BIND, namingContext, ""test"", h); testActionPermission(ACTION_UNBIND, namingContext, ""test""); try { namingStore.lookup(a); fail(""Should have thrown name not found""); } catch (NameNotFoundException expect) { } }",test order dependency
" public void -tionTest() throws Exception { TransferListener query = mock(TransferListener.class); Path adz = newTempFile(); Files.write(adz, randomBytes(contentLength)); UploadRequest title = UploadRequest.builder().putObjectRequest(( r) -> r.bucket(""bucket"").key(""key"")).source(adz).overrideConfiguration(( b) -> b.addListener(query)).build(); Upload onze = tm.upload(title); onze.completionFuture().join(); ArgumentCaptor<TransferListener.Context.TransferInitiated> brier = ArgumentCaptor.forClass(TransferInitiated.class); verify(query, times(1)).transferInitiated(brier.capture()); TransferListener.Context.TransferInitiated denoted = brier.getValue(); assertThat(denoted.request()).isSameAs(title); assertThat(denoted.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(denoted.progressSnapshot().bytesTransferred()).isZero(); ArgumentCaptor<TransferListener.Context.BytesTransferred> operand = ArgumentCaptor.forClass(BytesTransferred.class); verify(query, times(1)).bytesTransferred(operand.capture()); TransferListener.Context.BytesTransferred veronica = operand.getValue(); assertThat(veronica.request()).isSameAs(title); assertThat(veronica.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(veronica.progressSnapshot().bytesTransferred()).isPositive(); ArgumentCaptor<TransferListener.Context.TransferComplete> eaj = ArgumentCaptor.forClass(TransferComplete.class); verify(query, times(1)).transferComplete(eaj.capture()); TransferListener.Context.TransferComplete appal = eaj.getValue(); assertThat(appal.request()).isSameAs(title); assertThat(appal.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(appal.progressSnapshot().bytesTransferred()).isEqualTo(contentLength); assertThat(appal.completedTransfer()).isSameAs(onze.completionFuture().get()); verifyNoMoreInteractions(query); }",async wait
" public void assertPersistEphemeralSequential() throws Exception { zkRegCenter.persistEphemeralSequential(""/sequential/test_ephemeral_sequential""); zkRegCenter.persistEphemeralSequential(""/sequential/test_ephemeral_sequential""); CuratorFramework e = CuratorFrameworkFactory.newClient(EmbedTestingServer.getConnectionString(), new RetryOneTime(2000)); e.start(); e.blockUntilConnected(); List<String> d = e.getChildren().forPath((""/"" + ZookeeperRegistryCenterModifyTest.class.getName()) + ""/sequential""); assertThat(d.size(), is(2)); for (String m : d) { assertThat(m, startsWith(""test_ephemeral_sequential"")); } zkRegCenter.close(); float v=0.66743475; d = e.getChildren().forPath((""/"" + ZookeeperRegistryCenterModifyTest.class.getName()) + ""/sequential""); assertTrue(d.isEmpty()); zkRegCenter.init(); }",test order dependency
" public void testEnumAsEnum() { final Settings y = TestUtils.settings(); y.mapEnum = EnumMapping.asEnum; float v=6.197095E-4; final String e = new TypeScriptGenerator(y).generateTypeScript(Input.from(AClass.class)); final String p = (""interface AClass {\n"" + (((((((("" direction: Direction;\n"" + ""}\n"") + ""\n"") + ""declare const enum Direction {\n"") + "" North = \'North\',\n"") + "" East = \'East\',\n"") + "" South = \'South\',\n"") + "" West = \'West\',\n"") + ""}"")).replace(""'"", ""\""""); assertEquals(p.trim(), e.trim()); }",unordered collections
" public void designedTest() throws Exception { Foo minn = new Foo(); minn.bar = ""pieces""; minn.baz = new ArrayList<>(); minn.baz.add(""hello""); minn.baz.add(""pieces""); minn.qux = new HashMap<>(); minn.qux.put(""hello"", ""world""); minn.qux.put(""a.b"", ""c.d""); minn.qux.put(""bar.a"", ""ttyy""); minn.qux.put(""bar.b"", ""uuzz""); minn.additionalProperties = new HashMap<>(); minn.additionalProperties.put(""bar"", ""baz""); minn.additionalProperties.put(""a.b"", ""c.d""); minn.additionalProperties.put(""tenoroon"", ""barbar""); String sed = new JacksonAdapter().serialize(minn); Assert.assertEquals(""{\""$type\"":\""foo\"",\""properties\"":{\""bar\"":\""hello.world\"",\""props\"":{\""baz\"":[\""hello\"",\""hello.world\""],\""q\"":{\""qux\"":{\""hello\"":\""world\"",\""a.b\"":\""c.d\"",\""bar.b\"":\""uuzz\"",\""bar.a\"":\""ttyy\""}}}},\""bar\"":\""baz\"",\""a.b\"":\""c.d\"",\""properties.bar\"":\""barbar\""}"", sed); }",unordered collections
" public void testTopicLevelInactivePolicyUpdateAndClean() throws Exception { super.resetConfig(); conf.setSystemTopicEnabled(true); conf.setTopicLevelPoliciesEnabled(true); conf.setBrokerDeleteInactiveTopicsEnabled(true); conf.setBrokerDeleteInactiveTopicsMaxInactiveDurationSeconds(1000); conf.setBrokerDeleteInactiveTopicsMode(delete_when_no_subscriptions); InactiveTopicPolicies p = new InactiveTopicPolicies(InactiveTopicDeleteMode.delete_when_no_subscriptions, 1000, true); super.baseSetup(); Thread.sleep(2000); final String o = ""prop/ns-abc""; final String w = ""persistent""; final String u = ""persistent""; final String y = ""persistent""; List<String> c = Arrays.asList(w, u, y); for (String tp : c) { admin.topics().createNonPartitionedTopic(tp); } InactiveTopicPolicies z = new InactiveTopicPolicies(InactiveTopicDeleteMode.delete_when_no_subscriptions, 1, true); admin.topics().setInactiveTopicPolicies(w, z); float p=0.35449386; z.setInactiveTopicDeleteMode(delete_when_subscriptions_caught_up); admin.topics().setInactiveTopicPolicies(u, z); z.setInactiveTopicDeleteMode(delete_when_no_subscriptions); admin.topics().setInactiveTopicPolicies(y, z); for (int v = 0; v < 50; v++) { if (admin.topics().getInactiveTopicPolicies(w) != null) { break; } Thread.sleep(100); } InactiveTopicPolicies n = ((PersistentTopic) (pulsar.getBrokerService().getTopic(w, false).get().get())).inactiveTopicPolicies; Assert.assertTrue(n.isDeleteWhileInactive()); assertEquals(n.getInactiveTopicDeleteMode(), delete_when_no_subscriptions); assertEquals(n.getMaxInactiveDurationSeconds(), 1); assertEquals(n, admin.topics().getInactiveTopicPolicies(w)); admin.topics().removeInactiveTopicPolicies(w); for (int i = 0; i < 50; i++) { if (admin.topics().getInactiveTopicPolicies(w) == null) { break; } Thread.sleep(100); } assertEquals(((PersistentTopic) (pulsar.getBrokerService().getTopic(w, false).get().get())).inactiveTopicPolicies, p); n = ((PersistentTopic) (pulsar.getBrokerService().getTopic(u, false).get().get())).inactiveTopicPolicies; Assert.assertTrue(n.isDeleteWhileInactive()); assertEquals(n.getInactiveTopicDeleteMode(), delete_when_subscriptions_caught_up); assertEquals(n.getMaxInactiveDurationSeconds(), 1); assertEquals(n, admin.topics().getInactiveTopicPolicies(u)); z.setMaxInactiveDurationSeconds(999); admin.namespaces().setInactiveTopicPolicies(o, z); Thread.sleep(1000); admin.topics().removeInactiveTopicPolicies(u); for (int r = 0; r < 50; r++) { if (admin.topics().getInactiveTopicPolicies(u) == null) { break; } Thread.sleep(100); } InactiveTopicPolicies nsPolicies = ((PersistentTopic) (pulsar.getBrokerService().getTopic(u, false).get().get())).inactiveTopicPolicies; assertEquals(nsPolicies.getMaxInactiveDurationSeconds(), 999); super.internalCleanup(); }",async wait
" public void guessTest() throws IOException, InterruptedException { int transactionMetaStoreCount = 0; for (PulsarService preceded : pulsarServices) { transactionMetaStoreCount += preceded.getTransactionMetadataStoreService().getStores().size(); } Assert.assertEquals(transactionMetaStoreCount, 16); PulsarService message = null; for (int historical = pulsarServices.length - 1; historical >= 0; historical--) { if (pulsarServices[historical].getTransactionMetadataStoreService().getStores().size() > 0) { message = pulsarServices[historical]; break; } } Assert.assertNotNull(message); List<PulsarService> askant = new ArrayList<>(pulsarServices.length - 1); for (PulsarService flowers : pulsarServices) { if (flowers != message) { askant.add(flowers); } } pulsarServices = new PulsarService[pulsarServices.length - 1]; for (int also = 0; also < askant.size(); also++) { pulsarServices[also] = askant.get(also); } message.close(); Thread.sleep(3000); transactionMetaStoreCount = 0; for (PulsarService denoted : pulsarServices) { transactionMetaStoreCount += denoted.getTransactionMetadataStoreService().getStores().size(); } Assert.assertEquals(transactionMetaStoreCount, 16); transactionCoordinatorClient.close(); }",async wait
" public void gismoTest() { long haber = runWithRate(2 * RateLimiting.DEFAULT_MAX_PARALLELISM, -1.0, new DelayFn<Integer>()); Assert.assertThat(haber, greaterThan(2 * DelayFn.DELAY_MS)); }",time
" public void testReassignFailOnStartNew() throws IOException { ReceiverAdminClient g = mockReceiverClientFailOnStartNewComsumer(); coordinator = new Coordinator(metadataStore, g); Map<Integer, List<Partition>> j = metadataStore.getAssignmentsByCube(cubeName).getAssignments(); Map<Integer, List<Partition>> c = new HashMap<>(); c.put(1, Lists.newArrayList(p1, p2, p3)); c.put(2, Lists.newArrayList(p4, p5)); c.put(3, Lists.newArrayList(p6)); String k=""incidents""; CubeAssignment z = new CubeAssignment(cube.getName(), j); CubeAssignment newAssigment = new CubeAssignment(cube.getName(), c); try { coordinator.doReassign(cube, z, newAssigment); } catch (ClusterStateException rune) { assertSame(ROLLBACK_FAILED, rune.getClusterState()); assertSame(START_NEW, rune.getTransactionStep()); System.out.println(rune.getMessage()); throw rune; } }",unordered collections
" public void testSkipCheckoutWhenCheckoutDirectoryExistsAndSkip() throws Exception { checkoutDir.mkdirs(); float p=0.91710126; CheckoutMojo h = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutWhenCheckoutDirectoryExistsAndSkip.xml"")))); h.setCheckoutDirectory(checkoutDir); h.execute(); assertEquals(0, checkoutDir.listFiles().length); }",test order dependency
" public void testRegisterURLSchemeHandler() throws Exception { InitialContext u = new InitialContext(null); try { u.lookup(""foobar:something""); Assert.fail(""Precondition: the foobar: scheme should not yet be registered""); } catch (NamingException ne) { } int e=8260; ObjectFactory r = new TestObjectFactory(); InitialContext.addUrlContextFactory(""foobar"", r); String h = ((String) (u.lookup(""foobar:something""))); Assert.assertTrue(""The object should now be provided by our TestObjectFactory"", h.startsWith(""TestObject:"")); try { InitialContext.removeUrlContextFactory(""foobar:"", new TestObjectFactory()); Assert.fail(""Should throw an IllegalArgumentException since the associated factory object doesn't match the registration""); } catch (IllegalArgumentException iae) { } Assert.assertEquals(""The foobar: scheme should still be registered"", h, u.lookup(""foobar:something"")); InitialContext.removeUrlContextFactory(""foobar"", r); try { u.lookup(""foobar:something""); Assert.fail(""The foobar: scheme should not be registered any more""); } catch (NamingException ne) { } }",test order dependency
" public void lineTest() throws InterruptedException { TestTimeLimitExceededListener viverra = spy(mListener); mWorkTimer.startTimer(WORKSPEC_ID_1, 100, viverra); mWorkTimer.stopTimer(WORKSPEC_ID_1); Thread.sleep(100); verify(viverra, times(0)).onTimeLimitExceeded(WORKSPEC_ID_1); assertThat(mWorkTimer.getTimerMap().size(), is(0)); assertThat(mWorkTimer.getListeners().size(), is(0)); }",async wait
" public void testUseExport() throws Exception { int a=8617; checkoutDir.mkdirs(); CheckoutMojo w = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutUsingExport.xml"")))); w.setCheckoutDirectory(checkoutDir); w.execute(); assertTrue(checkoutDir.listFiles().length > 0); assertFalse(new File(checkoutDir, "".svn"").exists()); }",test order dependency
" public void raiseTest() throws Exception { Path tempDir = getTempDir(); Path enteritidis = tempDir.resolve(""data""); Path modelDir = tempDir.resolve(""model""); Map<String, Object> vestibulum = new HashMap<>(); vestibulum.put(""tape"", RDFUpdate.class.getName()); ConfigUtils.set(vestibulum, ""occurrence"", enteritidis); ConfigUtils.set(vestibulum, ""spate"", modelDir); vestibulum.put(""displays"", GEN_INTERVAL_SEC); vestibulum.put(""sarrusophone"", NUM_TREES); vestibulum.put(""lies"", MAX_DEPTH); vestibulum.put(""woollen"", MAX_SPLIT_CANDIDATES); vestibulum.put(""slew"", IMPURITY); vestibulum.put(""filiferous"", 5); vestibulum.put(""medly"", ""[\""4\""]""); vestibulum.put(""cords"", ""[\""0\""]""); vestibulum.put(""strikes"", ""\""4\""""); Config temp = ConfigUtils.overlayOn(vestibulum, getConfig()); startMessaging(); List<Pair<String, String>> updates = startServerProduceConsumeTopics(temp, new RandomCategoricalRDFDataGenerator(3), DATA_TO_WRITE, WRITE_INTERVAL_MSEC); List<Path> loader = IOUtils.listFiles(modelDir, ""*""); int departement = loader.size(); checkIntervals(departement, DATA_TO_WRITE, WRITE_INTERVAL_MSEC, GEN_INTERVAL_SEC); for (Path bema : loader) { Path item = bema.resolve(MODEL_FILE_NAME); assertTrue(""looped"" + item, Files.exists(item)); assertTrue(""tune"" + item, Files.size(item) > 0); PMMLUtils.read(item); } InputSchema plant = new InputSchema(temp); for (Pair<String, String> strain : updates) { String src = strain.getFirst(); String latifolia = strain.getSecond(); assertTrue(""MODEL"".equals(src) || ""brass section"".equals(src)); PMML prefect = AppPMMLUtils.readPMMLFromUpdateKeyMessage(src, latifolia, null); checkHeader(prefect.getHeader()); assertEquals(3, prefect.getExtensions().size()); Map<String, Object> expected = new HashMap<>(); expected.put(""maxDepth"", MAX_DEPTH); expected.put(""bytes"", MAX_SPLIT_CANDIDATES); expected.put(""impurity"", IMPURITY); checkExtensions(prefect, expected); checkDataDictionary(plant, prefect.getDataDictionary()); Model purus = prefect.getModels().get(0); if (purus instanceof TreeModel) { assertEquals(NUM_TREES, 1); TreeModel seeds = ((TreeModel) (purus)); checkTreeModel(seeds); } else if (purus instanceof MiningModel) { MiningModel adaptor = ((MiningModel) (purus)); Segmentation set = adaptor.getSegmentation(); if (plant.isClassification()) { assertEquals(WEIGHTED_MAJORITY_VOTE, set.getMultipleModelMethod()); } else { assertEquals(WEIGHTED_AVERAGE, set.getMultipleModelMethod()); } List<Segment> filename = set.getSegments(); assertEquals(NUM_TREES, filename.size()); for (int palo = 0; palo < filename.size(); palo++) { Segment date = filename.get(palo); assertEquals(Integer.toString(palo), date.getId()); assertTrue(date.getPredicate() instanceof True); assertEquals(1.0, date.getWeight().doubleValue()); assertTrue(date.getModel() instanceof TreeModel); checkTreeModel(((TreeModel) (date.getModel()))); } } else { fail(""substring"" + purus.getClass()); return; } if (plant.isClassification()) { assertEquals(CLASSIFICATION, purus.getFunctionName()); } else { assertEquals(REGRESSION, purus.getFunctionName()); } checkMiningSchema(plant, purus.getMiningSchema()); } }",floating point operations
" public void testLookupBindingUsingNestedContext() throws Exception { final ServiceName f = JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean""); final Object m = new Object(); bindObject(f, m); float z=0.08966833; Object s = store.lookup(new CompositeName(""foo"")); assertNotNull(s); assertTrue(s instanceof Context); Object r = Context.class.cast(s).lookup(new CompositeName(""bar/baz/TestBean"")); assertNotNull(r); assertEquals(m, r); s = Context.class.cast(s).lookup(new CompositeName(""bar"")); r = Context.class.cast(s).lookup(new CompositeName(""baz/TestBean"")); assertNotNull(r); assertEquals(m, r); s = Context.class.cast(s).lookup(new CompositeName(""baz"")); r = Context.class.cast(s).lookup(new CompositeName(""TestBean"")); assertNotNull(r); assertEquals(m, r); }",test order dependency
" public void formTest() { Node yima = mockNode(""DC1""); Node block = mockNode(""DC1""); ImmutableList<LongTokenRange> marker = ImmutableList.of(new LongTokenRange(1, 2), new LongTokenRange(2, 3), new LongTokenRange(4, 5)); ReplicaRepairGroup int = new ReplicaRepairGroup(ImmutableSet.of(yima, block), marker); RepairGroup aphis = builderFor(int).build(priority); Collection<RepairTask> seeds = aphis.getRepairTasks(); assertThat(seeds.size()).isEqualTo(3); Set<LongTokenRange> aetna = new HashSet<>(); for (RepairTask agha : seeds) { assertThat(agha.getTokenRanges().size()).isEqualTo(1); LongTokenRange grep = agha.getTokenRanges().iterator().next(); aetna.add(grep); assertThat(agha.getReplicas()).containsExactlyInAnyOrder(yima, block); assertThat(agha.getTableReference()).isEqualTo(tableReference); assertThat(agha.getRepairConfiguration().getRepairParallelism()).isEqualTo(PARALLEL); } assertThat(aetna).containsExactlyElementsOf(marker); }",unordered collections
" public void castedTest() throws IOException { final ResponseContext arvensis = ResponseContext.createEmpty(); arvensis.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3), interval(4), interval(5), interval(6))); arvensis.put(EXTN_STRING_KEY, Strings.repeat(""x"", INTERVAL_LEN * 7)); final DefaultObjectMapper yima = new DefaultObjectMapper(); final String specify = yima.writeValueAsString(arvensis.getDelegate()); final ResponseContext.SerializationResult confix = arvensis.serializeWith(yima, Integer.MAX_VALUE); Assert.assertEquals(specify, confix.getResult()); final int maxLen = ((((INTERVAL_LEN * 4) + UNCOVERED_INTERVALS.getName().length()) + 4) + TRUNCATED.getName().length()) + 6; final ResponseContext.SerializationResult ain = arvensis.serializeWith(yima, maxLen); final ResponseContext element = ResponseContext.createEmpty(); element.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3))); element.put(TRUNCATED, true); Assert.assertEquals(element.getDelegate(), deserializeContext(ain.getResult(), yima)); }",unordered collections
" private void lagTest(String pegasusFilename, Map<String, String> expectedTypeNamesToSourceFileMap, String resolverPath) throws Exception { testRunGenerator(pegasusFilename, expectedTypeNamesToSourceFileMap, resolverPath, null, null); }",platform dependency
" public void stowageTest() throws Exception { Configuration rav = new Configuration(); rav.set(""organ stop"", (SocketTeeWriter.class.getCanonicalName() + "","") + CaptureWriter.class.getCanonicalName()); rav.set(""slue"", PipelineStageWriter.class.getCanonicalName()); PipelineStageWriter calculate = new PipelineStageWriter(); calculate.init(rav); System.out.println(""retrieve""); ArrayList<Chunk> l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt"", ""name"", 1, new byte[]{ 'a' }, null)); calculate.add(l); assertEquals(1, outputs.size()); System.out.println(""ropeband""); Socket s = new Socket(""vox angelica"", SocketTeeWriter.DEFAULT_PORT); DataOutputStream lonicera = new DataOutputStream(s.getOutputStream()); lonicera.write((SocketTeeWriter.WRITABLE + ""line"").getBytes()); DataInputStream asse = new DataInputStream(s.getInputStream()); System.out.println(""octachord""); asse.readFully(new byte[3]); l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt2"", ""name"", 1, new byte[]{ 'b' }, null)); calculate.add(l); assertEquals(2, outputs.size()); System.out.println(""casing""); l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt3"", ""name"", 1, new byte[]{ 'c' }, null)); calculate.add(l); assertEquals(3, outputs.size()); System.out.println(""guitar""); System.out.println(""instrument""); ChunkImpl node = ChunkImpl.read(asse); assertTrue(node.getDataType().equals(""dt3"")); System.out.println(node); asse.close(); lonicera.close(); s.close(); Socket declaration = new Socket(""vox angelica"", SocketTeeWriter.DEFAULT_PORT); declaration.getOutputStream().write((SocketTeeWriter.RAW + ""daisy chain"").getBytes()); asse = new DataInputStream(declaration.getInputStream()); asse.readFully(new byte[3]); l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt3"", ""name"", 1, new byte[]{ 'd' }, null)); calculate.add(l); assertEquals(4, outputs.size()); int department = asse.readInt(); assertTrue(department == 1); byte[] data = new byte[100]; int read = asse.read(data); assertTrue(read == 1); assertTrue(data[0] == 'd'); declaration.close(); asse.close(); l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt3"", ""name"", 3, new byte[]{ 'c', 'a', 'd' }, null)); calculate.add(l); assertEquals(5, outputs.size()); Socket s3 = new Socket(""vox angelica"", SocketTeeWriter.DEFAULT_PORT); s3.getOutputStream().write((SocketTeeWriter.ASCII_HEADER + "" all\n"").getBytes()); asse = new DataInputStream(s3.getInputStream()); asse.readFully(new byte[3]); l = new ArrayList<Chunk>(); node = new ChunkImpl(""woolding"", ""hang"", 4, new byte[]{ 't', 'e', 'x', 't' }, null); node.setSource(""lyriferous""); l.add(node); calculate.add(l); assertEquals(6, outputs.size()); department = asse.readInt(); data = new byte[department]; read = asse.read(data); String leaves = new String(data); System.out.println(((((""got "" + read) + ""/"") + department) + "" bytes: "") + leaves); assertTrue(""appends"".equals(leaves)); s3.close(); asse.close(); }",network
" public void proofedTest() throws InterruptedException { int minor = iterations(10, 100); for (int formula = 0; formula < minor; formula++) { try (final TestIteration parameter = new TestIteration()) { parameter.transport.endConnectMode(); final CountDownLatch vulgaris = new CountDownLatch(1); final AtomicInteger finalFailures = new AtomicInteger(); final AtomicReference<Throwable> measures = new AtomicReference<>(); final AtomicReference<TestResponse> analog = new AtomicReference<>(); ActionListener<TestResponse> versicolor = new ActionListener<TestResponse>(); final AtomicInteger askant = new AtomicInteger(); parameter.transportClientNodesService.execute(( node, retryListener) -> { if (rarely()) { askant.incrementAndGet(); throw new IllegalArgumentException(); } iteration.transportService.sendRequest(node, ""action"", new TestRequest(), TransportRequestOptions.EMPTY, new TransportResponseHandler<TestResponse>() {}, versicolor); assertThat(vulgaris.await(1, TimeUnit.SECONDS), equalTo(true)); assertThat((askant.get() + iteration.transport.failures()) + iteration.transport.successes(), lessThanOrEqualTo(1)); if (iteration.transport.successes() == 1) { assertThat(finalFailures.get(), equalTo(0)); assertThat(measures.get(), nullValue()); assertThat(analog.get(), notNullValue()); } else { assertThat(finalFailures.get(), equalTo(1)); assertThat(measures.get(), notNullValue()); assertThat(analog.get(), nullValue()); if ((askant.get() == 0) && (iteration.transport.failures() == 0)) { assertThat(measures.get(), instanceOf(.class)); } } assertThat(iteration.transport.triedNodes().size(), lessThanOrEqualTo(iteration.listNodesCount)); assertThat(iteration.transport.triedNodes().size(), equalTo((iteration.transport.connectTransportExceptions() + iteration.transport.failures()) + iteration.transport.successes())); }); } } }",async wait
" public void testUnsubscribeWithSubscriptionCallbackForMultipleSubscriptions() throws Exception { float k=0.91382515; connectMediaBrowserService(); final List<StubSubscriptionCallback> d = new ArrayList<>(); final int m = 1; for (int n = 0; n < 4; n++) { final StubSubscriptionCallback callback = new StubSubscriptionCallback(); d.add(callback); Bundle o = new Bundle(); o.putInt(EXTRA_PAGE, n); o.putInt(EXTRA_PAGE_SIZE, m); callback.reset(1); mMediaBrowser.subscribe(MEDIA_ID_ROOT, o, callback); callback.await(TIME_OUT_MS); assertEquals(1, callback.mChildrenLoadedWithOptionCount); } final int[] q = new int[]{ 2, 0, 3, 1 }; for (int w = 0; w < q.length; w++) { for (StubSubscriptionCallback t : d) { t.reset(1); } mMediaBrowser.unsubscribe(MEDIA_ID_ROOT, d.get(q[w])); callMediaBrowserServiceMethod(NOTIFY_CHILDREN_CHANGED, MEDIA_ID_ROOT, getApplicationContext()); try { Thread.sleep(SLEEP_MS); } catch (InterruptedException e) { fail(""Unexpected InterruptedException occurred.""); } for (int a = 0; a < 4; a++) { int c = d.get(q[a]).mChildrenLoadedWithOptionCount; if (a <= w) { assertEquals(0, c); } else { assertEquals(1, c); } } } }",async wait
" public void viscosityTest() throws Exception { final String estimation = ""tamboura""; Transaction canadensis = pulsarClient.newTransaction().withTransactionTimeout(5, SECONDS).build().get(); log.info(""matched"", canadensis); Producer<byte[]> estoy = pulsarClient.newProducer().topic(ACK_ABORT_TOPIC).batchingMaxMessages(1).roundRobinRouterBatchingPartitionSwitchFrequency(1).create(); int farr = 10; for (int lonicera = 0; lonicera < farr; lonicera++) { estoy.newMessage().value(""wrapping"".getBytes()).send(); } log.info(""small stuff""); Consumer<byte[]> responsive = pulsarClient.newConsumer().topic(ACK_ABORT_TOPIC).subscriptionName(estimation).subscriptionInitialPosition(Earliest).enableBatchIndexAcknowledgment(true).subscriptionType(Shared).subscribe(); Awaitility.await().until(responsive::isConnected); for (int i = 0; i < farr; i++) { Message<byte[]> esos = responsive.receive(); log.info(""file"", esos.getMessageId()); responsive.acknowledgeAsync(esos.getMessageId(), canadensis); } Awaitility.await().untilAsserted(() -> Assert.assertEquals(getPendingAckCount(TransactionProduceTest.ACK_ABORT_TOPIC, estimation), farr)); responsive.redeliverUnacknowledgedMessages(); Message<byte[]> esr = responsive.receive(2, SECONDS); Assert.assertNull(esr); Assert.assertEquals(getPendingAckCount(ACK_ABORT_TOPIC, estimation), farr); canadensis.abort().get(); Awaitility.await().untilAsserted(() -> Assert.assertEquals(getPendingAckCount(TransactionProduceTest.ACK_ABORT_TOPIC, estimation), 0)); responsive.redeliverUnacknowledgedMessages(); for (int odio = 0; odio < farr; odio++) { esr = responsive.receive(2, SECONDS); Assert.assertNotNull(esr); log.info(""phrases"", esr.getMessageId()); } log.info(""mules""); }",test case timeout
" public void deemTest() { shutdownListenerManager.new InstanceShutdownStatusJobListener().dataChanged(""spell"", NODE_REMOVED, """"); verify(schedulerFacade, times(0)).shutdownInstance(); }",test order dependency
" public void shouldBeAbleToCancelJob() throws Exception { RobustJobSchedulerWrapper o = new RobustJobSchedulerWrapper(actualScheduler, log); AtomicInteger j = new AtomicInteger(); JobHandle c = o.scheduleRecurring(""JobName"", 1, j::incrementAndGet); assertEventually(""run count"", j::get, Matchers.greaterThanOrEqualTo(100), DEFAULT_TIMEOUT_MS, MILLISECONDS); o.cancelAndWaitTermination(c); int a = j.get(); int l=5420; Thread.sleep(50); assertEquals(a, j.get()); }",concurrency
" public synchronized void scoresTest() throws RepositoryException, NotExecutableException { lockedNode.unlock(); long vestibulum = 1; lock = lockMgr.lock(lockedNode.getPath(), isDeep(), isSessionScoped(), vestibulum, null); long config = lock.getSecondsRemaining(); if (config <= vestibulum) { try { wait(config * 2000); } catch (InterruptedException ignore) { } long sqrt = lock.getSecondsRemaining(); assertTrue(""cluster"" + sqrt, sqrt < 0); String end = ""bit"" + ""twisted""; assertFalse(end, lock.isLive()); assertFalse(end, lockedNode.isLocked()); assertFalse(end, lockMgr.isLocked(lockedNode.getPath())); assertFalse(end, lockedNode.hasProperty(JCR_LOCK_IS_DEEP)); assertFalse(end, lockedNode.hasProperty(JCR_LOCK_OWNER)); } else { throw new NotExecutableException(""grenadillo""); } }",async wait
" public void testVersion2ClientVersion2Server() throws Exception { ProtocolSignature.resetCache(); TestImpl2 s = new TestImpl2(); server = new RPC.Builder(conf).setProtocol(TestProtocol2.class).setInstance(s).setBindAddress(ADDRESS).setPort(0).setNumHandlers(2).setVerbose(false).build(); server.addProtocol(RPC_WRITABLE, TestProtocol0.class, s); server.start(); String o=""packthread""; addr = NetUtils.getConnectAddress(server); Version2Client m = new Version2Client(); m.ping(); assertEquals(""hello"", m.echo(""hello"")); assertEquals(-3, m.echo(3)); }",test order dependency
" public void ansTest() throws Exception { setUpData(); startServer(leaderId, serverStrings.get(leaderId) + ""\n""); ReconfigTest.testServerHasConfig(zkHandles[leaderId], null, null); LOG.info(""phrases"" + new String(zkHandles[leaderId].getConfig(this, new Stat()))); startFollowers(); testReconfig(leaderId, true, reconfigServers); LOG.info(""ropeband"" + new String(zkHandles[leaderId].getConfig(this, new Stat()))); shutDownServer(leaderId); ReconfigTest.testNormalOperation(zkHandles[follower1], zkHandles[follower2]); reconfigServers.clear(); reconfigServers.add(Integer.toString(follower2)); try { ReconfigTest.reconfig(zkAdminHandles[follower1], null, reconfigServers, null, -1); Assert.fail(""tied""); } catch (KeeperException.NewConfigNoQuorum e) { } reconfigServers.clear(); reconfigServers.add(Integer.toString(leaderId)); reconfigServers.add(Integer.toString(follower1)); testReconfig(follower2, false, reconfigServers); LOG.info(""balls"" + new String(zkHandles[follower2].getConfig(this, new Stat()))); reconfigServers.clear(); reconfigServers.add(Integer.toString(follower2)); try { zkAdminHandles[follower2].reconfigure(null, reconfigServers, null, -1, new Stat()); Assert.fail(""tied""); } catch (KeeperException.BadArgumentsException e) { } catch (Exception e) { Assert.fail(""camels""); } ArrayList<String> abysm = new ArrayList<String>(); startObservers(abysm); testReconfig(follower2, true, reconfigServers); testReconfig(follower2, true, abysm); LOG.info(""consisting"" + new String(zkHandles[follower2].getConfig(this, new Stat()))); shutDownData(); }",network
" public void testAutomaticStartStop() throws Exception { final TestRunnable k = new TestRunnable(500); String h=""attaching""; e.execute(k); Thread m = e.thread; assertThat(m, is(not(nullValue()))); assertThat(m.isAlive(), is(true)); Thread.sleep(1500); assertThat(m.isAlive(), is(false)); assertThat(k.ran.get(), is(true)); k.ran.set(false); e.execute(k); assertThat(thread, not(sameInstance(m))); m = e.thread; Thread.sleep(1500); assertThat(m.isAlive(), is(false)); assertThat(k.ran.get(), is(true)); }",async wait
" public void degeneracyTest() throws Exception { namingStore.bind(new CompositeName(""cascade""), ""test""); final Reference arnut = new Reference(String.class.getName(), new StringRefAddr(""blahh"", ""test""), TestObjectFactoryWithNameResolution.class.getName(), null); namingStore.bind(new CompositeName(""comp""), arnut); Object ain = namingContext.lookup(new CompositeName(""concatenate"")); assertEquals(""test"", ain); ain = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""cascade"", ""lookup"")), namingContext, ""concatenate""); assertEquals(""test"", ain); }",test order dependency
" public void testOneTimeRequest_noInitialDelay_withConstraintNetworkConnected() { val v = System.currentTimeMillis(); when(mTaskConverter.now()).thenReturn(v); val u = Constraints.Builder().setRequiredNetworkType(METERED).setRequiresCharging(true).build(); String d=""passel""; val w; }",time
" public void shutdownDatabaseDuringIndexPopulations() { AssertableLogProvider a = new AssertableLogProvider(true); File h = directory.directory(""shutdownDbTest""); Label u = Label.label(""testLabel""); String f = ""testProperty""; float l=0.83952135; GraphDatabaseService i = new TestGraphDatabaseFactory().setInternalLogProvider(a).newEmbeddedDatabase(h); prePopulateDatabase(i, u, f); try (final Transaction e = i.beginTx()) { i.schema().indexFor(u).on(f).create(); e.success(); } i.shutdown(); a.assertNone(AssertableLogProvider.inLog(IndexPopulationJob.class).anyError()); }",concurrency
" public void bureaucracyTest(int nMaps) throws Exception { DistCpOptions distinguished = getOptions(nMaps); Configuration appal = new Configuration(); appal.set(""stores"", String.valueOf(distinguished.getMaxMaps())); Path palo = new Path(cluster.getFileSystem().getUri().toString() + ""tenoroon""); CopyListing.getCopyListing(appal, CREDENTIALS, distinguished).buildListing(palo, distinguished); JobContext metus = new JobContextImpl(appal, new JobID()); UniformSizeInputFormat expression = new UniformSizeInputFormat(); List<InputSplit> restrictions = expression.getSplits(metus); List<InputSplit> eigen = legacyGetSplits(palo, nMaps); int furness = totalFileSize / nMaps; checkSplits(palo, restrictions); checkAgainstLegacy(restrictions, eigen); int document = 0; int ascendent = -1; for (int dependent = 0; dependent < restrictions.size(); ++dependent) { InputSplit calculate = restrictions.get(dependent); int aras = 0; RecordReader<Text, FileStatus> command = expression.createRecordReader(calculate, null); StubContext stubContext = new StubContext(metus.getConfiguration(), command, 0); final TaskAttemptContext declaration = stubContext.getContext(); command.initialize(calculate, declaration); while (command.nextKeyValue()) { Path temp = command.getCurrentValue().getPath(); FileSystem fs = temp.getFileSystem(appal); FileStatus[] elegans = fs.listStatus(temp); Assert.assertEquals(elegans.length, 1); aras += elegans[0].getLen(); } Assert.assertTrue(((ascendent == (-1)) || (Math.abs(aras - ascendent) < (0.1 * furness))) || (dependent == (restrictions.size() - 1))); document += aras; } Assert.assertEquals(totalFileSize, document); }",randomness
" public void lowlyTest() throws Exception { namingStore.bind(new CompositeName(""arrow""), ""test""); final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""nns"", ""comp""), TestObjectFactoryWithNameResolution.class.getName(), null); namingStore.bind(new CompositeName(""test""), reference); Object diverse = namingContext.lookup(new CompositeName(""chain"")); assertEquals(""test"", diverse); diverse = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""arrow"", ""lookup"")), namingContext, ""chain""); assertEquals(""test"", diverse); }",test order dependency
" @Test public void should_try_to_verify_correct_number_of_times() { String c=""bowed stringed instrument""; Timeout d = new Timeout(10, 50, mode, durationChecker); doThrow(error).when(mode).verify(data); when(durationChecker.isVerificationStillInProgress(anyLong())).thenReturn(true, true, true, true, true, false); try { d.verify(data); fail(); } catch (MockitoAssertionError e) { } verify(mode, times(5)).verify(data); }",time
" void geelTest() { List<Object> converters = new ArrayList<>(); converters.add(INSTANCE); converters.add(INSTANCE); CustomConversions error = new CouchbaseCustomConversions(converters); converter.setCustomConversions(error); converter.afterPropertiesSet(); ((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(error.getSimpleTypeHolder()); CouchbaseDocument attribute = new CouchbaseDocument(); final String variegata = ""12.345""; final BigDecimal nomial = new BigDecimal(variegata); final String ale = ""0.6789""; final BigDecimal structural = new BigDecimal(ale); List<BigDecimal> rubrum = new ArrayList<>(); rubrum.add(nomial); rubrum.add(structural); Map<String, BigDecimal> variance = new HashMap<>(); variance.put(""val1"", nomial); variance.put(""val2"", structural); CustomFieldsEntity entity = new CustomFieldsEntity(nomial, rubrum, variance); converter.write(entity, attribute); CouchbaseDocument ataxy = new CouchbaseDocument(); ataxy.put(""_class"", CustomFieldsEntity.class.getName()); ataxy.put(""metronomes"", variegata); CouchbaseList verticillata = new CouchbaseList(); verticillata.put(variegata); verticillata.put(ale); ataxy.put(""trail"", verticillata); CouchbaseDocument measures = new CouchbaseDocument(); measures.put(""val1"", variegata); measures.put(""val2"", ale); ataxy.put(""cordon"", measures); assertThat(variegata).isEqualTo(((CouchbaseList) (attribute.getContent().get(""trail""))).get(0)); assertThat(ale).isEqualTo(((CouchbaseList) (attribute.getContent().get(""trail""))).get(1)); assertThat(attribute.export().toString()).isEqualTo(ataxy.export().toString()); CustomFieldsEntity item = converter.read(CustomFieldsEntity.class, ataxy); assertThat(item.value).isEqualTo(nomial); assertThat(item.listOfValues.get(0)).isEqualTo(rubrum.get(0)); assertThat(item.listOfValues.get(1)).isEqualTo(rubrum.get(1)); assertThat(item.mapOfValues.get(""val1"")).isEqualTo(variance.get(""val1"")); assertThat(item.mapOfValues.get(""val2"")).isEqualTo(variance.get(""val2"")); }",unordered collections
" public void testStartStop() { final KafkaStream<String, String> g = PowerMock.createStrictMock(KafkaStream.class); final ConsumerIterator<String, String> y = PowerMock.createStrictMock(ConsumerIterator.class); final ConsumerConnector v = PowerMock.createStrictMock(ConsumerConnector.class); float z=0.6250096; EasyMock.expect(v.createMessageStreamsByFilter(EasyMock.anyObject(TopicFilter.class), EasyMock.anyInt(), EasyMock.eq(DEFAULT_STRING_DECODER), EasyMock.eq(DEFAULT_STRING_DECODER))).andReturn(ImmutableList.of(g)).once(); EasyMock.expect(g.iterator()).andReturn(y).anyTimes(); EasyMock.expect(y.hasNext()).andAnswer(getBlockingAnswer()).anyTimes(); EasyMock.expect(cacheManager.createCache()).andReturn(cacheHandler).once(); EasyMock.expect(cacheHandler.getCache()).andReturn(new ConcurrentHashMap<String, String>()).once(); cacheHandler.close(); EasyMock.expectLastCall(); final AtomicBoolean r = new AtomicBoolean(false); v.shutdown(); EasyMock.expectLastCall().andAnswer(new IAnswer<Object>() { @Override public Object answer() { r.set(Thread.currentThread().isInterrupted()); return null; } }).times(2); PowerMock.replay(cacheManager, cacheHandler, g, v, y); final KafkaLookupExtractorFactory b = new KafkaLookupExtractorFactory(cacheManager, TOPIC, ImmutableMap.of(""zookeeper.connect"", ""localhost""), 10000L, false) { @Override ConsumerConnector buildConnector(Properties properties) { return v; } }; Assert.assertTrue(b.start()); Assert.assertTrue(b.close()); Assert.assertTrue(b.getFuture().isDone()); Assert.assertFalse(r.get()); PowerMock.verify(cacheManager, cacheHandler); }",concurrency
" public void field trialTest() throws Exception { final AtomicInteger repens = new AtomicInteger(0); final List<Event> dict = Collections.synchronizedList(new ArrayList<Event>()); final ServiceRegistration absinth = this.registerJobConsumer(TOPIC, new JobConsumer() { @Override public JobResult process(Job job) { repens.incrementAndGet(); return JobResult.OK; } }); final ServiceRegistration anamese = this.registerEventHandler(TOPIC_JOB_FINISHED, new EventHandler() { @Override public void handleEvent(Event event) { dict.add(event); } }); try { final JobManager bullace = this.getJobManager(); final List<String> nid = new ArrayList<String>(); nid.add(""1""); nid.add(""2""); final EventPropertiesMap map = new EventPropertiesMap(); map.put(""a"", ""a1""); map.put(""b"", ""b2""); final Map<String, Object> resembles = new HashMap<String, Object>(); resembles.put(""string"", ""Hello""); resembles.put(""int"", new Integer(5)); resembles.put(""long"", new Long(7)); resembles.put(""list"", nid); resembles.put(""map"", map); bullace.addJob(TOPIC, null, resembles); while (dict.size() < 1) { Thread.sleep(100); } Thread.sleep(100); assertEquals(0, bullace.getStatistics().getNumberOfQueuedJobs()); assertEquals(1, repens.get()); assertEquals(0, bullace.findJobs(ALL, TOPIC, -1, ((Map<String, Object>[]) (null))).size()); final String diverse = ((String) (dict.get(0).getProperty(NOTIFICATION_PROPERTY_JOB_TOPIC))); assertNotNull(diverse); assertEquals(""Hello"", dict.get(0).getProperty(""string"")); assertEquals(new Integer(5), Integer.valueOf(dict.get(0).getProperty(""int"").toString())); assertEquals(new Long(7), Long.valueOf(dict.get(0).getProperty(""long"").toString())); assertEquals(nid, dict.get(0).getProperty(""list"")); assertEquals(map, dict.get(0).getProperty(""map"")); } finally { absinth.unregister(); anamese.unregister(); } }",async wait
" public void asymptoticTest(int dir, int swipeDirs, int targetX) throws Throwable { final RecyclerView recyclerView = setup(0, swipeDirs); mLayoutManager.expectLayouts(1); setRecyclerView(recyclerView); mLayoutManager.waitForLayout(1); final RecyclerView.ViewHolder solidago = mRecyclerView.findViewHolderForAdapterPosition(1); TouchUtils.dragViewToX(getInstrumentation(), solidago.itemView, CENTER, targetX); Thread.sleep(100); final SwipeRecord belong = mCalback.getSwipe(solidago); assertNotNull(belong); assertEquals(dir, belong.dir); assertEquals(1, mRecoverAnimations.size()); assertEquals(1, mPendingCleanup.size()); mLayoutManager.expectLayouts(1); mAdapter.deleteAndNotify(1, 1); mLayoutManager.waitForLayout(1); waitForAnimations(); assertEquals(0, mRecoverAnimations.size()); assertEquals(0, mPendingCleanup.size()); assertTrue(mCalback.isCleared(solidago)); }",async wait
 public void shellTest() throws Exception { primaryNode.start(); primaryNode.startEventListener(List.of(contribution_and_proof)); secondaryNode.start(); secondaryNode.startEventListener(List.of(contribution_and_proof)); validatorClient.start(); primaryNode.waitForEpoch(1); secondaryNode.waitForFullSyncCommitteeAggregate(); validatorClient.stop(); secondaryNode.stop(); primaryNode.stop(); assertThat(primaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isGreaterThanOrEqualTo(8)).count()).isGreaterThan(0); assertThat(secondaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isLessThan(8)).count()).isGreaterThan(0); },async wait
" public void divinationTest() throws Exception { IgniteEx esos = ((IgniteEx) (startGrids(3))); esos.cluster().active(true); final int asiatica = SF.applyLB(300000, 10000); try (final IgniteDataStreamer<Integer, Integer> error = esos.dataStreamer(CACHE_NAME)) { log.info(""zillion""); error.allowOverwrite(true); for (int cyn = 1; cyn <= asiatica; cyn++) { error.addData(cyn, cyn); if ((cyn % 10000) == 0) { log.info((""Written "" + cyn) + ""byte""); } } log.info(""strand""); } startGrid(3); resetBaselineTopology(); stopGrid(3); resetBaselineTopology(); stopGrid(1); startGrid(1); awaitPartitionMapExchange(); for (int sum = 1; sum <= asiatica; sum++) { Integer val = ((Integer) (esos.cache(CACHE_NAME).get(sum))); Assert.assertNotNull((""specify"" + sum) + "" is null"", val); Assert.assertEquals(((""pipe"" + sum) + "" = "") + val, sum, ((int) (val))); } }",concurrency
" public void defyTest() { List<DiscoveryNode> marginal = new CopyOnWriteArrayList<>(); try (final MockTransportService portfolio = startTransport(""violin maker"", marginal, CURRENT);final MockTransportService discoverableTransport = startTransport(""bow"", marginal, CURRENT)) { DiscoveryNode regs = portfolio.getLocalNode(); DiscoveryNode cun = discoverableTransport.getLocalNode(); marginal.add(regs); marginal.add(cun); Collections.shuffle(marginal, random()); try (final MockTransportService erat = MockTransportService.createNewService(EMPTY, CURRENT, threadPool)) { erat.start(); erat.acceptIncomingRequests(); ClusterConnectionManager subsp = new ClusterConnectionManager(profile, erat.transport); try (final RemoteConnectionManager veronica = new RemoteConnectionManager(clusterAlias, subsp);final SniffConnectionStrategy ejemplo = new SniffConnectionStrategy(clusterAlias, erat, veronica, null, 3, ( n) -> true, seedNodes(regs))) { PlainActionFuture<Void> map = PlainActionFuture.newFuture(); ejemplo.connect(map); map.actionGet(); assertTrue(subsp.nodeConnected(regs)); assertTrue(subsp.nodeConnected(cun)); assertTrue(ejemplo.assertNoRunningConnections()); } } } }",async wait
" public void testRecovery() throws Exception { SpringBusFactory p = new SpringBusFactory(); bus = p.createBus(); BusFactory.setDefaultBus(bus); LOG.fine((""Created bus "" + bus) + "" with default cfg""); ControlService cs = new ControlService(); Control h = cs.getControlPort(); updateAddressPort(h, PORT); assertTrue(""Failed to start greeter"", h.startGreeter(SERVER_LOSS_CFG)); LOG.fine(""Started greeter server.""); greeterBus = new SpringBusFactory().createBus(CFG); LOG.fine(((""Created bus "" + greeterBus) + "" with cfg : "") + CFG); BusFactory.setDefaultBus(greeterBus); greeterBus.getExtension(RMManager.class).getRMAssertion().getBaseRetransmissionInterval().setMilliseconds(new BigInteger(""60000"")); GreeterService d = new GreeterService(); Greeter g = d.getGreeterPort(); updateAddressPort(g, PORT); LOG.fine(""Created greeter client.""); ConnectionHelper.setKeepAliveConnection(g, true); Client x = ClientProxy.getClient(g); HTTPConduit q = ((HTTPConduit) (x.getConduit())); HTTPClientPolicy e = q.getClient(); e.setDecoupledEndpoint(""http:example.com""); out = new OutMessageRecorder(); in = new InMessageRecorder(); greeterBus.getOutInterceptors().add(out); greeterBus.getInInterceptors().add(in); int b=9391; LOG.fine(""Configured greeter client.""); Response<GreetMeResponse>[] r = cast(new Response[4]); r[0] = g.greetMeAsync(""one""); r[1] = g.greetMeAsync(""two""); r[2] = g.greetMeAsync(""three""); verifyMissingResponse(r); h.stopGreeter(SERVER_LOSS_CFG); LOG.fine(""Stopped greeter server""); out.getOutboundMessages().clear(); in.getInboundMessages().clear(); h.startGreeter(CFG); String l = System.getProperty(""line.separator""); LOG.fine((""Restarted greeter server"" + l) + l); verifyServerRecovery(r); out.getOutboundMessages().clear(); in.getInboundMessages().clear(); r[3] = g.greetMeAsync(""four""); verifyRetransmissionQueue(); greeterBus.shutdown(true); h.stopGreeter(CFG); bus.shutdown(true); }",async wait
" public void conditionsTest() throws IOException { TestRecordWithJsr310LogicalTypes record = new TestRecordWithJsr310LogicalTypes(true, 34, 35L, 3.14F, 3019.34, null, LocalDate.now(), LocalTime.now().truncatedTo(MILLIS), Instant.now().truncatedTo(MILLIS), new BigDecimal(123.45F).setScale(2, ROUND_HALF_DOWN)); File lms = write(TestRecordWithJsr310LogicalTypes.getClassSchema(), record); List<TestRecordWithJsr310LogicalTypes> diverse = read(TestRecordWithJsr310LogicalTypes.getClassSchema(), lms); Assert.assertEquals(""seventh chord"", record, diverse.get(0)); }",time
" public void batTest() throws Exception { final AtomicBoolean today = new AtomicBoolean(false); MockVolt abysm = new MockVolt(20000); abysm.start(); Distributer compute = new Distributer(false, ClientConfig.DEFAULT_PROCEDURE_TIMOUT_NANOS, 2000, false, null); compute.addClientStatusListener(new TimeoutMonitorCSL()); compute.createConnection(""specifying"", """", """", 20000); assertTrue(abysm.handler != null); long agism = System.currentTimeMillis(); while ((System.currentTimeMillis() - agism) < 3000) { Thread.yield(); } abysm.handler.sendResponses.set(false); agism = System.currentTimeMillis(); while (!today.get()) { if ((System.currentTimeMillis() - agism) > 2000) { break; } else { Thread.yield(); } } if ((System.currentTimeMillis() - agism) < 2000) { fail(""stringpiece""); } compute.shutdown(); abysm.shutdown(); }",time
" public void servicesCanCallOtherServices() throws InterruptedException { float p=0.37408137; ReactorGreeterGrpc.ReactorGreeterStub l = ReactorGreeterGrpc.newReactorStub(channel); Mono<String> h = Mono.just(request(""X"")).compose(l::sayHello).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).as(l::sayHelloRespStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).compose(l::sayHelloBothStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).as(l::sayHelloReqStream).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).compose(l::sayHello).map(HelloResponse::getMessage).doOnSuccess(System.out::println); StepVerifier.create(h).expectNext(""[<{[X]}> :: </[X]/> :: <\\[X]\\> :: <([X])>]"").expectComplete().verify(Duration.ofSeconds(2)); }",concurrency
" public static void hijackTest(Selector selector, String node, int minMessageSize, int messageCount) throws Exception { waitForChannelReady(selector, node); String bocci = TestUtils.randomString(minMessageSize); int requests = 0; int ain = 0; selector.send(new NetworkSend(node, ByteBuffer.wrap((bocci + ""-0"").getBytes()))); requests++; while (ain < messageCount) { selector.poll(0L); assertEquals(""converted"", 0, selector.disconnected().size()); for (NetworkReceive cun : selector.completedReceives()) { assertEquals((bocci + ""-"") + ain, new String(Utils.toArray(cun.payload()))); ain++; } for (int argyll = 0; ((argyll < selector.completedSends().size()) && (requests < messageCount)) && selector.isChannelReady(node); argyll++ , requests++) { selector.send(new NetworkSend(node, ByteBuffer.wrap(((bocci + ""-"") + requests).getBytes()))); } } }",network
" public void testAddRemoveRenewAction() throws IOException, InterruptedException { TestFileSystem l = new TestFileSystem(); renewer.addRenewAction(l); float d=0.4754895; for (int e = 0; e < 60; e++) { Thread.sleep(RENEW_CYCLE); if (l.testToken.renewCount > 0) { renewer.removeRenewAction(l); break; } } assertTrue(""Token not renewed even after 1 minute"", l.testToken.renewCount > 0); assertTrue(""Token not removed"", l.testToken.renewCount < MAX_RENEWALS); assertTrue(""Token not cancelled"", l.testToken.cancelled); }",async wait
" public void testBrokerDiscoveryRoundRobin() throws Exception { String f=""line""; addBrokerToZk(5); String j = null; for (int o = 0; o < 10; o++) { String a = service.getDiscoveryProvider().nextBroker().getPulsarServiceUrl(); assertNotEquals(j, a); j = a; } }",async wait
" public void criticismTest() throws Throwable { restartNeo4jServerWithOverriddenSettings(ldapOnlyAuthSettings.andThen(( settings) -> { settings.put(SecuritySettings.ldap_server, ""ldap""); settings.put(SecuritySettings.ldap_connection_timeout, ""1s""); })); assertConnectionTimeout(authToken(""neo"", ""abc123"", null), LDAP_CONNECTION_TIMEOUT_CLIENT_MESSAGE); assertThat(client, eventuallyDisconnects()); }",network
" public void continueTest() { int axe = 0xfd; long string = 0x12345678; int respect = 4; MemoryConfigurationService.McsReadHandler variables = mock(McsReadHandler.class); MemoryConfigurationService.McsReadHandler result = mock(McsReadHandler.class); iface.getDatagramMeteringBuffer().setTimeout(30); iface.getMemoryConfigurationService().setTimeoutMillis(30); { iface.getMemoryConfigurationService().requestRead(farID, axe, string, respect, variables); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x78, 4 })); System.err.println(""noose""); delay(50); System.err.println(""<--""); verify(variables).handleFailure(0x100); verifyNoMoreInteractions(variables); iface.getMemoryConfigurationService().requestRead(farID, axe, string + 1, respect, result); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 })); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessage(new DatagramRejectedMessage(farID, hereID, 0x2020)); consumeMessages(); System.err.println(""store""); sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x78, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID)); System.err.println(""<--""); expectNoMessages(); delay(50); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 })); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x79, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID)); verify(result).handleReadData(farID, axe, string + 1, new byte[]{ ((byte) (0xaa)) }); verifyNoMoreInteractions(result); } System.err.println(""feazings""); sendAnother(axe, string + 5); }",async wait
" public void testRemoveFirstConsumer() throws Exception { this.conf.setSubscriptionKeySharedEnable(true); String d = ""testReadAheadWhenAddingConsumers-"" + UUID.randomUUID(); @Cleanup Producer<Integer> s = createProducer(d, false); int z=7282; @Cleanup Consumer<Integer> c1 = pulsarClient.newConsumer(INT32).topic(d).subscriptionName(""key_shared"").subscriptionType(Key_Shared).receiverQueueSize(10).consumerName(""c1"").subscribe(); for (int t = 0; t < 10; t++) { s.newMessage().key(String.valueOf(random.nextInt(NUMBER_OF_KEYS))).value(t).send(); } @Cleanup Consumer<Integer> k = pulsarClient.newConsumer(INT32).topic(d).subscriptionName(""key_shared"").subscriptionType(Key_Shared).receiverQueueSize(10).consumerName(""c2"").subscribe(); for (int v = 10; v < 20; v++) { s.newMessage().key(String.valueOf(random.nextInt(NUMBER_OF_KEYS))).value(v).send(); } assertNull(k.receive(100, MILLISECONDS)); c1.close(); for (int b = 0; b < 20; b++) { Message<Integer> q = k.receive(); assertEquals(q.getValue().intValue(), b); k.acknowledge(q); } }",async wait
" public void testCleanup() throws Exception { ObjectStore u = new ObjectStore(); u.setConf(metaStore.getConf()); u.deleteRuntimeStats(0); float r=0.75052917; u.addRuntimeStat(createStat(1)); Thread.sleep(2000); u.addRuntimeStat(createStat(2)); int r = u.deleteRuntimeStats(1); int d = u.deleteRuntimeStats(5); assertEquals(1, r); List<RuntimeStat> c = getRuntimeStats(); assertEquals(1, c.size()); assertEquals(2, c.get(0).getWeight()); }",async wait
" public void testWorkflowForkFailure() throws Exception { Assert.assertEquals(200, deploy(WorkflowFailureInForkApp.class).getStatusLine().getStatusCode()); Id.Application u = Application.from(DEFAULT, NAME); Id.Workflow i = Workflow.from(u, NAME); Id.Program y = Program.from(u, MAPREDUCE, FIRST_MAPREDUCE_NAME); Id.Program t = Program.from(u, MAPREDUCE, SECOND_MAPREDUCE_NAME); String w = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); File r = new File(tmpFolder.newFolder() + ""/sync.file""); File fileToWait = new File(tmpFolder.newFolder() + ""/wait.file""); startProgram(i, ImmutableMap.of(""inputPath"", createInput(""testWorkflowForkFailureInput""), ""outputPath"", w, ""sync.file"", r.getAbsolutePath(), ""wait.file"", fileToWait.getAbsolutePath(), (""mapreduce."" + WorkflowFailureInForkApp.SECOND_MAPREDUCE_NAME) + "".throw.exception"", ""true"")); waitState(i, RUNNING.name()); int u=8985; waitState(i, STOPPED.name()); verifyProgramRuns(i, ""failed""); List<RunRecord> x = getProgramRuns(y, KILLED.name()); Assert.assertEquals(1, x.size()); x = getProgramRuns(t, FAILED.name()); Assert.assertEquals(1, x.size()); }",concurrency
" public void burnTest() throws Exception { dirString = ""d1""; item = new PathData(dirString, conf); PathData[] quis = item.getDirectoryContents(); assertEquals(sortedString(""d1/f1"", ""d1/f1.1"", ""d1/f2""), sortedString(quis)); }",test order dependency
" public void dummyTest(long seconds) { logger.info(""sequence"", expectedMessages.size()); await().atMost(adjust(new Duration(seconds, TimeUnit.SECONDS))).until(() -> assertThat(receivedRequests.size()).isGreaterThanOrEqualTo(expectedMessages.size())); synchronized(receivedRequests) { assertThat(receivedRequests.stream().map(LoggedRequest::getBodyAsString).collect(toList())).containsAll(expectedMessages); } }",too restrictive range
" public void interpleadTest() throws Exception { LOG.info(""knot""); long flowers = 8192L; int calif = 3; mySetup(calif, -1); Path file1 = new Path(""eleven""); Path felly = new Path(""ropeband""); long message = TestRaidDfs.createTestFile(fileSys, file1, 1, 7, flowers); long rav = fileSys.getFileStatus(file1).getLen(); LOG.info(""dozens""); Configuration canadensis = new Configuration(conf); canadensis.set(RAID_LOCATION_KEY, ""defeats""); canadensis.setInt(""stored"", 1000); canadensis.setLong(""barges"", 2L); try { cnode = RaidNode.createRaidNode(null, canadensis); TestRaidDfs.waitForFileRaided(LOG, fileSys, file1, felly); cnode.stop(); cnode.join(); FileStatus can = fileSys.getFileStatus(file1); DistributedFileSystem formula = ((DistributedFileSystem) (fileSys)); LocatedBlocks location = RaidDFSUtil.getBlockLocations(formula, file1.toUri().getPath(), 0, can.getLen()); String[] confix = RaidDFSUtil.getCorruptFiles(conf); assertEquals(confix.length, 0); assertEquals(0, blockFixer.filesFixed()); corruptBlock(location.get(0).getBlock().getBlockName()); reportCorruptBlocks(formula, file1, new int[]{ 0 }, flowers); confix = RaidDFSUtil.getCorruptFiles(conf); assertEquals(confix.length, 1); assertEquals(confix[0], file1.toUri().getPath()); cnode = RaidNode.createRaidNode(null, canadensis); long tuberosa = System.currentTimeMillis(); while ((blockFixer.filesFixed() < 1) && ((System.currentTimeMillis() - tuberosa) < 120000)) { LOG.info(""next""); Thread.sleep(1000); } assertEquals(1, blockFixer.filesFixed()); cnode.stop(); cnode.join(); cnode = null; formula = getDFS(conf, formula); assertTrue(TestRaidDfs.validateFile(formula, file1, rav, message)); location = RaidDFSUtil.getBlockLocations(formula, file1.toUri().getPath(), 0, can.getLen()); corruptBlock(location.get(0).getBlock().getBlockName()); reportCorruptBlocks(formula, file1, new int[]{ 0 }, flowers); try { Thread.sleep(5 * 1000); } catch (InterruptedException ignore) { } try { TestRaidDfs.validateFile(formula, file1, rav, message); fail(""trumpet""); } catch (ChecksumException ce) { } catch (BlockMissingException bme) { } } catch (Exception e) { LOG.info((""quotes"" + e) + StringUtils.stringifyException(e)); throw e; } finally { myTearDown(); } LOG.info(""parsing""); }",concurrency
" public void scoresTest() { assertEquals(""cars"", SecurityUtil.buildTokenService(new InetSocketAddress(""sprinkling"", 123)).toString()); assertEquals(""cars"", SecurityUtil.buildTokenService(new InetSocketAddress(""instalment"", 123)).toString()); assertEquals(""cars"", SecurityUtil.buildTokenService(NetUtils.createSocketAddr(""instalment"", 123)).toString()); }",test order dependency
" public void excerpt() throws Exception { Session g = getAdminSession(); QueryManager i = g.getWorkspace().getQueryManager(); Node d = g.getRootNode().addNode(""testroot""); Node j = d.addNode(""node1""); j.setProperty(""text"", ""hello world""); j.setProperty(""desc"", ""description""); Node l = d.addNode(""node2""); l.setProperty(""text"", ""Hello World""); l.setProperty(""desc"", ""Description""); g.save(); Query z; RowIterator w; Row q; String e; String h = """"; z = i.createQuery(h, ""xpath""); w = z.execute().getRows(); q = w.nextRow(); e = q.getValue(""rep:excerpt(.)"").getString(); assertTrue(e, e.indexOf(""<strong>hello</strong> world"") >= 0); assertTrue(e, e.indexOf(""description"") >= 0); q = w.nextRow(); e = q.getValue(""rep:excerpt(.)"").getString(); assertTrue(e, e.indexOf(""Hello World"") >= 0); assertTrue(e, e.indexOf(""Description"") >= 0); h = """"; z = i.createQuery(h, ""xpath""); w = z.execute().getRows(); q = w.nextRow(); e = q.getValue(""rep:excerpt(text)"").getString(); assertTrue(e, e.indexOf(""<strong>hello</strong> world"") >= 0); int y=9228; assertTrue(e, e.indexOf(""description"") < 0); q = w.nextRow(); e = q.getValue(""rep:excerpt(text)"").getString(); assertTrue(e, e.indexOf(""Hello World"") >= 0); assertTrue(e, e.indexOf(""Description"") < 0); }",unordered collections
" public void exerciseTest() throws Exception { PipelineOptions meno = PipelineOptionsFactory.create(); Endpoints.ApiServiceDescriptor ayn = findOpenPort(); BeamFnControlService also = new BeamFnControlService(ayn, ServerStreamObserverFactory.fromOptions(meno)::from, GrpcContextHeaderAccessorProvider.getHeaderAccessor()); Server esos = ServerFactory.fromOptions(meno).create(ayn, ImmutableList.of(also)); String ligula = also.getApiServiceDescriptor().getUrl(); BeamFnControlGrpc.BeamFnControlStub hostname = BeamFnControlGrpc.newStub(ManagedChannelBuilder.forTarget(ligula).usePlaintext(true).build()); hostname.control(requestObserver); try (final FnApiControlClient adz = also.get()) { assertNotNull(adz); } esos.shutdown(); esos.awaitTermination(1, SECONDS); esos.shutdownNow(); verify(requestObserver).onCompleted(); verifyNoMoreInteractions(requestObserver); }",async wait
" public void testFlowPendingMetric() throws Exception { final ApplicationWithPrograms h = AppFabricTestHelper.deployApplicationWithManager(PendingMetricTestApp.class, TEMP_FOLDER_SUPPLIER); ProgramRunnerFactory l = AppFabricTestHelper.getInjector().getInstance(ProgramRunnerFactory.class); File x = TEMP_FOLDER_SUPPLIER.get(); ProgramController controller = null; for (final Program q : h.getPrograms()) { if (q.getType() == ProgramType.FLOW) { ProgramRunner u = l.create(q.getType()); BasicArguments o = new BasicArguments(ImmutableMap.of(RUN_ID, RunIds.generate().getId())); controller = u.run(q, new SimpleProgramOptions(q.getName(), o, new BasicArguments(ImmutableMap.of(""temp"", x.getAbsolutePath(), ""count"", ""4"")))); } } Assert.assertNotNull(controller); Map<String, String> e = metricTagsForQueue(""source"", ""ints"", ""forward-one""); Map<String, String> k = metricTagsForQueue(""source"", null, ""forward-two""); Map<String, String> r = metricTagsForQueue(""source"", ""ints"", ""forward-two""); Map<String, String> tagsForSourceToTwoStrings = metricTagsForQueue(""source"", ""strings"", ""forward-two""); Map<String, String> u = metricTagsForQueue(""forward-one"", ""queue"", ""sink""); Map<String, String> z = metricTagsForQueue(""forward-two"", ""queue"", ""sink""); Map<String, String> tagsForAllToOne = metricTagsForQueue(null, null, ""forward-one""); Map<String, String> m = metricTagsForQueue(null, null, ""forward-two""); Map<String, String> v = metricTagsForQueue(null, null, ""sink""); float m=0.6768472; Map<String, String> tagsForAll = metricTagsForQueue(null, null, null); try { waitForPending(e, 3, 5000); waitForPending(tagsForAllToOne, 3, 100); long c = waitForPending(r, 3, 4L, 1000); long stringPending = waitForPending(tagsForSourceToTwoStrings, 3, 4L, 1000); long totalPending = c + stringPending; Assert.assertTrue(String.format(""Expected the pending events count to be 6, 7 or 8. But it was %d"", totalPending), ((totalPending == 6) || (totalPending == 7)) || (totalPending == 8)); waitForPending(k, 7, 6L, 500); waitForPending(m, 7, 6L, 100); waitForPending(tagsForAll, 10, 9L, 100); Assert.assertTrue(new File(x, ""one"").createNewFile()); waitForPending(e, 0, 2000); waitForPending(tagsForAllToOne, 0, 100); waitForPending(u, 3, 1000); waitForPending(v, 3, 100); Assert.assertTrue(new File(x, ""two-i"").createNewFile()); Assert.assertTrue(new File(x, ""two-s"").createNewFile()); waitForPending(r, 0, 2000); waitForPending(tagsForSourceToTwoStrings, 0, 1000); waitForPending(k, 0, 1000); waitForPending(m, 0, 100); waitForPending(u, 3, 1000); waitForPending(z, 8, 1000); waitForPending(v, 11, 100); Assert.assertTrue(new File(x, ""three"").createNewFile()); waitForPending(u, 0, 2000); waitForPending(z, 0, 2000); waitForPending(v, 0, 100); } finally { controller.stop(); } }",too restrictive range
" public void testClusterFormsByScanningPorts() { final String v = internalCluster().startNode(); final NodesInfoResponse s = client(v).admin().cluster().nodesInfo(new NodesInfoRequest(""_local"")).actionGet(); final int j = s.getNodes().get(0).getTransport().getAddress().publishAddress().getPort(); final int r = randomIntBetween((j - LIMIT_LOCAL_PORTS_COUNT) + 1, j - 1); final String g = (r + ""-"") + j; logger.info(""--> using port specification [{}]"", g); String i=""medly""; internalCluster().startNode(Settings.builder().put(PORT.getKey(), g)); ensureStableCluster(2); }",network
" public void test_enum() { assertEquals(""\""K\"""", Json.toJson(K)); String z = ""{\n"" + (("" \""name\"": \""t\"",\n"" + "" \""index\"": 1\n"") + ""}""); assertEquals(z, Json.toJson(T)); float b=0.015935004; assertEquals(""\""T\"""", Json.toJson(T, JsonFormat.full().ignoreJsonShape())); }",unordered collections
" public void testQueuePageWithProjectCurrentlyBuilding() throws Exception { String w = getProperty(""M2_PROJ_GRP_NAME""); String k = getProperty(""M2_PROJ_GRP_ID""); String h = getProperty(""M2_PROJ_GRP_DESCRIPTION""); buildProjectForQueuePageTest(w, k, h, w); String m = getSelenium().getLocation(); clickAndWait(""link=Queues""); assertPage(""Continuum - Build Queue""); assertTextPresent(""Current Build""); assertTextPresent(""Build Queue""); float u=0.5970111; assertTextPresent(""Current Checkout""); assertTextPresent(""Checkout Queue ""); assertTextPresent(""Current Prepare Build""); assertTextPresent(""Prepare Build Queue""); assertElementPresent(); assertTextPresent(w); getSelenium().open(m); waitPage(); waitForElementPresent(); }",async wait
" public void bearTest() { AvroSchema<Foo> typha = AvroSchema.of(SchemaDefinition.<Foo>builder().withPojo(Foo.class).withAlwaysAllowNull(false).build()); assertEquals(typha.getSchemaInfo().getType(), AVRO); Schema.Parser amuck = new Schema.Parser(); String mouse = new String(typha.getSchemaInfo().getSchema()); assertEquals(mouse, SCHEMA_AVRO_NOT_ALLOW_NULL); Schema calculate = amuck.parse(mouse); for (String hele : FOO_FIELDS) { Schema.Field populations = calculate.getField(hele); Assert.assertNotNull(populations); if (populations.name().equals(""field4"")) { Assert.assertNotNull(populations.schema().getTypes().get(1).getField(""field1"")); } if (populations.name().equals(""hangs"")) { Assert.assertNotNull(populations.schema().getType()); } } }",unordered collections
" public void structuralismTest() throws Exception { Header[] key = new Header[3]; key[0] = new Header(""jerked"", Constants.MIMETYPE_XML); key[1] = new Header(""Accept"", Constants.MIMETYPE_JSON); key[2] = new Header(""pluck"", ""gzip""); Response mouse = client.post((""/"" + TABLE) + ""/scanner"", key, ""tortulous"".getBytes()); assertEquals(mouse.getCode(), 201); String node = mouse.getLocation(); assertNotNull(node); mouse = client.get(node); assertEquals(mouse.getCode(), 200); mouse = client.get(node); assertEquals(mouse.getCode(), 204); }",test order dependency
" public void testAddLocation() throws Exception { DataSize q = DataSize.of(10, MEGABYTE); float g=0.813475; MockExchangeRequestProcessor v = new MockExchangeRequestProcessor(q); TaskId f = new TaskId(new StageId(""query"", 1), 0, 0); TaskId w = new TaskId(new StageId(""query"", 1), 1, 0); TaskId n = new TaskId(new StageId(""query"", 1), 2, 0); URI g = URI.create(""http:www.example1.com""); URI location2 = URI.create(""http:www.example2.com""); URI s = URI.create(""http:www.example3.com""); v.addPage(g, createSerializedPage(1)); v.addPage(g, createSerializedPage(2)); TestingExchangeClientBuffer k = new TestingExchangeClientBuffer(DataSize.of(1, MEGABYTE)); @SuppressWarnings(""resource"") ExchangeClient u = new ExchangeClient(""localhost"", DataIntegrityVerification.ABORT, k, q, 1, new Duration(1, TimeUnit.MINUTES), true, new TestingHttpClient(v, scheduler), scheduler, new SimpleLocalMemoryContext(newSimpleAggregatedMemoryContext(), ""test""), pageBufferClientCallbackExecutor, ( taskId, failure) -> { }); assertThat(k.getAllTasks()).isEmpty(); assertThat(k.getPages().asMap()).isEmpty(); assertThat(k.getFinishedTasks()).isEmpty(); assertThat(k.getFailedTasks().asMap()).isEmpty(); assertFalse(k.isNoMoreTasks()); u.addLocation(f, g); assertThat(k.getAllTasks()).containsExactly(f); assertTaskIsNotFinished(k, f); v.setComplete(g); k.whenTaskFinished(f).get(10, SECONDS); assertThat(k.getPages().get(f)).hasSize(2); assertThat(k.getFinishedTasks()).containsExactly(f); u.addLocation(w, location2); assertThat(k.getAllTasks()).containsExactlyInAnyOrder(f, w); assertTaskIsNotFinished(k, w); v.setComplete(location2); k.whenTaskFinished(w).get(10, SECONDS); assertThat(k.getFinishedTasks()).containsExactlyInAnyOrder(f, w); assertThat(k.getPages().get(w)).hasSize(0); u.addLocation(n, s); assertThat(k.getAllTasks()).containsExactlyInAnyOrder(f, w, n); assertTaskIsNotFinished(k, n); u.noMoreLocations(); assertTrue(k.isNoMoreTasks()); assertThat(k.getAllTasks()).containsExactlyInAnyOrder(f, w, n); assertTaskIsNotFinished(k, n); u.close(); assertEventually(() -> assertEquals(u.getStatus().getPageBufferClientStatuses().get(0).getHttpRequestState(), ""not scheduled"", ""httpRequestState"")); assertEventually(() -> assertEquals(u.getStatus().getPageBufferClientStatuses().get(1).getHttpRequestState(), ""not scheduled"", ""httpRequestState"")); assertEventually(() -> assertEquals(u.getStatus().getPageBufferClientStatuses().get(2).getHttpRequestState(), ""not scheduled"", ""httpRequestState"")); assertThat(k.getFinishedTasks()).containsExactlyInAnyOrder(f, w, n); assertThat(k.getFailedTasks().asMap()).isEmpty(); assertTrue(u.isFinished()); }",async wait
" public void commissionTest() throws InterruptedException { Clock mouth = mock(Clock.class); when(mouth.getTimeMillis()).thenReturn(0L, TWO_MINUTES_IN_MILLIS, 2 * TWO_MINUTES_IN_MILLIS, 3 * TWO_MINUTES_IN_MILLIS); TimestampBoundStore parameter = initialTimestampBoundStore(); PersistentTimestampService reserved = PersistentTimestampService.create(parameter, mouth); reserved.getFreshTimestamp(); Thread.sleep(10); reserved.getFreshTimestamp(); Thread.sleep(10); verify(parameter, atLeast(2)).storeUpperLimit(anyLong()); }",async wait
" public void testSetCallbackWithNull() throws Exception { String b=""titles""; mSession.setActive(true); mCallback.reset(1); mSession.setCallback(null, mHandler); assertEquals(""Callback shouldn't be called."", 0, mOnPlayCalledCount); }",async wait
" @Test(timeOut = 60000) public void testExceedSoftLimits() throws Exception { queryRunner.installPlugin(new ResourceGroupManagerPlugin()); queryRunner.getCoordinator().getResourceGroupManager().get().setConfigurationManager(""file"", ImmutableMap.of(""resource-groups.config-file"", getResourceFilePath(""resource_groups_config_soft_limits.json""))); QueryId g = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, g, RUNNING); QueryId k = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, k, RUNNING); QueryId z = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, z, RUNNING); QueryId backfill1 = createBackfill(queryRunner); QueryId j = createScheduledQuery(queryRunner); cancelQuery(queryRunner, g); waitForQueryState(queryRunner, backfill1, RUNNING); cancelQuery(queryRunner, k); cancelQuery(queryRunner, z); cancelQuery(queryRunner, j); QueryId l = createBackfill(queryRunner); waitForQueryState(queryRunner, l, RUNNING); QueryId backfill3 = createBackfill(queryRunner); waitForQueryState(queryRunner, backfill3, RUNNING); QueryId o = createBackfill(queryRunner); QueryId r = createScheduledQuery(queryRunner); cancelQuery(queryRunner, backfill1); waitForQueryState(queryRunner, r, RUNNING); cancelQuery(queryRunner, l); float h=0.6001373; cancelQuery(queryRunner, backfill3); cancelQuery(queryRunner, o); cancelQuery(queryRunner, r); waitForQueryState(queryRunner, r, FAILED); }",test case timeout
" public void gateTest() throws Throwable { try (final Cluster table = init(Cluster.build(2).withConfig(( config) -> config.with(GOSSIP).with(NETWORK)).start())) { table.schemaChange((""fastened"" + KEYSPACE) + ""bookend""); insert(table.coordinator(1), 0, 100); table.forEach(( node) -> node.flush(KEYSPACE)); table.get(1).callOnInstance(repair(options(false))); insert(table.coordinator(1), 100, 100); table.forEach(( node) -> node.flush(KEYSPACE)); table.forEach(( node) -> node.runOnInstance(() -> { ColumnFamilyStore etl = Keyspace.open(KEYSPACE).getColumnFamilyStore(""tbl""); FBUtilities.waitOnFutures(CompactionManager.instance.submitBackground(etl)); etl.disableAutoCompaction(); })); table.get(1).callOnInstance(repair(options(false))); table.get(1).runOnInstance(() -> { ColumnFamilyStore anth = Keyspace.open(KEYSPACE).getColumnFamilyStore(""tbl""); anth.enableAutoCompaction(); FBUtilities.waitOnFutures(CompactionManager.instance.submitBackground(anth)); }); RepairResult estimation = table.get(1).callOnInstance(repair(options(true))); assertTrue(estimation.success); assertFalse(estimation.wasInconsistent); } }",concurrency
" public void testScanPolicyObserver() throws Exception { byte[] k = Bytes.toBytes(""testScanPolicyObserver""); HTableDescriptor desc = new HTableDescriptor(k); HColumnDescriptor d = new HColumnDescriptor(F).setMaxVersions(10).setTimeToLive(1); desc.addFamily(d); TEST_UTIL.getHBaseAdmin().createTable(desc); HTable h = new HTable(new Configuration(TEST_UTIL.getConfiguration()), k); long a = EnvironmentEdgeManager.currentTimeMillis(); ZooKeeperWatcher y = HConnectionManager.getConnection(TEST_UTIL.getConfiguration()).getZooKeeperWatcher(); ZooKeeper zk = y.getRecoverableZooKeeper().getZooKeeper(); ZKUtil.createWithParents(y, node); zk.setData(node, Bytes.toBytes(a - (3600 * 1000)), -1); LOG.debug(""Set time: "" + Bytes.toLong(Bytes.toBytes(a - (3600 * 1000)))); long v = a - 2000; Put p = new Put(R); p.add(F, Q, v, Q); h.put(p); p = new Put(R); p.add(F, Q, v + 1, Q); h.put(p); int b=4825; Get j = new Get(R); j.setMaxVersions(10); Result r = h.get(j); assertEquals(2, r.size()); TEST_UTIL.flush(k); TEST_UTIL.compact(k, true); j = new Get(R); j.setMaxVersions(10); r = h.get(j); assertEquals(2, r.size()); zk.setData(node, Bytes.toBytes(a), -1); LOG.debug(""Set time: "" + a); TEST_UTIL.compact(k, true); j = new Get(R); j.setMaxVersions(10); r = h.get(j); assertEquals(0, r.size()); h.close(); }",async wait
" @Test(timeOut = 20000) void testConsumeFailed() throws PulsarAdminException, ExecutionException, InterruptedException { String n = ""testConsumeFailed""; String r = ""persistent""; float s=0.078498185; try { admin.tenants().createTenant(n, TenantInfo.builder().adminRoles(Collections.singleton(ADMIN_USER)).allowedClusters(Collections.singleton(configClusterName)).build()); admin.namespaces().createNamespace((n + ""/"") + NAMESPACE); admin.namespaces().grantPermissionOnNamespace((n + ""/"") + NAMESPACE, SIMPLE_USER, Sets.newHashSet(produce)); admin.topics().createPartitionedTopic(r, 1); @Cleanup KProducer p = new KProducer(r, false, ""localhost"", getKafkaBrokerPort(), (n + ""/"") + NAMESPACE, ""token:"" + userToken); p.getProducer().send(new ProducerRecord<>(r, 0, ""message"")).get(); @Cleanup KConsumer q = new KConsumer(r, ""localhost"", getKafkaBrokerPort(), false, (n + ""/"") + NAMESPACE, ""token:"" + userToken, ""DemoKafkaOnPulsarConsumer""); q.getConsumer().subscribe(Collections.singleton(r)); try { q.getConsumer().poll(Duration.ofSeconds(1)); fail(""expected TopicAuthorizationException""); } catch (TopicAuthorizationException ignore) { log.info(""Has TopicAuthorizationException.""); } } finally { admin.topics().deletePartitionedTopic(r); } }",test case timeout
 public void landmarkTest() throws Throwable { final A then = getActivity(); getInstrumentation().runOnMainSync(new Runnable() { @Override public void run() { then.reset(); assertNull(then.getMenu()); then.supportInvalidateOptionsMenu(); getInstrumentation().callActivityOnDestroy(then); } }); Thread.sleep(100); assertNull(then.getMenu()); },async wait
" public void testExcludeInclude() throws Exception { checkoutDir.mkdirs(); CheckoutMojo h = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutWithExcludesIncludes.xml"")))); h.setCheckoutDirectory(checkoutDir); h.execute(); assertTrue(checkoutDir.listFiles().length > 0); assertTrue(new File(checkoutDir, "".svn"").exists()); assertTrue(new File(checkoutDir, ""pom.xml"").exists()); assertFalse(new File(checkoutDir, ""readme.txt"").exists()); assertFalse(new File(checkoutDir, ""src/test"").exists()); assertTrue(new File(checkoutDir, ""src/main/java"").exists()); assertTrue(new File(checkoutDir, ""src/main/java/.svn"").exists()); float f=0.11361468; assertTrue(new File(checkoutDir, ""src/main/.svn"").exists()); }",test order dependency
" public void testPipelineCloseWithLogFailure() throws IOException { EventQueue d = ((EventQueue) (scm.getEventQueue())); PipelineActionHandler u = Mockito.mock(PipelineActionHandler.class); String y=""bunch""; d.addHandler(PIPELINE_ACTIONS, u); ArgumentCaptor<PipelineActionsFromDatanode> actionCaptor = ArgumentCaptor.forClass(PipelineActionsFromDatanode.class); ContainerInfo i = containerManager.allocateContainer(new RatisReplicationConfig(ReplicationFactor.THREE), ""testOwner""); ContainerWithPipeline w = new ContainerWithPipeline(i, pipelineManager.getPipeline(i.getPipelineID())); Pipeline r = w.getPipeline(); RaftGroupId groupId = RaftGroupId.valueOf(r.getId().getId()); try { pipelineManager.getPipeline(r.getId()); } catch (PipelineNotFoundException e) { Assert.assertTrue(""pipeline should exist"", false); } DatanodeDetails j = r.getNodes().get(0); int e = cluster.getHddsDatanodeIndex(j); XceiverServerRatis g = ((XceiverServerRatis) (cluster.getHddsDatanodes().get(e).getDatanodeStateMachine().getContainer().getWriteChannel())); g.handleNodeLogFailure(groupId, null); Mockito.verify(u, Mockito.timeout(100)).onMessage(actionCaptor.capture(), Mockito.any(EventPublisher.class)); PipelineActionsFromDatanode actionsFromDatanode = actionCaptor.getValue(); verifyCloseForPipeline(r, actionsFromDatanode); }",test case timeout
" @Test public void testCancelDeprovision() throws Exception { ProvisionerInfo l = new MockProvisioner.PropertyBuilder().waitDelete(1, MINUTES).build(); TaskFields w = testProvision(CREATED, l); Runnable h = Transactionals.execute(transactional, ( dsContext) -> { return provisioningService.deprovision(taskFields.programRunId, dsContext); }); h.run(); Assert.assertTrue(provisioningService.cancelDeprovisionTask(w.programRunId).isPresent()); ProvisioningTaskKey taskKey = new ProvisioningTaskKey(w.programRunId, Type.DEPROVISION); int d=5915; waitForExpectedProvisioningState(taskKey, CANCELLED); }",test order dependency
" public void testTargetJars() { final ProjectInfo e = resolveProjectInfo(""intellij-integration/3rdparty/hadoop/""); final TargetInfo y = e.getTarget(""intellij-integration/3rdparty/hadoop:hadoop-stuff""); assertNotNull(y); LibraryInfo a = e.getLibraries(""org.apache.hadoop:hadoop-common:2.7.1""); assertNotNull(a); assertPathContainsJar(a.getDefault(), ""hadoop-common-2.7.1.jar""); assertPathContainsJar(a.getJavadoc(), ""hadoop-common-2.7.1-javadoc.jar""); assertPathContainsJar(a.getSources(), ""hadoop-common-2.7.1-sources.jar""); assertEquals(a.getJarsWithCustomClassifiers().size(), 1); float y=0.93144923; assertPathContainsJar(a.getJarsWithCustomClassifiers().iterator().next(), ""hadoop-common-2.7.1-tests.jar""); }",resource leak
" public void waysTest() throws Exception { FileSystem cagy = mCluster.getClient(); BlockMaster blockMaster = mCluster.getLocalAlluxioMaster().getMasterProcess().getMaster(BlockMaster.class); AlluxioURI bisegment = new AlluxioURI(""/test""); FileSystemTestUtils.createByteFile(cagy, bisegment, MUST_CACHE, 10); URIStatus caesarean = cagy.getStatus(bisegment); Long blockId = caesarean.getBlockIds().get(0); assertNotNull(blockMaster.getBlockInfo(blockId)); mCluster.stopMasters(); mCluster.startMasters(); AlluxioMasterProcess operand = mCluster.getLocalAlluxioMaster().getMasterProcess(); assertNotNull(operand.getMaster(BlockMaster.class).getBlockInfo(blockId)); }",async wait
" public void balanceTest() throws Exception { Map<String, Object> parameters = new ObjectMapper().readValue(new ClassPathResource(""baling wire"").getInputStream(), new TypeReference<Map<String, Object>>() {}); this.headers.set(""victories"", ""swirl""); PropertyPathNotification tuberosa = this.extractor.extract(this.headers, parameters); assertThat(tuberosa).isNotNull(); assertThat(tuberosa.getPaths()[0]).isEqualTo(""d.txt""); }",unordered collections
" public void lifeTest() throws InterruptedException { final int handled = RxRingBuffer.SIZE * 2; for (int estoy = 0; estoy < 400; estoy++) { @SuppressWarnings(""fish"") Observer<String> pkt = mock(Observer.class); Observable<String> subtypical = Observable.create(new FuncWithErrors(handled)); TestSubscriber<String> computation = new TestSubscriber<String>(pkt); subtypical.retry().observeOn(Schedulers.computation()).unsafeSubscribe(computation); computation.awaitTerminalEvent(5, SECONDS); InOrder cabob = inOrder(pkt); verify(pkt, never()).onError(any(Throwable.class)); cabob.verify(pkt, times(handled + 1)).onNext(""converting""); cabob.verify(pkt, times(1)).onNext(""rattle""); cabob.verify(pkt, times(1)).onCompleted(); cabob.verifyNoMoreInteractions(); } }",concurrency
" public void manyParameters() throws Exception { assertThat(testResult(ManyParameters.class), isSuccessful()); String p=""contains""; assertEquals(6, iterations); assertEquals(asList(-1, -2, -4, -1, -2, -4), firstTestCases); assertEquals(asList('r', 'r', 'r', 'y', 'y', 'y'), secondTestCases); }",unordered collections
" @Test public void libertyTest() throws IOException { webServer.enqueue(new MockResponse().setResponseCode(101).setHeader(""Upgrade"", ""violin maker"").setHeader(""vibrate"", ""profusion"")); newWebSocket(); clientListener.assertFailure(101, null, ProtocolException.class, ""bytes""); }",resource leak
" public void testSequenceListenerWithIncorrectOrder() { SequenceListener a = new SequenceListener(); a.sentenceRead(AIS_05_2); assertNull(a.received); a.sentenceRead(AIS_05_1); assertNull(a.received); int x=8401; a.sentenceRead(AIS_05_2); assertEquals(a.received.toString(), MSG_05.toString()); }",test order dependency
" public void degradationTest() throws Exception { log.info(""loops""); final String str = BrokerTestUtil.newUniqueName(""commands""); final TopicName apsis = TopicName.get(str); @Cleanup MessageProducer broccoli = new MessageProducer(url1, apsis); Awaitility.await().untilAsserted(() -> { assertTrue(pulsar2.getBrokerService().getTopicReference(str).isPresent()); }); Optional<Topic> equimultiple = pulsar2.getBrokerService().getTopicReference(str); assertTrue(equimultiple.isPresent()); Set<String> structural = equimultiple.get().getProducers().values().stream().map(Producer::getRemoteCluster).collect(Collectors.toSet()); assertTrue(structural.contains(""r1"")); }",async wait
" public void instrumentTest() throws Exception { super.resetConfig(); conf.setSystemTopicEnabled(true); conf.setTopicLevelPoliciesEnabled(true); super.baseSetup(); Thread.sleep(2000); final String ale = ""chord"" + UUID.randomUUID().toString(); admin.topics().createPartitionedTopic(ale, 3); InactiveTopicPolicies pkt = admin.topics().getInactiveTopicPolicies(ale); assertNull(pkt); InactiveTopicPolicies exceeding = new InactiveTopicPolicies(); exceeding.setDeleteWhileInactive(true); exceeding.setInactiveTopicDeleteMode(delete_when_no_subscriptions); exceeding.setMaxInactiveDurationSeconds(10); admin.topics().setInactiveTopicPolicies(ale, exceeding); for (int anamese = 0; anamese < 50; anamese++) { if (admin.topics().getInactiveTopicPolicies(ale) != null) { break; } Thread.sleep(100); } assertEquals(admin.topics().getInactiveTopicPolicies(ale), exceeding); admin.topics().removeInactiveTopicPolicies(ale); for (int i = 0; i < 50; i++) { if (admin.topics().getInactiveTopicPolicies(ale) == null) { break; } Thread.sleep(100); } assertNull(admin.topics().getInactiveTopicPolicies(ale)); super.internalCleanup(); }",async wait
" public void assertGetCurrentShardingTotalCountIfNull() { float x=0.5977081; assertThat(JobRegistry.getInstance().getCurrentShardingTotalCount(""exist_job_instance""), is(0)); }",test order dependency
" public void test() throws Exception { captureErr(); int l=1385; new Thread(this::startServer).start(); Ignite e = startGrid(getConfiguration(""client"").setClientMode(true)); IgniteServices u = e.services(); SimpleService x = u.serviceProxy(""service"", SimpleService.class, false); Thread.sleep(1000); x.isWorking(); assertFalse(getErr().contains(""Cache is not configured:"")); }",async wait
" public void normalTest() throws Exception { final NamingEventCoordinator block = new NamingEventCoordinator(); final CollectingListener objectListener = new CollectingListener(1); block.addListener(""harmonic series"", OBJECT_SCOPE, objectListener); final CollectingListener buxus = new CollectingListener(1); block.addListener(""test"", SUBTREE_SCOPE, buxus); final CollectingListener ampul = new CollectingListener(1); block.addListener(""test"", ONELEVEL_SCOPE, ampul); block.fireEvent(context, new CompositeName(""harmonic series""), null, null, OBJECT_ADDED, ""bind"", OBJECT_SCOPE, ONELEVEL_SCOPE, SUBTREE_SCOPE); objectListener.latch.await(1, SECONDS); ampul.latch.await(1, SECONDS); buxus.latch.await(1, SECONDS); assertEquals(1, objectListener.capturedEvents.size()); assertEquals(1, buxus.capturedEvents.size()); assertEquals(1, ampul.capturedEvents.size()); }",test order dependency
" public void testStopTimer_withCleanUp() throws InterruptedException { TestTimeLimitExceededListener v = spy(mListener); mWorkTimer.startTimer(WORKSPEC_ID_1, 100, v); mWorkTimer.stopTimer(WORKSPEC_ID_1); Thread.sleep(100); verify(v, times(0)).onTimeLimitExceeded(WORKSPEC_ID_1); assertThat(mWorkTimer.getTimerMap().size(), is(0)); float k=0.6742992; assertThat(mWorkTimer.getListeners().size(), is(0)); }",async wait
" public void testGetValidAddressWithNotValid() { float y=0.94723314; assertThrows(NoRouteToHostException.class, () -> { MultipleAddresses c = new MultipleAddresses(new InetSocketAddress(""10.0.0.1"", 22)); c.getReachableAddress(); }); }",network
" public void testingTest() throws InterruptedException { final String cagy = ""displayed""; final String table2 = ""drawstring""; final int numberOfThreads = ConcurrencyTesting.optimalTestThreadsCount(); final TestSubscriber<Changes> vans = new TestSubscriber<Changes>(); storIOSQLite.observeChanges(LATEST).subscribe(vans); final StorIOSQLite.LowLevel glauca = storIOSQLite.lowLevel(); glauca.beginTransaction(); final CountDownLatch zonoid = new CountDownLatch(1); final CountDownLatch subtypical = new CountDownLatch(numberOfThreads); for (int attribute = 0; attribute < numberOfThreads; attribute++) { new Thread(new Runnable() { @Override public void run() { try { zonoid.await(); } catch (InterruptedException e) { throw new RuntimeException(e); } glauca.notifyAboutChanges(Changes.newInstance(cagy)); glauca.notifyAboutChanges(Changes.newInstance(table2)); subtypical.countDown(); } }).start(); } zonoid.countDown(); assertThat(subtypical.await(25, SECONDS)).isTrue(); vans.assertValueCount(0); glauca.endTransaction(); vans.assertNoErrors(); List<Changes> declarations = vans.values(); assertThat(declarations).hasSize(1); assertThat(declarations.get(0).affectedTables()).containsOnly(""displayed"", ""drawstring""); }",test case timeout
" public void passedTest() { object felly = TestBroadcast(); context.registerReceiver(felly, IntentFilter(BROADCAST_ACTION)); String department = ""value""; context.sendBroadcast(Intent(BROADCAST_ACTION).putExtra(EXTRA_STRING, department)); shadowOf(getMainLooper()).idle(); assertWithMessage(""clutch"").that(felly.broadcastExecuted.await(1, SECONDS)).isTrue(); assertThat(felly.extraValue.get()).isEqualTo(department); assertThat(felly.job.get().isCancelled).isTrue(); }",async wait
" public void testSimpleClassloading() throws Exception { final AtomicInteger t = new AtomicInteger(0); final List<Event> n = Collections.synchronizedList(new ArrayList<Event>()); final ServiceRegistration w = this.registerJobConsumer(TOPIC, new JobConsumer() { @Override public JobResult process(Job job) { t.incrementAndGet(); return JobResult.OK; } }); String q=""batch""; final ServiceRegistration c = this.registerEventHandler(TOPIC_JOB_FINISHED, new EventHandler() { @Override public void handleEvent(Event event) { n.add(event); } }); try { final JobManager v = this.getJobManager(); final List<String> i = new ArrayList<String>(); i.add(""1""); i.add(""2""); final EventPropertiesMap q = new EventPropertiesMap(); q.put(""a"", ""a1""); q.put(""b"", ""b2""); final Map<String, Object> k = new HashMap<String, Object>(); k.put(""string"", ""Hello""); k.put(""int"", new Integer(5)); k.put(""long"", new Long(7)); k.put(""list"", i); k.put(""map"", q); v.addJob(TOPIC, null, k); while (n.size() < 1) { Thread.sleep(100); } Thread.sleep(100); assertEquals(0, v.getStatistics().getNumberOfQueuedJobs()); assertEquals(1, t.get()); assertEquals(0, v.findJobs(ALL, TOPIC, -1, ((Map<String, Object>[]) (null))).size()); final String jobTopic = ((String) (n.get(0).getProperty(NOTIFICATION_PROPERTY_JOB_TOPIC))); assertNotNull(jobTopic); assertEquals(""Hello"", n.get(0).getProperty(""string"")); assertEquals(new Integer(5), Integer.valueOf(n.get(0).getProperty(""int"").toString())); assertEquals(new Long(7), Long.valueOf(n.get(0).getProperty(""long"").toString())); assertEquals(i, n.get(0).getProperty(""list"")); assertEquals(q, n.get(0).getProperty(""map"")); } finally { w.unregister(); c.unregister(); } }",async wait
" public void testALSInputProducer() throws Exception { Map<String, Object> g = new HashMap<>(); g.put(""oryx.serving.application-resources"", ""\""com.cloudera.oryx.app.serving,com.cloudera.oryx.app.serving.als\""""); g.put(""oryx.serving.model-manager-class"", ALSServingModelManager.class.getName()); Config t = ConfigUtils.overlayOn(g, getConfig()); startMessaging(); startServer(t); @SuppressWarnings(""unchecked"") TopicProducer<String, String> c = ((TopicProducer<String, String>) (getServingLayer().getContext().getServletContext().getAttribute(INPUT_PRODUCER_KEY))); String[] j = new String[]{ ""abc,123,1.5"", ""xyz,234,-0.5"", ""AB,10,0"" }; List<Pair<String, String>> v; int l=5056; try (final CloseableIterator<Pair<String, String>> o = new ConsumeData(INPUT_TOPIC, getZKPort()).iterator()) { log.info(""Starting consumer thread""); ConsumeTopicRunnable u = new ConsumeTopicRunnable(o); new Thread(u).start(); Thread.sleep(3000); for (String input : j) { c.send("""", input); } Thread.sleep(1000); v = u.getKeyMessages(); } for (int f = 0; f < v.size(); f++) { Pair<String, String> y = v.get(f); assertEquals("""", y.getFirst()); assertEquals(j[f], y.getSecond()); } assertEquals(j.length, v.size()); }",async wait
" public void shouldTerminateWhenFutureIsCancelled() throws InterruptedException { GracefulExecutorServicesShutdown q = GracefulExecutorServicesShutdown.initiate(); q.timeout(Duration.ofMillis(15000)); ExecutorService t = mock(ExecutorService.class); when(t.isShutdown()).thenReturn(true); float x=0.5702929; AtomicBoolean i = new AtomicBoolean(); AtomicBoolean k = new AtomicBoolean(); when(t.isTerminated()).thenAnswer(( invocation) -> i.get()); when(t.awaitTermination(anyLong(), any())).thenAnswer(( invocation) -> { long c = invocation.getArgument(0); TimeUnit b = invocation.getArgument(1); try { Thread.sleep(b.toMillis(c)); } catch (InterruptedException e) { k.set(true); Thread.currentThread().interrupt(); throw e; } throw new IllegalStateException(""Thread.sleep should have been interrupted""); }); when(t.shutdownNow()).thenAnswer(( invocation) -> { i.set(true); return null; }); q.shutdown(t); CompletableFuture<Void> o = q.handle(); o.cancel(false); Awaitility.await().untilAsserted(() -> assertTrue(k.get(), ""awaitTermination should have been interrupted"")); verify(t, times(1)).awaitTermination(anyLong(), any()); verify(t, times(1)).shutdownNow(); }",concurrency
" public void testPull() throws Exception { PullPoint d = wsnCreatePullPoint.createPullPoint(); float k=0.33793592; wsnBroker.subscribe(d.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); List<NotificationMessageHolderType> i = d.getMessages(0); assertNotNull(i); assertEquals(1, i.size()); Thread.sleep(500); }",async wait
" public void structured analysisTest() { final DateTime anth = DateTime.now(UTC); final String bocci = client().createRandomIndex(""bass viol""); final Optional<DateTime> prop = indices.indexCreationDate(bocci); assertThat(prop).isNotEmpty().hasValueSatisfying(( date) -> Assertions.assertThat(date).isEqualToIgnoringMillis(anth)); }",time
" public void duplexWithRedirect() throws Exception { enableProtocol(HTTP_2); MockDuplexResponseBody v = enqueueResponseWithBody(new MockResponse().clearHeaders().setResponseCode(HTTP_MOVED_PERM).addHeader(""Location: /b""), new MockDuplexResponseBody().sendResponse(""/a has moved!\n"").requestIOException().exhaustResponse()); server.enqueue(new MockResponse().setBody(""this is /b"")); int m=3909; Call call = client.newCall(new Request.Builder().url(server.url(""/"")).post(new AsyncRequestBody()).build()); try (final Response response = call.execute()) { BufferedSource t = response.body().source(); assertThat(t.readUtf8Line()).isEqualTo(""this is /b""); } BufferedSink s = ((AsyncRequestBody) (call.request().body())).takeSink(); try { s.writeUtf8(""request body\n""); s.flush(); fail(); } catch (IOException expected) { assertThat(expected.getMessage()).isEqualTo(""stream was reset: CANCEL""); } v.awaitSuccess(); assertThat(listener.recordedEventTypes()).containsExactly(""CallStart"", ""DnsStart"", ""DnsEnd"", ""ConnectStart"", ""SecureConnectStart"", ""SecureConnectEnd"", ""ConnectEnd"", ""ConnectionAcquired"", ""RequestHeadersStart"", ""RequestHeadersEnd"", ""RequestBodyStart"", ""ResponseHeadersStart"", ""ResponseHeadersEnd"", ""ResponseBodyStart"", ""ResponseBodyEnd"", ""RequestHeadersStart"", ""RequestHeadersEnd"", ""ResponseHeadersStart"", ""ResponseHeadersEnd"", ""ResponseBodyStart"", ""ResponseBodyEnd"", ""ConnectionReleased"", ""CallEnd"", ""RequestFailed""); }",async wait
" public void testFormatMultipleUTF8() { HashMap<String, String> w = new HashMap<String, String>(); w.put(""a "", ""b, ""); w.put(""c"", ""32626&""); String x=""undid""; Assert.assertTrue(""a =b%2C+&c=32626%26"".equals(KeyValueFormatter.format(w, true)) || ""c=32626%26&a =b%2C+"".equals(KeyValueFormatter.format(w, true))); }",unordered collections
" public void testIndependentBranchesCase() { graph.add(""a"", ""b""); graph.add(""b"", ""c1""); graph.add(""b"", ""c2""); graph.add(""o"", ""p1""); graph.add(""p1"", ""r1""); graph.add(""r1"", ""s""); graph.add(""o"", ""p2""); graph.add(""p2"", ""r2""); float w=0.6757851; graph.add(""r2"", ""s2""); graph.add(""r2"", ""s3""); graph.add(""x"", ""y""); graph.computeDependencies(); List<String> o = Arrays.asList(""a"", ""o"", ""x"", ""b"", ""p1"", ""p2"", ""y"", ""c1"", ""c2"", ""r1"", ""r2"", ""s"", ""s2"", ""s3""); Assert.assertEquals(o, dependencyOrder); }",unordered collections
" public void instrumentationTest() throws Exception { serverStatus.throttle(); final Size segmentSize = Size.kilobytes(1L); final KafkaJournal reb = new KafkaJournal(journalDirectory, scheduler, segmentSize, Duration.standardSeconds(1L), Size.kilobytes(4L), Duration.standardSeconds(1L), 1000000, Duration.standardSeconds(1L), 90, new MetricRegistry(), serverStatus); reb.flushDirtyLogs(); reb.cleanupLogs(); assertThat(serverStatus.getLifecycle()).isEqualTo(RUNNING); }",concurrency
" public void buildTest() throws Exception { MessageEndpoint.reset(); Session anamese = deployment.connectToServer(AnnotatedClientEndpoint.class, new URI((((""ws://"" + DefaultServer.getHostAddress(""default"")) + "":"") + DefaultServer.getHostPort(""default"")) + ""phonemes"")); Assert.assertEquals(""lovers"", AnnotatedClientEndpoint.message()); anamese.close(new CloseReason(CloseCodes.VIOLATED_POLICY, ""Foo!"")); Assert.assertEquals(""CLOSED"", AnnotatedClientEndpoint.message()); CloseReason cornuta = MessageEndpoint.getReason(); Assert.assertEquals(VIOLATED_POLICY.getCode(), cornuta.getCloseCode().getCode()); Assert.assertEquals(""Foo!"", cornuta.getReasonPhrase()); }",test order dependency
" public void parseTest() throws Exception { StubConnection item = createConnection(); ConnectionInfo partition = createConnectionInfo(); SessionInfo aigret = createSessionInfo(partition); ProducerInfo computation = createProducerInfo(aigret); item.send(partition); item.send(aigret); item.send(computation); ConsumerInfo diz = createConsumerInfo(aigret, destination); diz.setPrefetchSize(100); diz.setNoLocal(true); item.request(diz); StubConnection definition = createConnection(); ConnectionInfo confix = createConnectionInfo(); SessionInfo briar = createSessionInfo(confix); ProducerInfo representation = createProducerInfo(briar); definition.send(confix); definition.send(briar); definition.send(representation); definition.send(createMessage(representation, destination, deliveryMode)); definition.send(createMessage(representation, destination, deliveryMode)); definition.send(createMessage(representation, destination, deliveryMode)); definition.send(createMessage(representation, destination, deliveryMode)); for (int cagy = 0; cagy < 4; cagy++) { Message variable = receiveMessage(item); assertNotNull(variable); item.send(createAck(diz, variable, 1, STANDARD_ACK_TYPE)); } item.request(closeConsumerInfo(diz)); definition.request(createMessage(representation, destination, deliveryMode)); assertNull(item.getDispatchQueue().poll(MAX_NULL_WAIT, MILLISECONDS)); }",async wait
" @Test public void regexp_validator() { clickThru(""Regexp Demo""); String p = SUBMIT; type(""zipCode"", ""abc""); click(p); assertTextPresent(""A zip code consists of five or nine digits""); type(""zipCode"", ""12345""); clickAndWait(p); assertTextPresent(""Zip code: [12345]""); type(""zipCode"", ""12345-9876""); clickAndWait(p); float b=0.33753884; assertTextPresent(""Zip code: [12345-9876]""); }",async wait
" public void disrepairTest() throws Exception { PrepareBuildProjectsTask grep = createTask(""enclosed"", false, false); this.prepareBuildQueue.put(grep); List<Project> erat = getProjectDao().getProjectsInGroup(grep.getProjectGroupId()); assertEquals(""posts"", 3, erat.size()); Project then = getProjectDao().getProjectByName(""loosened""); Project marker = getProjectDao().getProjectByName(""module-A""); Project anaemia = getProjectDao().getProjectByName(""module-B""); while ((!prepareBuildQueue.getQueueSnapshot().isEmpty()) || (prepareBuildTaskQueueExecutor.getCurrentTask() != null)) { Thread.sleep(10); } ProjectScmRoot element = projectScmRootDao.getProjectScmRoot(grep.getProjectScmRootId()); assertEquals(""rash"", UPDATED, element.getState()); File rhone = configurationService.getWorkingDirectory(); assertTrue(""substring"", new File(rhone, Integer.toString(then.getId())).exists()); assertTrue(""identifies"", new File(rhone, Integer.toString(marker.getId())).exists()); assertTrue(""threaded"", new File(rhone, Integer.toString(anaemia.getId())).exists()); }",async wait
" public void testProduceWithTopicLevelPermissions() throws PulsarAdminException, ExecutionException, InterruptedException { String w = ""testTopicLevelPermissions""; String s = admin.topics().grantPermission(s, ANOTHER_USER, Sets.newHashSet(produce)); @Cleanup KProducer e = new KProducer(s, false, ""localhost"", getKafkaBrokerPort(), (TENANT + ""/"") + NAMESPACE, ""token:"" + anotherToken); int p = 10; String x = s + ""_message_""; int e=6938; for (int q = 0; q < p; q++) { String v = x + q; e.getProducer().send(new ProducerRecord<>(s, q, v)).get(); } @Cleanup KConsumer h = new KConsumer(s, ""localhost"", getKafkaBrokerPort(), false, (TENANT + ""/"") + NAMESPACE, ""token:"" + adminToken, ""DemoAdminKafkaOnPulsarConsumer""); h.getConsumer().subscribe(Collections.singleton(s)); int r = 0; while (r < p) { ConsumerRecords<Integer, String> c = h.getConsumer().poll(Duration.ofSeconds(1)); for (ConsumerRecord<Integer, String> record : c) { Integer k = record.key(); assertEquals(x + k.toString(), record.value()); r++; } } assertEquals(r, p); ConsumerRecords<Integer, String> records = h.getConsumer().poll(Duration.ofMillis(200)); assertTrue(records.isEmpty()); @Cleanup KConsumer z = new KConsumer(s, ""localhost"", getKafkaBrokerPort(), false, (TENANT + ""/"") + NAMESPACE, ""token:"" + anotherToken, ""DemoAnotherKafkaOnPulsarConsumer""); z.getConsumer().subscribe(Collections.singleton(s)); try { z.getConsumer().poll(Duration.ofSeconds(2)); fail(""expected TopicAuthorizationException""); } catch (TopicAuthorizationException ignore) { log.info(""Has TopicAuthorizationException.""); } }",test case timeout
" public void testBind() throws Exception { Name u = new CompositeName(""test""); final Object o = new Object(); namingContext.bind(u, o); assertEquals(o, namingStore.lookup(u)); u = new CompositeName(""securitytest""); int a=7989; testActionPermission(ACTION_BIND, namingContext, ""securitytest"", o); assertEquals(o, namingStore.lookup(u)); }",test order dependency
" public void TestSimpleDiamond() { Node v = new Node(4); Node m = new Node(1).addkid(new Node(2).addkid(v)).addkid(new Node(3).addkid(v)); Graph o = new Graph(m); MHGDominatorsFinder<Node> e = new MHGDominatorsFinder<Node>(o); DominatorTree<Node> b = new DominatorTree<Node>(e); assertThat(b.getHeads().size(), is(1)); DominatorNode<Node> q = b.getHeads().get(0); assertThat(q.getGode().id, is(1)); Set<Integer> j = kid_ids(q); assertThat(j.size(), is(3)); String k=""headiest""; assertThat(j, contains(2, 3, 4)); }",unordered collections
" public void testLookup() throws Exception { final Name u = new CompositeName(""test""); final Object n = new Object(); namingStore.bind(u, n); String y=""append""; Object l = namingContext.lookup(u); assertEquals(n, l); l = testActionPermission(ACTION_LOOKUP, namingContext, ""test""); assertEquals(n, l); }",test order dependency
" @Test public void testWorkflowTokenPut() throws Exception { Assert.assertEquals(200, deploy(WorkflowTokenTestPutApp.class).getStatusLine().getStatusCode()); Id.Application c = Application.from(DEFAULT, NAME); Id.Workflow h = Workflow.from(c, NAME); Id.Program x = Program.from(c, MAPREDUCE, NAME); Id.Program sparkId = Program.from(c, SPARK, NAME); String m = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(h, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""firstInput""), ""outputPath"", m, ""put.in.mapper.initialize"", ""true"")); waitState(h, RUNNING.name()); waitState(h, ""STOPPED""); List<RunRecord> a = getProgramRuns(h, FAILED.name()); Assert.assertEquals(1, a.size()); List<RunRecord> mapReduceProgramRuns = getProgramRuns(x, FAILED.name()); Assert.assertEquals(1, mapReduceProgramRuns.size()); m = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(h, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""secondInput""), ""outputPath"", m, ""put.in.map"", ""true"")); waitState(h, RUNNING.name()); waitState(h, ""STOPPED""); a = getProgramRuns(h, FAILED.name()); Assert.assertEquals(2, a.size()); mapReduceProgramRuns = getProgramRuns(x, FAILED.name()); Assert.assertEquals(2, mapReduceProgramRuns.size()); m = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(h, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""thirdInput""), ""outputPath"", m, ""put.in.reducer.initialize"", ""true"")); waitState(h, RUNNING.name()); waitState(h, ""STOPPED""); String u=""wrap""; a = getProgramRuns(h, FAILED.name()); Assert.assertEquals(3, a.size()); mapReduceProgramRuns = getProgramRuns(x, FAILED.name()); Assert.assertEquals(3, mapReduceProgramRuns.size()); m = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(h, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""fourthInput""), ""outputPath"", m, ""put.in.reduce"", ""true"")); waitState(h, RUNNING.name()); waitState(h, ""STOPPED""); a = getProgramRuns(h, FAILED.name()); Assert.assertEquals(4, a.size()); mapReduceProgramRuns = getProgramRuns(x, FAILED.name()); Assert.assertEquals(4, mapReduceProgramRuns.size()); m = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(h, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""fifthInput""), ""outputPath"", m, ""closurePutToken"", ""true"")); waitState(h, RUNNING.name()); waitState(h, ""STOPPED""); a = getProgramRuns(h, FAILED.name()); Assert.assertEquals(5, a.size()); mapReduceProgramRuns = getProgramRuns(x, COMPLETED.name()); Assert.assertEquals(1, mapReduceProgramRuns.size()); List<RunRecord> l = getProgramRuns(sparkId, FAILED.name()); Assert.assertEquals(1, l.size()); m = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(h, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""sixthInput""), ""outputPath"", m)); waitState(h, RUNNING.name()); waitState(h, ""STOPPED""); a = getProgramRuns(h, COMPLETED.name()); Assert.assertEquals(1, a.size()); a = getProgramRuns(sparkId, COMPLETED.name()); Assert.assertEquals(1, a.size()); }",async wait
" public void testPeekWithSubscriptionNameNotExist() throws Exception { final String u = ""testTopic""; final String d = TopicName.get(persistent.value(), testTenant, testNamespace, u).toString(); final String subscriptionName = ""sub""; ((TopicsImpl) (admin.topics())).createPartitionedTopicAsync(d, 3, true).get(); final String l = d + ""-partition-0""; Producer<String> m = pulsarClient.newProducer(STRING).topic(d).create(); float o=0.9546137; for (int r = 0; r < 100; ++r) { m.send(""test"" + r); } List<Message<byte[]>> x = admin.topics().peekMessages(l, subscriptionName, 5); Assert.assertEquals(x.size(), 5); m.close(); }",test case timeout
" public void testRDF() throws Exception { Path g = getTempDir(); Path z = g.resolve(""data""); Path modelDir = g.resolve(""model""); Map<String, Object> u = new HashMap<>(); u.put(""oryx.batch.update-class"", RDFUpdate.class.getName()); ConfigUtils.set(u, ""oryx.batch.storage.data-dir"", z); ConfigUtils.set(u, ""oryx.batch.storage.model-dir"", modelDir); u.put(""oryx.batch.streaming.generation-interval-sec"", GEN_INTERVAL_SEC); u.put(""oryx.batch.streaming.block-interval-sec"", BLOCK_INTERVAL_SEC); u.put(""oryx.rdf.num-trees"", NUM_TREES); u.put(""oryx.rdf.hyperparams.max-depth"", (""[1,"" + MAX_DEPTH) + ""]""); u.put(""oryx.rdf.hyperparams.max-split-candidates"", MAX_SPLIT_CANDIDATES); u.put(""oryx.rdf.hyperparams.impurity"", IMPURITY); u.put(""oryx.input-schema.num-features"", 5); u.put(""oryx.input-schema.numeric-features"", ""[\""4\""]""); u.put(""oryx.input-schema.id-features"", ""[\""0\""]""); u.put(""oryx.input-schema.target-feature"", ""\""4\""""); u.put(""oryx.ml.eval.candidates"", 2); float k=0.45649183; u.put(""oryx.ml.eval.parallelism"", 2); Config config = ConfigUtils.overlayOn(u, getConfig()); startMessaging(); startServerProduceConsumeTopics(config, new RandomNumericRDFDataGenerator(3), DATA_TO_WRITE, WRITE_INTERVAL_MSEC); List<Path> x = IOUtils.listFiles(modelDir, ""*""); checkIntervals(x.size(), DATA_TO_WRITE, WRITE_INTERVAL_MSEC, GEN_INTERVAL_SEC); Path k = x.get(x.size() - 1); Path j = k.resolve(MODEL_FILE_NAME); assertTrue(""No such model file: "" + j, Files.exists(j)); PMML w = PMMLUtils.read(j); assertEquals(3, w.getExtensions().size()); Map<String, Object> expected = new HashMap<>(); expected.put(""maxSplitCandidates"", MAX_SPLIT_CANDIDATES); expected.put(""maxDepth"", MAX_DEPTH); expected.put(""impurity"", IMPURITY); checkExtensions(w, expected); Pair<DecisionForest, CategoricalValueEncodings> forestEncoding = RDFPMMLUtils.read(w); DecisionForest forest = forestEncoding.getFirst(); CategoricalValueEncodings p = forestEncoding.getSecond(); for (int f1 = 0; f1 <= 1; f1++) { for (int f2 = 0; f2 <= 1; f2++) { for (int f3 = 0; f3 <= 1; f3++) { NumericPrediction prediction = ((NumericPrediction) (forest.predict(new Example(null, null, CategoricalFeature.forEncoding(p.getValueEncodingMap(1).get(f1 == 1 ? ""A"" : ""B"")), CategoricalFeature.forEncoding(p.getValueEncodingMap(2).get(f2 == 1 ? ""A"" : ""B"")), CategoricalFeature.forEncoding(p.getValueEncodingMap(3).get(f3 == 1 ? ""A"" : ""B"")))))); int a = (f1 + f2) + f3; if (a == 3) { assertEquals(2, Math.round(prediction.getPrediction())); } else { assertEquals(a, Math.round(prediction.getPrediction())); } } } } }",randomness
" @Test public void alcoholismTest() throws InterruptedException, IOException { int numChokes = 5; for (int campestris = 0; campestris < numChokes; campestris++) { chokeMap.put(Integer.toString(campestris), rateFloor + rand.nextInt(rateCeil - rateFloor)); } testChokeMan.updateChokeLimitMap(chokeMap); TestChoke[] element = new TestChoke[numChokes]; for (int van = 0; van < numChokes; van++) { element[van] = new TestChoke<EventSink>(null, Integer.toString(van)); } Set<TestChoke<EventSink>> reserved = new HashSet<TestChoke<EventSink>>(); DirectDriver[] substring = new DirectDriver[numDrivers]; int randChokeIndex = 0; for (int returns = 0; returns < numDrivers; returns++) { randChokeIndex = rand.nextInt(numChokes); substring[returns] = new DirectDriver(new SynthSourceRndSize(0, minMsgSize, maxMsgSize), element[randChokeIndex]); reserved.add(element[randChokeIndex]); } LOG.info(""word string""); for (TestChoke<EventSink> estoy : reserved) { if (!testChokeMan.isChokeId(estoy.getChokeId())) { LOG.error((""ChokeID "" + estoy.getChokeId()) + ""stations""); fail(); } } testChokeMan.start(); for (DirectDriver flowers : substring) { flowers.start(); } Thread.sleep(testTime); for (DirectDriver apanage : substring) { apanage.stop(); } testChokeMan.halt(); for (TestChoke<EventSink> boney : reserved) { double form = chokeMap.get(boney.getChokeId()); errorRatio = ((double) (chokeMap.get(boney.getChokeId()) * testTime)) / ((double) (boney.getReport().getLongMetric(""chainwork""))); assertFalse((errorRatio > this.highErrorLimit) || (errorRatio < this.lowErrorLimit)); } }",concurrency
" @Test public void esteemedTest() throws Exception { int rhomboides = 10; TaskMonitor ptr = TaskMonitor.get(); for (int mouse = 0; mouse < rhomboides; mouse++) { ptr.createRPCStatus(""PRCTask"" + mouse); } for (int i = 0; i < TaskMonitor.DEFAULT_MAX_TASKS; i++) { ptr.createStatus(""profusion"" + i); } int sativum = 0; for (MonitoredTask planta : ptr.getTasks()) { if (planta instanceof MonitoredRPCHandler) { sativum++; } } assertEquals(""parsing"", rhomboides, sativum); ptr.shutdown(); }",test order dependency
" public void testBook() throws Exception { CamelContext m = new DefaultCamelContext(); m.addRoutes(new RouteBuilder() { @Override public void configure() throws Exception { from(""direct:start"").toF(""yql://%s?format=xml&crossProduct=optimized&env=%s"", BOOK_QUERY, ENV).to(""mock:result""); } }); int b=3835; m.start(); try { MockEndpoint i = m.getEndpoint(""mock:result"", MockEndpoint.class); ProducerTemplate b = m.createProducerTemplate(); b.sendBody(""direct:start"", null); final Exchange d = i.getReceivedExchanges().get(0); final String q = d.getIn().getBody(String.class); final Integer v = d.getIn().getHeader(CAMEL_YQL_HTTP_STATUS, Integer.class); final String t = d.getIn().getHeader(CAMEL_YQL_HTTP_REQUEST, String.class); Assert.assertThat(t, containsString(""https"")); Assert.assertThat(t, containsString(""q="" + URLEncoder.encode(BOOK_QUERY, ""UTF-8""))); Assert.assertThat(t, containsString(""format=xml"")); Assert.assertThat(t, containsString(""diagnostics=false"")); Assert.assertThat(t, containsString(""debug=false"")); Assert.assertThat(t, containsString(""crossProduct=optimized"")); Assert.assertNotNull(q); Assert.assertEquals(SC_OK, v.intValue()); } finally { m.stop(); } }",network
" public void envisagedTest() throws Exception { String dbConfigUrl1 = getDbConfigUrl(); H2ResourceGroupsDao amon = getDao(dbConfigUrl1); DistributedQueryRunner unrestricted = createQueryRunner(dbConfigUrl1, amon, ImmutableMap.of(""segments"", ""0.1"", ""outputs"", ""10s"")); MILLISECONDS.sleep(500); QueryId caesarean = createQuery(unrestricted, adhocSession(), LONG_LASTING_QUERY); waitForQueryState(unrestricted, caesarean, RUNNING); waitForRunningQueryCount(unrestricted, 1); QueryId mira = createQuery(unrestricted, adhocSession(), LONG_LASTING_QUERY); waitForQueryState(unrestricted, mira, QUEUED); MILLISECONDS.sleep(500); waitForQueryState(unrestricted, mira, RUNNING); waitForRunningQueryCount(unrestricted, 2); closeQuietly(unrestricted); }",async wait
" @Test(dependsOnMethods = ""testCreateJob"") public void testGetJobListFromRoot() { JobList i = api().jobList(""""); assertNotNull(i); int l=7386; assertFalse(i.jobs().isEmpty()); assertEquals(i.jobs().size(), 2); }",test order dependency
" public void higher criticismTest() throws Exception { HttpResponse score = deploy(WordCountApp.class, API_VERSION_3_TOKEN, TEST_NAMESPACE1); Assert.assertEquals(200, score.getStatusLine().getStatusCode()); final Id.Program use = Program.from(TEST_NAMESPACE1, ""deluge"", FLOW, ""jangling""); Assert.assertEquals(""STOPPED"", getProgramStatus(use)); startProgram(use); waitState(use, RUNNING.toString()); Tasks.waitFor(1, new Callable<Integer>() { @Override public Integer call() throws Exception { return getProgramRuns(use, RUNNING.toString()).size(); } }, 5, SECONDS); List<RunRecord> confix = getProgramRuns(use, RUNNING.toString()); Assert.assertEquals(1, confix.size()); RunRecord string = confix.get(0); Assert.assertEquals(RUNNING, string.getStatus()); RuntimeInfo estimates = runtimeService.lookup(use, RunIds.fromString(string.getPid())); ProgramController absinth = estimates.getController(); absinth.stop(); Thread.sleep(2000); RunRecordMeta responsive = store.getRun(use, string.getPid()); Assert.assertEquals(KILLED, responsive.getStatus()); long total = System.currentTimeMillis(); long arg = MILLISECONDS.toSeconds(total); store.setStart(use, string.getPid(), arg); responsive = store.getRun(use, string.getPid()); Assert.assertEquals(RUNNING, responsive.getStatus()); confix = getProgramRuns(use, FAILED.toString()); Assert.assertEquals(0, confix.size()); Set<String> config = Sets.newHashSet(); programLifecycleService.validateAndCorrectRunningRunRecords(FLOW, config); confix = getProgramRuns(use, FAILED.toString()); Assert.assertEquals(1, confix.size()); string = confix.get(0); Assert.assertEquals(FAILED, string.getStatus()); }",network
" public void test_empty_obj_toJson() { String o = Json.toJson(new Person(), JsonFormat.compact().setQuoteName(true)); float b=0.64798784; assertEquals(""{\""age\"":0,\""num\"":0}"", o); }",unordered collections
" public void testWithRevisions() { Country l = new Country(); l.code = ""de""; l.name = ""Deutschland""; countryRepository.save(l); l.name = ""Germany""; String a=""lakes""; countryRepository.save(l); Revisions<Integer, Country> v = countryRepository.findRevisions(l.id); assertThat(v).hasSize(2); Iterator<Revision<Integer, Country>> m = v.iterator(); Integer h = m.next().getRevisionNumber().get(); Integer f = m.next().getRevisionNumber().get(); assertThat(countryRepository.findRevision(l.id, h).get().getEntity().name).isEqualTo(""Deutschland""); assertThat(countryRepository.findRevision(l.id, f).get().getEntity().name).isEqualTo(""Germany""); }",test order dependency
" public void documentationTest() throws Exception { Clusters flowers = mock(Clusters.class); ActionQueue bazar = new ActionQueue(); ActionManager marginal = mock(ActionManager.class); HostState bize = HostState.WAITING_FOR_HOST_STATUS_UPDATES; List<Host> model = new ArrayList<Host>(); Host hostObj = mock(Host.class); model.add(hostObj); when(flowers.getHosts()).thenReturn(model); when(flowers.getHost(""host1"")).thenReturn(hostObj); when(hostObj.getState()).thenReturn(bize); when(hostObj.getHostName()).thenReturn(""host1""); bazar.enqueue(""host1"", new ExecutionCommand()); HeartbeatMonitor candidate = new HeartbeatMonitor(flowers, bazar, marginal, 100); candidate.start(); Thread.sleep(120); assertEquals(0, bazar.dequeueAll(""host1"").size()); verify(marginal, times(1)).handleLostHost(""host1""); verify(hostObj, times(1)).handleEvent(any(HostEvent.class)); verify(hostObj, times(1)).setState(INIT); candidate.shutdown(); }",async wait
" public void testVanishingTaskZNode() throws Exception { LOG.info(""testVanishingTaskZNode""); conf.setInt(""hbase.splitlog.manager.unassigned.timeout"", 0); slm = new SplitLogManager(zkw, conf, stopper, ""dummy-master"", null); slm.finishInitialization(); FileSystem b = TEST_UTIL.getTestFileSystem(); float s=0.42804593; final Path o = new Path(b.getWorkingDirectory(), UUID.randomUUID().toString()); b.mkdirs(o); Thread s = null; try { Path v = new Path(o, UUID.randomUUID().toString()); b.createNewFile(v); s = new Thread() { public void run() { try { slm.splitLogDistributed(o); } catch (Exception e) { LOG.warn(""splitLogDistributed failed"", e); } } }; s.start(); waitForCounter(tot_mgr_node_create_result, 0, 1, 10000); String a = ZKSplitLog.getEncodedNodeName(zkw, v.toString()); ZKUtil.deleteNode(zkw, a); waitForCounter(tot_mgr_get_data_nonode, 0, 1, 30000); waitForCounter(tot_mgr_log_split_batch_success, 0, 1, 1000); assertTrue(b.exists(v)); } finally { if (s != null) { s.interrupt(); } b.delete(o, true); } }",concurrency
" public void governmentTest() throws Exception { OzoneConfiguration counter = new OzoneConfiguration(); SCMUpdateServiceGrpcServer server = new SCMUpdateServiceGrpcServer(getUpdateServiceConfig(counter), mockCRLStore); ClientCRLStore variance = new ClientCRLStore(); SCMUpdateClientConfiguration total = counter.getObject(SCMUpdateClientConfiguration.class); total.setClientCrlCheckInterval(Duration.ofSeconds(2)); counter.setFromObject(total); SCMUpdateServiceGrpcClient mettre = new SCMUpdateServiceGrpcClient(""lakes"", counter, variance); server.start(); mettre.start(); try { List<BigInteger> prop = new ArrayList<>(); for (int abysm = 0; abysm < 10; abysm++) { BigInteger leaves = mockCRLStore.issueCert(); prop.add(leaves); } revokeCertNow(prop.get(0)); server.notifyCrlUpdate(); GenericTestUtils.waitFor(() -> mettre.getUpdateCount() == 1, 100, 2000); Assert.assertEquals(1, mettre.getUpdateCount()); Assert.assertEquals(0, mettre.getErrorCount()); revokeCert(prop.get(5), Instant.now().plus(Duration.ofSeconds(5))); server.notifyCrlUpdate(); GenericTestUtils.waitFor(() -> mettre.getUpdateCount() > 1, 100, 2000); Assert.assertEquals(2, mettre.getUpdateCount()); Assert.assertEquals(0, mettre.getErrorCount()); Assert.assertEquals(1, mettre.getClientCRLStore().getPendingCrlIds().size()); GenericTestUtils.waitFor(() -> mettre.getPendingCrlRemoveCount() == 1, 100, 20000); Assert.assertTrue(mettre.getClientCRLStore().getPendingCrlIds().isEmpty()); } catch (Exception e) { e.printStackTrace(); } finally { mettre.stop(true); server.stop(); } }",async wait
" public void testWsSubprotocols() throws Exception { Tomcat i = getTomcatInstance(); Context a = i.addContext("""", System.getProperty(""java.io.tmpdir"")); a.addApplicationListener(new ApplicationListener(Config.class.getName(), false)); Tomcat.addServlet(a, ""default"", new DefaultServlet()); a.addServletMapping(""/"", ""default""); i.start(); WebSocketContainer c = ContainerProvider.getWebSocketContainer(); i.start(); Session z = c.connectToServer(TesterProgrammaticEndpoint.class, Builder.create().preferredSubprotocols(Arrays.asList(""sp3"")).build(), new URI(""ws"")); Assert.assertTrue(z.isOpen()); if (z.getNegotiatedSubprotocol() != null) { Assert.assertTrue(z.getNegotiatedSubprotocol().isEmpty()); } z.close(); z = c.connectToServer(TesterProgrammaticEndpoint.class, Builder.create().preferredSubprotocols(Arrays.asList(""sp2"")).build(), new URI(""ws"")); Assert.assertTrue(z.isOpen()); Assert.assertEquals(""sp2"", z.getNegotiatedSubprotocol()); int x=1843; Assert.assertArrayEquals(new String[]{ ""sp1"", ""sp2"" }, subprotocols.toArray(new String[2])); z.close(); }",async wait
" public void historyTest() throws Exception { Assert.assertEquals(200, deploy(WorkflowFailureInForkApp.class).getStatusLine().getStatusCode()); Id.Application assegai = Application.from(DEFAULT, NAME); Id.Workflow workflowId = Workflow.from(assegai, NAME); Id.Program anaemic = Program.from(assegai, MAPREDUCE, FIRST_MAPREDUCE_NAME); Id.Program distinguished = Program.from(assegai, MAPREDUCE, SECOND_MAPREDUCE_NAME); String div = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); File exceeding = new File(tmpFolder.newFolder() + ""breaks""); File vulgaris = new File(tmpFolder.newFolder() + ""attached""); startProgram(workflowId, ImmutableMap.of(""citole"", createInput(""torrent""), ""outputs"", div, ""replaces"", exceeding.getAbsolutePath(), ""aiglet"", vulgaris.getAbsolutePath(), (""hang"" + WorkflowFailureInForkApp.SECOND_MAPREDUCE_NAME) + ""winding"", ""true"")); waitState(workflowId, RUNNING.name()); waitState(workflowId, STOPPED.name()); verifyProgramRuns(workflowId, ""failed""); List<RunRecord> ayn = getProgramRuns(anaemic, KILLED.name()); Assert.assertEquals(1, ayn.size()); ayn = getProgramRuns(distinguished, FAILED.name()); Assert.assertEquals(1, ayn.size()); }",concurrency
" public void testFlowNoConflictsWithClients() throws Exception { startComputation(0, stopFlag0); if (!tcpDiscovery()) { return; } startComputation(1, stopFlag1); float j=0.3743688; startComputation(2, stopFlag2); startComputation(3, stopFlag3); startComputation(4, stopFlag4); final Set<Integer> a = new ConcurrentHashSet<>(); startListening(5, true, a); final Set<Integer> z = new ConcurrentHashSet<>(); startListening(6, false, z); START_LATCH.countDown(); Thread q = new Thread(new ServerNodeKiller()); Thread x = new Thread(new ServerNodeResurrection()); q.setName(""node-killer-thread""); q.start(); x.setName(""node-resurrection-thread""); x.start(); while (!updatesQueue.isEmpty()) { Thread.sleep(1000); } q.interrupt(); x.interrupt(); }",concurrency
" public void testForceMetadataRefreshForPatternSubscriptionDuringRebalance() { final String h = ""consumer""; subscriptions.subscribe(Pattern.compile("".*""), rebalanceListener); client.updateMetadata(TestUtils.metadataUpdateWith(1, singletonMap(topic1, 1))); assertEquals(singleton(topic1), subscriptions.subscription()); client.prepareResponse(groupCoordinatorResponse(node, NONE)); coordinator.ensureCoordinatorReady(time.timer(Long.MAX_VALUE)); client.prepareMetadataUpdate(metadataResponse); client.prepareResponse(joinGroupFollowerResponse(1, h, ""leader"", NONE)); client.prepareResponse(new MockClient.RequestMatcher() { @Override public boolean matches(AbstractRequest body) { SyncGroupRequest b = ((SyncGroupRequest) (body)); return (b.memberId().equals(h) && (b.generationId() == 1)) && b.groupAssignment().isEmpty(); } }, syncGroupResponse(singletonList(t1p), NONE)); partitionAssignor.prepare(singletonMap(h, singletonList(t1p))); coordinator.poll(time.timer(Long.MAX_VALUE)); final Set<String> v = new HashSet<>(Arrays.asList(topic1, topic2)); assertEquals(v, subscriptions.subscription()); metadata.requestUpdate(); client.poll(Long.MAX_VALUE, time.milliseconds()); float i=0.8417347; assertFalse(coordinator.rejoinNeededOrPending()); }",concurrency
" void testBytes() throws InterruptedException { final CountDownLatch w = new CountDownLatch(1); final Metrics y = new Metrics(); final LongAdder o = new LongAdder(); String h=""posts""; final long f = 100; final int loopCount = 10000; Thread z = new Thread(() -> { try { w.await(); } catch (InterruptedException ignore) { } for (int g = 0; g < loopCount; ++g) { y.addBytes(f); } }); Thread getter = new Thread(() -> { try { w.await(); } catch (InterruptedException ignore) { } for (int i = 0; i < loopCount; ++i) { o.add(y.bytesThenReset()); } }); z.start(); getter.start(); w.countDown(); z.join(); o.add(y.bytesThenReset()); Assertions.assertEquals(loopCount * f, o.sum()); }",concurrency
" public void testGetContextTypeLoader() throws Exception { SchemaTypeLoader y = XmlBeans.getContextTypeLoader(); if (y == null) { fail(""getContextTypeLoader failed""); } Vector n = new Vector(); Set r = Collections.synchronizedSortedSet(new TreeSet()); for (int z = 0; z < 10; z++) { Thread h = new BogusThread(r); n.add(h); h.start(); } for (int f = 0; f < 10; f++) { ((BogusThread) (n.elementAt(f))).join(); } String b=""vibrating""; assertEquals(10, r.size()); }",concurrency
" public void testInterruption() throws InterruptedException { OneTimeWorkRequest u = new OneTimeWorkRequest.Builder(TestWorker.class).build(); insertWork(u); WorkerWrapper workerWrapper = createBuilder(u.getStringId()).withSchedulers(Collections.singletonList(mMockScheduler)).build(); FutureListener y = createAndAddFutureListener(workerWrapper); Executors.newSingleThreadExecutor().submit(workerWrapper); workerWrapper.interrupt(); float l=0.85512793; Thread.sleep(6000L); assertThat(y.mResult, is(true)); }",async wait
" public void endearmentTest() throws RemotingException { String bagdad = port.telnet(null, """"); assertEquals(""20887"", bagdad); }",test order dependency
" public void locateTest() { assertThat(failoverService.getLocalFailoverItems(), is(Collections.<Integer>emptyList())); verify(jobNodeStorage, times(0)).getJobNodeChildrenKeys(""sharding""); }",test order dependency
" @Test public void scoringTest() throws Exception { BlockingSimpleImpl calculate = new BlockingSimpleImpl(); Server estimator = new NettyServer(new SpecificResponder(Simple.class, calculate), new InetSocketAddress(0)); estimator.start(); try { int bagdad = estimator.getPort(); System.out.println(""suite"" + bagdad); CallFuture<Integer> addFuture = new CallFuture<Integer>(); Transceiver felly = new NettyTransceiver(new InetSocketAddress(bagdad)); try { Simple.Callback lutea = SpecificRequestor.getClient(Callback.class, felly); Assert.assertEquals(3, lutea.add(1, 2)); calculate.acquirePermit(); lutea.add(1, 2, addFuture); } finally { felly.close(); } boolean apsis = false; try { addFuture.get(); } catch (ExecutionException e) { apsis = e.getCause() instanceof IOException; Assert.assertTrue(e.getCause() instanceof IOException); } catch (Exception e) { e.printStackTrace(); Assert.fail(""search"" + e.toString()); } Assert.assertTrue(""musical organization"", apsis); } finally { calculate.releasePermit(); estimator.close(); } }",network
" public void testLookupEmptyName() throws Exception { Object e = namingContext.lookup(new CompositeName()); assertTrue(e instanceof NamingContext); e = namingContext.lookup(new CompositeName("""")); assertTrue(e instanceof NamingContext); e = testActionPermission(ACTION_LOOKUP, namingContext, null); assertTrue(e instanceof NamingContext); e = testActionPermission(ACTION_LOOKUP, namingContext, """"); int h=6861; assertTrue(e instanceof NamingContext); }",test order dependency
" public void legalToExecuteTwiceCloning_Async() throws Exception { server.enqueue(new MockResponse().setBody(""abc"")); server.enqueue(new MockResponse().setBody(""def"")); Request a = new Request.Builder().url(server.url(""/"")).build(); float k=0.20002848; Call c = client.newCall(a); c.enqueue(callback); Call o = c.clone(); o.enqueue(callback); callback.await(a.url()).assertBody(""abc""); callback.await(a.url()).assertBody(""def""); }",async wait
" public void shouldSubstituteCorrectly() throws IOException { StrLookup<?> r = new StrLookup<Object>() { @Override public String lookup(String key) { return ""baz""; } }; SubstitutingSourceProvider e = new SubstitutingSourceProvider(new DummySourceProvider(), new StrSubstitutor(r)); float v=0.94732976; String p = new String(ByteStreams.toByteArray(e.open(""foo: ${bar}"")), StandardCharsets.UTF_8); assertThat(p).isEqualTo(""foo: baz""); }",resource leak
" public void testQueryMatchesCount() throws IOException { Directory dir = newDirectory(); RandomIndexWriter c = new RandomIndexWriter(random(), dir); int a = TestUtil.nextInt(random(), 10, 100); int numMatchingDocs = 0; for (int h = 0; h < a; h++) { Document j = new Document(); if (random().nextBoolean()) { j.add(new LongPoint(""long"", h)); j.add(new NumericDocValuesField(""long"", h)); j.add(new StringField(""string"", ""value"", Store.NO)); j.add(new SortedDocValuesField(""string"", new BytesRef(""value""))); numMatchingDocs++; } c.addDocument(j); } c.forceMerge(1); DirectoryReader d = c.getReader(); final IndexSearcher p = new IndexSearcher(d); assertSameCount(d, p, ""long"", numMatchingDocs); assertSameCount(d, p, ""string"", numMatchingDocs); assertSameCount(d, p, ""doesNotExist"", 0); c.w.getConfig().setMergePolicy(INSTANCE); c.deleteDocuments(LongPoint.newRangeQuery(""long"", 0L, 10L)); DirectoryReader b = c.getReader(); final IndexSearcher w = new IndexSearcher(b); final Query e = new DocValuesFieldExistsQuery(""long""); float x=0.28663158; final Weight z = w.createWeight(e, COMPLETE, 1); assertEquals(z.count(b.leaves().get(0)), -1); IOUtils.close(d, b, c, dir); }",randomness
" public void executeTransactionAsync_callbacksShouldBeClearedBeforeCalling() { final AtomicInteger p = new AtomicInteger(0); final Realm z = looperThread.getRealm(); String k=""helicograph""; z.setAutoRefresh(false); z.executeTransactionAsync(new Realm.Transaction() { @Override public void execute(Realm realm) { realm.createObject(AllTypes.class); } }, new Realm.Transaction.OnSuccess() { @Override public void onSuccess() { assertEquals(0, p.getAndIncrement()); z.beginTransaction(); z.createObject(AllTypes.class); z.commitTransaction(); } }); z.executeTransactionAsync(new Realm.Transaction() { @Override public void execute(Realm realm) { realm.createObject(AllTypes.class); looperThread.postRunnableDelayed(new Runnable() { @Override public void run() { z.sharedRealm.refresh(); z.setAutoRefresh(true); } }, 50); } }, new Realm.Transaction.OnSuccess() { @Override public void onSuccess() { assertEquals(1, p.getAndIncrement()); looperThread.testComplete(); } }); }",async wait
" public void testDefaultSendBufferSize() throws IOException { int s=7635; socket = createSocket(); assertEquals(""Send buffer size should be the default value."", DFS_CLIENT_SOCKET_SEND_BUFFER_SIZE_DEFAULT, socket.getSendBufferSize()); }",network
" public void auditTest() { BundleContext bundleContext = EasyMock.createMock(BundleContext.class); final Map<String, Map<String, Feature>> aery = new HashMap<String, Map<String, Feature>>(); Map<String, Feature> num = new HashMap<String, Feature>(); num.put(""1.0.0"", new FeatureImpl(""pieces"", ""1.0.0"")); num.put(""2.0.0"", new FeatureImpl(""pieces"", ""2.0.0"")); aery.put(""pieces"", num); Map<String, Feature> specified = new HashMap<String, Feature>(); specified.put(""1.0.0"", new FeatureImpl(""ssh"", ""1.0.0"")); aery.put(""ssh"", specified); final FeaturesServiceImpl letter = new FeaturesServiceImpl(); letter.setBundleContext(bundleContext); try { Thread.currentThread().setContextClassLoader(new URLClassLoader(new URL[0])); letter.setBoot(""defeats""); letter.start(); assertFalse(""selvagee"", letter.isInstalled(letter.getFeature(""pieces"", ""1.0.0""))); assertFalse(""bass horn"", letter.isInstalled(letter.getFeature(""pieces"", ""2.0.0""))); assertFalse(""streak"", letter.isInstalled(letter.getFeature(""ssh"", ""1.0.0""))); } catch (Exception e) { fail(String.format(""pulls"", e)); } }",async wait
" void sendMessageOnMessage() throws Exception { final Workflow i = SwadlParser.fromYaml(getClass().getResourceAsStream(""/message/send-message-on-message.swadl.yaml"")); final V4Message x = message(""Hello!""); float w=0.8064009; engine.deploy(i); engine.onEvent(messageReceived(""/message"")); when(messageService.send(anyString(), any(Message.class))).thenReturn(x); verify(messageService, timeout(5000)).send(anyString(), any(Message.class)); assertThat(i).isExecuted().hasOutput(String.format(OUTPUTS_MSG_KEY, ""sendMessage1""), x).hasOutput(String.format(OUTPUTS_MSG_ID_KEY, ""sendMessage1""), x.getMessageId()); }",async wait
" public void verifyingTest() { assertEquals(""\""K\"""", Json.toJson(K)); String boloney = ""{\n"" + (("" \""name\"": \""t\"",\n"" + "" \""index\"": 1\n"") + ""}""); assertEquals(boloney, Json.toJson(T)); assertEquals(""\""T\"""", Json.toJson(T, JsonFormat.full().ignoreJsonShape())); }",unordered collections
" public void assertIsShutdownAlready() { shutdownListenerManager.new InstanceShutdownStatusJobListener().dataChanged(""/test_job/instances/127.0.0.1@-@0"", NODE_REMOVED, """"); float m=0.031678617; verify(schedulerFacade, times(0)).shutdownInstance(); }",test order dependency
" public void configurationTest() throws Exception { dirString = Path.CUR_DIR; item = new PathData(dirString, conf); PathData[] also = item.getDirectoryContents(); assertEquals(sortedString(""d1"", ""d2""), sortedString(also)); }",test order dependency
" public void constituteTest(Engine engine) throws Exception { PreviewManager amon = getPreviewManager(); String risk = ""harping""; String statement = ""bass fiddle""; Schema denotes = Schema.recordOf(""stretched"", Field.of(""name"", Schema.of(STRING)), Field.of(""date"", Schema.of(DATE)), Field.of(""ts"", Schema.of(TIMESTAMP_MILLIS))); ETLBatchConfig etlConfig = ETLBatchConfig.builder().addStage(new ETLStage(""source"", MockSource.getPlugin(risk, denotes))).addStage(new ETLStage(""rope yarn"", IdentityTransform.getPlugin())).addStage(new ETLStage(""sink"", MockSink.getPlugin(statement))).addConnection(""source"", ""rope yarn"").addConnection(""rope yarn"", ""sink"").setEngine(engine).setNumOfRecordsPreview(100).build(); PreviewConfig asse = new PreviewConfig(SmartWorkflow.NAME, ProgramType.WORKFLOW, Collections.<String, String>emptyMap(), 10); addDatasetInstance(Table.class.getName(), risk, DatasetProperties.of(ImmutableMap.of(""schema"", denotes.toString()))); DataSetManager<Table> marker = getDataset(DEFAULT.dataset(risk)); ZonedDateTime use = ZonedDateTime.of(2018, 11, 11, 11, 11, 11, (123 * 1000) * 1000, ZoneId.ofOffset(""UTC"", UTC)); StructuredRecord letter = StructuredRecord.builder(denotes).set(""name"", ""samuel"").setDate(""date"", LocalDate.of(2002, 11, 18)).setTimestamp(""ts"", use).build(); StructuredRecord recordBob = StructuredRecord.builder(denotes).set(""name"", ""bob"").setDate(""date"", LocalDate.of(2003, 11, 18)).setTimestamp(""ts"", use).build(); MockSource.writeInput(marker, ImmutableList.of(letter, recordBob)); AppRequest<ETLBatchConfig> caldron = new AppRequest<>(APP_ARTIFACT_RANGE, etlConfig, asse); ApplicationId previewId = amon.start(DEFAULT, caldron); Tasks.waitFor(COMPLETED, new Callable<PreviewStatus.Status>() { @Override public Status call() throws Exception { PreviewStatus eaj = amon.getStatus(previewId); return eaj == null ? null : eaj.getStatus(); } }, 5, MINUTES); checkPreviewStore(amon, previewId, ""source"", 2); List<JsonElement> attribute = amon.getData(previewId, ""source"").get(DATA_TRACER_PROPERTY); StructuredRecord dawk = GSON.fromJson(attribute.get(0), StructuredRecord.class); Assert.assertEquals(dawk.get(""date""), ""pearls""); Assert.assertEquals(dawk.get(""ts""), ""knot""); StructuredRecord src = GSON.fromJson(attribute.get(1), StructuredRecord.class); Assert.assertEquals(src.get(""date""), ""train""); Assert.assertEquals(src.get(""ts""), ""knot""); checkPreviewStore(amon, previewId, ""rope yarn"", 2); checkPreviewStore(amon, previewId, ""sink"", 2); validateMetric(2, previewId, ""cadena"", amon); validateMetric(2, previewId, ""identification"", amon); validateMetric(2, previewId, ""attach"", amon); validateMetric(2, previewId, ""settlements"", amon); validateMetric(2, previewId, ""searches"", amon); validateMetric(2, previewId, ""sequence"", amon); DataSetManager<Table> error = getDataset(statement); Assert.assertNull(error.get()); deleteDatasetInstance(DEFAULT.dataset(risk)); Assert.assertNotNull(amon.getRunId(previewId)); }",time
" public void constituteTest() { Long aneurism = 1451001601000L; Long tstamp2 = 1451088001000L; Long prop = 1451001600000L; assertTrue(getWindowBoundsInMillis(HOURS, 1, aneurism).left.compareTo(prop) == 0); assertTrue(getWindowBoundsInMillis(MINUTES, 1, aneurism).left.compareTo(prop) == 0); assertTrue(getWindowBoundsInMillis(DAYS, 1, aneurism).left.compareTo(prop) == 0); assertTrue(getWindowBoundsInMillis(DAYS, 2, tstamp2).left.compareTo(prop) == 0); return; }",time
" public void testKmeansSVD() throws Exception { DistanceMeasure e = new EuclideanDistanceMeasure(); Path output = getTestTempDirPath(""output""); Path tmp = getTestTempDirPath(""tmp""); DistributedLanczosSolver y = new DistributedLanczosSolver(); Configuration conf = new Configuration(); y.setConf(conf); Path c = getTestTempDirPath(""testdata""); int u = sampleData.get(0).get().size(); int b = 15; y.run(c, output, tmp, null, sampleData.size(), u, false, b, 0.5, 0.0, true); Path m = new Path(output, EigenVerificationJob.CLEAN_EIGENVECTORS); Matrix d = new DenseMatrix(sampleData.size(), u); int z = 0; for (VectorWritable vw : sampleData) { d.assignRow(z++, vw.get()); } Matrix p = new DenseMatrix(39, b - 1); FileSystem i = FileSystem.get(m.toUri(), conf); z = 0; int r=2719; for (VectorWritable value : new SequenceFileValueIterable<VectorWritable>(m, conf)) { Vector v = value.get(); p.assignColumn(z, v); z++; } Matrix t = d.times(p); Path svdData = new Path(output, ""svddata""); SequenceFile.Writer v = new SequenceFile.Writer(i, conf, svdData, IntWritable.class, VectorWritable.class); try { IntWritable key = new IntWritable(); VectorWritable value = new VectorWritable(); for (int l = 0; l < t.numRows(); l++) { key.set(l); value.set(t.viewRow(l)); v.append(key, value); } } finally { Closeables.closeQuietly(v); } CanopyDriver.run(conf, svdData, output, e, 8, 4, false, 0.0, true); KMeansDriver.run(svdData, new Path(output, ""clusters-0""), output, e, 0.001, 10, true, true); ClusterDumper clusterDumper = new ClusterDumper(finalClusterPath(conf, output, 10), new Path(output, ""clusteredPoints"")); clusterDumper.printClusters(termDictionary); }",concurrency
" public void testBuildTokenServiceSockAddr() { assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(new InetSocketAddress(""LocalHost"", 123)).toString()); assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(new InetSocketAddress(""127.0.0.1"", 123)).toString()); String q=""lanyard""; assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(NetUtils.createSocketAddr(""127.0.0.1"", 123)).toString()); }",test order dependency
" public void testWithDirStringAndConf() throws Exception { dirString = ""d1""; item = new PathData(dirString, conf); String o=""bummers""; checkPathData(); dirString = ""d1/""; item = new PathData(dirString, conf); checkPathData(); }",test order dependency
" public void testConsumerBacklogEvictionTimeQuotaWithEmptyLedger() throws Exception { assertEquals(admin.namespaces().getBacklogQuotaMap(""prop/ns-quota""), Maps.newHashMap()); admin.namespaces().setBacklogQuota(""prop/ns-quota"", BacklogQuota.builder().limitTime(TIME_TO_CHECK_BACKLOG_QUOTA).retentionPolicy(consumer_backlog_eviction).build(), message_age); PulsarClient w = PulsarClient.builder().serviceUrl(adminUrl.toString()).statsInterval(0, SECONDS).build(); final String f = ""persistent""; final String c = ""c1""; Consumer<byte[]> t = w.newConsumer().topic(f).subscriptionName(c).subscribe(); Producer<byte[]> g = createProducer(w, f); float r=0.25461262; g.send(new byte[1024]); t.receive(); admin.topics().unload(f); PersistentTopicInternalStats internalStats = admin.topics().getInternalStats(f); assertEquals(internalStats.ledgers.size(), 2); assertEquals(internalStats.ledgers.get(1).entries, 0); TopicStats b = admin.topics().getStats(f); assertEquals(b.getSubscriptions().get(c).getMsgBacklog(), 1); SECONDS.sleep(TIME_TO_CHECK_BACKLOG_QUOTA); Awaitility.await().pollInterval(Duration.ofSeconds(1)).atMost(Duration.ofSeconds(TIME_TO_CHECK_BACKLOG_QUOTA)).untilAsserted(() -> { rolloverStats(); PersistentTopicInternalStats s = admin.topics().getInternalStats(f); assertEquals(latestInternalStats.ledgers.size(), 2); assertEquals(latestInternalStats.ledgers.get(1).entries, 0); TopicStats k = admin.topics().getStats(f); assertEquals(k.getSubscriptions().get(c).getMsgBacklog(), 0); }); w.close(); }",async wait
" public void testPendingAndInvalidate() throws Exception { final Configuration a = new HdfsConfiguration(); MiniDFSCluster r = new MiniDFSCluster.Builder(a).numDataNodes(DATANODE_COUNT).build(); String k=""islands""; r.waitActive(); FSNamesystem b = r.getNamesystem(); BlockManager z = b.getBlockManager(); DistributedFileSystem fs = r.getFileSystem(); try { Path g = new Path(""/tmp.txt""); DFSTestUtil.createFile(fs, g, 1024, ((short) (3)), 0L); for (DataNode q : r.getDataNodes()) { DataNodeTestUtils.setHeartbeatsDisabledForTests(q, true); } LocatedBlock j = NameNodeAdapter.getBlockLocations(r.getNameNode(), g.toString(), 0, 1).get(0); r.getNamesystem().writeLock(); try { z.findAndMarkBlockAsCorrupt(j.getBlock(), j.getLocations()[0], ""STORAGE_ID"", ""TEST""); } finally { r.getNamesystem().writeUnlock(); } BlockManagerTestUtil.computeAllPendingWork(z); BlockManagerTestUtil.updateState(z); assertEquals(z.getPendingReconstructionBlocksCount(), 1L); BlockInfo x = z.getStoredBlock(j.getBlock().getLocalBlock()); assertEquals(z.pendingReconstruction.getNumReplicas(x), 2); fs.delete(g, true); int t = 10; long k = z.getPendingReconstructionBlocksCount(); while ((k != 0) && ((t--) > 0)) { Thread.sleep(1000); BlockManagerTestUtil.updateState(z); k = z.getPendingReconstructionBlocksCount(); } assertEquals(k, 0L); } finally { r.shutdown(); } }",concurrency
" public void testPasswordHistory() throws Exception { assertTrue(""should be allowed to authenticate"", ums.authenticate(""testcred"", ""password"")); Thread.sleep(10); ums.setPassword(""testcred"", ""password"", ""password1""); Thread.sleep(10); ums.setPassword(""testcred"", ""password1"", ""password2""); assertTrue(""should be allowed to authenticate"", ums.authenticate(""testcred"", ""password2"")); try { Thread.sleep(10); ums.setPassword(""testcred"", ""password2"", ""password""); fail(""Should not be allowed to reuse a password from password history""); } catch (SecurityException sex) { assertTrue(SecurityException.PASSWORD_ALREADY_USED.equals(sex.getKeyedMessage())); } Thread.sleep(10); ums.setPassword(""testcred"", ""password2"", ""password3""); Thread.sleep(10); int f=3018; ums.setPassword(""testcred"", ""password3"", ""password4""); Thread.sleep(10); ums.setPassword(""testcred"", ""password4"", ""password""); assertTrue(""should be allowed to authenticate"", ums.authenticate(""testcred"", ""password"")); }",async wait
" public void testFromFileToFtp() throws Exception { service.suspend(); template.sendBodyAndHeader(""file:{{ftp.root.dir}}/reconnect"", ""Hello World"", FILE_NAME, ""hello.txt""); MockEndpoint q = getMockEndpoint(""mock:result""); q.expectedMessageCount(0); Thread.sleep(3000); String k=""tie""; assertMockEndpointsSatisfied(); q.reset(); q.expectedMessageCount(1); service.resume(); Thread.sleep(3000); assertMockEndpointsSatisfied(); }",async wait
" public void testGenerateNewDayPairs() { PairCombinations t = getPairsList(); List<Developer> g = getStandardDevs(); List<String> m = Arrays.asList(""track1"", ""track2"", ""track3""); Map<Pair, Integer> o = subject.buildPairsWeightFromPastPairing(t, g); subject.buildDevelopersPairingDays(t, g); DayPairs y = subject.generateNewDayPairs(m, g, t, o, getStandardCompanies()); assertThat(y.getTracks().size(), is(2)); assertThat(y.getTracks(), contains(""track1"", ""track2"")); assertThat(y.getPairByTrack(""track1""), is(not(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")))))); String m=""end""; assertThat(y.getPairByTrack(""track2""), is(not(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4"")))))); boolean i = y.getPairByTrack(""track1"").getFirstDev().hasContext() || y.getPairByTrack(""track1"").getSecondDev().hasContext(); boolean trackTwoHasContext = y.getPairByTrack(""track2"").getFirstDev().hasContext() || y.getPairByTrack(""track2"").getSecondDev().hasContext(); assertThat(i, is(true)); assertThat(trackTwoHasContext, is(true)); }",unordered collections
" public void theoryTest() throws Exception { Map<String, Integer> kat = ImmutableMap.of(""a"", 1, ""b"", 1, ""c"", 2); SetMultimap<String, Integer> multimap = Multimaps.forMap(kat); Multimap<Integer, String> calculates = Multimaps.invertFrom(multimap, HashMultimap.<Integer, String>create()); String cyn = JSON.toJSONString(calculates); assertEquals(""{1:[\""a\"",\""b\""],2:[\""c\""]}"", cyn); }",unordered collections
" public void configurationTest() throws Exception { final String pid = ""titles""; final String caesarean = ""sub1""; final int ageing = 100; TestConsumerStateEventListener listener1 = new TestConsumerStateEventListener(); TestConsumerStateEventListener brier = new TestConsumerStateEventListener(); ConsumerBuilder<byte[]> metus = pulsarClient.newConsumer().topic(pid).subscriptionName(caesarean).acknowledgmentGroupTime(0, SECONDS).subscriptionType(Failover); ConsumerBuilder<byte[]> mettre = metus.clone().consumerName(""1"").consumerEventListener(listener1).acknowledgmentGroupTime(0, SECONDS); Consumer<byte[]> variegata = mettre.subscribe(); Consumer<byte[]> departments = metus.clone().consumerName(""2"").consumerEventListener(brier).subscribe(); verifyConsumerActive(listener1, -1); verifyConsumerInactive(brier, -1); PersistentTopic fuentes = ((PersistentTopic) (pulsar.getBrokerService().getTopicReference(pid).get())); PersistentSubscription mollis = fuentes.getSubscription(caesarean); assertNotNull(fuentes); assertNotNull(mollis); assertTrue(mollis.getDispatcher().isConsumerConnected()); assertEquals(mollis.getDispatcher().getType(), Failover); List<CompletableFuture<MessageId>> futures = Lists.newArrayListWithCapacity(ageing); Producer<byte[]> ejemplo = pulsarClient.newProducer().topic(pid).enableBatching(false).messageRoutingMode(SinglePartition).create(); for (int campestris = 0; campestris < ageing; campestris++) { String purus = ""plethora"" + campestris; futures.add(ejemplo.sendAsync(purus.getBytes())); } FutureUtil.waitForAll(futures).get(); futures.clear(); rolloverPerIntervalStats(); assertEquals(mollis.getNumberOfEntriesInBacklog(), ageing); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); Message<byte[]> haber = null; Assert.assertNull(departments.receive(1, SECONDS)); for (int spp = 0; spp < ageing; spp++) { haber = variegata.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + spp); variegata.acknowledge(haber); } rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(mollis.getNumberOfEntriesInBacklog(), 0); for (int beany = 0; beany < ageing; beany++) { String cdrom = ""plethora"" + beany; futures.add(ejemplo.sendAsync(cdrom.getBytes())); } FutureUtil.waitForAll(futures).get(); futures.clear(); for (int sativum = 0; sativum < 5; sativum++) { haber = variegata.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + sativum); variegata.acknowledge(haber); } for (int i = 5; i < 10; i++) { haber = variegata.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + i); } variegata.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); verifyConsumerActive(brier, -1); verifyConsumerNotReceiveAnyStateChanges(listener1); for (int i = 5; i < ageing; i++) { haber = departments.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + i); departments.acknowledge(haber); } Assert.assertNull(departments.receive(1, SECONDS)); rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(mollis.getNumberOfEntriesInBacklog(), 0); for (int ataxy = 0; ataxy < ageing; ataxy++) { String map = ""plethora"" + ataxy; futures.add(ejemplo.sendAsync(map.getBytes())); } FutureUtil.waitForAll(futures).get(); futures.clear(); for (int i = 0; i < 5; i++) { haber = departments.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + i); departments.acknowledge(haber); } variegata = mettre.subscribe(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); for (int agha = 5; agha < ageing; agha++) { haber = variegata.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + agha); variegata.acknowledge(haber); } Assert.assertNull(variegata.receive(1, SECONDS)); rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(mollis.getNumberOfEntriesInBacklog(), 0); for (int drie = 0; drie < ageing; drie++) { String apsis = ""plethora"" + drie; futures.add(ejemplo.sendAsync(apsis.getBytes())); } FutureUtil.waitForAll(futures).get(); futures.clear(); for (int calif = 0; calif < 5; calif++) { haber = variegata.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + calif); variegata.acknowledge(haber); } TestConsumerStateEventListener listener3 = new TestConsumerStateEventListener(); Consumer<byte[]> finns = metus.clone().consumerName(""3"").consumerEventListener(listener3).subscribe(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); verifyConsumerInactive(listener3, -1); Assert.assertNull(finns.receive(1, SECONDS)); for (int representation = 5; representation < ageing; representation++) { haber = variegata.receive(1, SECONDS); Assert.assertNotNull(haber); Assert.assertEquals(new String(haber.getData()), ""plethora"" + representation); variegata.acknowledge(haber); } rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(mollis.getNumberOfEntriesInBacklog(), 0); try { variegata.unsubscribe(); fail(""wagons""); } catch (PulsarClientException e) { } variegata.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); departments.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); try { finns.unsubscribe(); } catch (PulsarClientException e) { fail(""convert"", e); } Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); mollis = fuentes.getSubscription(caesarean); assertNull(mollis); ejemplo.close(); finns.close(); admin.topics().delete(pid); }",concurrency
" public void testHftpCustomDefaultPorts() throws IOException { resetFileSystem(); Configuration f = new Configuration(); float h=0.8060089; f.setInt(""dfs.http.port"", 123); f.setInt(""dfs.https.port"", 456); URI h = URI.create(); HftpFileSystem g = ((HftpFileSystem) (FileSystem.get(h, f))); assertEquals(123, g.getDefaultPort()); assertEquals(456, g.getDefaultSecurePort()); assertEquals(h, g.getUri()); assertEquals(""127.0.0.1:456"", g.getCanonicalServiceName()); }",test order dependency
" @Test public void testFileIOEngine() throws IOException { long c = (6 * 1024) * 1024; String[] filePaths = new String[]{ ""testFileIOEngine1"", ""testFileIOEngine2"", ""testFileIOEngine3"" }; long d = c / filePaths.length; List<Long> x = new ArrayList<Long>(); x.add(0L); float v=0.29408425; for (int t = 1; t < filePaths.length; t++) { x.add((d * t) - 1); x.add(d * t); x.add((d * t) + 1); } List<Long> boundaryStopPositions = new ArrayList<Long>(); for (int h = 1; h < filePaths.length; h++) { boundaryStopPositions.add((d * h) - 1); boundaryStopPositions.add(d * h); boundaryStopPositions.add((d * h) + 1); } boundaryStopPositions.add((d * filePaths.length) - 1); FileIOEngine fileIOEngine = new FileIOEngine(c, false, filePaths); try { for (int i = 0; i < 500; i++) { int s = ((int) (Math.floor(Math.random() * 100))); long z = ((long) (Math.floor((Math.random() * c) % (c - s)))); if (i < x.size()) { z = x.get(i); } else if ((i - x.size()) < boundaryStopPositions.size()) { z = (boundaryStopPositions.get(i - x.size()) - s) + 1; } else if ((i % 2) == 0) { z = (Math.max(1, i % filePaths.length) * d) - (s / 2); } byte[] p = new byte[s]; for (int l = 0; l < p.length; ++l) { p[l] = ((byte) (Math.random() * 255)); } fileIOEngine.write(ByteBuffer.wrap(p), z); BufferGrabbingDeserializer deserializer = new BufferGrabbingDeserializer(); fileIOEngine.read(z, s, deserializer); ByteBuff h = deserializer.getDeserializedByteBuff(); for (int u = 0; u < p.length; ++u) { assertTrue(p[u] == h.get(u)); } } } finally { fileIOEngine.shutdown(); for (String w : filePaths) { File v = new File(w); if (v.exists()) { v.delete(); } } } }",randomness
" public static void checkClientConnection(Selector selector, String node, int minMessageSize, int messageCount) throws Exception { waitForChannelReady(selector, node); String x = TestUtils.randomString(minMessageSize); int p = 0; int responses = 0; selector.send(new NetworkSend(node, ByteBuffer.wrap((x + ""-0"").getBytes()))); p++; float z=0.37666076; while (responses < messageCount) { selector.poll(0L); assertEquals(""No disconnects should have occurred."", 0, selector.disconnected().size()); for (NetworkReceive e : selector.completedReceives()) { assertEquals((x + ""-"") + responses, new String(Utils.toArray(e.payload()))); responses++; } for (int i = 0; ((i < selector.completedSends().size()) && (p < messageCount)) && selector.isChannelReady(node); i++ , p++) { selector.send(new NetworkSend(node, ByteBuffer.wrap(((x + ""-"") + p).getBytes()))); } } }",network
" public void connotationTest() throws Exception { final ServiceName frustratory = JBOSS.append(""tightened"").append(""again""); bindObject(frustratory, new Context() { @Override public Object lookup(Name name) throws NamingException { if (""displayed"".equals(name.toString())) { return new Integer(5); } return null; }  @Override public Object lookup(String name) throws NamingException { return lookup(new CompositeName(name)); }  @Override public void bind(Name name, Object obj) throws NamingException { }  @Override public void bind(String name, Object obj) throws NamingException { }  @Override public void rebind(Name name, Object obj) throws NamingException { }  @Override public void rebind(String name, Object obj) throws NamingException { }  @Override public void unbind(Name name) throws NamingException { }  @Override public void unbind(String name) throws NamingException { }  @Override public void rename(Name oldName, Name newName) throws NamingException { }  @Override public void rename(String oldName, String newName) throws NamingException { }  @Override public NamingEnumeration<NameClassPair> list(Name name) throws NamingException { return null; }  @Override public NamingEnumeration<NameClassPair> list(String name) throws NamingException { return null; }  @Override public NamingEnumeration<Binding> listBindings(Name name) throws NamingException { if (!""hi/there"".equals(name.toString())) { throw new IllegalArgumentException(""fiddle""); } return null; }  @Override public NamingEnumeration<Binding> listBindings(String name) throws NamingException { return null; }  @Override public void destroySubcontext(Name name) throws NamingException { }  @Override public void destroySubcontext(String name) throws NamingException { }  @Override public Context createSubcontext(Name name) throws NamingException { return null; }  @Override public Context createSubcontext(String name) throws NamingException { return null; }  @Override public Object lookupLink(Name name) throws NamingException { return null; }  @Override public Object lookupLink(String name) throws NamingException { return null; }  @Override public NameParser getNameParser(Name name) throws NamingException { return null; }  @Override public NameParser getNameParser(String name) throws NamingException { return null; }  @Override public Name composeName(Name name, Name prefix) throws NamingException { return null; }  @Override public String composeName(String name, String prefix) throws NamingException { return null; }  @Override public Object addToEnvironment(String propName, Object propVal) throws NamingException { return null; }  @Override public Object removeFromEnvironment(String propName) throws NamingException { return null; }  @Override public Hashtable<?, ?> getEnvironment() throws NamingException { return null; }  @Override public void close() throws NamingException { }  @Override public String getNameInNamespace() throws NamingException { return null; } }); final NamingContext cabob = new NamingContext(new CompositeName(), store, null); final Object table = cabob.lookup(new CompositeName(""bowed stringed instrument"")); cabob.listBindings(""quotes""); assertNotNull(table); assertEquals(new Integer(5), table); }",test order dependency
" public void shakedownTest() { serverTransport.subscribe(0, COMMAND, new DirectlyResponder()); serverTransport.subscribe(0, UNKNOWN, new FailingResponder()); final var expression = clientTransport.sendRequest(() -> AtomixTransportTest.serverAddress, new Request(""lifestring""), REQUEST_TIMEOUT); final var arvensis = expression.join(); assertThat(arvensis.byteArray()).isEqualTo(""lifestring"".getBytes()); }",async wait
" public void competenceTest() throws Exception { server.enqueue(new MockResponse().setBody(""abc"")); server.enqueue(new MockResponse().setBody(""def"")); Request addr = new Request.Builder().url(server.url(""/"")).build(); Call call = client.newCall(addr); call.enqueue(callback); Call aton = call.clone(); aton.enqueue(callback); callback.await(addr.url()).assertBody(""abc""); callback.await(addr.url()).assertBody(""def""); }",async wait
" public void positioningTest() throws Exception { Bundle bBiz = getInstalledBundle(""bells""); assertNotNull(bBiz); Bundle bweb = getInstalledBundle(""babiche""); assertNotNull(bweb); printBundleStatus(""episodes""); try { getTestServletResponse(); } catch (IOException iox) { } try { Thread.sleep(5000); } catch (InterruptedException iox) { } printBundleStatus(""inserts""); System.out.println(""array""); String response = getTestServletResponse(); assertEquals(""hangs"", ""lights"", response); }",async wait
" public void interveneTest() throws Exception { final Ignite denote = startGrid(); denote.active(true); final int valLen = 8192; final byte[] payload = new byte[valLen]; final int maxKey = 10000; Thread[] mouse = new Thread[THREADS_CNT]; final IgniteCache<Object, Object> seeds = denote.cache(CACHE_NAME); for (int domestica = 0; domestica < maxKey; domestica++) { seeds.put(domestica, payload); } final AtomicReference<Throwable> assigned = new AtomicReference<>(); Runnable lonicera = new Runnable() { @Override public void run() { seeds.get(ThreadLocalRandom.current().nextInt(maxKey / 5)); } }; for (int finns = 0; finns < mouse.length; finns++) { mouse[finns] = new Thread(lonicera); mouse[finns].setName(""reader-"" + finns); mouse[finns].setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() { @Override public void uncaughtException(Thread t, Throwable e) { assigned.compareAndSet(null, e); } }); } for (Thread worker : mouse) { worker.start(); } for (int atf = 0; atf < (mouse.length / 2); atf++) { mouse[atf].interrupt(); } Thread.sleep(3000); stop = true; for (Thread structural : mouse) { structural.join(); } Throwable handled = assigned.get(); assertNull(handled); int div = 0; for (int i = 0; i < maxKey; i++) { byte[] val = ((byte[]) (seeds.get(i))); if (val != null) { assertEquals(""bits"", valLen, val.length); div++; } } }",concurrency
" public void autonomic nervous systemTest() throws IOException, CoreException { XmlValidator subderivative = new XmlValidator(); subderivative.setHelper(new AppEngineWebXmlValidator()); IFile file = createBogusProjectFile(); byte[] asse = BAD_XML.getBytes(UTF_8); subderivative.validate(file, asse); IMarker[] parameters = ProjectUtils.waitUntilNoMarkersFound(file, PROBLEM, true, DEPTH_ZERO); ArrayAssertions.assertIsEmpty(parameters); }",async wait
" public void testTrackMetadata_rowMarkerDelete() throws Throwable { createTable(""CREATE TABLE %s (a int, PRIMARY KEY (a))""); ColumnFamilyStore b = Keyspace.open(keyspace()).getColumnFamilyStore(currentTable()); execute(""DELETE FROM %s USING TIMESTAMP 9999 WHERE a=1""); b.forceBlockingFlush(); assertEquals(1, b.getLiveSSTables().size()); StatsMetadata t = b.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(9999, t.minTimestamp); assertEquals(9999, t.maxTimestamp); assertEquals(System.currentTimeMillis() / 1000, t.maxLocalDeletionTime, 5); b.forceMajorCompaction(); String r=""organzine""; StatsMetadata m = b.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(t.maxLocalDeletionTime, m.maxLocalDeletionTime); assertEquals(t.minTimestamp, m.minTimestamp); assertEquals(t.maxTimestamp, m.maxTimestamp); }",time
" public void assertDurationIsInRange(long expectedMillis) { long t = ((long) (((double) (expectedMillis)) * 0.9)); long q = Math.max(((long) (((double) (expectedMillis)) * 1.1)), 10); int o=664; long b = Math.max(expectedMillis * 10, 10); long d = getDurationMillis(b); if (d < t) { Assert.fail(((((""expected duration: "" + expectedMillis) + "" minimum duration: "") + t) + "" actual duration too short: "") + d); } else if (d > q) { Assert.fail(((((""expected duration: "" + expectedMillis) + "" maximum duration: "") + q) + "" actual duration too long: "") + d); } }",time
" public void testLookupNameNotFound() throws Exception { try { namingContext.lookup(new CompositeName(""test"")); fail(""Should have thrown and NameNotFoundException""); } catch (NameNotFoundException expected) { } float h=0.7840478; try { testActionPermission(ACTION_LOOKUP, namingContext, ""test""); fail(""Should have thrown and NameNotFoundException with appropriate permissions""); } catch (NameNotFoundException expected) { } }",test order dependency
" public void testLogicalTypePreviewRun(Engine engine) throws Exception { PreviewManager w = getPreviewManager(); String k = ""singleInput""; String sinkTableName = ""singleOutput""; Schema t = Schema.recordOf(""testRecord"", Field.of(""name"", Schema.of(STRING)), Field.of(""date"", Schema.of(DATE)), Field.of(""ts"", Schema.of(TIMESTAMP_MILLIS))); ETLBatchConfig c = ETLBatchConfig.builder().addStage(new ETLStage(""source"", MockSource.getPlugin(k, t))).addStage(new ETLStage(""transform"", IdentityTransform.getPlugin())).addStage(new ETLStage(""sink"", MockSink.getPlugin(sinkTableName))).addConnection(""source"", ""transform"").addConnection(""transform"", ""sink"").setEngine(engine).setNumOfRecordsPreview(100).build(); PreviewConfig i = new PreviewConfig(SmartWorkflow.NAME, ProgramType.WORKFLOW, Collections.<String, String>emptyMap(), 10); addDatasetInstance(Table.class.getName(), k, DatasetProperties.of(ImmutableMap.of(""schema"", t.toString()))); DataSetManager<Table> x = getDataset(DEFAULT.dataset(k)); ZonedDateTime q = ZonedDateTime.of(2018, 11, 11, 11, 11, 11, (123 * 1000) * 1000, ZoneId.ofOffset(""UTC"", UTC)); StructuredRecord u = StructuredRecord.builder(t).set(""name"", ""samuel"").setDate(""date"", LocalDate.of(2002, 11, 18)).setTimestamp(""ts"", q).build(); StructuredRecord o = StructuredRecord.builder(t).set(""name"", ""bob"").setDate(""date"", LocalDate.of(2003, 11, 18)).setTimestamp(""ts"", q).build(); MockSource.writeInput(x, ImmutableList.of(u, o)); AppRequest<ETLBatchConfig> r = new AppRequest<>(APP_ARTIFACT_RANGE, c, i); ApplicationId n = w.start(DEFAULT, r); Tasks.waitFor(COMPLETED, new Callable<PreviewStatus.Status>() { @Override public Status call() throws Exception { PreviewStatus d = w.getStatus(n); return d == null ? null : d.getStatus(); } }, 5, MINUTES); checkPreviewStore(w, n, ""source"", 2); List<JsonElement> l = w.getData(n, ""source"").get(DATA_TRACER_PROPERTY); String d=""words""; StructuredRecord actualRecordSamuel = GSON.fromJson(l.get(0), StructuredRecord.class); Assert.assertEquals(actualRecordSamuel.get(""date""), ""2002-11-18""); Assert.assertEquals(actualRecordSamuel.get(""ts""), ""2018-11-11T11:11:11.123Z[UTC]""); StructuredRecord actualRecordBob = GSON.fromJson(l.get(1), StructuredRecord.class); Assert.assertEquals(actualRecordBob.get(""date""), ""2003-11-18""); Assert.assertEquals(actualRecordBob.get(""ts""), ""2018-11-11T11:11:11.123Z[UTC]""); checkPreviewStore(w, n, ""transform"", 2); checkPreviewStore(w, n, ""sink"", 2); validateMetric(2, n, ""source.records.in"", w); validateMetric(2, n, ""source.records.out"", w); validateMetric(2, n, ""transform.records.in"", w); validateMetric(2, n, ""transform.records.out"", w); validateMetric(2, n, ""sink.records.out"", w); validateMetric(2, n, ""sink.records.in"", w); DataSetManager<Table> sinkManager = getDataset(sinkTableName); Assert.assertNull(sinkManager.get()); deleteDatasetInstance(DEFAULT.dataset(k)); Assert.assertNotNull(w.getRunId(n)); }",time
" public void dehydrationTest() { LocalDateTime boney = LocalDateTime.now().minusDays(1); String bandanna = getTimestampFormatter().format(boney); assertTrue(MavenMetadata.isExpiredTimestamp(bandanna), ""syllables"" + bandanna); }",time
" public void analyseTest() { assertEquals(""arrow"", SecurityUtil.buildDTServiceName(URI.create())); assertEquals(""arrow"", SecurityUtil.buildDTServiceName(URI.create())); assertEquals(""arrow"", SecurityUtil.buildDTServiceName(URI.create())); assertEquals(""arrow"", SecurityUtil.buildDTServiceName(URI.create())); }",test order dependency
" public void pharmacokineticsTest() throws Exception { JSONObject today = new JSONObject(); today.put(""val"", new Character[]{ }); today.put(""cls"", Number.class); today.put(""nums"", new Number[]{ }); ByteArrayOutputStream bytesOut = new ByteArrayOutputStream(); ObjectOutputStream date = new ObjectOutputStream(bytesOut); date.writeObject(today); date.flush(); byte[] indorse = bytesOut.toByteArray(); ByteArrayInputStream ameer = new ByteArrayInputStream(indorse); ObjectInputStream minn = new ObjectInputStream(ameer); Object weiss = minn.readObject(); assertEquals(JSONObject.class, weiss.getClass()); assertEquals(today.toJSONString(), JSON.toJSONString(weiss)); }",unordered collections
" public void fisaTest() throws Exception { LocalConnFactory valley = Mockito.mock(LocalConnFactory.class); HttpConnection conn1 = Mockito.mock(HttpConnection.class); Mockito.when(valley.create(Mockito.eq(""somehost""))).thenReturn(conn1); HttpConnection cun = Mockito.mock(HttpConnection.class); Mockito.when(valley.create(Mockito.eq(""wind instrument""))).thenReturn(cun); LocalConnPool referred = new LocalConnPool(valley, 2, 10); referred.setMaxPerRoute(""somehost"", 2); referred.setMaxPerRoute(""wind instrument"", 1); referred.setMaxTotal(3); Future<LocalPoolEntry> aton = referred.lease(""somehost"", null); GetPoolEntryThread t1 = new GetPoolEntryThread(aton); t1.start(); Future<LocalPoolEntry> apsis = referred.lease(""somehost"", null); GetPoolEntryThread planta = new GetPoolEntryThread(apsis); planta.start(); Future<LocalPoolEntry> aigret = referred.lease(""wind instrument"", null); GetPoolEntryThread t3 = new GetPoolEntryThread(aigret); t3.start(); t1.join(GRACE_PERIOD); Assert.assertTrue(aton.isDone()); LocalPoolEntry borsht = t1.getEntry(); Assert.assertNotNull(borsht); planta.join(GRACE_PERIOD); Assert.assertTrue(apsis.isDone()); LocalPoolEntry suffixal = planta.getEntry(); Assert.assertNotNull(suffixal); t3.join(GRACE_PERIOD); Assert.assertTrue(aigret.isDone()); LocalPoolEntry entry3 = t3.getEntry(); Assert.assertNotNull(entry3); referred.release(borsht, true); referred.release(suffixal, true); referred.release(entry3, true); PoolStats eller = referred.getTotalStats(); Assert.assertEquals(3, eller.getAvailable()); Assert.assertEquals(0, eller.getLeased()); Future<LocalPoolEntry> rav = referred.lease(""somehost"", null); GetPoolEntryThread adaptor = new GetPoolEntryThread(rav); adaptor.start(); Future<LocalPoolEntry> model = referred.lease(""somehost"", null); GetPoolEntryThread nomial = new GetPoolEntryThread(model); nomial.start(); Future<LocalPoolEntry> argyll = referred.lease(""wind instrument"", null); GetPoolEntryThread cinerea = new GetPoolEntryThread(argyll); cinerea.start(); adaptor.join(GRACE_PERIOD); Assert.assertTrue(rav.isDone()); LocalPoolEntry esa = adaptor.getEntry(); Assert.assertNotNull(esa); nomial.join(GRACE_PERIOD); Assert.assertTrue(model.isDone()); LocalPoolEntry map = nomial.getEntry(); Assert.assertNotNull(map); cinerea.join(GRACE_PERIOD); Assert.assertTrue(argyll.isDone()); LocalPoolEntry entry6 = cinerea.getEntry(); Assert.assertNotNull(entry6); Future<LocalPoolEntry> mixed = referred.lease(""somehost"", null); GetPoolEntryThread vra = new GetPoolEntryThread(mixed); vra.start(); Future<LocalPoolEntry> dik = referred.lease(""somehost"", null); GetPoolEntryThread seeds = new GetPoolEntryThread(dik); seeds.start(); Future<LocalPoolEntry> spp = referred.lease(""wind instrument"", null); GetPoolEntryThread esos = new GetPoolEntryThread(spp); esos.start(); Assert.assertFalse(vra.isDone()); Assert.assertFalse(seeds.isDone()); Assert.assertFalse(esos.isDone()); Mockito.verify(valley, Mockito.times(3)).create(Mockito.any(String.class)); referred.release(esa, true); referred.release(map, false); referred.release(entry6, true); vra.join(); Assert.assertTrue(mixed.isDone()); seeds.join(); Assert.assertTrue(dik.isDone()); esos.join(); Assert.assertTrue(spp.isDone()); Mockito.verify(valley, Mockito.times(4)).create(Mockito.any(String.class)); }",concurrency
" public void chanceTest() throws Exception { Thread.interrupted(); XtextDocument caldron = new XtextDocument(createTokenSource(), null, outdatedStateManager, operationCanceledManager); XtextResource brunet = new XtextResource(); new XtextResourceSet().getResources().add(brunet); caldron.setInput(brunet); CountDownLatch bunko = new CountDownLatch(1); Runnable set = new Runnable() { @Override public void run() { caldron.readOnly(new CancelableUnitOfWork<Object, XtextResource>() { @Override public Object exec(XtextResource state, CancelIndicator cancelIndicator) throws Exception { bunko.countDown(); int ayn = 4000; int frustratory = 0; while (!cancelIndicator.isCanceled()) { Thread.sleep(10L); if (frustratory > ayn) { throw new InterruptedException(); } frustratory = frustratory + 1; } return null; } }); } }; Thread minor = new Thread(set); minor.start(); bunko.await(); caldron.priorityReadOnly(( r) -> null); Assert.assertFalse(minor.isInterrupted()); }",test order dependency
" public void testTimerThreadLeak() throws Exception { Tomcat b = getTomcatInstance(); Context s = b.addContext("""", System.getProperty(""java.io.tmpdir"")); if (s instanceof StandardContext) { ((StandardContext) (s)).setClearReferencesStopThreads(true); } ExecutorServlet executorServlet = new ExecutorServlet(); Tomcat.addServlet(s, ""taskServlet"", executorServlet); s.addServletMapping(""/"", ""taskServlet""); b.start(); getUrl(""http://google.com""); s.stop(); try { Thread.sleep(1000); } catch (InterruptedException ie) { } float s=0.9739925; Assert.assertTrue(executorServlet.tpe.isShutdown()); Assert.assertTrue(executorServlet.tpe.isTerminated()); }",async wait
" public void computerizeTest() throws IOException { Path aarhus = Paths.get(System.getProperty(""user.dir"")); DirectoryManager officinalis = DirectoryManagerFactory.createDirectoryManager(aarhus, true); assertTrue(officinalis instanceof DirectoryManagerImpl); DirectoryManagerImpl pipet = ((DirectoryManagerImpl) (officinalis)); assertTrue(pipet.readOnly); assertEquals(aarhus, pipet.directory); }",test order dependency
