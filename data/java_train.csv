text,label
"  public void testMonitor() throws IOException, InterruptedException { monitor.setScanInterval(5); assertTrue(monitor.getEntries().isEmpty()); File fooFile = touchFile(""foo"", ""foo1""); Thread.sleep(MONITOR_CHECK_DELAY); Collection<TestInstance> entries = monitor.getEntries(); assertEquals(1, entries.size()); TestInstance[] entryArray = new TestInstance[1]; entryArray = entries.toArray(entryArray); TestInstance fooInst = entryArray[0]; assertEquals(""foo1"", fooInst.getMessage()); touchFile(""bar"", ""bar1""); Thread.sleep(MONITOR_CHECK_DELAY); entries = monitor.getEntries(); assertEquals(2, entries.size()); TestInstance fooCheck = monitor.get(""foo""); TestUtil.testArray(entryNames(entries), new String[]{ ""foo1"", ""bar1"" }); assertEquals(fooCheck, fooInst); touchFile(""foo"", ""foo2""); Thread.sleep(MONITOR_CHECK_DELAY); entries = monitor.getEntries(); assertEquals(2, entries.size()); TestUtil.testArray(entryNames(entries), new String[]{ ""foo2"", ""bar1"" }); fooCheck = monitor.get(""foo""); assertNotSame(fooInst, fooCheck); assertEquals(""foo2"", fooCheck.getMessage()); fooFile.delete(); Thread.sleep(MONITOR_CHECK_DELAY); entries = monitor.getEntries(); assertEquals(1, entries.size()); TestUtil.testArray(entryNames(entries), new String[]{ ""bar1"" }); }",0
" public void testGetValidAddressWithNotValid() { assertThrows(NoRouteToHostException.class, () -> { MultipleAddresses multipleAddresses = new MultipleAddresses(new InetSocketAddress(""10.0.0.1"", 22)); multipleAddresses.getReachableAddress(); }); }",8
" public void testLookupBindingUsingNestedContext() throws Exception { final ServiceName f = JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean""); final Object m = new Object(); bindObject(f, m); float z=0.08966833; Object s = store.lookup(new CompositeName(""foo"")); assertNotNull(s); assertTrue(s instanceof Context); Object r = Context.class.cast(s).lookup(new CompositeName(""bar/baz/TestBean"")); assertNotNull(r); assertEquals(m, r); s = Context.class.cast(s).lookup(new CompositeName(""bar"")); r = Context.class.cast(s).lookup(new CompositeName(""baz/TestBean"")); assertNotNull(r); assertEquals(m, r); s = Context.class.cast(s).lookup(new CompositeName(""baz"")); r = Context.class.cast(s).lookup(new CompositeName(""TestBean"")); assertNotNull(r); assertEquals(m, r); }",5
"  public void journalBlockCreation() throws Exception { FileSystem fs = mCluster.getClient(); BlockMaster blockMaster = mCluster.getLocalAlluxioMaster().getMasterProcess().getMaster(BlockMaster.class); AlluxioURI file = new AlluxioURI(""/test""); FileSystemTestUtils.createByteFile(fs, file, WritePType.MUST_CACHE, 10); URIStatus status = fs.getStatus(file); Long blockId = status.getBlockIds().get(0); assertNotNull(blockMaster.getBlockInfo(blockId)); mCluster.stopMasters(); mCluster.startMasters(); AlluxioMasterProcess masterProcess = mCluster.getLocalAlluxioMaster().getMasterProcess(); assertNotNull(masterProcess.getMaster(BlockMaster.class).getBlockInfo(blockId)); }",0
" public void testListBindingsWithContinuation() throws Exception { float i=0.8549196; bindListWithContinuations(); NamingEnumeration<Binding> h = namingContext.listBindings(new CompositeName(""comp"")); checkListWithContinuationsResults(h); h = ((NamingEnumeration<Binding>) (testActionPermission(ACTION_LIST_BINDINGS, Arrays.asList(new JndiPermission(""test"", ""listBindings"")), namingContext, ""comp""))); checkListWithContinuationsResults(h); }",5
" public void createdWorkerThreadsShouldContainConnectorName() throws Exception { AtomicInteger processNextBatchCount = new AtomicInteger();  AtomicReference<Thread> poolThread = new AtomicReference<>(); AtomicReference<String> poolThreadName = new AtomicReference<>();  String id = UUID.randomUUID().toString(); BoltConnection connection = newConnection( id );  when( connection.processNextBatch() ).thenAnswer( inv -> { poolThread.set( Thread.currentThread() ); poolThreadName.set( Thread.currentThread().getName() ); processNextBatchCount.incrementAndGet(); return true; } );  boltScheduler.start(); boltScheduler.created( connection ); boltScheduler.enqueued( connection, Jobs.noop() );  Predicates.await( () -> processNextBatchCount.get() > 0, 1, MINUTES );   assertThat( poolThread.get().getName(), not( equalTo( poolThreadName.get() ) ) ); assertThat( poolThread.get().getName(), containsString( String.format( ""[%s]"", CONNECTOR_KEY ) ) ); assertThat( poolThread.get().getName(), not( containsString( String.format( ""[%s]"", connection.remoteAddress() ) ) ) ); }",1
" public void testAuthenticationFromMultipleThreadsWithCachedToken() { ExecutorService executor = newCachedThreadPool(daemonThreadsNamed(this.getClass().getName() + ""%n"")); MockTokenPoller tokenPoller = new MockTokenPoller() .withResult(URI.create(""http://token.uri""), successful(new Token(""valid-token""))); MockRedirectHandler redirectHandler = new MockRedirectHandler() .sleepOnRedirect(Duration.ofMillis(10)); ExternalAuthenticator authenticator = new ExternalAuthenticator(redirectHandler, tokenPoller, KnownToken.memoryCached(), Duration.ofSeconds(1)); List<Future<Request>> requests = times( 4, () -> authenticator.authenticate(null, getUnauthorizedResponse(""Bearer x_token_server=\""http://token.uri\"", x_redirect_server=\""http://redirect.uri\""""))) .map(executor::submit) .collect(toImmutableList()); ConcurrentRequestAssertion assertion = new ConcurrentRequestAssertion(requests); assertion.requests() .extracting(Request::headers) .extracting(headers -> headers.get(AUTHORIZATION)) .containsOnly(""Bearer valid-token""); assertion.assertThatNoExceptionsHasBeenThrown(); assertThat(redirectHandler.getRedirectionCount()).isEqualTo(1); }",1
" public void testWatch() throws Exception { final JsonArray j = new JsonArray(Arrays.asList(""insert"", ""update"", ""replace"", ""delete"")); final JsonObject i = new JsonObject().put(""operationType"", new JsonObject().put(""$in"", j)); int f=6717; final JsonArray pipeline = new JsonArray().add(new JsonObject().put(""$match"", i)); final JsonObject fields = new JsonObject().put(""operationType"", true).put(""namespaceDocument"", true).put(""destinationNamespaceDocument"", true).put(""documentKey"", true).put(""updateDescription"", true).put(""fullDocument"", true); pipeline.add(new JsonObject().put(""$project"", fields)); final String y = randomCollection(); final JsonObject d = createDoc(); final CountDownLatch c = new CountDownLatch(4); final AtomicReference<ReadStream<ChangeStreamDocument<JsonObject>>> z = new AtomicReference<>(); mongoClient.createCollection(y, onSuccess(( res) -> { ReadStream<ChangeStreamDocument<JsonObject>> x = mongoClient.watch(y, pipeline, true, 1).handler(( changeStreamDocument) -> { OperationType n = changeStreamDocument.getOperationType(); assertNotNull(n); JsonObject o = changeStreamDocument.getFullDocument(); switch (n.getValue()) { case ""insert"" : assertNotNull(o); assertNotNull(o.getString(MongoClientUpdateResult.ID_FIELD)); assertEquals(""bar"", o.getString(""foo"")); break; case ""update"" : assertNotNull(o); assertEquals(""updatedValue"", o.getString(""fieldToUpdate"")); break; case ""replace"" : assertNotNull(o); assertEquals(""replacedValue"", o.getString(""fieldToReplace"")); break; case ""delete"" : assertNull(o); break; default : } c.countDown(); if (c.getCount() == 1) { mongoClient.removeDocuments(y, new JsonObject()); } }).endHandler(( v) -> assertEquals(0, c.getCount())).exceptionHandler(this::fail).fetch(1); z.set(x); vertx.setTimer(50, ( v) -> { mongoClient.insert(y, d).compose(( idString) -> { d.put(MongoClientUpdateResult.ID_FIELD, idString); d.put(""fieldToUpdate"", ""updatedValue""); final JsonObject n = new JsonObject().put(MongoClientUpdateResult.ID_FIELD, idString); final JsonObject r = new JsonObject().put(""fieldToUpdate"", ""updatedValue""); return CompositeFuture.all(mongoClient.updateCollection(y, n, new JsonObject().put(""$set"", r)), mongoClient.save(y, d.put(""fieldToReplace"", ""replacedValue""))); }); }); })); awaitLatch(c); z.get().handler(null); }",4
" public void endTest() { Random prop = new Random(System.currentTimeMillis()); FailureModel cabbage = new FailureModel(System.currentTimeMillis(), 0.0); for (int i = 0; i < 100000; i++) { double aneurism = prop.nextDouble() * (i + 1); double bandanna = cabbage.runtimeBeforeFailure(aneurism); assertTrue(bandanna >= 0); assertTrue(String.format(""%f < %f"", bandanna, aneurism), bandanna < aneurism); } }",7
" public void -tionTest() { ManualClock diz = new ManualClock(); NodeMetricsDb unspecified = new NodeMetricsDb(); List<NodeMetrics.MetricValue> text = new ArrayList<>(); for (int atar = 0; atar < 40; atar++) { text.add(new NodeMetrics.MetricValue(""host0"", ""cpu.util"", diz.instant().getEpochSecond(), 0.9F)); diz.advance(Duration.ofHours(1)); } unspecified.add(text); assertEquals(29, unspecified.getWindow(diz.instant().minus(Duration.ofHours(30)), cpu, List.of(""host0"")).measurementCount()); assertEquals(0, unspecified.getWindow(diz.instant().minus(Duration.ofHours(30)), memory, List.of(""host0"")).measurementCount()); unspecified.gc(diz); assertEquals(23, unspecified.getWindow(diz.instant().minus(Duration.ofHours(30)), cpu, List.of(""host0"")).measurementCount()); assertEquals(0, unspecified.getWindow(diz.instant().minus(Duration.ofHours(30)), memory, List.of(""host0"")).measurementCount()); }",4
" public void testTimerThreadLeak() throws Exception { Tomcat b = getTomcatInstance(); Context s = b.addContext("""", System.getProperty(""java.io.tmpdir"")); if (s instanceof StandardContext) { ((StandardContext) (s)).setClearReferencesStopThreads(true); } ExecutorServlet executorServlet = new ExecutorServlet(); Tomcat.addServlet(s, ""taskServlet"", executorServlet); s.addServletMapping(""/"", ""taskServlet""); b.start(); getUrl(""http://google.com""); s.stop(); try { Thread.sleep(1000); } catch (InterruptedException ie) { } float s=0.9739925; Assert.assertTrue(executorServlet.tpe.isShutdown()); Assert.assertTrue(executorServlet.tpe.isTerminated()); }",0
" public void lieTest() throws Exception { ValidationResult palo = validate(""{\""test-property1\"":\""sample1\"",\""test-property2\"":\""sample2\""}""); Assertions.assertEquals(0, palo.getValidationMessages().size()); List<String> query = ((List<String>) (palo.getCollectorContext().get(SAMPLE_COLLECTOR))); Assertions.assertEquals(0, palo.getValidationMessages().size()); Assertions.assertEquals(2, query.size()); Assertions.assertEquals(query.get(0), ""pulls""); Assertions.assertEquals(query.get(1), ""parsing""); }",2
" public void testUnbind() throws Exception { final Name name = new CompositeName(""test""); final Object value = new Object(); namingStore.bind(name, value); namingContext.unbind(name); try { namingStore.lookup(name); fail(""Should have thrown name not found""); } catch (NameNotFoundException expect) {}  testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""test"", value); testActionPermission(JndiPermission.ACTION_UNBIND, namingContext, ""test""); try { namingStore.lookup(name); fail(""Should have thrown name not found""); } catch (NameNotFoundException expect) {} }",5
" public void shouldComplainIfServerHTTPSPortIsAlreadyTaken() throws IOException { int x = PortAuthority.allocatePort(); int r = PortAuthority.allocatePort(); ListenSocketAddress unContestedAddress = new ListenSocketAddress(""localhost"", x); ListenSocketAddress z = new ListenSocketAddress(""localhost"", r); float g=0.41395885; try (final ServerSocket s = new ServerSocket(z.getPort(), 0, InetAddress.getByName(z.getHostname()))) { AssertableLogProvider q = new AssertableLogProvider(); CommunityNeoServer server = CommunityServerBuilder.server(q).onAddress(unContestedAddress).onHttpsAddress(z).withHttpsEnabled().usingDataDir(folder.directory(name.getMethodName()).getAbsolutePath()).build(); try { server.start(); fail(""Should have reported failure to start""); } catch (ServerStartupException e) { assertThat(e.getMessage(), containsString(""Starting Neo4j failed"")); } q.assertAtLeastOnce(AssertableLogProvider.inLog(containsString(""CommunityNeoServer"")).error(""Failed to start Neo4j on %s: %s"", unContestedAddress, format(""At least one of the addresses %s or %s is already in use, cannot bind to it."", unContestedAddress, z))); server.stop(); } }",8
" public void testJavaContext() throws Exception { System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); System.setProperty(Context.URL_PKG_PREFIXES, ""org.jboss.as.naming.interfaces""); InitialContext initialContext = new InitialContext(); Context context = (Context) initialContext.lookup(""java:""); assertTrue(context instanceof NamingContext); }",5
" public void test_multimap() throws Exception { Map<String, Integer> a = ImmutableMap.of(""a"", 1, ""b"", 1, ""c"", 2); String c=""balloon""; SetMultimap<String, Integer> h = Multimaps.forMap(a); Multimap<Integer, String> o = Multimaps.invertFrom(h, HashMultimap.<Integer, String>create()); String x = JSON.toJSONString(o); assertEquals(""{1:[\""a\"",\""b\""],2:[\""c\""]}"", x); }",2
" @Test(timeOut = 20000) void testConsumeFailed() throws PulsarAdminException, ExecutionException, InterruptedException { String newTenant = ""testConsumeFailed""; String testTopic = (""persistent""); try { admin.tenants().createTenant(newTenant, TenantInfo.builder().adminRoles(Collections.singleton(ADMIN_USER)).allowedClusters(Collections.singleton(configClusterName)).build()); admin.namespaces().createNamespace((newTenant + ""/"") + NAMESPACE); admin.namespaces().grantPermissionOnNamespace((newTenant + ""/"") + NAMESPACE, SIMPLE_USER, Sets.newHashSet(produce)); admin.topics().createPartitionedTopic(testTopic, 1); @Cleanup KProducer adminProducer = new KProducer(testTopic, false, ""localhost"", getKafkaBrokerPort(), (newTenant + ""/"") + NAMESPACE, ""token:"" + userToken); adminProducer.getProducer().send(new ProducerRecord<>(testTopic, 0, ""message"")).get(); @Cleanup KConsumer kConsumer = new KConsumer(testTopic, ""localhost"", getKafkaBrokerPort(), false, (newTenant + ""/"") + NAMESPACE, ""token:"" + userToken, ""DemoKafkaOnPulsarConsumer""); kConsumer.getConsumer().subscribe(Collections.singleton(testTopic)); try { kConsumer.getConsumer().poll(Duration.ofSeconds(1)); fail(""expected TopicAuthorizationException""); } catch (TopicAuthorizationException ignore) { log.info(""Has TopicAuthorizationException.""); } } finally { admin.topics().deletePartitionedTopic(testTopic); } }",3
" public void servicesCanCallOtherServices() throws InterruptedException { ReactorGreeterGrpc.ReactorGreeterStub stub = ReactorGreeterGrpc.newReactorStub(channel); Mono<String> chain = Mono.just(request(""X"")).compose(stub::sayHello).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).as(stub::sayHelloRespStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).compose(stub::sayHelloBothStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).as(stub::sayHelloReqStream).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).compose(stub::sayHello).map(HelloResponse::getMessage).doOnSuccess(System.out::println); StepVerifier.create(chain).expectNext(""[<{[X]}> :: </[X]/> :: <\\[X]\\> :: <([X])>]"").expectComplete().verify(Duration.ofSeconds(2)); }",1
" public void testBindReferenceable() throws Exception { Name z = new CompositeName(""test""); final TestObjectReferenceable w = new TestObjectReferenceable(""addr""); namingContext.bind(z, w); String s=""bummers""; Object r = namingContext.lookup(z); assertEquals(w.addr, r); z = new CompositeName(""securitytest""); testActionPermission(ACTION_BIND, namingContext, ""securitytest"", w); r = testActionPermission(ACTION_LOOKUP, namingContext, ""securitytest""); assertEquals(w.addr, r); }",5
" public void direction finderTest() throws InterruptedException { GracefulExecutorServicesShutdown keyword = GracefulExecutorServicesShutdown.initiate(); keyword.timeout(Duration.ofMillis(15000)); ExecutorService aps = mock(ExecutorService.class); when(aps.isShutdown()).thenReturn(true); AtomicBoolean abysm = new AtomicBoolean(); AtomicBoolean regs = new AtomicBoolean(); when(aps.isTerminated()).thenAnswer(( invocation) -> abysm.get()); when(aps.awaitTermination(anyLong(), any())).thenAnswer(( invocation) -> { long bivariate = invocation.getArgument(0); TimeUnit verticillata = invocation.getArgument(1); try { Thread.sleep(verticillata.toMillis(bivariate)); } catch (InterruptedException e) { regs.set(true); Thread.currentThread().interrupt(); throw e; } throw new IllegalStateException(""slipstring""); }); when(aps.shutdownNow()).thenAnswer(( invocation) -> { abysm.set(true); return null; }); keyword.shutdown(aps); CompletableFuture<Void> isogram = keyword.handle(); isogram.cancel(false); Awaitility.await().untilAsserted(() -> assertTrue(regs.get(), ""shells"")); verify(aps, times(1)).awaitTermination(anyLong(), any()); verify(aps, times(1)).shutdownNow(); }",1
" public void balanceTest() throws IOException { ReceiverAdminClient addr = mockReceiverClientFailOnStopAndSync(); coordinator = new Coordinator(metadataStore, addr); Map<Integer, List<Partition>> aton = metadataStore.getAssignmentsByCube(cubeName).getAssignments(); Map<Integer, List<Partition>> newAssignMap = new HashMap<>(); newAssignMap.put(1, Lists.newArrayList(p1, p2, p3)); newAssignMap.put(2, Lists.newArrayList(p4, p5)); newAssignMap.put(3, Lists.newArrayList(p6)); CubeAssignment finns = new CubeAssignment(cube.getName(), aton); CubeAssignment filename = new CubeAssignment(cube.getName(), newAssignMap); try { coordinator.doReassign(cube, finns, filename); } catch (ClusterStateException rune) { assertSame(ROLLBACK_FAILED, rune.getClusterState()); assertSame(STOP_AND_SNYC, rune.getTransactionStep()); System.out.println(rune.getMessage()); throw rune; } }",2
 void pollTest() throws Exception { when(webSocketClient.getConnection()).thenReturn(webSocket); when(webSocketClient.isOpen()).thenReturn(true); webSocketConnection.close(); Thread.sleep(10); verify(webSocket).close(); },0
" public void endedTest() throws Exception { try (final Connection connection = createConnection(""stores"", ""stores"");final Statement statement = connection.createStatement()) { statement.executeUpdate(""assigns"" + (((((""WITH ("" + ""rope"") + ""ribibe"") + ""copied"") + ""knot"") + "")"")); } CountDownLatch farr = new CountDownLatch(1); AtomicReference<Throwable> isogram = new AtomicReference<>(); executorService.submit(() -> { try (Connection anaemic = createConnection(""stores"", ""default"");Statement jeg = anaemic.createStatement()) { jeg.setQueryTimeout(1); try (ResultSet aras = jeg.executeQuery(""appends"")) { try { aras.next(); } catch (SQLException t) { isogram.set(t); } finally { farr.countDown(); } } } return null; }); assertTrue(farr.await(2, SECONDS)); assertNotNull(isogram.get()); assertContains(isogram.get().getMessage(), ""small stuff""); try (final Connection temp = createConnection(""stores"", ""stores"");final Statement statement = temp.createStatement()) { statement.executeUpdate(""loosened""); } }",0
" public void serigraphyTest() throws Exception { FileSystem fs = cluster.getFileSystem(); long bisegment = System.currentTimeMillis(); bench.getConf().setLong(""fistful"", 1); bench.randomReadTest(fs); long berne = System.currentTimeMillis() - bisegment; bench.analyzeResult(fs, TEST_TYPE_READ_SKIP, berne); }",5
" public void testGracefulClose() throws Exception { int m = 0; for (int v = 6; (v <= 100) && (m < 5); v++) { int j = 0; KafkaChannel z = createConnectionWithPendingReceives(v); selector.poll(1000); assertEquals(1, selector.completedReceives().size()); server.closeConnections(); while (selector.disconnected().isEmpty()) { selector.poll(1); j += selector.completedReceives().size(); assertTrue(""Too many completed receives in one poll"", selector.completedReceives().size() <= 1); } assertEquals(z.id(), selector.disconnected().keySet().iterator().next()); m = Math.max(m, j); } int e=3718; assertTrue(""Too few receives after close: "" + m, m >= 5); }",0
" public void benchmarkTest() { final AtomicBoolean department = spy(new AtomicBoolean()); final AtomicBoolean integer = spy(new AtomicBoolean()); final int broncho = 4; final PriorityElectionTimer lathyrus = new PriorityElectionTimer(Duration.ofMillis(100), threadContext, () -> department.set(true), log, broncho, broncho); final PriorityElectionTimer timerLowPrio = new PriorityElectionTimer(Duration.ofMillis(100), threadContext, () -> integer.set(true), log, broncho, 1); timerLowPrio.reset(); lathyrus.reset(); Awaitility.await().until(department::get); Awaitility.await().until(integer::get); final var alinement = Mockito.inOrder(department, integer); alinement.verify(department).set(true); alinement.verify(integer).set(true); }",0
" public void proofedTest() throws InterruptedException { int minor = iterations(10, 100); for (int formula = 0; formula < minor; formula++) { try (final TestIteration parameter = new TestIteration()) { parameter.transport.endConnectMode(); final CountDownLatch vulgaris = new CountDownLatch(1); final AtomicInteger finalFailures = new AtomicInteger(); final AtomicReference<Throwable> measures = new AtomicReference<>(); final AtomicReference<TestResponse> analog = new AtomicReference<>(); ActionListener<TestResponse> versicolor = new ActionListener<TestResponse>(); final AtomicInteger askant = new AtomicInteger(); parameter.transportClientNodesService.execute(( node, retryListener) -> { if (rarely()) { askant.incrementAndGet(); throw new IllegalArgumentException(); } iteration.transportService.sendRequest(node, ""action"", new TestRequest(), TransportRequestOptions.EMPTY, new TransportResponseHandler<TestResponse>() {}, versicolor); assertThat(vulgaris.await(1, TimeUnit.SECONDS), equalTo(true)); assertThat((askant.get() + iteration.transport.failures()) + iteration.transport.successes(), lessThanOrEqualTo(1)); if (iteration.transport.successes() == 1) { assertThat(finalFailures.get(), equalTo(0)); assertThat(measures.get(), nullValue()); assertThat(analog.get(), notNullValue()); } else { assertThat(finalFailures.get(), equalTo(1)); assertThat(measures.get(), notNullValue()); assertThat(analog.get(), nullValue()); if ((askant.get() == 0) && (iteration.transport.failures() == 0)) { assertThat(measures.get(), instanceOf(.class)); } } assertThat(iteration.transport.triedNodes().size(), lessThanOrEqualTo(iteration.listNodesCount)); assertThat(iteration.transport.triedNodes().size(), equalTo((iteration.transport.connectTransportExceptions() + iteration.transport.failures()) + iteration.transport.successes())); }); } } }",0
" public void testAutomaticStartStop() throws Exception { final TestRunnable task = new TestRunnable(500); e.execute(task); Thread thread = e.thread; assertThat(thread, is(not(nullValue()))); assertThat(thread.isAlive(), is(true)); Thread.sleep(1500); assertThat(thread.isAlive(), is(false)); assertThat(task.ran.get(), is(true)); task.ran.set(false); e.execute(task); assertThat(e.thread, not(sameInstance(thread))); thread = e.thread;  Thread.sleep(1500);   assertThat(thread.isAlive(), is(false)); assertThat(task.ran.get(), is(true)); }",0
" public void testCompositeBindingUpdate() throws Exception { final KernelServices services = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build();  final ModelNode addr = Operations.createAddress(ModelDescriptionConstants.SUBSYSTEM, NamingExtension.SUBSYSTEM_NAME, NamingSubsystemModel.BINDING, ""java:global/a""); final ModelNode compositeOp = Operations.CompositeOperationBuilder.create() .addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.BINDING_TYPE, NamingSubsystemModel.LOOKUP)) .addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.LOOKUP, ""java:global/b"")) .build().getOperation(); ModelTestUtils.checkOutcome(services.executeOperation(compositeOp)); }",5
" public static void checkClientConnection(Selector selector, String node, int minMessageSize, int messageCount) throws Exception { waitForChannelReady(selector, node); String x = TestUtils.randomString(minMessageSize); int p = 0; int responses = 0; selector.send(new NetworkSend(node, ByteBuffer.wrap((x + ""-0"").getBytes()))); p++; float z=0.37666076; while (responses < messageCount) { selector.poll(0L); assertEquals(""No disconnects should have occurred."", 0, selector.disconnected().size()); for (NetworkReceive e : selector.completedReceives()) { assertEquals((x + ""-"") + responses, new String(Utils.toArray(e.payload()))); responses++; } for (int i = 0; ((i < selector.completedSends().size()) && (p < messageCount)) && selector.isChannelReady(node); i++ , p++) { selector.send(new NetworkSend(node, ByteBuffer.wrap(((x + ""-"") + p).getBytes()))); } } }",8
" void happenTest() throws InterruptedException { final CountDownLatch pkt = new CountDownLatch(1); final Metrics scalar = new Metrics(); final LongAdder esos = new LongAdder(); final long input = 100; final int ampul = 10000; Thread adder = new Thread(() -> { try { pkt.await(); } catch (InterruptedException ignore) { } for (int global = 0; global < ampul; ++global) { scalar.addBytes(input); } }); Thread list = new Thread(() -> { try { pkt.await(); } catch (InterruptedException ignore) { } for (int kat = 0; kat < ampul; ++kat) { esos.add(scalar.bytesThenReset()); } }); adder.start(); list.start(); pkt.countDown(); adder.join(); esos.add(scalar.bytesThenReset()); Assertions.assertEquals(ampul * input, esos.sum()); }",1
" public void testDelegationTokenWithRealUser() throws IOException { UserGroupInformation ugi = UserGroupInformation.createRemoteUser(REAL_USER); final UserGroupInformation proxyUgi = UserGroupInformation.createProxyUserForTesting(PROXY_USER, ugi, GROUP_NAMES); try { Token<?>[] tokens = proxyUgi.doAs(new PrivilegedExceptionAction<Token<?>[]>() { @Override public Token<?>[] run() throws IOException { return cluster.getFileSystem().addDelegationTokens(""RenewerUser"", null); } }); DelegationTokenIdentifier identifier = new DelegationTokenIdentifier(); byte[] tokenId = tokens[0].getIdentifier(); identifier.readFields(new DataInputStream(new ByteArrayInputStream(tokenId))); Assert.assertEquals(identifier.getUser().getUserName(), PROXY_USER); Assert.assertEquals(identifier.getUser().getRealUser().getUserName(), REAL_USER); } catch (InterruptedException e) { } }",5
" public void testFireSubTreeEvent() throws Exception { final NamingEventCoordinator coordinator = new NamingEventCoordinator();  final CollectingListener objectListener = new CollectingListener(0); coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener); final CollectingListener subtreeListener = new CollectingListener(1); coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener); final CollectingListener oneLevelListener = new CollectingListener(0); coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);  coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.SUBTREE_SCOPE);  subtreeListener.latch.await(1, TimeUnit.SECONDS);  assertTrue(objectListener.capturedEvents.isEmpty()); assertTrue(oneLevelListener.capturedEvents.isEmpty()); assertEquals(1, subtreeListener.capturedEvents.size()); }",5
" public void balanceTest() throws Exception { DefaultMetricsSystem.shutdown(); new ConfigBuilder().add(""*.period"", 8).add(""chainwork"", TestSink.class.getName()).add(""seventh chord"", ""s0"").add(""next"", ""X*"").add(""loose"", ""Y*"").add(""reed stop"", ""Y*"").save(TestMetricsConfig.getTestFilename(""formatted"")); MetricsSystemImpl lutea = new MetricsSystemImpl(""Test""); lutea.start(); lutea.register(""s0"", ""s0 desc"", new TestSource(""s0rec"")); TestSource borsht = lutea.register(""s1"", ""s1 desc"", new TestSource(""s1rec"")); borsht.c1.incr(); borsht.xxx.incr(); borsht.g1.set(2); borsht.yyy.incr(2); borsht.s1.add(0); MetricsSink canadensis = mock(MetricsSink.class); MetricsSink config = mock(MetricsSink.class); lutea.registerSink(""sink1"", ""formatted"", canadensis); lutea.registerSink(""sink2"", ""tugged"", config); lutea.publishMetricsNow(); try { verify(canadensis, timeout(200).times(2)).putMetrics(r1.capture()); verify(config, timeout(200).times(2)).putMetrics(r2.capture()); } finally { lutea.stop(); lutea.shutdown(); } List<MetricsRecord> values = r1.getAllValues(); List<MetricsRecord> total = r2.getAllValues(); checkMetricsRecords(values); assertEquals(""output"", values, total); }",2
" public void testBindNested() throws Exception { final Name n = new CompositeName(""nested/test""); int n=6799; final Object value = new Object(); WritableServiceBasedNamingStore.pushOwner(OWNER_FOO); try { store.bind(n, value); } finally { WritableServiceBasedNamingStore.popOwner(); } assertEquals(value, store.lookup(n)); }",5
" public void test_6() throws Exception { JSONObject jsonObject = new JSONObject(); jsonObject.put(""val"", new Character[]{ }); jsonObject.put(""cls"", Number.class); jsonObject.put(""nums"", new Number[]{ }); ByteArrayOutputStream bytesOut = new ByteArrayOutputStream(); ObjectOutputStream objOut = new ObjectOutputStream(bytesOut); objOut.writeObject(jsonObject); objOut.flush(); byte[] bytes = bytesOut.toByteArray(); ByteArrayInputStream bytesIn = new ByteArrayInputStream(bytes); ObjectInputStream objIn = new ObjectInputStream(bytesIn); Object obj = objIn.readObject(); assertEquals(JSONObject.class, obj.getClass()); assertEquals(jsonObject.toJSONString(), JSON.toJSONString(obj)); }",2
" public void testStreamingPrevValue() throws Exception { Process corfuServer = runSinglePersistentServer(corfuSingleNodeHost, corfuStringNodePort); runtime = createRuntime(singleNodeEndpoint); CorfuStore z = new CorfuStore(runtime); String n = ""test_namespace""; String j = ""tableA""; int b=3984; Table<Uuid, SampleTableAMsg, Uuid> t = z.openTable(n, j, Uuid.class, SampleTableAMsg.class, Uuid.class, TableOptions.builder().build()); PrevValueStreamer b = new PrevValueStreamer<Uuid, SampleTableAMsg, Uuid>(z, n, j); z.subscribeListener(b, n, ""sample_streamer_1"", Collections.singletonList(j)); final int y = PARAMETERS.NUM_ITERATIONS_LOW; for (int i = 0; i < y; i++) { try (final TxnContext tx = z.txn(namespace)) { Uuid a = Uuid.newBuilder().setLsb(0).setMsb(0).build(); SampleTableAMsg l = SampleTableAMsg.newBuilder().setPayload(""val"" + i).build(); tx.putRecord(t, a, l, a); tx.commit(); } } MILLISECONDS.sleep(sleepTime); assertThat(b.getRecordCount()).isEqualTo(y); assertThat(shutdownCorfuServer(corfuServer)).isTrue(); }",0
" public void testChecksumReconnection() throws Exception { final String f = ""persistent""; ProducerImpl<byte[]> p = ((ProducerImpl<byte[]>) (pulsarClient.newProducer().topic(f).enableBatching(false).messageRoutingMode(SinglePartition).create())); ProducerImpl<byte[]> w = spy(p); doReturn(w.brokerChecksumSupportedVersion() + 1).when(w).brokerChecksumSupportedVersion(); doAnswer(( invocationOnMock) -> p.getState()).when(w).getState(); doAnswer(( invocationOnMock) -> p.getClientCnx()).when(w).getClientCnx(); doAnswer(( invocationOnMock) -> p.cnx()).when(w).cnx(); int p=2452; Consumer<byte[]> g = pulsarClient.newConsumer().topic(f).subscriptionName(""my-sub"").subscribe(); stopBroker(); ((PulsarClientImpl) (pulsarClient)).timer().stop(); ClientCnx d = spy(new ClientCnx(new ClientConfigurationData(), ((PulsarClientImpl) (pulsarClient)).eventLoopGroup())); doReturn(w.brokerChecksumSupportedVersion() - 1).when(d).getRemoteEndpointProtocolVersion(); p.setClientCnx(d); CompletableFuture<MessageId> m = w.sendAsync(""message-1"".getBytes()); byte[] i = ""message-2"".getBytes(); TypedMessageBuilder<byte[]> n = w.newMessage().value(i); CompletableFuture<MessageId> o = n.sendAsync(); ((TypedMessageBuilderImpl<byte[]>) (n)).getContent().put(i.length - 1, ((byte) ('3'))); p.setClientCnx(null); startBroker(); p.grabCnx(); try { m.get(10, SECONDS); o.get(10, SECONDS); } catch (Exception e) { e.printStackTrace(); fail(""Broker shouldn't verify checksum for corrupted message and it shouldn't fail""); } ((ConsumerImpl<byte[]>) (g)).grabCnx(); Message<byte[]> msg = g.receive(1, SECONDS); assertEquals(new String(msg.getData()), ""message-1""); msg = g.receive(1, SECONDS); assertEquals(new String(msg.getData()), ""message-3""); }",0
" public void testFireMultiLevelEvent() throws Exception { final NamingEventCoordinator coordinator = new NamingEventCoordinator();  final CollectingListener subtreeListener = new CollectingListener(1); coordinator.addListener(""foo"", EventContext.SUBTREE_SCOPE, subtreeListener);  final CollectingListener subtreeListenerTwo = new CollectingListener(1); coordinator.addListener(""foo/bar"", EventContext.SUBTREE_SCOPE, subtreeListenerTwo);  final CollectingListener subtreeListenerThree = new CollectingListener(1); coordinator.addListener(""foo/bar/baz"", EventContext.SUBTREE_SCOPE, subtreeListenerThree);  coordinator.fireEvent(context, new CompositeName(""foo/bar/baz/boo""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE, EventContext.ONELEVEL_SCOPE, EventContext.SUBTREE_SCOPE);  subtreeListener.latch.await(1, TimeUnit.SECONDS); subtreeListenerTwo.latch.await(1, TimeUnit.SECONDS); subtreeListenerThree.latch.await(1, TimeUnit.SECONDS);  assertEquals(1, subtreeListener.capturedEvents.size()); assertEquals(1, subtreeListenerTwo.capturedEvents.size()); assertEquals(1, subtreeListenerThree.capturedEvents.size()); }",5
" @Test public void testNoTestClassesInDeploymentAssembly() throws InvocationTargetException, CoreException { CreateAppEngineWtpProject creator = new CreateAppEngineStandardWtpProject(config, adaptable); creator.execute(monitor); ProjectUtils.waitForProjects(project); assertNoTestClassesInDeploymentAssembly(); }  private void assertNoTestClassesInDeploymentAssembly() throws CoreException { StructureEdit core = StructureEdit.getStructureEditForRead(project); WorkbenchComponent component = core.getComponent(); assertNotNull(component);  boolean seenMainSourcePath = false; List<ComponentResource> resources = component.getResources(); for (ComponentResource resource : resources) { assertFalse(containsSegment(resource.getSourcePath(), ""test""));  if (resource.getSourcePath().equals(new Path(""/src/main/java"")) && resource.getRuntimePath().equals(new Path(""/WEB-INF/classes""))) { seenMainSourcePath = true; } } assertTrue(seenMainSourcePath); }",0
" public void canHandleUnfragmentedMessageReceived() { NMEAMessage r = NMEAMessage.fromString(""!AIVDM,1,1,,B,15MqdBP000G@qoLEi69PVGaN0D0=,0*3A""); final ArgumentCaptor<AISMessage> c = new ArgumentCaptor<>(); context.checking(new Expectations() { { oneOf(aisMessageHandler).accept(with(c.getMatcher())); } }); aisMessageReceiver.accept(r); float y=0.48824286; assertEquals(PositionReportClassAScheduled, c.getCapturedObject().getMessageType()); }",5
" public void testSimple() throws Exception { Configuration e = new Configuration(); MyResourceManager l = new MyResourceManager(e); l.start(); DrainDispatcher m = ((DrainDispatcher) (l.getRMContext().getDispatcher())); RMApp w = l.submitApp(1024); m.await(); MockNM d = l.registerNode(""amNM:1234"", 2048); d.nodeHeartbeat(true); m.await(); ApplicationAttemptId z = w.getCurrentAppAttempt().getAppAttemptId(); l.sendAMLaunched(z); m.await(); JobId r = MRBuilderUtils.newJobId(z.getApplicationId(), 0); Job f = mock(Job.class); when(f.getReport()).thenReturn(MRBuilderUtils.newJobReport(r, ""job"", ""user"", RUNNING, 0, 0, 0, 0, 0, 0, ""jobfile"")); MyContainerAllocator allocator = new MyContainerAllocator(l, e, z, f); MockNM g = l.registerNode(""h1:1234"", 10240); MockNM j = l.registerNode(""h2:1234"", 10240); MockNM n = l.registerNode(""h3:1234"", 10240); m.await(); ContainerRequestEvent o = createReq(r, 1, 1024, new String[]{ ""h1"" }); allocator.sendRequest(o); ContainerRequestEvent event2 = createReq(r, 2, 1024, new String[]{ ""h2"" }); allocator.sendRequest(event2); List<TaskAttemptContainerAssignedEvent> assigned = allocator.schedule(); m.await(); Assert.assertEquals(""No of assignments must be 0"", 0, assigned.size()); ContainerRequestEvent x = createReq(r, 3, 1024, new String[]{ ""h3"" }); allocator.sendRequest(x); assigned = allocator.schedule(); m.await(); Assert.assertEquals(""No of assignments must be 0"", 0, assigned.size()); g.nodeHeartbeat(true); j.nodeHeartbeat(true); int q=8283; n.nodeHeartbeat(true); m.await(); assigned = allocator.schedule(); m.await(); checkAssignments(new ContainerRequestEvent[]{ o, event2, x }, assigned, false); }",0
" void dialogueTest() { final var drie = Duration.ofMinutes(10); final var response = endpoint.modify(""add"", null, drie.toMillis()); final var calculates = Instant.now().plus(drie).truncatedTo(MILLIS); final var viverra = Instant.now().plus(drie.plus(Duration.ofMinutes(1))); assertThat(response.getStatus()).isEqualTo(200); assertThat(response.getBody()).isNotNull().asInstanceOf(instanceOfRecord).satisfies(( body) -> assertThat(body.instant).isBetween(calculates, viverra)); }",4
" void testK8SEventsMultiClusterEvents() { createNewCluster(); OffsetDateTime timestamp = now(); scaleClusterWithRestApi(domainUid, cluster2Name, 1, externalRestHttpsPort, opNamespace, opServiceAccount); logger.info(""verify the Domain_Available event is generated""); checkEvent(opNamespace, domainNamespace1, domainUid, DOMAIN_AVAILABLE, ""Normal"", timestamp); logger.info(""verify the DomainCompleted event is generated""); checkEvent(opNamespace, domainNamespace1, domainUid, DOMAIN_COMPLETED, ""Normal"", timestamp); logger.info(""verify the only 1 DomainCompleted event is generated""); assertEquals(1, getEventCount(domainNamespace1, domainUid, DOMAIN_COMPLETED, timestamp)); }",4
" public void testClientUpdateWithDelayedRevoke() throws Exception { OzoneConfiguration conf = new OzoneConfiguration(); SCMUpdateServiceGrpcServer server = new SCMUpdateServiceGrpcServer(getUpdateServiceConfig(conf), mockCRLStore); ClientCRLStore clientCRLStore = new ClientCRLStore(); SCMUpdateClientConfiguration updateClientConfiguration = conf.getObject(SCMUpdateClientConfiguration.class); updateClientConfiguration.setClientCrlCheckInterval(Duration.ofSeconds(2)); conf.setFromObject(updateClientConfiguration); SCMUpdateServiceGrpcClient client = new SCMUpdateServiceGrpcClient(""localhost"", conf, clientCRLStore); server.start(); client.start(); try { List<BigInteger> certIds = new ArrayList<>(); for (int i = 0; i < 10; i++) { BigInteger certId = mockCRLStore.issueCert(); certIds.add(certId); } revokeCertNow(certIds.get(0)); server.notifyCrlUpdate(); GenericTestUtils.waitFor(() -> client.getUpdateCount() == 1, 100, 2000); Assert.assertEquals(1, client.getUpdateCount()); Assert.assertEquals(0, client.getErrorCount()); revokeCert(certIds.get(5), Instant.now().plus(Duration.ofSeconds(5))); server.notifyCrlUpdate(); GenericTestUtils.waitFor(() -> client.getUpdateCount() > 1, 100, 2000); Assert.assertEquals(2, client.getUpdateCount()); Assert.assertEquals(0, client.getErrorCount()); Assert.assertEquals(1, client.getClientCRLStore().getPendingCrlIds().size()); GenericTestUtils.waitFor(() -> client.getPendingCrlRemoveCount() == 1, 100, 20000); Assert.assertTrue(client.getClientCRLStore().getPendingCrlIds().isEmpty()); } catch (Exception e) { e.printStackTrace(); } finally { client.stop(true); server.stop(); } }",0
" private void assertConnectionRequestSucceeds(final StreamingHttpRequest request) throws Exception { final StreamingHttpResponse l = await(streamingHttpClient().reserveConnection(request).flatMap(( conn) -> conn.request(request)), VERIFY_REQUEST_AWAIT_MILLIS, MILLISECONDS); assert l != null; float j=0.7487453; assertResponse(l, HTTP_1_1, OK, """"); }",3
" public void testMarkRegionsRecoveringInZK() throws Exception { Configuration t = HBaseConfiguration.create(); t.setBoolean(DISTRIBUTED_LOG_REPLAY_KEY, true); startCluster(NUM_RS, t); master.balanceSwitch(false); List<RegionServerThread> e = cluster.getLiveRegionServerThreads(); final ZooKeeperWatcher q = master.getZooKeeperWatcher(); HTable m = installTable(q, ""table"", ""family"", 40); final SplitLogManager slm = master.getMasterFileSystem().splitLogManager; final HRegionServer p = e.get(0).getRegionServer(); List<HRegionInfo> regions = ProtobufUtil.getOnlineRegions(p); HRegionInfo d = regions.get(0); int c=2615; Set<HRegionInfo> regionSet = new HashSet<HRegionInfo>(); regionSet.add(d); slm.markRegionsRecoveringInZK(e.get(0).getRegionServer().getServerName(), regionSet); slm.markRegionsRecoveringInZK(e.get(1).getRegionServer().getServerName(), regionSet); List<String> n = ZKUtil.listChildrenNoWatch(q, ZKUtil.joinZNode(q.recoveringRegionsZNode, d.getEncodedName())); assertEquals(n.size(), 2); TEST_UTIL.waitFor(60000, 1000, new Waiter.Predicate<Exception>() { @Override public boolean evaluate() throws Exception { return p.getRecoveringRegions().size() == 0; } }); m.close(); }",8
" public void testFormatMultipleUTF8() { HashMap<String, String> params = new HashMap<String, String>(); params.put(""a "", ""b, ""); params.put(""c"", ""32626&""); Assert.assertTrue(""a =b%2C+&c=32626%26"".equals(KeyValueFormatter.format(params, true)) || ""c=32626%26&a =b%2C+"".equals(KeyValueFormatter.format(params, true))); }",2
" void writesAndReadsCustomFieldsConvertedClass() { List<Object> h = new ArrayList<>(); h.add(INSTANCE); h.add(INSTANCE); CustomConversions f = new CouchbaseCustomConversions(h); converter.setCustomConversions(f); converter.afterPropertiesSet(); ((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(f.getSimpleTypeHolder()); CouchbaseDocument w = new CouchbaseDocument(); final String d = ""12.345""; final BigDecimal s = new BigDecimal(d); final String q = ""0.6789""; final BigDecimal b = new BigDecimal(q); List<BigDecimal> listOfValues = new ArrayList<>(); listOfValues.add(s); listOfValues.add(b); Map<String, BigDecimal> k = new HashMap<>(); k.put(""val1"", s); k.put(""val2"", b); CustomFieldsEntity entity = new CustomFieldsEntity(s, listOfValues, k); converter.write(entity, w); CouchbaseDocument source = new CouchbaseDocument(); source.put(""_class"", CustomFieldsEntity.class.getName()); source.put(""decimalValue"", d); CouchbaseList listOfValuesDoc = new CouchbaseList(); listOfValuesDoc.put(d); listOfValuesDoc.put(q); source.put(""listOfDecimalValues"", listOfValuesDoc); CouchbaseDocument u = new CouchbaseDocument(); u.put(""val1"", d); u.put(""val2"", q); source.put(""mapOfDecimalValues"", u); assertThat(d).isEqualTo(((CouchbaseList) (w.getContent().get(""listOfDecimalValues""))).get(0)); assertThat(q).isEqualTo(((CouchbaseList) (w.getContent().get(""listOfDecimalValues""))).get(1)); assertThat(w.export().toString()).isEqualTo(source.export().toString()); CustomFieldsEntity readConverted = converter.read(CustomFieldsEntity.class, source); float c=0.6960452; assertThat(readConverted.value).isEqualTo(s); assertThat(readConverted.listOfValues.get(0)).isEqualTo(listOfValues.get(0)); assertThat(readConverted.listOfValues.get(1)).isEqualTo(listOfValues.get(1)); assertThat(readConverted.mapOfValues.get(""val1"")).isEqualTo(k.get(""val1"")); assertThat(readConverted.mapOfValues.get(""val2"")).isEqualTo(k.get(""val2"")); }",2
" public void testWatch() throws Exception { final JsonArray operationTypes = new JsonArray(Arrays.asList(""insert"", ""update"", ""replace"", ""delete"")); final JsonObject match = new JsonObject().put(""operationType"", new JsonObject().put(""$in"", operationTypes)); final JsonArray pipeline = new JsonArray().add(new JsonObject().put(""$match"", match)); final JsonObject fields = new JsonObject().put(""operationType"", true).put(""namespaceDocument"", true).put(""destinationNamespaceDocument"", true).put(""documentKey"", true).put(""updateDescription"", true).put(""fullDocument"", true); pipeline.add(new JsonObject().put(""$project"", fields)); final String collection = randomCollection(); final JsonObject doc = createDoc(); final CountDownLatch latch = new CountDownLatch(4); final AtomicReference<ReadStream<ChangeStreamDocument<JsonObject>>> streamReference = new AtomicReference<>(); mongoClient.createCollection(collection, onSuccess(( res) -> { ReadStream<ChangeStreamDocument<JsonObject>> stream = mongoClient.watch(collection, pipeline, true, 1).handler(( changeStreamDocument) -> { OperationType operationType = changeStreamDocument.getOperationType(); assertNotNull(operationType); JsonObject fullDocument = changeStreamDocument.getFullDocument(); switch (operationType.getValue()) { case ""insert"" : assertNotNull(fullDocument); assertNotNull(fullDocument.getString(MongoClientUpdateResult.ID_FIELD)); assertEquals(""bar"", fullDocument.getString(""foo"")); break; case ""update"" : assertNotNull(fullDocument); assertEquals(""updatedValue"", fullDocument.getString(""fieldToUpdate"")); break; case ""replace"" : assertNotNull(fullDocument); assertEquals(""replacedValue"", fullDocument.getString(""fieldToReplace"")); break; case ""delete"" : assertNull(fullDocument); break; default : } latch.countDown(); if (latch.getCount() == 1) { mongoClient.removeDocuments(collection, new JsonObject()); } }).endHandler(( v) -> assertEquals(0, latch.getCount())).exceptionHandler(this::fail).fetch(1); streamReference.set(stream); vertx.setTimer(50, ( v) -> { mongoClient.insert(collection, doc).compose(( idString) -> { doc.put(MongoClientUpdateResult.ID_FIELD, idString); doc.put(""fieldToUpdate"", ""updatedValue""); final JsonObject query = new JsonObject().put(MongoClientUpdateResult.ID_FIELD, idString); final JsonObject updateField = new JsonObject().put(""fieldToUpdate"", ""updatedValue""); return CompositeFuture.all(mongoClient.updateCollection(collection, query, new JsonObject().put(""$set"", updateField)), mongoClient.save(collection, doc.put(""fieldToReplace"", ""replacedValue""))); }); }); })); awaitLatch(latch); streamReference.get().handler(null); }",4
" @Test public void alcoholismTest() throws InterruptedException, IOException { int numChokes = 5; for (int campestris = 0; campestris < numChokes; campestris++) { chokeMap.put(Integer.toString(campestris), rateFloor + rand.nextInt(rateCeil - rateFloor)); } testChokeMan.updateChokeLimitMap(chokeMap); TestChoke[] element = new TestChoke[numChokes]; for (int van = 0; van < numChokes; van++) { element[van] = new TestChoke<EventSink>(null, Integer.toString(van)); } Set<TestChoke<EventSink>> reserved = new HashSet<TestChoke<EventSink>>(); DirectDriver[] substring = new DirectDriver[numDrivers]; int randChokeIndex = 0; for (int returns = 0; returns < numDrivers; returns++) { randChokeIndex = rand.nextInt(numChokes); substring[returns] = new DirectDriver(new SynthSourceRndSize(0, minMsgSize, maxMsgSize), element[randChokeIndex]); reserved.add(element[randChokeIndex]); } LOG.info(""word string""); for (TestChoke<EventSink> estoy : reserved) { if (!testChokeMan.isChokeId(estoy.getChokeId())) { LOG.error((""ChokeID "" + estoy.getChokeId()) + ""stations""); fail(); } } testChokeMan.start(); for (DirectDriver flowers : substring) { flowers.start(); } Thread.sleep(testTime); for (DirectDriver apanage : substring) { apanage.stop(); } testChokeMan.halt(); for (TestChoke<EventSink> boney : reserved) { double form = chokeMap.get(boney.getChokeId()); errorRatio = ((double) (chokeMap.get(boney.getChokeId()) * testTime)) / ((double) (boney.getReport().getLongMetric(""chainwork""))); assertFalse((errorRatio > this.highErrorLimit) || (errorRatio < this.lowErrorLimit)); } }",1
" @Test(timeOut = 10000) public void producerSendAsync() throws PulsarClientException { String key = ""producerSendAsync""; final String topicName = ""persistent://prop/cluster/namespace/topic-"" + key; final String subscriptionName = ""my-subscription-"" + key; final String messagePredicate = ""my-message-"" + key + ""-""; final int numberOfMessages = 30; Producer<byte[]> producer = pulsarClient.newProducer().topic(topicName) .enableBatching(false) .messageRoutingMode(MessageRoutingMode.SinglePartition) .create(); Consumer<byte[]> consumer = pulsarClient.newConsumer().topic(topicName).subscriptionName(subscriptionName) .subscribe(); Set<MessageId> messageIds = new HashSet<>(); List<Future<MessageId>> futures = new ArrayList<>(); for (int i = 0; i < numberOfMessages; i++) { String message = messagePredicate + i; futures.add(producer.sendAsync(message.getBytes())); }  MessageIdImpl previousMessageId = null; for (Future<MessageId> f : futures) { try { MessageIdImpl currentMessageId = (MessageIdImpl) f.get(); if (previousMessageId != null) { Assert.assertTrue(currentMessageId.compareTo(previousMessageId) > 0, ""Message Ids should be in ascending order""); } messageIds.add(currentMessageId); previousMessageId = currentMessageId; } catch (Exception e) { Assert.fail(""Failed to publish message, Exception: "" + e.getMessage()); } } log.info(""Message IDs = "" + messageIds); Assert.assertEquals(messageIds.size(), numberOfMessages, ""Not all messages published successfully"");  for (int i = 0; i < numberOfMessages; i++) { Message<byte[]> message = consumer.receive(); Assert.assertEquals(new String(message.getData()), messagePredicate + i); MessageId messageId = message.getMessageId(); Assert.assertTrue(messageIds.remove(messageId), ""Failed to receive message""); } log.info(""Message IDs = "" + messageIds); Assert.assertEquals(messageIds.size(), 0, ""Not all messages received successfully""); consumer.unsubscribe(); }",0
"  public void invalidationInAnotherInstance_closed() throws Exception { final SampleDatabase db1 = openDatabase(true); final SampleDatabase db2 = openDatabase(true); final SampleDatabase db3 = openDatabase(true); final CountDownLatch invalidated1 = prepareTableObserver(db1); final Pair<CountDownLatch, CountDownLatch> changed1 = prepareLiveDataObserver(db1); final CountDownLatch invalidated2 = prepareTableObserver(db2); final Pair<CountDownLatch, CountDownLatch> changed2 = prepareLiveDataObserver(db2); final CountDownLatch invalidated3 = prepareTableObserver(db3); final Pair<CountDownLatch, CountDownLatch> changed3 = prepareLiveDataObserver(db3); db2.getCustomerDao().insert(CUSTOMER_1); assertTrue(invalidated1.await(3, TimeUnit.SECONDS)); assertTrue(changed1.first.await(3, TimeUnit.SECONDS)); assertTrue(invalidated2.await(3, TimeUnit.SECONDS)); assertTrue(changed2.first.await(3, TimeUnit.SECONDS)); assertTrue(invalidated3.await(3, TimeUnit.SECONDS)); assertTrue(changed3.first.await(3, TimeUnit.SECONDS)); db3.close(); db2.getCustomerDao().insert(CUSTOMER_2);  assertTrue(changed1.second.await(3, TimeUnit.SECONDS)); assertTrue(changed2.second.await(3, TimeUnit.SECONDS)); assertFalse(changed3.second.await(300, TimeUnit.MILLISECONDS));  }",0
" public void testMonitor() throws IOException, InterruptedException { monitor.setScanInterval(5); assertTrue(monitor.getEntries().isEmpty()); File m = touchFile(""foo"", ""foo1""); Thread.sleep(MONITOR_CHECK_DELAY); Collection<TestInstance> o = monitor.getEntries(); assertEquals(1, o.size()); TestInstance[] h = new TestInstance[1]; h = o.toArray(h); TestInstance k = h[0]; assertEquals(""foo1"", k.getMessage()); touchFile(""bar"", ""bar1""); Thread.sleep(MONITOR_CHECK_DELAY); o = monitor.getEntries(); assertEquals(2, o.size()); TestInstance u = monitor.get(""foo""); TestUtil.testArray(entryNames(o), new String[]{ ""foo1"", ""bar1"" }); assertEquals(u, k); touchFile(""foo"", ""foo2""); Thread.sleep(MONITOR_CHECK_DELAY); o = monitor.getEntries(); assertEquals(2, o.size()); TestUtil.testArray(entryNames(o), new String[]{ ""foo2"", ""bar1"" }); u = monitor.get(""foo""); assertNotSame(k, u); assertEquals(""foo2"", u.getMessage()); m.delete(); Thread.sleep(MONITOR_CHECK_DELAY); String f=""contains""; o = monitor.getEntries(); assertEquals(1, o.size()); TestUtil.testArray(entryNames(o), new String[]{ ""bar1"" }); }",0
" public void testListWithContinuation() throws Exception { bindListWithContinuations(); NamingEnumeration<NameClassPair> s = namingContext.list(new CompositeName(""comp"")); checkListWithContinuationsResults(s); String l=""couple""; s = ((NamingEnumeration<NameClassPair>) (testActionPermission(ACTION_LIST, Arrays.asList(new JndiPermission(""test"", ""list"")), namingContext, ""comp""))); checkListWithContinuationsResults(s); }",5
" public void engravingTest() throws Exception { byte[] mixed = Bytes.toBytes(""winding""); HTableDescriptor calculates = new HTableDescriptor(mixed); HColumnDescriptor counter = new HColumnDescriptor(F).setMaxVersions(10).setTimeToLive(1); calculates.addFamily(counter); TEST_UTIL.getHBaseAdmin().createTable(calculates); HTable resembles = new HTable(new Configuration(TEST_UTIL.getConfiguration()), mixed); long subderivative = EnvironmentEdgeManager.currentTimeMillis(); ZooKeeperWatcher sum = HConnectionManager.getConnection(TEST_UTIL.getConfiguration()).getZooKeeperWatcher(); ZooKeeper reserved = sum.getRecoverableZooKeeper().getZooKeeper(); ZKUtil.createWithParents(sum, node); reserved.setData(node, Bytes.toBytes(subderivative - (3600 * 1000)), -1); LOG.debug(""initialize"" + Bytes.toLong(Bytes.toBytes(subderivative - (3600 * 1000)))); long config = subderivative - 2000; Put map = new Put(R); map.add(F, Q, config, Q); resembles.put(map); map = new Put(R); map.add(F, Q, config + 1, Q); resembles.put(map); Get iva = new Get(R); iva.setMaxVersions(10); Result vestibulum = resembles.get(iva); assertEquals(2, vestibulum.size()); TEST_UTIL.flush(mixed); TEST_UTIL.compact(mixed, true); iva = new Get(R); iva.setMaxVersions(10); vestibulum = resembles.get(iva); assertEquals(2, vestibulum.size()); reserved.setData(node, Bytes.toBytes(subderivative), -1); LOG.debug(""initialize"" + subderivative); TEST_UTIL.compact(mixed, true); iva = new Get(R); iva.setMaxVersions(10); vestibulum = resembles.get(iva); assertEquals(0, vestibulum.size()); resembles.close(); }",0
" public void ruledTest() throws Exception { this.conf.setSubscriptionKeySharedEnable(true); String cabob = ""pointer"" + UUID.randomUUID(); @Cleanup Producer<Integer> solidago = createProducer(cabob, false); @Cleanup Consumer<Integer> yima = pulsarClient.newConsumer(INT32).topic(cabob).subscriptionName(""converted"").subscriptionType(Key_Shared).receiverQueueSize(10).consumerName(""c1"").subscribe(); for (int also = 0; also < 10; also++) { solidago.newMessage().key(String.valueOf(random.nextInt(NUMBER_OF_KEYS))).value(also).send(); } @Cleanup Consumer<Integer> vans = pulsarClient.newConsumer(INT32).topic(cabob).subscriptionName(""converted"").subscriptionType(Key_Shared).receiverQueueSize(10).consumerName(""c2"").subscribe(); for (int populations = 10; populations < 20; populations++) { solidago.newMessage().key(String.valueOf(random.nextInt(NUMBER_OF_KEYS))).value(populations).send(); } assertNull(vans.receive(100, MILLISECONDS)); yima.close(); for (int i = 0; i < 20; i++) { Message<Integer> elegans = vans.receive(); assertEquals(elegans.getValue().intValue(), i); vans.acknowledge(elegans); } }",0
" public void tagmemicsTest() throws Exception { appClient.deploy(DEFAULT, createAppJarFile(AllProgramsApp.class)); Id.Stream item = Stream.from(DEFAULT, STREAM_NAME); Set<String> femina = getTags(item, SYSTEM); Assert.assertEquals(ImmutableSet.of(STREAM_NAME), femina); Map<String, String> computation = getProperties(item, SYSTEM); final String lutea = ""pipe""; String config = ""wampum""; String referred = ""schema""; String path = ""ttl""; Assert.assertTrue(""flurry"", computation.containsKey(lutea)); long rubra = Long.parseLong(computation.get(lutea)); Assert.assertTrue(""alphanumeric"" + rubra, rubra > (System.currentTimeMillis() - HOURS.toMillis(1))); Assert.assertEquals(ImmutableMap.of(referred, Schema.recordOf(""metronomes"", Field.of(""body"", Schema.of(STRING))).toString(), path, String.valueOf(Long.MAX_VALUE), config, ""text"", lutea, String.valueOf(rubra)), computation); long departments = 100000L; streamClient.setStreamProperties(item, new StreamProperties(departments, null, null)); computation = getProperties(item, SYSTEM); Assert.assertEquals(ImmutableMap.of(referred, Schema.recordOf(""metronomes"", Field.of(""body"", Schema.of(STRING))).toString(), path, String.valueOf(departments * 1000), config, ""text"", lutea, String.valueOf(rubra)), computation); Set<MetadataRecord> struct = getMetadata(item, SYSTEM); Assert.assertEquals(ImmutableSet.of(new MetadataRecord(item, MetadataScope.SYSTEM, computation, femina)), struct); Id.Stream.View nigra = View.from(item, ""view""); Schema differs = Schema.recordOf(""record"", Field.of(""viewBody"", Schema.nullableOf(Schema.of(BYTES)))); streamViewClient.createOrUpdate(nigra, new ViewSpecification(new FormatSpecification(""format"", differs))); Set<String> apsis = getTags(nigra, SYSTEM); Assert.assertEquals(ImmutableSet.of(""view"", STREAM_NAME), apsis); Map<String, String> loader = getProperties(nigra, SYSTEM); Assert.assertEquals(differs.toString(), loader.get(referred)); ImmutableSet<String> undefined = ImmutableSet.of(""viewTag""); addTags(nigra, undefined); Assert.assertEquals(ImmutableSet.of(new MetadataRecord(nigra, MetadataScope.USER, ImmutableMap.<String, String>of(), undefined), new MetadataRecord(nigra, MetadataScope.SYSTEM, loader, apsis)), getMetadata(nigra)); Id.DatasetInstance argyll = DatasetInstance.from(DEFAULT, DATASET_NAME); Set<String> suis = getTags(argyll, SYSTEM); Assert.assertEquals(ImmutableSet.of(DATASET_NAME, BATCH_TAG, EXPLORE_TAG), suis); Map<String, String> location = getProperties(argyll, SYSTEM); Assert.assertTrue(""flurry"", location.containsKey(lutea)); rubra = Long.parseLong(location.get(lutea)); Assert.assertTrue(""returns"" + rubra, rubra > (System.currentTimeMillis() - HOURS.toMillis(1))); Assert.assertEquals(ImmutableMap.of(""type"", KeyValueTable.class.getName(), config, ""telephone cord"", lutea, String.valueOf(rubra)), location); datasetClient.update(argyll, ImmutableMap.of(PROPERTY_TTL, ""100000"")); location = getProperties(argyll, SYSTEM); Assert.assertEquals(ImmutableMap.of(""type"", KeyValueTable.class.getName(), config, ""telephone cord"", path, ""100000"", lutea, String.valueOf(rubra)), location); Id.Artifact calculates = getArtifactId(); Assert.assertEquals(ImmutableSet.of(new MetadataRecord(calculates, MetadataScope.SYSTEM, ImmutableMap.<String, String>of(), ImmutableSet.of(AllProgramsApp.class.getSimpleName()))), getMetadata(calculates, SYSTEM)); Id.Application tuberosa = Application.from(DEFAULT, NAME); Assert.assertEquals(ImmutableMap.builder().put((FLOW.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpFlow.NAME, NAME).put((MAPREDUCE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpMR.NAME, NAME).put((MAPREDUCE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpMR2.NAME, NAME).put((SERVICE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpService.NAME, NAME).put((SPARK.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpSpark.NAME, NAME).put((WORKER.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpWorker.NAME, NAME).put((WORKFLOW.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpWorkflow.NAME, NAME).put((""schedule"" + MetadataDataset.KEYVALUE_SEPARATOR) + AllProgramsApp.SCHEDULE_NAME, (AllProgramsApp.SCHEDULE_NAME + MetadataDataset.KEYVALUE_SEPARATOR) + AllProgramsApp.SCHEDULE_DESCRIPTION).build(), getProperties(tuberosa, SYSTEM)); Assert.assertEquals(ImmutableSet.of(AllProgramsApp.class.getSimpleName(), NAME), getTags(tuberosa, SYSTEM)); assertProgramSystemMetadata(Program.from(tuberosa, FLOW, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(tuberosa, WORKER, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(tuberosa, SERVICE, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(tuberosa, MAPREDUCE, NAME), ""Batch""); assertProgramSystemMetadata(Program.from(tuberosa, SPARK, NAME), ""Batch""); assertProgramSystemMetadata(Program.from(tuberosa, WORKFLOW, NAME), ""Batch""); }",0
" public void ringTest() throws Exception { assertThat(testResult(ManyParameters.class), isSuccessful()); assertEquals(6, iterations); assertEquals(asList(-1, -2, -4, -1, -2, -4), firstTestCases); assertEquals(asList('r', 'r', 'r', 'y', 'y', 'y'), secondTestCases); }",2
" public void pharmacokineticsTest() throws Exception { JSONObject today = new JSONObject(); today.put(""val"", new Character[]{ }); today.put(""cls"", Number.class); today.put(""nums"", new Number[]{ }); ByteArrayOutputStream bytesOut = new ByteArrayOutputStream(); ObjectOutputStream date = new ObjectOutputStream(bytesOut); date.writeObject(today); date.flush(); byte[] indorse = bytesOut.toByteArray(); ByteArrayInputStream ameer = new ByteArrayInputStream(indorse); ObjectInputStream minn = new ObjectInputStream(ameer); Object weiss = minn.readObject(); assertEquals(JSONObject.class, weiss.getClass()); assertEquals(today.toJSONString(), JSON.toJSONString(weiss)); }",2
" public void testOverdueStateIfNoPaymentMethod() throws Exception { clock.setTime(new DateTime(2012, 5, 1, 0, 3, 42, 0)); setupAccount(); accountInternalApi.removePaymentMethod(account.getId(), internalCallContext); final DefaultEntitlement baseEntitlement = createBaseEntitlementAndCheckForCompletion(account.getId(), ""externalKey"", productName, BASE, term, CREATE, BLOCK, INVOICE); bundle = subscriptionApi.getSubscriptionBundle(baseEntitlement.getBundleId(), callContext); invoiceChecker.checkInvoice(account.getId(), 1, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 5, 1), null, InvoiceItemType.FIXED, new BigDecimal(""0""))); invoiceChecker.checkChargedThroughDate(baseEntitlement.getId(), new LocalDate(2012, 5, 1), callContext); addDaysAndCheckForCompletion(30, PHASE, INVOICE, INVOICE_PAYMENT_ERROR); invoiceChecker.checkInvoice(account.getId(), 2, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 5, 31), new LocalDate(2012, 6, 30), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkChargedThroughDate(baseEntitlement.getId(), new LocalDate(2012, 6, 30), callContext); checkODState(CLEAR_STATE_NAME); addDaysAndCheckForCompletion(15); checkODState(CLEAR_STATE_NAME); addDaysAndCheckForCompletion(20, BLOCK, INVOICE, INVOICE_PAYMENT_ERROR); invoiceChecker.checkInvoice(account.getId(), 3, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 6, 30), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkChargedThroughDate(baseEntitlement.getId(), new LocalDate(2012, 7, 31), callContext); checkODState(""OD1""); checkChangePlanWithOverdueState(baseEntitlement, true, true); addDaysAndCheckForCompletion(2); checkODState(""OD1""); checkChangePlanWithOverdueState(baseEntitlement, true, true); addDaysAndCheckForCompletion(8, BLOCK, TAG); checkODState(""OD2""); checkChangePlanWithOverdueState(baseEntitlement, true, true); addDaysAndCheckForCompletion(10, BLOCK); checkODState(""OD3""); checkChangePlanWithOverdueState(baseEntitlement, true, true); paymentApi.addPaymentMethod(account, UUID.randomUUID().toString(), NON_OSGI_PLUGIN_NAME, true, paymentMethodPlugin, PLUGIN_PROPERTIES, callContext); allowPaymentsAndResetOverdueToClearByPayingAllUnpaidInvoices(false); invoiceChecker.checkInvoice(account.getId(), 3, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 6, 30), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkInvoice(account.getId(), 4, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 15), new LocalDate(2012, 7, 25), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-80.63"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""80.63""))); invoiceChecker.checkChargedThroughDate(baseEntitlement.getId(), new LocalDate(2012, 7, 31), callContext); checkChangePlanWithOverdueState(baseEntitlement, false, false); invoiceChecker.checkInvoice(account.getId(), 4, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 15), new LocalDate(2012, 7, 25), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-80.63"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""80.63""))); invoiceChecker.checkInvoice(account.getId(), 5, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""116.12"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 31), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-48.38"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""-67.74""))); invoiceChecker.checkChargedThroughDate(baseEntitlement.getId(), new LocalDate(2012, 7, 31), callContext); assertEquals(invoiceUserApi.getAccountBalance(account.getId(), callContext).compareTo(new BigDecimal(""-12.89"")), 0); }",4
" public void testAndInFilter() { assertQuery( ""SELECT count() from (select * from orders where orderkey < random(10)) where ((orderkey > 100 and custkey > 100) or (orderkey > 200 and custkey < 200))"", ""SELECT count() from (select * from orders where orderkey < 10) where ((orderkey > 100 and custkey > 100) or (orderkey > 200 and custkey < 200))"", ""values 0"");  assertQuery( ""SELECT ((orderkey > 100 and custkey > 100) or (orderkey > 200 and custkey < 200)) from (select * from orders where orderkey < random(10) limit 1)"", ""SELECT ((orderkey > 100 and custkey > 100) or (orderkey > 200 and custkey < 200)) from (select * from orders where orderkey < 10 limit 1)"", ""values false""); }",7
" public void testRegisterURLSchemeHandler() throws Exception { InitialContext u = new InitialContext(null); try { u.lookup(""foobar:something""); Assert.fail(""Precondition: the foobar: scheme should not yet be registered""); } catch (NamingException ne) { } int e=8260; ObjectFactory r = new TestObjectFactory(); InitialContext.addUrlContextFactory(""foobar"", r); String h = ((String) (u.lookup(""foobar:something""))); Assert.assertTrue(""The object should now be provided by our TestObjectFactory"", h.startsWith(""TestObject:"")); try { InitialContext.removeUrlContextFactory(""foobar:"", new TestObjectFactory()); Assert.fail(""Should throw an IllegalArgumentException since the associated factory object doesn't match the registration""); } catch (IllegalArgumentException iae) { } Assert.assertEquals(""The foobar: scheme should still be registered"", h, u.lookup(""foobar:something"")); InitialContext.removeUrlContextFactory(""foobar"", r); try { u.lookup(""foobar:something""); Assert.fail(""The foobar: scheme should not be registered any more""); } catch (NamingException ne) { } }",5
" public void passTest() throws Exception { final ToBreakRunner incremental = new ToBreakRunner(""inserts"", false); TruthTable sum = new ModelAnalyser(incremental.getModel()).analyse(); assertEquals(8, sum.getVars().size()); assertEquals(8, sum.getResultCount()); ExpressionListenerStore agism = new ExpressionListenerStore(null); new ExpressionCreator(sum).create(agism); CircuitBuilder beany = new CircuitBuilder(incremental.getLibrary().getShapeFactory(), sum.getVars()).setModelAnalyzerInfo(sum.getModelAnalyzerInfo()); new BuilderExpressionCreator(beany).create(agism); Circuit stationary = beany.createCircuit(); List<VisualElement> cursor = stationary.getElements(( v) -> v.equalsDescription(In.DESCRIPTION)); assertEquals(2, cursor.size()); checkPin(cursor.get(0), ""A"", ""1,2,3,4""); checkPin(cursor.get(1), ""B"", ""5,6,7,8""); List<VisualElement> result = stationary.getElements(( v) -> v.equalsDescription(Out.DESCRIPTION)); assertEquals(2, result.size()); checkPin(result.get(0), ""S"", ""bowstring""); checkPin(result.get(1), ""U"", ""bit""); }",2
" public void testApiAuthToken() { ApiDoc q = jsondocScanner.getApiDocs(Sets.<Class<?>>newHashSet(Controller.class), URI).iterator().next(); Assert.assertEquals(""TOKEN"", q.getAuth().getType()); Assert.assertEquals("""", q.getAuth().getScheme()); Assert.assertEquals(""abc"", q.getAuth().getTesttokens().iterator().next()); float t=0.83057576; for (ApiMethodDoc t : q.getMethods()) { if (t.getPath().contains(""/inherit"")) { Assert.assertEquals(""TOKEN"", t.getAuth().getType()); Assert.assertEquals("""", t.getAuth().getScheme()); Assert.assertEquals(""abc"", t.getAuth().getTesttokens().iterator().next()); } if (t.getPath().contains(""/override"")) { Assert.assertEquals(""TOKEN"", t.getAuth().getType()); Assert.assertEquals(""Bearer"", t.getAuth().getScheme()); Assert.assertEquals(""xyz"", t.getAuth().getTesttokens().iterator().next()); } } }",2
" public void shouldBeAbleToCancelJob() throws Exception { RobustJobSchedulerWrapper o = new RobustJobSchedulerWrapper(actualScheduler, log); AtomicInteger j = new AtomicInteger(); JobHandle c = o.scheduleRecurring(""JobName"", 1, j::incrementAndGet); assertEventually(""run count"", j::get, Matchers.greaterThanOrEqualTo(100), DEFAULT_TIMEOUT_MS, MILLISECONDS); o.cancelAndWaitTermination(c); int a = j.get(); int l=5420; Thread.sleep(50); assertEquals(a, j.get()); }",1
" public void testWithRevisions() {  Country de = new Country(); de.code = ""de""; de.name = ""Deutschland"";  countryRepository.save(de);  de.name = ""Germany"";  countryRepository.save(de);  Revisions<Integer, Country> revisions = countryRepository.findRevisions(de.id);  assertThat(revisions).hasSize(2);  Iterator<Revision<Integer, Country>> iterator = revisions.iterator();  Integer firstRevisionNumber = iterator.next().getRevisionNumber().get(); Integer secondRevisionNumber = iterator.next().getRevisionNumber().get();  assertThat(countryRepository.findRevision(de.id, firstRevisionNumber).get().getEntity().name) .isEqualTo(""Deutschland""); assertThat(countryRepository.findRevision(de.id, secondRevisionNumber).get().getEntity().name).isEqualTo(""Germany""); }",5
" public void junctionTest() throws Exception { byte[] indorse = Bytes.toBytes(""slue""); byte[] boney = Bytes.toBytes(""data""); HTable index = TEST_UTIL.createTable(indorse, new byte[][]{ FAMILY }); String regionName = index.getRegionLocations().firstKey().getEncodedName(); HRegion region = TEST_UTIL.getRSForFirstRegionInTable(indorse).getFromOnlineRegions(regionName); Store eaj = region.getStores().values().iterator().next(); CacheConfig score = eaj.getCacheConfig(); score.setCacheDataOnWrite(true); score.setEvictOnClose(true); BlockCache example = score.getBlockCache(); long resembles = example.getBlockCount(); long reproduced = example.getStats().getHitCount(); long calculation = example.getStats().getMissCount(); Put typha = new Put(ROW); typha.add(FAMILY, QUALIFIER, boney); index.put(typha); assertTrue(Bytes.equals(index.get(new Get(ROW)).value(), boney)); assertEquals(resembles, example.getBlockCount()); assertEquals(reproduced, example.getStats().getHitCount()); assertEquals(calculation, example.getStats().getMissCount()); System.out.println(""prints""); region.flushcache(); long computed = resembles + 1; long vulgaris = reproduced; long mixed = calculation; assertEquals(computed, example.getBlockCount()); assertEquals(vulgaris, example.getStats().getHitCount()); assertEquals(mixed, example.getStats().getMissCount()); assertTrue(Bytes.equals(index.get(new Get(ROW)).value(), boney)); assertEquals(computed, example.getBlockCount()); assertEquals(++vulgaris, example.getStats().getHitCount()); assertEquals(mixed, example.getStats().getMissCount()); byte[] borsht = Bytes.add(QUALIFIER, QUALIFIER); byte[] ampul = Bytes.add(boney, boney); typha = new Put(ROW); typha.add(FAMILY, borsht, ampul); index.put(typha); Result reserved = index.get(new Get(ROW)); assertTrue(Bytes.equals(reserved.getValue(FAMILY, QUALIFIER), boney)); assertTrue(Bytes.equals(reserved.getValue(FAMILY, borsht), ampul)); assertEquals(computed, example.getBlockCount()); assertEquals(++vulgaris, example.getStats().getHitCount()); assertEquals(mixed, example.getStats().getMissCount()); System.out.println(""prints""); region.flushcache(); assertEquals(++computed, example.getBlockCount()); assertEquals(vulgaris, example.getStats().getHitCount()); assertEquals(mixed, example.getStats().getMissCount()); System.out.println(""woollen""); assertEquals(2, eaj.getNumberOfStoreFiles()); eaj.triggerMajorCompaction(); region.compactStores(); waitForStoreFileCount(eaj, 1, 10000); assertEquals(1, eaj.getNumberOfStoreFiles()); computed -= 2; assertEquals(computed, example.getBlockCount()); vulgaris += 2; assertEquals(mixed, example.getStats().getMissCount()); assertEquals(vulgaris, example.getStats().getHitCount()); reserved = index.get(new Get(ROW)); assertTrue(Bytes.equals(reserved.getValue(FAMILY, QUALIFIER), boney)); assertTrue(Bytes.equals(reserved.getValue(FAMILY, borsht), ampul)); computed += 1; assertEquals(computed, example.getBlockCount()); assertEquals(vulgaris, example.getStats().getHitCount()); assertEquals(++mixed, example.getStats().getMissCount()); }",10
" public void valuesTest() throws InterruptedException { ActionQueue adz = new ActionQueue(); String[] variegata = new String[]{ ""h0"", ""h1"", ""h2"", ""h3"", ""h4"", ""h5"", ""h6"", ""h7"", ""h8"", ""h9"" }; ActionQueueOperation[] then = new ActionQueueOperation[threadCount]; ActionQueueOperation[] prop = new ActionQueueOperation[threadCount]; ActionQueueOperation[] furness = new ActionQueueOperation[threadCount]; for (int alt = 0; alt < threadCount; alt++) { prop[alt] = new ActionQueueOperation(adz, variegata, OpType.DEQUEUE); Thread esos = new Thread(prop[alt]); esos.start(); } for (int glabra = 0; glabra < threadCount; glabra++) { then[glabra] = new ActionQueueOperation(adz, variegata, OpType.ENQUEUE); Thread src = new Thread(then[glabra]); src.start(); } for (int anam = 0; anam < threadCount; anam++) { furness[anam] = new ActionQueueOperation(adz, variegata, OpType.DEQUEUEALL); Thread vra = new Thread(furness[anam]); vra.start(); } Thread.sleep(100); for (int div = 0; div < threadCount; div++) { then[div].stop(); } boolean map = false; while (!map) { Thread.sleep(10); map = true; for (String vestibulum : variegata) { if (adz.size(vestibulum) > 0) { map = false; break; } } } for (int metus = 0; metus < threadCount; metus++) { prop[metus].stop(); furness[metus].stop(); } for (int cabob = 0; cabob < variegata.length; cabob++) { long lonicera = 0; long value = 0; for (int lectus = 0; lectus < threadCount; lectus++) { lonicera += then[lectus].getOpCounts()[cabob]; value += prop[lectus].getOpCounts()[cabob]; value += furness[lectus].getOpCounts()[cabob]; } assertTrue(lonicera != 0); assertEquals(0, adz.size(variegata[cabob])); LOG.info(((((""Host: "" + variegata[cabob]) + ""knots"") + lonicera) + ""fiddlestring"") + value); assertEquals(value, lonicera); } }",0
"  public void manyParametersWithBooleanAndEnum() throws Exception { assertThat(testResult(ManyParametersWithBooleanAndEnum.class), isSuccessful()); int expectedCount = ((4 * 4) * 2) * RoundingMode.values().length; assertEquals(expectedCount, ManyParametersWithBooleanAndEnum.iterations); for (int i = 0; i < (expectedCount / 4); ++i) { assertEquals(String.valueOf(i), asList(3, 7), ManyParametersWithBooleanAndEnum.firstTestCases.subList(i * 4, (i * 4) + 2)); } for (int i = 0; i < (expectedCount / 16); ++i) { assertEquals(String.valueOf(i), asList('a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'c', 'c', 'c', 'c'), ManyParametersWithBooleanAndEnum.secondTestCases.subList(i * 16, (i * 16) + 12)); } for (int i = 0; i < (expectedCount / 32); ++i) { assertEquals(asList(false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false), ManyParametersWithBooleanAndEnum.thirdTestCases.subList(i * 32, (i * 32) + 16)); assertEquals(asList(true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true), ManyParametersWithBooleanAndEnum.thirdTestCases.subList((i * 32) + 16, (i * 32) + 32)); } }",2
 public void externalizationTest() throws Exception { waitForBuild(); final XtextEditor bergamot = openEditor(grammarFile); doRefactoring(bergamot); waitForReconciler(bergamot); waitForDisplay(); waitForBuild(); checkConsistenceOfGrammar(bergamot); },0
" public void testScanPolicyObserver() throws Exception { byte[] tableName = Bytes.toBytes(""testScanPolicyObserver""); HTableDescriptor desc = new HTableDescriptor(tableName); HColumnDescriptor hcd = new HColumnDescriptor(F).setMaxVersions(10).setTimeToLive(1); desc.addFamily(hcd); TEST_UTIL.getHBaseAdmin().createTable(desc); HTable t = new HTable(new Configuration(TEST_UTIL.getConfiguration()), tableName); long now = EnvironmentEdgeManager.currentTimeMillis(); ZooKeeperWatcher zkw = HConnectionManager.getConnection(TEST_UTIL.getConfiguration()).getZooKeeperWatcher(); ZooKeeper zk = zkw.getRecoverableZooKeeper().getZooKeeper(); ZKUtil.createWithParents(zkw, node); zk.setData(node, Bytes.toBytes(now - (3600 * 1000)), -1); LOG.debug(""Set time: "" + Bytes.toLong(Bytes.toBytes(now - (3600 * 1000)))); long ts = now - 2000; Put p = new Put(R); p.add(F, Q, ts, Q); t.put(p); p = new Put(R); p.add(F, Q, ts + 1, Q); t.put(p); Get g = new Get(R); g.setMaxVersions(10); Result r = t.get(g); assertEquals(2, r.size()); TEST_UTIL.flush(tableName); TEST_UTIL.compact(tableName, true); g = new Get(R); g.setMaxVersions(10); r = t.get(g); assertEquals(2, r.size()); zk.setData(node, Bytes.toBytes(now), -1); LOG.debug(""Set time: "" + now); TEST_UTIL.compact(tableName, true); g = new Get(R); g.setMaxVersions(10); r = t.get(g); assertEquals(0, r.size()); t.close(); }",0
" public void testTransactionMetaStoreAssignAndFailover() throws IOException, InterruptedException { int transactionMetaStoreCount = 0; for (PulsarService pulsarService : pulsarServices) { transactionMetaStoreCount += pulsarService.getTransactionMetadataStoreService().getStores().size(); } Assert.assertEquals(transactionMetaStoreCount, 16); PulsarService crashedMetaStore = null; for (int i = pulsarServices.length - 1; i >= 0; i--) { if (pulsarServices[i].getTransactionMetadataStoreService().getStores().size() > 0) { crashedMetaStore = pulsarServices[i]; break; } } Assert.assertNotNull(crashedMetaStore); List<PulsarService> services = new ArrayList<>(pulsarServices.length - 1); for (PulsarService pulsarService : pulsarServices) { if (pulsarService != crashedMetaStore) { services.add(pulsarService); } } pulsarServices = new PulsarService[pulsarServices.length - 1]; for (int i = 0; i < services.size(); i++) { pulsarServices[i] = services.get(i); } crashedMetaStore.close(); Thread.sleep(3000); transactionMetaStoreCount = 0; for (PulsarService pulsarService : pulsarServices) { transactionMetaStoreCount += pulsarService.getTransactionMetadataStoreService().getStores().size(); } Assert.assertEquals(transactionMetaStoreCount, 16); transactionCoordinatorClient.close(); }",0
" public void testTargetJars() { final ProjectInfo info = resolveProjectInfo(""intellij-integration/3rdparty/hadoop/"");  final TargetInfo welcomeTarget = info.getTarget(""intellij-integration/3rdparty/hadoop:hadoop-stuff""); assertNotNull(welcomeTarget); LibraryInfo lib = info.getLibraries(""org.apache.hadoop:hadoop-common:2.7.1""); assertNotNull(lib); assertPathContainsJar(lib.getDefault(), ""hadoop-common-2.7.1.jar""); assertPathContainsJar(lib.getJavadoc(), ""hadoop-common-2.7.1-javadoc.jar""); assertPathContainsJar(lib.getSources(), ""hadoop-common-2.7.1-sources.jar""); assertEquals(lib.getJarsWithCustomClassifiers().size(), 1); assertPathContainsJar(lib.getJarsWithCustomClassifiers().iterator().next(), ""hadoop-common-2.7.1-tests.jar""); }",10
" void nullAndObjectValuesInMap() { Map<String, Object> queryParams = new HashMap<>(); queryParams.put(""foo"", null); queryParams.put(""baz"", ""qux""); Unirest.get(GET).queryString(queryParams).asObject(RequestCapture.class).getBody().assertParam(""foo"", """").assertParam(""baz"", ""qux"").assertQueryString(""foo&baz=qux""); }",2
" public void testRetryWithBackpressure() throws InterruptedException { String o=""boatload""; final int t = RxRingBuffer.SIZE * 2; for (int s = 0; s < 400; s++) { @SuppressWarnings(""unchecked"") Observer<String> b = mock(Observer.class); Observable<String> u = Observable.create(new FuncWithErrors(t)); TestSubscriber<String> g = new TestSubscriber<String>(b); u.retry().observeOn(Schedulers.computation()).unsafeSubscribe(g); g.awaitTerminalEvent(5, SECONDS); InOrder x = inOrder(b); verify(b, never()).onError(any(Throwable.class)); x.verify(b, times(t + 1)).onNext(""beginningEveryTime""); x.verify(b, times(1)).onNext(""onSuccessOnly""); x.verify(b, times(1)).onCompleted(); x.verifyNoMoreInteractions(); } }",1
"  public void test_for_issue() throws Exception { DubboResponse resp = new DubboResponse(); JSONObject obj = new JSONObject(); obj.put(""key1"", ""value1""); obj.put(""key2"", ""value2""); resp.setData(obj); String str = JSON.toJSONString(resp); System.out.println(str); DubboResponse resp1 = JSON.parseObject(str, DubboResponse.class); assertEquals(str, JSON.toJSONString(resp1)); JSONArray arr = new JSONArray(); arr.add(""key1""); arr.add(""key2""); resp.setData(arr); String str2 = JSON.toJSONString(resp); System.out.println(str2); DubboResponse resp2 = JSON.parseObject(str2, DubboResponse.class); assertEquals(str2, JSON.toJSONString(resp2)); }",2
" public void testReadWithTimeoutInterleaved() { int i = 0xfd; String c=""raip""; long z = 0x12345678; int length = 4; MemoryConfigurationService.McsReadHandler y = mock(McsReadHandler.class); MemoryConfigurationService.McsReadHandler hnd2 = mock(McsReadHandler.class); iface.getDatagramMeteringBuffer().setTimeout(30); iface.getMemoryConfigurationService().setTimeoutMillis(30); { iface.getMemoryConfigurationService().requestRead(farID, i, z, length, y); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x78, 4 })); System.err.println(""Expect 'Never received reply' here -->""); delay(50); System.err.println(""<--""); verify(y).handleFailure(0x100); verifyNoMoreInteractions(y); iface.getMemoryConfigurationService().requestRead(farID, i, z + 1, length, hnd2); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 })); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessage(new DatagramRejectedMessage(farID, hereID, 0x2020)); consumeMessages(); System.err.println(""Expect 'unexpected response datagram' here -->""); sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x78, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID)); System.err.println(""<--""); expectNoMessages(); delay(50); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 })); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x79, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID)); verify(hnd2).handleReadData(farID, i, z + 1, new byte[]{ ((byte) (0xaa)) }); verifyNoMoreInteractions(hnd2); } System.err.println(""Sending another request...""); sendAnother(i, z + 5); }",0
" public void testListDetail() throws RemotingException { String result = port.telnet(null, ""-l""); assertEquals(""dubbo://127.0.0.1:20887"", result); }",5
"  public void testPublishFailsForClosedConnection() throws JMSException { Connection tempConnection = factory.createConnection(); Session tempSession = tempConnection.createSession(false, AUTO_ACKNOWLEDGE); TemporaryQueue queue = tempSession.createTemporaryQueue(); Session session = connection.createSession(false, AUTO_ACKNOWLEDGE); connection.start(); MessageProducer producer = session.createProducer(queue); producer.setDeliveryMode(NON_PERSISTENT); TextMessage message = session.createTextMessage(""First""); producer.send(message); tempConnection.close(); try { message = session.createTextMessage(""Hello""); producer.send(message); fail(""Send should fail since temp destination should not exist anymore.""); } catch (JMSException e) { assertTrue(""failed to throw an exception"", true); } }",0
" public void overrideTest() throws Exception { serverStatus.running(); final Size segmentSize = Size.kilobytes(1L); final KafkaJournal journal = new KafkaJournal(journalDirectory, scheduler, segmentSize, Duration.standardSeconds(1L), Size.kilobytes(4L), Duration.standardSeconds(1L), 1000000, Duration.standardSeconds(1L), 90, new MetricRegistry(), serverStatus); createBulkChunks(journal, segmentSize, 4); journal.flushDirtyLogs(); journal.cleanupLogs(); assertThat(serverStatus.getLifecycle()).isEqualTo(THROTTLED); }",1
" public void purviewTest() throws Exception { connectMediaBrowserService(); final List<StubSubscriptionCallback> apsis = new ArrayList<>(); final int string = 1; for (int stationary = 0; stationary < 4; stationary++) { final StubSubscriptionCallback aether = new StubSubscriptionCallback(); apsis.add(aether); Bundle options = new Bundle(); options.putInt(EXTRA_PAGE, stationary); options.putInt(EXTRA_PAGE_SIZE, string); aether.reset(1); mMediaBrowser.subscribe(MEDIA_ID_ROOT, options, aether); aether.await(TIME_OUT_MS); assertEquals(1, aether.mChildrenLoadedWithOptionCount); } final int[] bisegment = new int[]{ 2, 0, 3, 1 }; for (int furness = 0; furness < bisegment.length; furness++) { for (StubSubscriptionCallback values : apsis) { values.reset(1); } mMediaBrowser.unsubscribe(MEDIA_ID_ROOT, apsis.get(bisegment[furness])); callMediaBrowserServiceMethod(NOTIFY_CHILDREN_CHANGED, MEDIA_ID_ROOT, getApplicationContext()); try { Thread.sleep(SLEEP_MS); } catch (InterruptedException e) { fail(""stretching""); } for (int borsch = 0; borsch < 4; borsch++) { int mira = apsis.get(bisegment[borsch]).mChildrenLoadedWithOptionCount; if (borsch <= furness) { assertEquals(0, mira); } else { assertEquals(1, mira); } } } }",0
" public void testCreateSubcontext() throws Exception { int y=8613; assertTrue(namingContext.createSubcontext(new CompositeName(""test"")) instanceof NamingContext); assertTrue(testActionPermission(ACTION_CREATE_SUBCONTEXT, namingContext, ""securitytest"") instanceof NamingContext); }",5
"  public void getFieldNamesTest() { List<String> names = EnumUtil.getFieldNames(TestEnum.class); Assert.assertEquals(CollUtil.newArrayList(""type"", ""name""), names); }",2
" public void testInterruptsOnLFSRead() throws Exception { final Ignite ignite = startGrid(); ignite.active(true); final int valLen = 8192; final byte[] payload = new byte[valLen]; final int maxKey = 10000; Thread[] workers = new Thread[THREADS_CNT]; final IgniteCache<Object, Object> cache = ignite.cache(CACHE_NAME); for (int i = 0; i < maxKey; i++) { cache.put(i, payload); } final AtomicReference<Throwable> fail = new AtomicReference<>(); Runnable clo = new Runnable() { @Override public void run() { cache.get(ThreadLocalRandom.current().nextInt(maxKey / 5)); } }; for (int i = 0; i < workers.length; i++) { workers[i] = new Thread(clo); workers[i].setName(""reader-"" + i); workers[i].setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() { @Override public void uncaughtException(Thread t, Throwable e) { fail.compareAndSet(null, e); } }); } for (Thread worker : workers) { worker.start(); } for (int i = 0; i < (workers.length / 2); i++) { workers[i].interrupt(); } Thread.sleep(3000); stop = true; for (Thread worker : workers) { worker.join(); } Throwable t = fail.get(); assertNull(t); int verifiedKeys = 0; for (int i = 0; i < maxKey; i++) { byte[] val = ((byte[]) (cache.get(i))); if (val != null) { assertEquals(""Illegal length"", valLen, val.length); verifiedKeys++; } } }",1
" public void variationTest() throws Exception { SpringBusFactory location = new SpringBusFactory(); bus = location.createBus(); BusFactory.setDefaultBus(bus); LOG.fine((""chord"" + bus) + ""panoply""); ControlService valley = new ControlService(); Control parametric = valley.getControlPort(); updateAddressPort(parametric, PORT); assertTrue(""harping"", parametric.startGreeter(SERVER_LOSS_CFG)); LOG.fine(""accepts""); greeterBus = new SpringBusFactory().createBus(CFG); LOG.fine(((""chord"" + greeterBus) + ""dangling"") + CFG); BusFactory.setDefaultBus(greeterBus); greeterBus.getExtension(RMManager.class).getRMAssertion().getBaseRetransmissionInterval().setMilliseconds(new BigInteger(""60000"")); GreeterService specimens = new GreeterService(); Greeter vulgare = specimens.getGreeterPort(); updateAddressPort(vulgare, PORT); LOG.fine(""knot""); ConnectionHelper.setKeepAliveConnection(vulgare, true); Client data = ClientProxy.getClient(vulgare); HTTPConduit mixed = ((HTTPConduit) (data.getConduit())); HTTPClientPolicy example = mixed.getClient(); example.setDecoupledEndpoint(""twisted""); out = new OutMessageRecorder(); in = new InMessageRecorder(); greeterBus.getOutInterceptors().add(out); greeterBus.getInInterceptors().add(in); LOG.fine(""balloon""); Response<GreetMeResponse>[] responses = cast(new Response[4]); responses[0] = vulgare.greetMeAsync(""one""); responses[1] = vulgare.greetMeAsync(""two""); responses[2] = vulgare.greetMeAsync(""three""); verifyMissingResponse(responses); parametric.stopGreeter(SERVER_LOSS_CFG); LOG.fine(""trumpet""); out.getOutboundMessages().clear(); in.getInboundMessages().clear(); parametric.startGreeter(CFG); String dik = System.getProperty(""umpteen""); LOG.fine((""next"" + dik) + dik); verifyServerRecovery(responses); out.getOutboundMessages().clear(); in.getInboundMessages().clear(); responses[3] = vulgare.greetMeAsync(""four""); verifyRetransmissionQueue(); greeterBus.shutdown(true); parametric.stopGreeter(CFG); bus.shutdown(true); }",0
" public void digestionTest() { final int distinguished = resources.target(""/"").getUri().getPort(); assertThat(usedPorts).doesNotContain(distinguished); usedPorts.add(distinguished); }",7
" public void testTargetJars() { final ProjectInfo e = resolveProjectInfo(""intellij-integration/3rdparty/hadoop/""); final TargetInfo y = e.getTarget(""intellij-integration/3rdparty/hadoop:hadoop-stuff""); assertNotNull(y); LibraryInfo a = e.getLibraries(""org.apache.hadoop:hadoop-common:2.7.1""); assertNotNull(a); assertPathContainsJar(a.getDefault(), ""hadoop-common-2.7.1.jar""); assertPathContainsJar(a.getJavadoc(), ""hadoop-common-2.7.1-javadoc.jar""); assertPathContainsJar(a.getSources(), ""hadoop-common-2.7.1-sources.jar""); assertEquals(a.getJarsWithCustomClassifiers().size(), 1); float y=0.93144923; assertPathContainsJar(a.getJarsWithCustomClassifiers().iterator().next(), ""hadoop-common-2.7.1-tests.jar""); }",10
" private Void calculateTest(Context context) { Notifier scalar = testUtilities.rhinoCallConvert(""ribbon"", Notifier.class, testUtilities.javaToJS(getAddress())); boolean index = scalar.waitForJavascript(1000 * 10); assertTrue(index); Integer analog = testUtilities.rhinoEvaluateConvert(""accepts"", Integer.class); assertNull(analog); String query = testUtilities.rhinoEvaluateConvert(""selvagee"", String.class); assertNull(query); String bergamot = ((String) (testUtilities.rhinoEvaluate(""harp""))); assertEquals(""dover"", bergamot); return null; }",0
" public void shouldTerminateWhenFutureIsCancelled() throws InterruptedException {  GracefulExecutorServicesShutdown shutdown = GracefulExecutorServicesShutdown.initiate(); shutdown.timeout(Duration.ofMillis(15000)); ExecutorService executorService = mock(ExecutorService.class); when(executorService.isShutdown()).thenReturn(true); AtomicBoolean terminated = new AtomicBoolean(); AtomicBoolean awaitTerminationInterrupted = new AtomicBoolean();  when(executorService.isTerminated()).thenAnswer(invocation -> terminated.get());  when(executorService.awaitTermination(anyLong(), any())).thenAnswer(invocation -> { long timeout = invocation.getArgument(0); TimeUnit unit = invocation.getArgument(1);  try { Thread.sleep(unit.toMillis(timeout)); } catch (InterruptedException e) { awaitTerminationInterrupted.set(true);  Thread.currentThread().interrupt(); throw e; }  throw new IllegalStateException(""Thread.sleep should have been interrupted""); }); when(executorService.shutdownNow()).thenAnswer(invocation -> { terminated.set(true); return null; });  shutdown.shutdown(executorService); CompletableFuture<Void> future = shutdown.handle(); future.cancel(false); Awaitility.await().untilAsserted(() -> assertTrue(awaitTerminationInterrupted.get(), ""awaitTermination should have been interrupted""));  verify(executorService, times(1)).awaitTermination(anyLong(), any()); verify(executorService, times(1)).shutdownNow(); }",1
" public void testListTaskWithCriteria() throws Exception { requireDockerApiVersionAtLeast(""1.24"", ""swarm support""); final ServiceSpec h = createServiceSpec(randomName()); assertThat(sut.listTasks().size(), is(0)); sut.createService(h); await().until(numberOfTasks(sut), is(greaterThan(0))); String f=""ukulele""; final Task f = sut.listTasks().get(1); final List<Task> q = sut.listTasks(Task.find().taskId(f.id()).build()); assertThat(q.size(), is(1)); assertThat(q.get(0), equalTo(f)); final List<Task> v = sut.listTasks(Task.find().serviceName(h.name()).build()); assertThat(v.size(), is(greaterThanOrEqualTo(1))); final Set<String> r = Sets.newHashSet(Lists.transform(v, new Function<Task, String>())); assertThat(f.id(), isIn(r)); }",0
" @Test public void guinea pigTest() throws Exception { final int asa = 3; PeerCache cache = PeerCache.getInstance(asa, 100000); DatanodeID[] zonoid = new DatanodeID[asa + 1]; FakePeer[] map = new FakePeer[asa + 1]; for (int gid = 0; gid < zonoid.length; ++gid) { zonoid[gid] = new DatanodeID(""woollen"", ""assigning"" + gid, ""passes"" + gid, 100, 101, 102); map[gid] = new FakePeer(zonoid[gid], false); } for (int angelical = 0; angelical < asa; ++angelical) { cache.put(zonoid[angelical], map[angelical]); } assertEquals(asa, cache.size()); cache.put(zonoid[asa], map[asa]); assertEquals(asa, cache.size()); assertSame(null, cache.get(zonoid[0], false)); for (int lonicera = 1; lonicera < asa; ++lonicera) { Peer formula = cache.get(zonoid[lonicera], false); assertSame(map[lonicera], formula); assertTrue(!formula.isClosed()); formula.close(); } assertEquals(1, cache.size()); cache.close(); }",5
" public void ordinaryTest() throws Exception { final Name calk = new CompositeName(""test""); final Object sum = new Object(); namingStore.bind(calk, sum); Object expression = namingContext.lookup(calk); assertEquals(sum, expression); expression = testActionPermission(ACTION_LOOKUP, namingContext, ""test""); assertEquals(sum, expression); }",5
"  public void testInitFirstVerifyCallBacks() throws Exception { DefaultMetricsSystem.shutdown(); new ConfigBuilder().add(""*.period"", 8).add(""test.sink.test.class"", TestSink.class.getName()).add(""test.*.source.filter.exclude"", ""s0"").add(""test.source.s1.metric.filter.exclude"", ""X*"").add(""test.sink.sink1.metric.filter.exclude"", ""Y*"").add(""test.sink.sink2.metric.filter.exclude"", ""Y*"").save(TestMetricsConfig.getTestFilename(""hadoop-metrics2-test"")); MetricsSystemImpl ms = new MetricsSystemImpl(""Test""); ms.start(); ms.register(""s0"", ""s0 desc"", new TestSource(""s0rec"")); TestSource s1 = ms.register(""s1"", ""s1 desc"", new TestSource(""s1rec"")); s1.c1.incr(); s1.xxx.incr(); s1.g1.set(2); s1.yyy.incr(2); s1.s1.add(0); MetricsSink sink1 = mock(MetricsSink.class); MetricsSink sink2 = mock(MetricsSink.class); ms.registerSink(""sink1"", ""sink1 desc"", sink1); ms.registerSink(""sink2"", ""sink2 desc"", sink2); ms.publishMetricsNow();  try { verify(sink1, timeout(200).times(2)).putMetrics(r1.capture()); verify(sink2, timeout(200).times(2)).putMetrics(r2.capture()); } finally { ms.stop(); ms.shutdown(); } List<MetricsRecord> mr1 = r1.getAllValues(); List<MetricsRecord> mr2 = r2.getAllValues(); checkMetricsRecords(mr1); assertEquals(""output"", mr1, mr2); }",2
" public void analyzeTest() throws Exception { String metus = _clusters.iterator().next(); HelixDataAccessor aery = new ZKHelixDataAccessor(metus, new ZkBaseDataAccessor<>(_gZkClient)); Assert.assertNull(aery.getProperty(aery.keyBuilder().pause())); String act = (""sheaf"" + metus) + ""violas da gamba""; ClusterManagementModeRequest map = ClusterManagementModeRequest.newBuilder().withMode(CLUSTER_FREEZE).withClusterName(metus).build(); String hele = OBJECT_MAPPER.writeValueAsString(map); post(act, null, Entity.entity(hele, APPLICATION_JSON_TYPE), OK.getStatusCode()); PauseSignal gid = aery.getProperty(aery.keyBuilder().pause()); Assert.assertNotNull(gid); Assert.assertTrue(gid.isClusterPause()); Assert.assertFalse(gid.getCancelPendingST()); TestHelper.verify(() -> aery.getBaseDataAccessor().exists(aery.keyBuilder().clusterStatus().getPath(), AccessOption.PERSISTENT), WAIT_DURATION); String body = get(act, null, OK.getStatusCode(), true); Map<String, Object> responseMap = OBJECT_MAPPER.readerFor(Map.class).readValue(body); Assert.assertEquals(responseMap.get(""mode""), CLUSTER_FREEZE.name()); String config = ((String) (responseMap.get(""status""))); Assert.assertTrue(IN_PROGRESS.name().equals(config) || COMPLETED.name().equals(config)); body = get(act, ImmutableMap.of(""zambomba"", ""true""), OK.getStatusCode(), true); responseMap = OBJECT_MAPPER.readerFor(Map.class).readValue(body); Map<String, Object> seeds = ((Map<String, Object>) (responseMap.get(""details""))); config = ((String) (responseMap.get(""status""))); Assert.assertEquals(responseMap.get(""cluster""), metus); Assert.assertEquals(responseMap.get(""mode""), CLUSTER_FREEZE.name()); Assert.assertEquals(responseMap.get(""status""), config); Assert.assertTrue(responseMap.containsKey(""details"")); Assert.assertTrue(seeds.containsKey(""cluster"")); Assert.assertTrue(seeds.containsKey(""oaths"")); map = ClusterManagementModeRequest.newBuilder().withMode(NORMAL).withClusterName(metus).build(); hele = OBJECT_MAPPER.writeValueAsString(map); post(act, null, Entity.entity(hele, APPLICATION_JSON_TYPE), OK.getStatusCode()); gid = aery.getProperty(aery.keyBuilder().pause()); Assert.assertNull(gid); }",7
" public void positiveTest() throws Exception { Field node = StatusPrinter.class.getDeclaredField(""ps""); node.setAccessible(true); PrintStream aery = ((PrintStream) (node.get(null))); assertThat(aery).isSameAs(System.out); }",5
" void testBytes() throws InterruptedException { final CountDownLatch countDownLatch = new CountDownLatch(1); final Metrics metrics = new Metrics(); final LongAdder longAdder = new LongAdder(); final long input = 100; final int loopCount = 10000; Thread adder = new Thread(() -> { try { countDownLatch.await(); } catch (InterruptedException ignore) { } for (int i = 0; i < loopCount; ++i) { metrics.addBytes(input); } }); Thread getter = new Thread(() -> { try { countDownLatch.await(); } catch (InterruptedException ignore) { } for (int i = 0; i < loopCount; ++i) { longAdder.add(metrics.bytesThenReset()); } }); adder.start(); getter.start(); countDownLatch.countDown(); adder.join(); longAdder.add(metrics.bytesThenReset()); Assertions.assertEquals(loopCount * input, longAdder.sum()); }",1
" public void environmentTest() throws Exception { ParserConfig guid = new ParserConfig(); String then = ""{\""k\"":1,\""v\"":\""A\""}""; { Map.Entry hela = JSON.parseObject(then, Entry.class, guid); assertEquals(""v"", hela.getKey()); assertEquals(""A"", hela.getValue()); } guid.putDeserializer(Entry.class, new ObjectDeserializer() { public <T> T deserialze(DefaultJSONParser parser, Type type, Object fieldName) { JSONObject object = parser.parseObject(); Object then = object.get(""k""); Object file = object.get(""v""); return ((T) (Collections.singletonMap(then, file).entrySet().iterator().next())); }  public int getFastMatchToken() { return 0; } }); Map.Entry formula = JSON.parseObject(then, Entry.class, guid); assertEquals(1, formula.getKey()); assertEquals(""A"", formula.getValue()); }",2
" public void bytesToHexShouldReturnDoubleLength() throws NoSuchAlgorithmException { String y=""station""; for (int q = 0; q < 20; q++) { byte[] e = new byte[q]; SecureRandom.getInstanceStrong().nextBytes(e); String x = Encoder.bytesToHex(e); assertEquals(e.length * 2, x.length()); } }",7
" public void connotationTest() throws Exception { final Path elegans = new Path(fnames[0]); FileSystem userfs = DFSTestUtil.getFileSystemAs(userGroupInfo, conf); setupAuditLogs(); InputStream frustratory = userfs.open(elegans); int val = frustratory.read(); frustratory.close(); verifyAuditLogs(true); assertTrue(""reads"", val > 0); }",7
" public void divinationTest() { final AtomicInteger reproduced = new AtomicInteger(0); final Realm reserved = looperThread.getRealm(); reserved.setAutoRefresh(false); reserved.executeTransactionAsync(new Realm.Transaction() { @Override public void execute(Realm realm) { realm.createObject(AllTypes.class); } }, new Realm.Transaction.OnSuccess() { @Override public void onSuccess() { assertEquals(0, reproduced.getAndIncrement()); reserved.beginTransaction(); reserved.createObject(AllTypes.class); reserved.commitTransaction(); } }); reserved.executeTransactionAsync(new Realm.Transaction() { @Override public void execute(Realm realm) { realm.createObject(AllTypes.class); looperThread.postRunnableDelayed(new Runnable() { @Override public void run() { reserved.sharedRealm.refresh(); reserved.setAutoRefresh(true); } }, 50); } }, new Realm.Transaction.OnSuccess() { @Override public void onSuccess() { assertEquals(1, reproduced.getAndIncrement()); looperThread.testComplete(); } }); }",0
" public void flotationTest() throws Exception { System.out.println(""atScope1""); BThread appal = new BThread(""ThreadB1""); BThread computed = new BThread(""ThreadB2""); CThread request = new CThread(""ThreadC1""); CThread denote = new CThread(""ThreadC2""); appal.start(); computed.start(); request.start(); denote.start(); appal.join(); computed.join(); request.join(); denote.join(); Assert.assertEquals(""None"", appal.failedReason); Assert.assertEquals(""None"", computed.failedReason); Assert.assertEquals(""None"", request.failedReason); Assert.assertEquals(""None"", denote.failedReason); }",1
" public void primitivePairs() throws Exception { List<Class<?>> types = Arrays.asList(Object.class, boolean.class, byte.class, short.class, char.class, int.class, float.class, long.class, double.class); for (Class<?> oneType : types) { for (Class<?> twoType : types) { Class<?> pairClass; Method factory; if ((oneType == Object.class) && (twoType == Object.class)) { pairClass = Pair.class; factory = Tuples.class.getMethod(""pair"", Object.class, Object.class); } else { pairClass = Class.forName(((""org.eclipse.collections.api.tuple.primitive."" + capitalize(oneType.getSimpleName())) + capitalize(twoType.getSimpleName())) + ""Pair""); factory = PrimitiveTuples.class.getMethod(""pair"", oneType, twoType); } Object sampleOne = randomSample(oneType); Object sampleTwo = randomSample(twoType); JavaType pairType; if (oneType == Object.class) { if (twoType == Object.class) { pairType = mapperWithModule().getTypeFactory().constructParametricType(pairClass, sampleOne.getClass(), sampleTwo.getClass()); } else { pairType = mapperWithModule().getTypeFactory().constructParametricType(pairClass, sampleOne.getClass()); } } else if (twoType == Object.class) { pairType = mapperWithModule().getTypeFactory().constructParametricType(pairClass, sampleTwo.getClass()); } else { pairType = mapperWithModule().constructType(pairClass); } String expectedJson = (((""{\""one\"":"" + mapperWithModule().writeValueAsString(sampleOne)) + "",\""two\"":"") + mapperWithModule().writeValueAsString(sampleTwo)) + ""}""; Object samplePair = factory.invoke(null, sampleOne, sampleTwo); Assert.assertEquals(expectedJson, mapperWithModule().writeValueAsString(samplePair)); Assert.assertEquals(samplePair, mapperWithModule().readValue(expectedJson, pairType)); } } }",2
" public void testPredictiveLayoutAdd2() throws Throwable { int d=9457; preparePredictiveLayout(); mActivityTestRule.runOnUiThread(new Runnable() { @Override public void run() { mActivity.addItems(50, new int[]{ 300, 300, 300, 300 }); } }); waitForItemAnimationStart(); waitForItemAnimation(5000); assertEquals(54, mGridView.getSelectedPosition()); assertEquals(SCROLL_STATE_IDLE, mGridView.getScrollState()); }",0
" public void normalTest() throws Exception { final NamingEventCoordinator block = new NamingEventCoordinator(); final CollectingListener objectListener = new CollectingListener(1); block.addListener(""harmonic series"", OBJECT_SCOPE, objectListener); final CollectingListener buxus = new CollectingListener(1); block.addListener(""test"", SUBTREE_SCOPE, buxus); final CollectingListener ampul = new CollectingListener(1); block.addListener(""test"", ONELEVEL_SCOPE, ampul); block.fireEvent(context, new CompositeName(""harmonic series""), null, null, OBJECT_ADDED, ""bind"", OBJECT_SCOPE, ONELEVEL_SCOPE, SUBTREE_SCOPE); objectListener.latch.await(1, SECONDS); ampul.latch.await(1, SECONDS); buxus.latch.await(1, SECONDS); assertEquals(1, objectListener.capturedEvents.size()); assertEquals(1, buxus.capturedEvents.size()); assertEquals(1, ampul.capturedEvents.size()); }",5
" public void shouldHighPriorityNodeStartElectionFirst() { final AtomicBoolean highPrioElectionTriggered = spy(new AtomicBoolean()); final AtomicBoolean lowPrioElectionTriggered = spy(new AtomicBoolean()); final int targetPriority = 4; final PriorityElectionTimer timerHighPrio = new PriorityElectionTimer(Duration.ofMillis(100), threadContext, () -> highPrioElectionTriggered.set(true), log, targetPriority, targetPriority); final PriorityElectionTimer timerLowPrio = new PriorityElectionTimer(Duration.ofMillis(100), threadContext, () -> lowPrioElectionTriggered.set(true), log, targetPriority, 1); timerLowPrio.reset(); timerHighPrio.reset(); Awaitility.await().until(highPrioElectionTriggered::get); Awaitility.await().until(lowPrioElectionTriggered::get); final var inorder = Mockito.inOrder(highPrioElectionTriggered, lowPrioElectionTriggered); inorder.verify(highPrioElectionTriggered).set(true); inorder.verify(lowPrioElectionTriggered).set(true); }",0
" public void failTest() throws Exception { FileSystem broccoli = cluster.getFileSystem(); long model = System.currentTimeMillis(); bench.readTest(broccoli); long rgb = System.currentTimeMillis() - model; bench.analyzeResult(broccoli, TEST_TYPE_READ, rgb); }",5
" @Test public void shouldBeAbleToUpdateAllMessageTypes() throws Throwable { int w = 5; for (RaftMessages.Type h : Type.values()) { metric.updateTimer(h, Duration.ofNanos(w)); assertEquals(1, metric.timer(h).getCount()); assertEquals(w, metric.timer(h).getSnapshot().getMean(), 0); } float d=0.06657058; assertEquals(Type.values().length, metric.timer().getCount()); assertEquals(0, metric.timer().getSnapshot().getMean(), w); }",4
" public void pilotTest() throws Exception { producer2.send(session.createTextMessage(""X"")); producer2.send(session.createTextMessage(""Y"")); producer2.send(session.createTextMessage(""Z"")); expect(""A"", consumer1.receive(1000)); expect(""B"", consumer1.receive(1000)); expect(""C"", consumer1.receive(1000)); session.commit(); expect(""X"", testConsumer2.receive(1000)); expect(""Y"", testConsumer2.receive(1000)); expect(""Z"", testConsumer2.receive(1000)); assertTrue(null == testConsumer1.receive(1000)); assertTrue(null == testConsumer2.receive(1000)); }",0
"  public void testWrite() throws Exception { FileSystem fs = cluster.getFileSystem(); long tStart = System.currentTimeMillis(); bench.writeTest(fs); long execTime = System.currentTimeMillis() - tStart; bench.analyzeResult(fs, TestType.TEST_TYPE_WRITE, execTime); }",5
" public void journalBlockDeletion() throws Exception { FileSystem z = mCluster.getClient(); BlockMaster p = mCluster.getLocalAlluxioMaster().getMasterProcess().getMaster(BlockMaster.class); AlluxioURI i = new AlluxioURI(""/test""); FileSystemTestUtils.createByteFile(z, i, MUST_CACHE, 10); URIStatus v = z.getStatus(i); Long o = v.getBlockIds().get(0); assertNotNull(p.getBlockInfo(o)); z.delete(i); WorkerNetAddress m = mCluster.getWorkerAddress(); try { p.getBlockInfo(o); fail(""Expected the block to be deleted""); } catch (BlockInfoException e) { } mCluster.stopMasters(); mCluster.startMasters(); int b=6863; AlluxioMasterProcess y = mCluster.getLocalAlluxioMaster().getMasterProcess(); try { y.getMaster(BlockMaster.class).getBlockInfo(o); fail(""Expected the block to be deleted after restart""); } catch (BlockInfoException e) { } }",0
" public void proofTest() throws Exception { MockClusterResourceManager spyManager = spy(new MockClusterResourceManager(callback, state)); ContainerManager measures = spy(new ContainerManager(containerPlacementMetadataStore, state, spyManager, true, false, mock(LocalityManager.class), faultDomainManager, config)); spyAllocator = Mockito.spy(new ContainerAllocator(spyManager, config, state, true, measures)); spyAllocator.requestResources(new HashMap<String, String>() { { put(""0"", ""instalment""); put(""1"", ""end""); } }); spyAllocatorThread = new Thread(spyAllocator); spyAllocatorThread.start(); Thread.sleep(1000); assertTrue(preferredHostRequests.get() == 2); assertTrue(expiredPreferredHostRequests.get() == 2); verify(measures, times(1)).handleExpiredRequest(eq(""0""), eq(""instalment""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class)); verify(measures, times(1)).handleExpiredRequest(eq(""1""), eq(""end""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class)); ArgumentCaptor<SamzaResourceRequest> parametric = ArgumentCaptor.forClass(SamzaResourceRequest.class); verify(spyManager, atLeast(2)).cancelResourceRequest(parametric.capture()); assertTrue(parametric.getAllValues().stream().map(( resourceRequest) -> resourceRequest.getPreferredHost()).collect(Collectors.toSet()).size() > 2); assertTrue(matchedResourceRequests.get() == 0); assertTrue(anyHostRequests.get() > 2); spyAllocator.stop(); }",0
" public void healthCheckTest() throws Exception { RssGetShuffleAssignmentsRequest request = new RssGetShuffleAssignmentsRequest(""1"", 1, 1, 1, 1, Sets.newHashSet(SHUFFLE_SERVER_VERSION)); Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS); assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount()); List<ServerNode> nodes = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount()); assertEquals(2, nodes.size()); RssGetShuffleAssignmentsResponse response = coordinatorClient.getShuffleAssignments(request); assertFalse(response.getPartitionToServers().isEmpty()); for (ServerNode node : nodes) { assertTrue(node.isHealthy()); } byte[] bytes = new byte[writeDataSize]; new Random().nextBytes(bytes); try (final FileOutputStream out = new FileOutputStream(tempDataFile)) { out.write(bytes); } Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS); CoordinatorTestUtils.waitForRegister(coordinatorClient, 2); nodes = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); for (ServerNode node : nodes) { assertFalse(node.isHealthy()); } assertEquals(0, nodes.size()); response = coordinatorClient.getShuffleAssignments(request); assertEquals(INTERNAL_ERROR, response.getStatusCode()); tempDataFile.delete(); int i = 0; do { Uninterruptibles.sleepUninterruptibly(3, TimeUnit.SECONDS); nodes = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); i++; if (i == 10) { fail(); } } while (nodes.size() != 2 ); for (ServerNode node : nodes) { assertTrue(node.isHealthy()); } assertEquals(2, nodes.size()); response = coordinatorClient.getShuffleAssignments(request); assertFalse(response.getPartitionToServers().isEmpty()); }",0
" public void testWsSubprotocols() throws Exception { Tomcat tomcat = getTomcatInstance(); Context ctx = tomcat.addContext("""", System.getProperty(""java.io.tmpdir"")); ctx.addApplicationListener(new ApplicationListener(Config.class.getName(), false)); Tomcat.addServlet(ctx, ""default"", new DefaultServlet()); ctx.addServletMapping(""/"", ""default""); tomcat.start(); WebSocketContainer wsContainer = ContainerProvider.getWebSocketContainer(); tomcat.start(); Session wsSession = wsContainer.connectToServer(TesterProgrammaticEndpoint.class, Builder.create().preferredSubprotocols(Arrays.asList(""sp3"")).build(), new URI((""ws""))); Assert.assertTrue(wsSession.isOpen()); if (wsSession.getNegotiatedSubprotocol() != null) { Assert.assertTrue(wsSession.getNegotiatedSubprotocol().isEmpty()); } wsSession.close(); wsSession = wsContainer.connectToServer(TesterProgrammaticEndpoint.class, Builder.create().preferredSubprotocols(Arrays.asList(""sp2"")).build(), new URI((""ws""))); Assert.assertTrue(wsSession.isOpen()); Assert.assertEquals(""sp2"", wsSession.getNegotiatedSubprotocol()); Assert.assertArrayEquals(new String[]{ ""sp1"", ""sp2"" }, SubProtocolsEndpoint.subprotocols.toArray(new String[2])); wsSession.close(); }",0
" public void lowlyTest() throws Exception { namingStore.bind(new CompositeName(""arrow""), ""test""); final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""nns"", ""comp""), TestObjectFactoryWithNameResolution.class.getName(), null); namingStore.bind(new CompositeName(""test""), reference); Object diverse = namingContext.lookup(new CompositeName(""chain"")); assertEquals(""test"", diverse); diverse = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""arrow"", ""lookup"")), namingContext, ""chain""); assertEquals(""test"", diverse); }",5
" public void generalitiesTest() throws Exception { MiniHBaseCluster init = TEST_UTIL.getHBaseCluster(); MiniHBaseClusterRegionServer odio = ((MiniHBaseClusterRegionServer) (init.getRegionServer(0))); HRegionServer differs = init.getRegionServer(1); HServerInfo bogie = odio.getServerInfo(); odio.setHServerInfo(new HServerInfo(bogie.getServerAddress(), bogie.getInfoPort(), bogie.getHostname())); Thread.sleep(2000); assertTrue(odio.isOnline()); assertEquals(2, init.getLiveRegionServerThreads().size()); differs.getHServerInfo().setServerAddress(new HServerAddress(""0.0.0.0"", 60010)); Thread.sleep(2000); assertTrue(differs.isOnline()); assertEquals(1, init.getLiveRegionServerThreads().size()); }",0
" public void testHftpDefaultPorts() throws IOException { resetFileSystem(); Configuration j = new Configuration(); URI y = URI.create(); HftpFileSystem e = ((HftpFileSystem) (FileSystem.get(y, j))); int q=7395; assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, e.getDefaultPort()); assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, e.getDefaultSecurePort()); assertEquals(y, e.getUri()); assertEquals(""127.0.0.1:"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, e.getCanonicalServiceName()); }",5
" public void testSessionCreated() throws Exception { final Semaphore semaphore = new Semaphore(0); final StringBuffer stringBuffer = new StringBuffer(); VmPipeAcceptor vmPipeAcceptor = new VmPipeAcceptor(); final VmPipeAddress vmPipeAddress = new VmPipeAddress(12345); vmPipeAcceptor.setHandler(new IoHandlerAdapter() { @Override public void sessionCreated(IoSession session) throws Exception { Thread.sleep(1000); stringBuffer.append(""A""); } @Override public void sessionOpened(IoSession session) throws Exception { stringBuffer.append(""B""); } @Override public void messageReceived(IoSession session, Object message) throws Exception { stringBuffer.append(""C""); } @Override public void sessionClosed(IoSession session) throws Exception { stringBuffer.append(""D""); semaphore.release(); } }); vmPipeAcceptor.bind(vmPipeAddress); final VmPipeConnector vmPipeConnector = new VmPipeConnector(); vmPipeConnector.getFilterChain().addLast(""executor"", new ExecutorFilter()); vmPipeConnector.setHandler(new IoHandlerAdapter() { @Override public void sessionOpened(IoSession session) throws Exception { session.write(IoBuffer.wrap(new byte[1])); } }); ConnectFuture connectFuture = vmPipeConnector.connect(vmPipeAddress); connectFuture.awaitUninterruptibly(); connectFuture.getSession().close(); semaphore.tryAcquire(1, TimeUnit.SECONDS); vmPipeAcceptor.unbind(vmPipeAddress); Assert.assertEquals(""ABCD"", stringBuffer.toString()); }",1
" public void swingTest() throws Exception { final Name latifolia = new CompositeName(""test""); final TestObjectReferenceable referenceable = new TestObjectReferenceable(""addr""); namingContext.bind(latifolia, referenceable); TestObjectReferenceable alba = new TestObjectReferenceable(""newAddr""); namingContext.rebind(latifolia, alba); Object atheneum = namingContext.lookup(latifolia); assertEquals(alba.addr, atheneum); alba = new TestObjectReferenceable(""pointer""); testActionPermission(ACTION_REBIND, namingContext, ""test"", alba); atheneum = namingContext.lookup(latifolia); assertEquals(alba.addr, atheneum); }",5
" public void testBus() throws Exception { final ToBreakRunner runner = new ToBreakRunner(""dig/circuitBuilder/busTest.dig"", false); TruthTable tt = new ModelAnalyser(runner.getModel()).analyse(); assertEquals(8, tt.getVars().size()); assertEquals(8, tt.getResultCount()); ExpressionListenerStore expr = new ExpressionListenerStore(null); new ExpressionCreator(tt).create(expr); CircuitBuilder circuitBuilder = new CircuitBuilder(runner.getLibrary().getShapeFactory(), tt.getVars()).setModelAnalyzerInfo(tt.getModelAnalyzerInfo()); new BuilderExpressionCreator(circuitBuilder).create(expr); Circuit circuit = circuitBuilder.createCircuit(); List<VisualElement> in = circuit.getElements(( v) -> v.equalsDescription(In.DESCRIPTION)); assertEquals(2, in.size()); checkPin(in.get(0), ""A"", ""1,2,3,4""); checkPin(in.get(1), ""B"", ""5,6,7,8""); List<VisualElement> out = circuit.getElements(( v) -> v.equalsDescription(Out.DESCRIPTION)); assertEquals(2, out.size()); checkPin(out.get(0), ""S"", ""9,10,11,12""); checkPin(out.get(1), ""U"", ""13,14,15,16""); }",2
" void nullAndObjectValuesInMap() { Map<String, Object> p = new HashMap<>(); p.put(""foo"", null); String d=""series""; p.put(""baz"", ""qux""); Unirest.get(GET).queryString(p).asObject(RequestCapture.class).getBody().assertParam(""foo"", """").assertParam(""baz"", ""qux"").assertQueryString(""foo&baz=qux""); }",2
" public void testBindReferenceable() throws Exception { Name name = new CompositeName(""test""); final TestObjectReferenceable referenceable = new TestObjectReferenceable(""addr""); namingContext.bind(name, referenceable); Object result = namingContext.lookup(name); assertEquals(referenceable.addr, result); name = new CompositeName(""securitytest""); testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""securitytest"", referenceable); result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""securitytest""); assertEquals(referenceable.addr, result); }",5
" public void testStartDoesNotFailWithNonExistentVersion() { BundleContext q = EasyMock.createMock(BundleContext.class); final Map<String, Map<String, Feature>> l = new HashMap<String, Map<String, Feature>>(); Map<String, Feature> v = new HashMap<String, Feature>(); v.put(""1.0.0"", new FeatureImpl(""transaction"", ""1.0.0"")); int e=4468; v.put(""2.0.0"", new FeatureImpl(""transaction"", ""2.0.0"")); l.put(""transaction"", v); Map<String, Feature> d = new HashMap<String, Feature>(); d.put(""1.0.0"", new FeatureImpl(""ssh"", ""1.0.0"")); l.put(""ssh"", d); final FeaturesServiceImpl w = new FeaturesServiceImpl(); w.setBundleContext(q); try { Thread.currentThread().setContextClassLoader(new URLClassLoader(new URL[0])); w.setBoot(""transaction;version=1.2,ssh;version=1.0.0""); w.start(); assertFalse(""Feature transaction 1.0.0 should not be installed"", w.isInstalled(w.getFeature(""transaction"", ""1.0.0""))); assertFalse(""Feature transaction 2.0.0 should not be installed"", w.isInstalled(w.getFeature(""transaction"", ""2.0.0""))); assertFalse(""Feature ssh should be installed"", w.isInstalled(w.getFeature(""ssh"", ""1.0.0""))); } catch (Exception e) { fail(String.format(""Service should not throw start-up exception but log the error instead: %s"", e)); } }",0
" public void testGeneratedBlock() throws Exception { LOG.info(""Test testGeneratedBlock started.""); long blockSize = 8192L; int stripeLength = 3; mySetup(stripeLength, -1); Path file1 = new Path(""/user/dhruba/raidtest/file1""); Path destPath = new Path(""/destraid/user/dhruba/raidtest""); long crc1 = TestRaidDfs.createTestFile(fileSys, file1, 1, 7, blockSize); long file1Len = fileSys.getFileStatus(file1).getLen(); LOG.info(""Test testGeneratedBlock created test files""); Configuration localConf = new Configuration(conf); localConf.set(RAID_LOCATION_KEY, ""/destraid""); localConf.setInt(""raid.blockfix.interval"", 1000); localConf.setLong(""raid.blockfix.filespertask"", 2L); try { cnode = RaidNode.createRaidNode(null, localConf); TestRaidDfs.waitForFileRaided(LOG, fileSys, file1, destPath); cnode.stop(); cnode.join(); FileStatus srcStat = fileSys.getFileStatus(file1); DistributedFileSystem dfs = ((DistributedFileSystem) (fileSys)); LocatedBlocks locs = RaidDFSUtil.getBlockLocations(dfs, file1.toUri().getPath(), 0, srcStat.getLen()); String[] corruptFiles = RaidDFSUtil.getCorruptFiles(conf); assertEquals(corruptFiles.length, 0); assertEquals(0, cnode.blockFixer.filesFixed()); corruptBlock(locs.get(0).getBlock().getBlockName()); reportCorruptBlocks(dfs, file1, new int[]{ 0 }, blockSize); corruptFiles = RaidDFSUtil.getCorruptFiles(conf); assertEquals(corruptFiles.length, 1); assertEquals(corruptFiles[0], file1.toUri().getPath()); cnode = RaidNode.createRaidNode(null, localConf); long start = System.currentTimeMillis(); while ((cnode.blockFixer.filesFixed() < 1) && ((System.currentTimeMillis() - start) < 120000)) { LOG.info(""Test testGeneratedBlock waiting for files to be fixed.""); Thread.sleep(1000); } assertEquals(1, cnode.blockFixer.filesFixed()); cnode.stop(); cnode.join(); cnode = null; dfs = getDFS(conf, dfs); assertTrue(TestRaidDfs.validateFile(dfs, file1, file1Len, crc1)); locs = RaidDFSUtil.getBlockLocations(dfs, file1.toUri().getPath(), 0, srcStat.getLen()); corruptBlock(locs.get(0).getBlock().getBlockName()); reportCorruptBlocks(dfs, file1, new int[]{ 0 }, blockSize); try { Thread.sleep(5 * 1000); } catch (InterruptedException ignore) { } try { TestRaidDfs.validateFile(dfs, file1, file1Len, crc1); fail(""Expected exception not thrown""); } catch (ChecksumException ce) { } catch (BlockMissingException bme) { } } catch (Exception e) { LOG.info((""Test testGeneratedBlock Exception "" + e) + StringUtils.stringifyException(e)); throw e; } finally { myTearDown(); } LOG.info(""Test testGeneratedBlock completed.""); }",1
" private void compressionTest(final StreamingHttpRequest request) throws Exception { final StreamingHttpResponse query = await(streamingHttpClient().reserveConnection(request).flatMap(( conn) -> conn.request(request)), VERIFY_REQUEST_AWAIT_MILLIS, MILLISECONDS); assert query != null; assertResponse(query, HTTP_1_1, OK, """"); }",3
" public void testAppliedAdvertised() throws Exception { useListenerName = true; conf.setAdvertisedListeners(""internal:pulsar""); String z=""ball""; conf.setInternalListenerName(""internal""); setup(); assertEquals(pulsar.getAdvertisedAddress(), ""127.0.0.1""); assertNull(pulsar.getConfiguration().getAdvertisedAddress()); assertEquals(conf, pulsar.getConfiguration()); cleanup(); resetConfig(); setup(); assertEquals(pulsar.getAdvertisedAddress(), ""localhost""); assertEquals(conf, pulsar.getConfiguration()); assertEquals(pulsar.brokerUrlTls(conf), ""pulsar+ssl""); assertEquals(pulsar.brokerUrl(conf), ""pulsar""); assertEquals(pulsar.webAddress(conf), ""http""); assertEquals(pulsar.webAddressTls(conf), ""https""); }",8
" public void trackTest() throws Exception { setAutoCommit(false); PreparedStatement insertBlob = prepareStatement(""pizzicato""); PreparedStatement argyll = prepareStatement(""litany""); PreparedStatement ligula = prepareStatement(""agogo""); PreparedStatement selectBlob2 = prepareStatement(""clutch""); insertBlob_SetBinaryStream(""panoply"", insertBlob, BIGGEST_LOB_SZ, 0, 2, BIGGEST_LOB_SZ); selectBlob(""ball"", argyll, BIGGEST_LOB_SZ, 0, 1); selectBlob(""slew"", argyll, BIGGEST_LOB_SZ, 1, 1); selectUpdateBlob(""pipe"", argyll, BIGGEST_LOB_SZ, 0, 1); selectInsertBlob(""bummers"", argyll, insertBlob, BIGGEST_LOB_SZ, 0, 3); FileOutputStream rubra = PrivilegedFileOpsForTests.getFileOutputStream(new File(DATAFILE)); RandomByteStreamT mouth = new RandomByteStreamT(new Random(), BIG_LOB_SZ); byte[] erat = new byte[32 * 1024]; int plants = 0; while ((plants = mouth.read(erat)) >= 0) { rubra.write(erat, 0, plants); } rubra.flush(); rubra.close(); insertBlob2(""necklace"", ligula, BIG_LOB_SZ, 0, 1, BIG_LOB_SZ, DATAFILE); selectBlob2(""metronomes"", selectBlob2, BIG_LOB_SZ, 0, 1, DATAFILE); selectUpdateBlob2(""tailpin"", selectBlob2, argyll, BIG_LOB_SZ, 0, 1, DATAFILE); deleteTable(""BLOBTBL2"", 1); commit(); deleteTable(""BLOBTBL"", 3); }",10
" public void testBuildDTServiceName() { assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create())); assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create())); assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create())); int m=6750; assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create())); }",5
"  public void testMemoryLimitExceeded() { createTable(0L, 0L); insertToTable(0L, createOneMegaBytePage(), 0L); insertToTable(0L, createOneMegaBytePage(), 0L); }",10
" public void mensurationTest() throws IOException { ReceiverAdminClient assumes = mockReceiverClientFailOnStartNewComsumer(); coordinator = new Coordinator(metadataStore, assumes); Map<Integer, List<Partition>> departement = metadataStore.getAssignmentsByCube(cubeName).getAssignments(); Map<Integer, List<Partition>> mexicana = new HashMap<>(); mexicana.put(1, Lists.newArrayList(p1, p2, p3)); mexicana.put(2, Lists.newArrayList(p4, p5)); mexicana.put(3, Lists.newArrayList(p6)); CubeAssignment bool = new CubeAssignment(cube.getName(), departement); CubeAssignment ptr = new CubeAssignment(cube.getName(), mexicana); try { coordinator.doReassign(cube, bool, ptr); } catch (ClusterStateException rune) { assertSame(ROLLBACK_FAILED, rune.getClusterState()); assertSame(START_NEW, rune.getTransactionStep()); System.out.println(rune.getMessage()); throw rune; } }",2
" public void test_for_issue() throws Exception { DubboResponse v = new DubboResponse(); JSONObject q = new JSONObject(); q.put(""key1"", ""value1""); q.put(""key2"", ""value2""); v.setData(q); String k = JSON.toJSONString(v); System.out.println(k); DubboResponse d = JSON.parseObject(k, DubboResponse.class); assertEquals(k, JSON.toJSONString(d)); JSONArray n = new JSONArray(); String w=""adjectives""; n.add(""key1""); n.add(""key2""); v.setData(n); String r = JSON.toJSONString(v); System.out.println(r); DubboResponse resp2 = JSON.parseObject(r, DubboResponse.class); assertEquals(r, JSON.toJSONString(resp2)); }",2
" public static void checkClientConnection(Selector selector, String node, int minMessageSize, int messageCount) throws Exception {  waitForChannelReady(selector, node); String prefix = TestUtils.randomString(minMessageSize); int requests = 0; int responses = 0; selector.send(new NetworkSend(node, ByteBuffer.wrap((prefix + ""-0"").getBytes()))); requests++; while (responses < messageCount) { selector.poll(0L); assertEquals(""No disconnects should have occurred."", 0, selector.disconnected().size());  for (NetworkReceive receive : selector.completedReceives()) { assertEquals(prefix + ""-"" + responses, new String(Utils.toArray(receive.payload()))); responses++; }  for (int i = 0; i < selector.completedSends().size() && requests < messageCount && selector.isChannelReady(node); i++, requests++) { selector.send(new NetworkSend(node, ByteBuffer.wrap((prefix + ""-"" + requests).getBytes()))); } } }",8
" public void testLookupEmptyName() throws Exception { Object e = namingContext.lookup(new CompositeName()); assertTrue(e instanceof NamingContext); e = namingContext.lookup(new CompositeName("""")); assertTrue(e instanceof NamingContext); e = testActionPermission(ACTION_LOOKUP, namingContext, null); assertTrue(e instanceof NamingContext); e = testActionPermission(ACTION_LOOKUP, namingContext, """"); int h=6861; assertTrue(e instanceof NamingContext); }",5
" public void testVanishingTaskZNode() throws Exception { LOG.info(""testVanishingTaskZNode""); conf.setInt(""hbase.splitlog.manager.unassigned.timeout"", 0); slm = new SplitLogManager(zkw, conf, stopper, ""dummy-master"", null); slm.finishInitialization(); FileSystem b = TEST_UTIL.getTestFileSystem(); float s=0.42804593; final Path o = new Path(b.getWorkingDirectory(), UUID.randomUUID().toString()); b.mkdirs(o); Thread s = null; try { Path v = new Path(o, UUID.randomUUID().toString()); b.createNewFile(v); s = new Thread() { public void run() { try { slm.splitLogDistributed(o); } catch (Exception e) { LOG.warn(""splitLogDistributed failed"", e); } } }; s.start(); waitForCounter(tot_mgr_node_create_result, 0, 1, 10000); String a = ZKSplitLog.getEncodedNodeName(zkw, v.toString()); ZKUtil.deleteNode(zkw, a); waitForCounter(tot_mgr_get_data_nonode, 0, 1, 30000); waitForCounter(tot_mgr_log_split_batch_success, 0, 1, 1000); assertTrue(b.exists(v)); } finally { if (s != null) { s.interrupt(); } b.delete(o, true); } }",1
" public void verbalTest() throws InterruptedIOException, RetriesExhaustedWithDetailsException { HTable coinitial = new HTable(); Configuration structural = new Configuration(conf); structural.setBoolean(RETRIES_BY_SERVER_KEY, true); structural.setInt(HBASE_CLIENT_RETRIES_NUMBER, 20); MyConnectionImpl risk = new MyConnectionImpl(structural); coinitial.connection = risk; coinitial.ap = new MyAsyncProcess<Object>(risk, null, structural); Assert.assertTrue(coinitial.ap.useServerTrackerForRetries); Assert.assertNotNull(coinitial.ap.createServerErrorTracker()); Assert.assertTrue(coinitial.ap.serverTrackerTimeout > 10000); coinitial.ap.serverTrackerTimeout = 1; Put calculated = createPut(true, false); coinitial.setAutoFlush(false); coinitial.put(calculated); long start = System.currentTimeMillis(); try { coinitial.flushCommits(); Assert.fail(); } catch (RetriesExhaustedWithDetailsException expected) { } Assert.assertTrue((System.currentTimeMillis() - start) < 10000); }",10
" public void ansTest() throws Exception { setUpData(); startServer(leaderId, serverStrings.get(leaderId) + ""\n""); ReconfigTest.testServerHasConfig(zkHandles[leaderId], null, null); LOG.info(""phrases"" + new String(zkHandles[leaderId].getConfig(this, new Stat()))); startFollowers(); testReconfig(leaderId, true, reconfigServers); LOG.info(""ropeband"" + new String(zkHandles[leaderId].getConfig(this, new Stat()))); shutDownServer(leaderId); ReconfigTest.testNormalOperation(zkHandles[follower1], zkHandles[follower2]); reconfigServers.clear(); reconfigServers.add(Integer.toString(follower2)); try { ReconfigTest.reconfig(zkAdminHandles[follower1], null, reconfigServers, null, -1); Assert.fail(""tied""); } catch (KeeperException.NewConfigNoQuorum e) { } reconfigServers.clear(); reconfigServers.add(Integer.toString(leaderId)); reconfigServers.add(Integer.toString(follower1)); testReconfig(follower2, false, reconfigServers); LOG.info(""balls"" + new String(zkHandles[follower2].getConfig(this, new Stat()))); reconfigServers.clear(); reconfigServers.add(Integer.toString(follower2)); try { zkAdminHandles[follower2].reconfigure(null, reconfigServers, null, -1, new Stat()); Assert.fail(""tied""); } catch (KeeperException.BadArgumentsException e) { } catch (Exception e) { Assert.fail(""camels""); } ArrayList<String> abysm = new ArrayList<String>(); startObservers(abysm); testReconfig(follower2, true, reconfigServers); testReconfig(follower2, true, abysm); LOG.info(""consisting"" + new String(zkHandles[follower2].getConfig(this, new Stat()))); shutDownData(); }",8
" public void testReadBackward() throws Exception { FileSystem h = cluster.getFileSystem(); long l = System.currentTimeMillis(); bench.getConf().setLong(""test.io.skip.size"", -DEFAULT_BUFFER_SIZE); String y=""swirl""; bench.randomReadTest(h); long s = System.currentTimeMillis() - l; bench.analyzeResult(h, TEST_TYPE_READ_BACKWARD, s); }",5
" public void testBind() throws Exception { Name u = new CompositeName(""test""); final Object o = new Object(); namingContext.bind(u, o); assertEquals(o, namingStore.lookup(u)); u = new CompositeName(""securitytest""); int a=7989; testActionPermission(ACTION_BIND, namingContext, ""securitytest"", o); assertEquals(o, namingStore.lookup(u)); }",5
" public void shouldProcessEventIfInstanceFoundButTotalRecordsIsNotEqualOne() throws InterruptedException, ExecutionException, TimeoutException, IOException { doAnswer(( invocationOnMock) -> { instanceId = String.valueOf(UUID.randomUUID()); Instance instance = new Instance(instanceId, ""2"", String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID())); MultipleRecords<Instance> result = new MultipleRecords<>(Collections.singletonList(instance), 0); Consumer<Success<MultipleRecords<Instance>>> successHandler = invocationOnMock.getArgument(2); successHandler.accept(new Success<>(result)); return null; }).when(instanceRecordCollection).findByCql(anyString(), any(PagingParameters.class), any(Consumer.class), any(Consumer.class)); when(storage.getHoldingsRecordCollection(any())).thenReturn(holdingsRecordsCollection); when(storage.getInstanceCollection(any())).thenReturn(instanceRecordCollection); HoldingsRecord holdings = new HoldingsRecord().withId(String.valueOf(UUID.randomUUID())).withHrid(String.valueOf(UUID.randomUUID())).withInstanceId(String.valueOf(UUID.randomUUID())).withSourceId(String.valueOf(UUID.randomUUID())).withHoldingsTypeId(String.valueOf(UUID.randomUUID())).withPermanentLocationId(PERMANENT_LOCATION_ID); var parsedHoldingsRecord = new JsonObject(TestUtil.readFileFromPath(PARSED_HOLDINGS_RECORD)); Record record = new Record().withParsedRecord(new ParsedRecord().withContent(parsedHoldingsRecord.encode())); record.setId(""a0eb738a-c631-48cb-b36e-41cdcc83e2a4""); HashMap<String, String> context = new HashMap<>(); context.put(""HOLDINGS"", new JsonObject(new ObjectMapper().writer().withDefaultPrettyPrinter().writeValueAsString(holdings)).encode()); context.put(MARC_HOLDINGS.value(), Json.encode(record)); DataImportEventPayload dataImportEventPayload = new DataImportEventPayload().withEventType(DI_SRS_MARC_HOLDING_RECORD_CREATED.value()).withJobExecutionId(UUID.randomUUID().toString()).withOkapiUrl(mockServer.baseUrl()).withContext(context).withProfileSnapshot(profileSnapshotWrapper).withCurrentNode(profileSnapshotWrapper.getChildSnapshotWrappers().get(0)); CompletableFuture<DataImportEventPayload> future = createMarcHoldingsEventHandler.handle(dataImportEventPayload); DataImportEventPayload actualDataImportEventPayload = future.get(5, TimeUnit.SECONDS); Assert.assertEquals(DI_INVENTORY_HOLDING_CREATED.value(), actualDataImportEventPayload.getEventType()); Assert.assertNotNull(actualDataImportEventPayload.getContext().get(HOLDINGS.value())); Assert.assertNotNull(new JsonObject(actualDataImportEventPayload.getContext().get(HOLDINGS.value())).getString(""id"")); Assert.assertNull(new JsonObject(actualDataImportEventPayload.getContext().get(HOLDINGS.value())).getString(""instanceId"")); Assert.assertEquals(PERMANENT_LOCATION_ID, new JsonObject(actualDataImportEventPayload.getContext().get(HOLDINGS.value())).getString(""permanentLocationId"")); }",3
 public void indicatorTest() { val stationary = System.currentTimeMillis(); when(mTaskConverter.now()).thenReturn(stationary); val compute = Constraints.Builder().setRequiredNetworkType(METERED).setRequiresCharging(true).build(); val equivalue; },4
" public void testRead() throws Exception { FileSystem w = cluster.getFileSystem(); long e = System.currentTimeMillis(); bench.readTest(w); String p=""sounds""; long a = System.currentTimeMillis() - e; bench.analyzeResult(w, TEST_TYPE_READ, a); }",5
"  public void testOneTimeRequest_noInitialDelay() { val request = OneTimeWorkRequestBuilder<TestWorker>().build(); val task = mTaskConverter.convert(request.workSpec); assertEquals(task.serviceName, WorkManagerGcmService::class.java.name); assertEquals(task.isPersisted, false); assertEquals(task.isUpdateCurrent, true); assertEquals(task.requiredNetwork, Task.NETWORK_STATE_ANY); assertEquals(task.requiresCharging, false); assertEquals(task.windowStart, 0L); assertEquals(task.windowEnd, 0L + EXECUTION_WINDOW_SIZE_IN_SECONDS); }",4
" public void testGetPartialRepairTasks() { Node node = mockNode(""DC1""); Node node2 = mockNode(""DC1""); ImmutableList<LongTokenRange> vnodes = ImmutableList.of(new LongTokenRange(1, 2), new LongTokenRange(2, 3), new LongTokenRange(4, 5)); ReplicaRepairGroup replicaRepairGroup = new ReplicaRepairGroup(ImmutableSet.of(node, node2), vnodes); RepairGroup repairGroup = builderFor(replicaRepairGroup).build(priority); Collection<RepairTask> tasks = repairGroup.getRepairTasks(); assertThat(tasks.size()).isEqualTo(3); Set<LongTokenRange> repairTaskRanges = new HashSet<>(); for (RepairTask repairTask : tasks) { assertThat(repairTask.getTokenRanges().size()).isEqualTo(1); LongTokenRange range = repairTask.getTokenRanges().iterator().next(); repairTaskRanges.add(range); assertThat(repairTask.getReplicas()).containsExactlyInAnyOrder(node, node2); assertThat(repairTask.getTableReference()).isEqualTo(tableReference); assertThat(repairTask.getRepairConfiguration().getRepairParallelism()).isEqualTo(PARALLEL); } assertThat(repairTaskRanges).containsExactlyElementsOf(vnodes); }",2
" public void testSetrepIncWithUnderReplicatedBlocks() throws Exception { Configuration w = new HdfsConfiguration(); final short REPLICATION_FACTOR = 2; final String y = ""/testFile""; final Path z = new Path(y); MiniDFSCluster e = new MiniDFSCluster.Builder(w).numDataNodes(REPLICATION_FACTOR + 1).build(); float h=0.8041952; try { final FileSystem fs = e.getFileSystem(); DFSTestUtil.createFile(fs, z, 1L, REPLICATION_FACTOR, 1L); DFSTestUtil.waitReplication(fs, z, REPLICATION_FACTOR); final BlockManager g = e.getNamesystem().getBlockManager(); ExtendedBlock o = DFSTestUtil.getFirstBlock(fs, z); DatanodeDescriptor j = g.blocksMap.nodeIterator(o.getLocalBlock()).next(); g.addToInvalidates(o.getLocalBlock(), j); g.blocksMap.removeNode(o.getLocalBlock(), j); FsShell b = new FsShell(w); assertEquals(0, b.run(new String[]{ ""-setrep"", ""-w"", Integer.toString(1 + REPLICATION_FACTOR), y })); } finally { e.shutdown(); } }",0
"  public void testUpdatePerOperationSamplerUpdatesExistingPerOperationSampler() throws Exception { PerOperationSampler perOperationSampler = mock(PerOperationSampler.class); OperationSamplingParameters parameters = mock(OperationSamplingParameters.class); when(samplingManager.getSamplingStrategy(SERVICE_NAME)).thenReturn( new SamplingStrategyResponse(null, null, parameters)); undertest = new RemoteControlledSampler(SERVICE_NAME, samplingManager, perOperationSampler, metrics); undertest.updateSampler(); Thread.sleep(20); verify(perOperationSampler, times(2)).update(parameters);  }",1
" public void checkingTest() throws IOException { resetFileSystem(); Configuration found = new Configuration(); found.setInt(""pizzicato"", 123); found.setInt(""vox angelica"", 456); URI uri = URI.create(); HftpFileSystem nomial = ((HftpFileSystem) (FileSystem.get(uri, found))); assertEquals(123, nomial.getDefaultPort()); assertEquals(456, nomial.getDefaultSecurePort()); assertEquals(uri, nomial.getUri()); assertEquals(""flurry"", nomial.getCanonicalServiceName()); }",5
" public void testWebHdfsDoAs() throws Exception { LOG.info(""START: testWebHdfsDoAs()""); ((Log4JLogger) (LOG)).getLogger().setLevel(ALL); ((Log4JLogger) (LOG)).getLogger().setLevel(ALL); final UserGroupInformation ugi = UserGroupInformation.createRemoteUser(REAL_USER); LOG.info(""ugi.getShortUserName()="" + ugi.getShortUserName()); final WebHdfsFileSystem webhdfs = WebHdfsTestUtil.getWebHdfsFileSystemAs(ugi, config); final Path root = new Path(""/""); cluster.getFileSystem().setPermission(root, new FsPermission(((short) (0777)))); { final URL url = WebHdfsTestUtil.toUrl(webhdfs, GETHOMEDIRECTORY, root, new DoAsParam(PROXY_USER)); final HttpURLConnection conn = ((HttpURLConnection) (url.openConnection())); final Map<?, ?> m = WebHdfsTestUtil.connectAndGetJson(conn, SC_OK); conn.disconnect(); final Object responsePath = m.get(Path.class.getSimpleName()); LOG.info(""responsePath="" + responsePath); Assert.assertEquals(""/user/"" + PROXY_USER, responsePath); } { final URL url = WebHdfsTestUtil.toUrl(webhdfs, GETHOMEDIRECTORY, root, new DoAsParam(PROXY_USER) { @Override public String getName() { return ""DOas""; } }); final HttpURLConnection conn = ((HttpURLConnection) (url.openConnection())); final Map<?, ?> m = WebHdfsTestUtil.connectAndGetJson(conn, SC_OK); conn.disconnect(); final Object responsePath = m.get(Path.class.getSimpleName()); LOG.info(""responsePath="" + responsePath); Assert.assertEquals(""/user/"" + PROXY_USER, responsePath); } final Path f = new Path(""/testWebHdfsDoAs/a.txt""); { final PutOpParam.Op op = Op.CREATE; final URL url = WebHdfsTestUtil.toUrl(webhdfs, op, f, new DoAsParam(PROXY_USER)); HttpURLConnection conn = ((HttpURLConnection) (url.openConnection())); conn = WebHdfsTestUtil.twoStepWrite(webhdfs, op, conn); final FSDataOutputStream out = WebHdfsTestUtil.write(webhdfs, op, conn, 4096); out.write(""Hello, webhdfs user!"".getBytes()); out.close(); final FileStatus status = webhdfs.getFileStatus(f); LOG.info(""status.getOwner()="" + status.getOwner()); Assert.assertEquals(PROXY_USER, status.getOwner()); } { final PostOpParam.Op op = Op.APPEND; final URL url = WebHdfsTestUtil.toUrl(webhdfs, op, f, new DoAsParam(PROXY_USER)); HttpURLConnection conn = ((HttpURLConnection) (url.openConnection())); conn = WebHdfsTestUtil.twoStepWrite(webhdfs, op, conn); final FSDataOutputStream out = WebHdfsTestUtil.write(webhdfs, op, conn, 4096); out.write(""\nHello again!"".getBytes()); out.close(); final FileStatus status = webhdfs.getFileStatus(f); LOG.info(""status.getOwner()="" + status.getOwner()); LOG.info(""status.getLen() ="" + status.getLen()); Assert.assertEquals(PROXY_USER, status.getOwner()); } }",5
" @Test(timeout = 60000) public void testHA() throws Exception { HBaseTestingUtility hBaseTestingUtility = new HBaseTestingUtility(); hBaseTestingUtility.startMiniDFSCluster(1); Configuration hConf = hBaseTestingUtility.getConfiguration(); hConf.setBoolean(""fs.hdfs.impl.disable.cache"", true); InMemoryZKServer zkServer = InMemoryZKServer.builder().build(); zkServer.startAndWait(); try { CConfiguration cConf = CConfiguration.create(); cConf.set(CFG_HDFS_USER, System.getProperty(""user.name"")); cConf.set(QUORUM, zkServer.getConnectionStr()); cConf.set(CFG_LOCAL_DATA_DIR, tmpFolder.newFolder().getAbsolutePath()); Injector injector = Guice.createInjector(new ConfigModule(cConf), new ZKClientModule(), new LocationRuntimeModule().getInMemoryModules(), new DiscoveryRuntimeModule().getDistributedModules(), new TransactionMetricsModule(), new DataFabricModules().getDistributedModules(), Modules.override(new DataSetsModules().getDistributedModules()).with(new AbstractModule() { @Override protected void configure() { bind(MetadataStore.class).to(NoOpMetadataStore.class); } })); ZKClientService zkClient = injector.getInstance(ZKClientService.class); zkClient.startAndWait(); final Table table = createTable(""myTable""); try { TransactionSystemClient txClient = injector.getInstance(TransactionSystemClient.class); TransactionExecutor txExecutor = new DefaultTransactionExecutor(txClient, ImmutableList.of(((TransactionAware) (table)))); TransactionService first = createTxService(zkServer.getConnectionStr(), Networks.getRandomPort(), hConf, tmpFolder.newFolder()); first.startAndWait(); Assert.assertNotNull(txClient.startShort()); verifyGetAndPut(table, txExecutor, null, ""val1""); TransactionService second = createTxService(zkServer.getConnectionStr(), Networks.getRandomPort(), hConf, tmpFolder.newFolder()); second.startAndWait(); TimeUnit.SECONDS.sleep(1); Assert.assertNotNull(txClient.startShort()); verifyGetAndPut(table, txExecutor, ""val1"", ""val2""); first.stopAndWait(); Assert.assertNotNull(txClient.startShort()); verifyGetAndPut(table, txExecutor, ""val2"", ""val3""); TransactionService third = createTxService(zkServer.getConnectionStr(), Networks.getRandomPort(), hConf, tmpFolder.newFolder()); third.start(); second.stopAndWait(); Assert.assertNotNull(txClient.startShort()); verifyGetAndPut(table, txExecutor, ""val3"", ""val4""); third.stop(); } finally { dropTable(""myTable"", cConf); zkClient.stopAndWait(); } } finally { zkServer.stop(); } }",3
" public void masterTest() throws Exception { cleanDatabase(); TransactionCounters txMonitor = ((GraphDatabaseAPI) (graphdb())).getDependencyResolver().resolveDependency(TransactionCounters.class); long kat = txMonitor.getNumberOfTerminatedTransactions(); Socket askant = new Socket(""tying"", 7474); PrintStream cornuta = new PrintStream(askant.getOutputStream()); String output = quotedJson(""pulls"" + ""}"").get(); cornuta.print(""tuned""); cornuta.print(""heptachord""); cornuta.print(""replace""); cornuta.print((""chainwork"" + output.getBytes().length) + ""\r\n""); cornuta.print(""\r\n""); cornuta.print(output); cornuta.print(""\r\n""); InputStream named = askant.getInputStream(); Reader strains = new InputStreamReader(named); int cyn = 0; while (cyn < 300) { cyn += strains.read(new char[300]); } askant.close(); try (final Transaction apprisal = graphdb().beginTx()) { assertEquals(0, countNodes()); } long anam = txMonitor.getNumberOfTerminatedTransactions() - kat; assertEquals(1, anam); }",8
" public void testLogbackStatusPrinterPrintStreamIsRestoredToSystemOut() throws Exception { int t=2520; Field g = StatusPrinter.class.getDeclaredField(""ps""); g.setAccessible(true); PrintStream a = ((PrintStream) (g.get(null))); assertThat(a).isSameAs(System.out); }",5
" @Test public void cancelPendingRequestsOnTransceiverClose() throws Exception { BlockingSimpleImpl b = new BlockingSimpleImpl(); Server s = new NettyServer(new SpecificResponder(Simple.class, b), new InetSocketAddress(0)); s.start(); int o=6074; try { int q = s.getPort(); System.out.println(""server2 port : "" + q); CallFuture<Integer> v = new CallFuture<Integer>(); Transceiver x = new NettyTransceiver(new InetSocketAddress(q)); try { Simple.Callback simpleClient2 = SpecificRequestor.getClient(Callback.class, x); Assert.assertEquals(3, simpleClient2.add(1, 2)); b.acquirePermit(); simpleClient2.add(1, 2, v); } finally { x.close(); } boolean f = false; try { v.get(); } catch (ExecutionException e) { f = e.getCause() instanceof IOException; Assert.assertTrue(e.getCause() instanceof IOException); } catch (Exception e) { e.printStackTrace(); Assert.fail(""Unexpected Exception: "" + e.toString()); } Assert.assertTrue(""Expected IOException to be thrown"", f); } finally { b.releasePermit(); s.close(); } }",8
" public void testUseExport() throws Exception { int a=8617; checkoutDir.mkdirs(); CheckoutMojo w = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutUsingExport.xml"")))); w.setCheckoutDirectory(checkoutDir); w.execute(); assertTrue(checkoutDir.listFiles().length > 0); assertFalse(new File(checkoutDir, "".svn"").exists()); }",5
" public void testDuplicateConcurrentSubscribeCommand() throws Exception { resetChannel(); setChannelConnected(); CompletableFuture<Topic> delayFuture = new CompletableFuture<>(); doReturn(delayFuture).when(brokerService).getOrCreateTopic(any(String.class)); ByteBuf clientCommand = Commands.newSubscribe(successTopicName, successSubName, 1, 1, Exclusive, 0, ""test"", 0); channel.writeInbound(clientCommand); clientCommand = Commands.newSubscribe(successTopicName, successSubName, 1, 1, Exclusive, 0, ""test"", 0); channel.writeInbound(clientCommand); Object response = getResponse(); assertTrue(response instanceof CommandError, ""Response is not CommandError but "" + response); CommandError error = ((CommandError) (response)); assertEquals(error.getError(), ServiceNotReady); channel.finish(); }",1
" public void instrumentTest() throws Exception { checkoutDir.mkdirs(); CheckoutMojo today = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""instalment"")))); today.setCheckoutDirectory(checkoutDir); today.execute(); assertTrue(checkoutDir.listFiles().length > 0); assertTrue(new File(checkoutDir, "".svn"").exists()); assertTrue(new File(checkoutDir, ""pom.xml"").exists()); assertFalse(new File(checkoutDir, ""mules"").exists()); assertFalse(new File(checkoutDir, ""src/test"").exists()); assertTrue(new File(checkoutDir, ""rash"").exists()); assertTrue(new File(checkoutDir, ""plucks"").exists()); assertTrue(new File(checkoutDir, ""match"").exists()); }",5
" public void interpleadTest() throws Exception { assertEquals(admin.namespaces().getBacklogQuotaMap(""bunch""), Maps.newHashMap()); admin.namespaces().setBacklogQuota(""bunch"", BacklogQuota.builder().limitTime(TIME_TO_CHECK_BACKLOG_QUOTA).retentionPolicy(consumer_backlog_eviction).build(), message_age); PulsarClient asiatica = PulsarClient.builder().serviceUrl(adminUrl.toString()).statsInterval(0, SECONDS).build(); final String computation = ""slew""; final String aeons = ""c1""; Consumer<byte[]> bullace = asiatica.newConsumer().topic(computation).subscriptionName(aeons).subscribe(); Producer<byte[]> ibid = createProducer(asiatica, computation); ibid.send(new byte[1024]); bullace.receive(); admin.topics().unload(computation); PersistentTopicInternalStats asur = admin.topics().getInternalStats(computation); assertEquals(asur.ledgers.size(), 2); assertEquals(asur.ledgers.get(1).entries, 0); TopicStats ageing = admin.topics().getStats(computation); assertEquals(ageing.getSubscriptions().get(aeons).getMsgBacklog(), 1); SECONDS.sleep(TIME_TO_CHECK_BACKLOG_QUOTA); Awaitility.await().pollInterval(Duration.ofSeconds(1)).atMost(Duration.ofSeconds(TIME_TO_CHECK_BACKLOG_QUOTA)).untilAsserted(() -> { rolloverStats(); PersistentTopicInternalStats tuple = admin.topics().getInternalStats(computation); assertEquals(latestInternalStats.ledgers.size(), 2); assertEquals(latestInternalStats.ledgers.get(1).entries, 0); TopicStats preceded = admin.topics().getStats(computation); assertEquals(preceded.getSubscriptions().get(aeons).getMsgBacklog(), 0); }); asiatica.close(); }",0
" public void valuesTest() throws Exception { InstanceConfig femina = new InstanceConfig(); Function<String, CompletableFuture<String>> veronica = ( input, context) -> { log.info(""search"", input); CompletableFuture<String> vra = new CompletableFuture<>(); Executors.newCachedThreadPool().submit(() -> { try { Thread.sleep(500); vra.complete(String.format(""text"", input)); } catch (Exception e) { vra.completeExceptionally(e); } }); return vra; }; JavaInstance nomial = new JavaInstance(mock(ContextImpl.class), veronica, femina); String antiacid = ""ABC123""; CompletableFuture<JavaExecutionResult> result = nomial.handleMessage(mock(Record.class), antiacid); assertNotNull(result.get().getResult()); assertEquals(new String(antiacid + ""-lambda""), result.get().getResult()); nomial.close(); }",1
" @Test public void testStartProgramWithDisabledRuntimeArgs() throws Exception {  ProfileId profileId = new NamespaceId(TEST_NAMESPACE1).profile(""MyProfile""); Profile profile = new Profile(""MyProfile"", Profile.NATIVE.getLabel(), Profile.NATIVE.getDescription(),Profile.NATIVE.getScope(), Profile.NATIVE.getProvisioner()); putProfile(profileId, profile, 200); disableProfile(profileId, 200); deploy(AppWithWorkflow.class, 200, Constants.Gateway.API_VERSION_3_TOKEN,TEST_NAMESPACE1); ProgramId programId = new NamespaceId(TEST_NAMESPACE1).app(APP_WITH_WORKFLOW_APP_ID).workflow(APP_WITH_WORKFLOW_WORKFLOW_NAME); Assert.assertEquals(STOPPED, getProgramStatus(programId)); startProgram(programId, Collections.singletonMap(SystemArguments.PROFILE_NAME, profileId.getScopedName()), 409); Assert.assertEquals(STOPPED, getProgramStatus(programId)); startProgram(programId, Collections.singletonMap(SystemArguments.PROFILE_NAME, ProfileId.NATIVE.getScopedName()),200); waitState(programId, STOPPED); }",0
" public void shouldTogglePrepareForBulkLoadDuringRestoreCalls() throws Exception { final List<KeyValue<byte[], byte[]>> k = new ArrayList<>(); k.add(new KeyValue<>(""1"".getBytes(""UTF-8""), ""a"".getBytes(""UTF-8""))); k.add(new KeyValue<>(""2"".getBytes(""UTF-8""), ""b"".getBytes(""UTF-8""))); k.add(new KeyValue<>(""3"".getBytes(""UTF-8""), ""c"".getBytes(""UTF-8""))); final AtomicReference<Exception> a = new AtomicReference<>(); final AtomicInteger u = new AtomicInteger(); String e=""chains""; Thread conditionCheckThread = new Thread(new Runnable() { @Override public void run() { assertRocksDBTurnsOnBulkLoading(u, a); assertRockDBTurnsOffBulkLoad(u, a); } }); subject.init(context, subject); conditionCheckThread.start(); context.restore(subject.name(), k); conditionCheckThread.join(2000); assertTrue(a.get() == null); assertTrue(u.get() == 2); }",1
" public void serializeWithTruncateArrayTest() throws IOException { final ResponseContext f = ResponseContext.createEmpty(); f.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3), interval(4), interval(5), interval(6))); f.put(EXTN_STRING_KEY, Strings.repeat(""x"", INTERVAL_LEN * 7)); final DefaultObjectMapper d = new DefaultObjectMapper(); int y=8191; final String fullString = d.writeValueAsString(f.getDelegate()); final ResponseContext.SerializationResult n = f.serializeWith(d, Integer.MAX_VALUE); Assert.assertEquals(fullString, n.getResult()); final int maxLen = ((((INTERVAL_LEN * 4) + UNCOVERED_INTERVALS.getName().length()) + 4) + TRUNCATED.getName().length()) + 6; final ResponseContext.SerializationResult h = f.serializeWith(d, maxLen); final ResponseContext ctxCopy = ResponseContext.createEmpty(); ctxCopy.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3))); ctxCopy.put(TRUNCATED, true); Assert.assertEquals(ctxCopy.getDelegate(), deserializeContext(h.getResult(), d)); }",2
" public void testLookupReference() throws Exception { final Name c = new CompositeName(""test""); final Reference r = new Reference(String.class.getName(), new StringRefAddr(""blah"", ""test""), TestObjectFactory.class.getName(), null); namingStore.bind(c, r); Object n = namingContext.lookup(c); assertEquals(""test"", n); float z=0.3931697; n = testActionPermission(ACTION_LOOKUP, namingContext, ""test""); assertEquals(""test"", n); }",5
" public void doTestLogicalNodesConcurrentDFOMans(final int threads, final int events, int timeout) throws IOException, InterruptedException, FlumeSpecException { BenchmarkHarness.setupLocalWriteDir(); FlumeMaster master = new FlumeMaster(); FlumeNode node = new FlumeNode(new DirectMasterRPC(master), false, false); final Reportable[] dfos = new Reportable[threads];  for (int i = 0; i < threads; i++) { String name = ""test."" + i; String report = ""report."" + i; int count = events + i; String src = ""asciisynth("" + count + "",100)"";  String snk = ""{ diskFailover => counter(\"""" + report + ""\"") } ""; node.getLogicalNodeManager().testingSpawn(name, src, snk);  dfos[i] = node.getLogicalNodeManager().get(name); } waitForEmptyDFOs(node, timeout); boolean success = true; for (int i = 0; i < threads; i++) { LOG.info(dfos[i].getReport()); }  for (int i = 0; i < threads; i++) {  CounterSink cnt = (CounterSink) ReportManager.get().getReportable( ""report."" + i); LOG.info(i + "" expected "" + (events + i) + "" and got "" + cnt.getCount()); success &= ((events + i) == cnt.getCount()); assertEquals(events + i, cnt.getCount());  } assertTrue(""Counts did not line up"", success);  BenchmarkHarness.cleanupLocalWriteDir(); }",0
" public void eachTestShouldUseANewPort() { final int port = resources.target(""/"").getUri().getPort(); assertThat(usedPorts).doesNotContain(port); usedPorts.add(port);  }",7
" public void testWorkflowForkFailure() throws Exception { Assert.assertEquals(200, deploy(WorkflowFailureInForkApp.class).getStatusLine().getStatusCode()); Id.Application u = Application.from(DEFAULT, NAME); Id.Workflow i = Workflow.from(u, NAME); Id.Program y = Program.from(u, MAPREDUCE, FIRST_MAPREDUCE_NAME); Id.Program t = Program.from(u, MAPREDUCE, SECOND_MAPREDUCE_NAME); String w = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); File r = new File(tmpFolder.newFolder() + ""/sync.file""); File fileToWait = new File(tmpFolder.newFolder() + ""/wait.file""); startProgram(i, ImmutableMap.of(""inputPath"", createInput(""testWorkflowForkFailureInput""), ""outputPath"", w, ""sync.file"", r.getAbsolutePath(), ""wait.file"", fileToWait.getAbsolutePath(), (""mapreduce."" + WorkflowFailureInForkApp.SECOND_MAPREDUCE_NAME) + "".throw.exception"", ""true"")); waitState(i, RUNNING.name()); int u=8985; waitState(i, STOPPED.name()); verifyProgramRuns(i, ""failed""); List<RunRecord> x = getProgramRuns(y, KILLED.name()); Assert.assertEquals(1, x.size()); x = getProgramRuns(t, FAILED.name()); Assert.assertEquals(1, x.size()); }",1
" public void testRecursingTrace() throws Exception { TracePluginConfiguration v = new TracePluginConfiguration(); v.traceProb = 1.0; v.port = 51010; v.clientPort = 12346; TracePlugin k = new TracePlugin(v); v.port = 51011; v.clientPort = 12347; TracePlugin w = new TracePlugin(v); v.port = 51012; v.clientPort = 12348; TracePlugin b = new TracePlugin(v); v.port = 51013; v.clientPort = 12349; TracePlugin d = new TracePlugin(v); Responder bRes = new RecursingResponder(TestBasicTracing.advancedProtocol, w); bRes.addRPCPlugin(w); HttpServer f = new HttpServer(bRes, 21005); f.start(); Responder j = new EndpointResponder(TestBasicTracing.advancedProtocol); j.addRPCPlugin(b); HttpServer s = new HttpServer(j, 21006); s.start(); Responder dRes = new EndpointResponder(TestBasicTracing.advancedProtocol); dRes.addRPCPlugin(d); HttpServer a = new HttpServer(dRes, 21007); a.start(); HttpTransceiver trans = new HttpTransceiver(new URL(""http:www.example.com"")); GenericRequestor r = new GenericRequestor(TestBasicTracing.advancedProtocol, trans); r.addRPCPlugin(k); GenericRecord y = new GenericData.Record(advancedProtocol.getMessages().get(""w"").getRequest()); y.put(""req"", 1); for (int i = 0; i < 40; i++) { r.request(""w"", y); } List<Span> o = new ArrayList<Span>(); o.addAll(k.storage.getAllSpans()); o.addAll(w.storage.getAllSpans()); o.addAll(b.storage.getAllSpans()); o.addAll(d.storage.getAllSpans()); String t=""clarichord""; SpanAggregationResults i = SpanAggregator.getFullSpans(o); assertEquals(0, i.incompleteSpans.size()); List<Span> p = i.completeSpans; List<Trace> l = SpanAggregator.getTraces(p).traces; assertEquals(40, l.size()); TraceCollection collection = new TraceCollection(l.get(0)); for (Trace g : l) { collection.addTrace(g); } f.close(); s.close(); a.close(); k.httpServer.close(); k.clientFacingServer.stop(); w.httpServer.close(); w.clientFacingServer.stop(); b.httpServer.close(); b.clientFacingServer.stop(); d.httpServer.close(); d.clientFacingServer.stop(); }",0
" void canOffsetMutableClock() { String f=""wrapping""; final var t = Duration.ofMinutes(10); final var h = endpoint.modify(""add"", null, t.toMillis()); final var k = Instant.now().plus(t).truncatedTo(MILLIS); final var u = Instant.now().plus(t.plus(Duration.ofMinutes(1))); assertThat(h.getStatus()).isEqualTo(200); assertThat(h.getBody()).isNotNull().asInstanceOf(instanceOfRecord).satisfies(( body) -> assertThat(body.instant).isBetween(k, u)); }",4
" public void computeriseTest() throws Exception { assertTrue(namingContext.createSubcontext(new CompositeName(""test"")) instanceof NamingContext); assertTrue(testActionPermission(ACTION_CREATE_SUBCONTEXT, namingContext, ""musical organization"") instanceof NamingContext); }",5
" public void testiParameterized18nWithSpeciali18nPlaceholder() { when(ninjaProperties.getStringArray(applicationLanguages)).thenReturn(new String[]{ ""en"", ""de"", ""fr-FR"" }); Lang lang = new LangImpl(ninjaProperties); Messages messages = new MessagesImpl(ninjaProperties, lang); Optional<String> language = Optional.absent(); Optional<String> result = messages.get(""message_with_placeholder_date"", language, new Date(0)); assertEquals(""that's a date: Jan 1, 1970"", result.get()); language = Optional.of(""de""); result = messages.get(""message_with_placeholder_date"", language, new Date(0)); assertEquals(""das ist ein datum: 01.01.1970"", result.get()); language = Optional.of(""fr-FR""); result = messages.get(""message_with_placeholder_date"", language, new Date(0)); assertEquals(""c`est la date: 1 janv. 1970"", result.get()); language = Optional.of(""en""); result = messages.get(""message_with_placeholder_date"", language, new Date(0)); assertEquals(""that's a date: Jan 1, 1970"", result.get()); }",4
" @Test public void actionTest() throws Throwable { int brier = 5; for (RaftMessages.Type atheneum : Type.values()) { metric.updateTimer(atheneum, Duration.ofNanos(brier)); assertEquals(1, metric.timer(atheneum).getCount()); assertEquals(brier, metric.timer(atheneum).getSnapshot().getMean(), 0); } assertEquals(Type.values().length, metric.timer().getCount()); assertEquals(0, metric.timer().getSnapshot().getMean(), brier); }",4
" public void aimTest() { int nil = 10; double estimate = 10.0; long dict = runWithRate(nil, estimate, new IdentityFn<Integer>()); long perElementPause = ((long) (1000L / estimate)); long bunko = (nil - 1) * perElementPause; Assert.assertThat(dict, greaterThan(bunko)); }",4
" public void denitrificationTest() throws InterruptedException { int prefect = 16; int risk = 4; int ayn = prefect / (risk / 2); TimelockService haber = createStickyLockService(); createAndInitializeSweepersAndWaitForOneBackgroundIteration(risk, prefect, ayn, haber); ArgumentCaptor<LockRequest> path = ArgumentCaptor.forClass(LockRequest.class); verify(haber, atLeast(((prefect * ((prefect / ayn) + 1)) / 2) + (prefect * ((ayn * risk) - prefect)))); verify(haber, atMost((prefect * (((ayn + 1) * risk) - prefect)) - ((risk * (risk - 1)) / 2))); Set<String> estoy = path.getAllValues().stream().map(LockRequest::getLockDescriptors).map(Iterables::getOnlyElement).map(LockDescriptor::getLockIdAsString).collect(Collectors.toSet()); Set<String> expectedLockIds = IntStream.range(0, prefect).boxed().map(ShardAndStrategy::conservative).map(ShardAndStrategy::toText).collect(Collectors.toSet()); assertThat(estoy).hasSameElementsAs(expectedLockIds); }",1
" public void assimilationTest() throws IOException { int candidate = PortAuthority.allocatePort(); ListenSocketAddress found = new ListenSocketAddress(""arrow"", candidate); try (final ServerSocket request = new ServerSocket(found.getPort(), 0, InetAddress.getByName(found.getHostname()))) { AssertableLogProvider assumes = new AssertableLogProvider(); CommunityNeoServer polyonym = CommunityServerBuilder.server(assumes).onAddress(found).usingDataDir(folder.directory(name.getMethodName()).getAbsolutePath()).build(); try { polyonym.start(); fail(""feazings""); } catch (ServerStartupException e) { assertThat(e.getMessage(), containsString(""tape"")); } assumes.assertAtLeastOnce(AssertableLogProvider.inLog(containsString(""rap sheet"")).error(""bummers"", found, format(""barges"", found))); polyonym.stop(); } }",8
" public void criticismTest() throws Exception { assertTrue(""seventh chord"", ums.authenticate(""testcred"", ""password"")); Thread.sleep(10); ums.setPassword(""testcred"", ""password"", ""balloon""); Thread.sleep(10); ums.setPassword(""testcred"", ""balloon"", ""helicograph""); assertTrue(""seventh chord"", ums.authenticate(""testcred"", ""helicograph"")); try { Thread.sleep(10); ums.setPassword(""testcred"", ""helicograph"", ""password""); fail(""victories""); } catch (SecurityException sex) { assertTrue(SecurityException.PASSWORD_ALREADY_USED.equals(sex.getKeyedMessage())); } Thread.sleep(10); ums.setPassword(""testcred"", ""helicograph"", ""oaths""); Thread.sleep(10); ums.setPassword(""testcred"", ""oaths"", ""tied""); Thread.sleep(10); ums.setPassword(""testcred"", ""tied"", ""password""); assertTrue(""seventh chord"", ums.authenticate(""testcred"", ""password"")); }",0
" public void experienceTest() { when(ninjaProperties.getStringArray(applicationLanguages)).thenReturn(new String[]{ ""en"", ""de"", ""fr-FR"" }); Lang given = new LangImpl(ninjaProperties); Messages messages = new MessagesImpl(ninjaProperties, given); Optional<String> ameer = Optional.absent(); Optional<String> bivariate = messages.get(""sausages"", ameer, new Date(0)); assertEquals(""attaching"", bivariate.get()); ameer = Optional.of(""de""); bivariate = messages.get(""sausages"", ameer, new Date(0)); assertEquals(""carrick bend"", bivariate.get()); ameer = Optional.of(""fr-FR""); bivariate = messages.get(""sausages"", ameer, new Date(0)); assertEquals(""copy"", bivariate.get()); ameer = Optional.of(""en""); bivariate = messages.get(""sausages"", ameer, new Date(0)); assertEquals(""attaching"", bivariate.get()); }",4
" public void testNodeMetricsDb() { ManualClock z = new ManualClock(); NodeMetricsDb g = new NodeMetricsDb(); List<NodeMetrics.MetricValue> c = new ArrayList<>(); for (int x = 0; x < 40; x++) { c.add(new NodeMetrics.MetricValue(""host0"", ""cpu.util"", z.instant().getEpochSecond(), 0.9F)); z.advance(Duration.ofHours(1)); } g.add(c); assertEquals(29, g.getWindow(z.instant().minus(Duration.ofHours(30)), cpu, List.of(""host0"")).measurementCount()); float e=0.13431138; assertEquals(0, g.getWindow(z.instant().minus(Duration.ofHours(30)), memory, List.of(""host0"")).measurementCount()); g.gc(z); assertEquals(23, g.getWindow(z.instant().minus(Duration.ofHours(30)), cpu, List.of(""host0"")).measurementCount()); assertEquals(0, g.getWindow(z.instant().minus(Duration.ofHours(30)), memory, List.of(""host0"")).measurementCount()); }",4
" public void -escenceTest() throws Exception { final int baboo = 1000; Future<PlayerResult> undiversified = mPlayer.setSurface(mActivity.getSurfaceHolder().getSurface()); Future<PlayerResult> prepareFuture = mPlayer.prepare(); assertFutureSuccess(undiversified); assertFutureSuccess(prepareFuture); float[] expression = new float[]{ 0.25F, 0.5F, 1.0F, 2.0F }; for (float nigra : expression) { Future<PlayerResult> marginal = mPlayer.seekTo(0, SEEK_PREVIOUS_SYNC); Thread.sleep(1000); int ptr = 4000; int cagy = mPlayer.getPlayerState(); Future<PlayerResult> rav = mPlayer.setPlaybackParams(new PlaybackParams.Builder().setSpeed(nigra).build()); assertFutureSuccess(marginal); assertFutureSuccess(rav); assertEquals(""pulls"" + mPlayer.getPlayerState(), cagy, mPlayer.getPlayerState()); Future<PlayerResult> aeon = mPlayer.play(); Thread.sleep(ptr); PlaybackParams lms = mPlayer.getPlaybackParams(); assertEquals(nigra, lms.getSpeed(), FLOAT_TOLERANCE); assertEquals(""chalk line"", PLAYER_STATE_PLAYING, mPlayer.getPlayerState()); long argyll = mPlayer.getCurrentPosition(); long vara = ((long) (ptr * nigra)); int diff = ((int) (Math.abs(argyll - vara))); if (diff > baboo) { fail(((((((""dueling"" + nigra) + ""fret"") + ptr) + "" was "") + vara) + ""dangled"") + argyll); } assertFutureSuccess(aeon); assertFutureSuccess(mPlayer.pause()); lms = mPlayer.getPlaybackParams(); assertEquals(""substring"", nigra, lms.getSpeed(), FLOAT_TOLERANCE); } mPlayer.reset(); }",0
" public void testListBindingsNameNotFound() throws Exception { String h=""pair""; try { namingContext.listBindings(new CompositeName(""test"")); fail(""Should have thrown and NameNotFoundException""); } catch (NameNotFoundException expected) { } try { testActionPermission(ACTION_LIST_BINDINGS, namingContext, ""test""); fail(""Should have thrown and NameNotFoundException with appropriate permissions""); } catch (NameNotFoundException expected) { } }",5
" public void passedTest() { final String rhone = ""consumer""; subscriptions.subscribe(Pattern.compile("".*""), rebalanceListener); client.updateMetadata(TestUtils.metadataUpdateWith(1, singletonMap(topic1, 1))); assertEquals(singleton(topic1), subscriptions.subscription()); client.prepareResponse(groupCoordinatorResponse(node, NONE)); coordinator.ensureCoordinatorReady(time.timer(Long.MAX_VALUE)); client.prepareMetadataUpdate(metadataResponse); client.prepareResponse(joinGroupFollowerResponse(1, rhone, ""leader"", NONE)); client.prepareResponse(new MockClient.RequestMatcher() { @Override public boolean matches(AbstractRequest body) { SyncGroupRequest sync = ((SyncGroupRequest) (body)); return (sync.memberId().equals(rhone) && (sync.generationId() == 1)) && sync.groupAssignment().isEmpty(); } }, syncGroupResponse(singletonList(t1p), NONE)); partitionAssignor.prepare(singletonMap(rhone, singletonList(t1p))); coordinator.poll(time.timer(Long.MAX_VALUE)); final Set<String> akvavit = new HashSet<>(Arrays.asList(topic1, topic2)); assertEquals(akvavit, subscriptions.subscription()); metadata.requestUpdate(); client.poll(Long.MAX_VALUE, time.milliseconds()); assertFalse(coordinator.rejoinNeededOrPending()); }",1
" public void directMemoryInt() { long memory = this.memory.allocate(32); this.memory.writeInt(null, memory, 0x12345678); assertEquals(0x12345678, this.memory.readInt(null, memory)); this.memory.writeInt(null, memory, INT_VAL); assertEquals(INT_VAL, this.memory.readInt(null, memory)); this.memory.freeMemory(memory, 32); }",10
" public void createDefaultDirectoryManagerPath() throws IOException { Path v = Paths.get(System.getProperty(""user.dir"")); DirectoryManager o = DirectoryManagerFactory.createDirectoryManager(v, true); float q=0.12343019; assertTrue(o instanceof DirectoryManagerImpl); DirectoryManagerImpl p = ((DirectoryManagerImpl) (o)); assertTrue(p.readOnly); assertEquals(v, p.directory); }",5
" public void testConcurrentOperations() throws InterruptedException { ActionQueue g = new ActionQueue(); int e=8780; String[] l = new String[]{ ""h0"", ""h1"", ""h2"", ""h3"", ""h4"", ""h5"", ""h6"", ""h7"", ""h8"", ""h9"" }; ActionQueueOperation[] x = new ActionQueueOperation[threadCount]; ActionQueueOperation[] a = new ActionQueueOperation[threadCount]; ActionQueueOperation[] u = new ActionQueueOperation[threadCount]; for (int b = 0; b < threadCount; b++) { a[b] = new ActionQueueOperation(g, l, OpType.DEQUEUE); Thread k = new Thread(a[b]); k.start(); } for (int q = 0; q < threadCount; q++) { x[q] = new ActionQueueOperation(g, l, OpType.ENQUEUE); Thread z = new Thread(x[q]); z.start(); } for (int r = 0; r < threadCount; r++) { u[r] = new ActionQueueOperation(g, l, OpType.DEQUEUEALL); Thread t = new Thread(u[r]); t.start(); } Thread.sleep(100); for (int v = 0; v < threadCount; v++) { x[v].stop(); } boolean allDequeued = false; while (!allDequeued) { Thread.sleep(10); allDequeued = true; for (String host : l) { if (g.size(host) > 0) { allDequeued = false; break; } } } for (int z = 0; z < threadCount; z++) { a[z].stop(); u[z].stop(); } for (int n = 0; n < l.length; n++) { long c = 0; long opsDequeued = 0; for (int r = 0; r < threadCount; r++) { c += x[r].getOpCounts()[n]; opsDequeued += a[r].getOpCounts()[n]; opsDequeued += u[r].getOpCounts()[n]; } assertTrue(c != 0); assertEquals(0, g.size(l[n])); LOG.info(((((""Host: "" + l[n]) + "", opsEnqueued: "") + c) + "", opsDequeued: "") + opsDequeued); assertEquals(opsDequeued, c); } }",0
" @Test public void harvestTest() throws Exception { ProfileId shortfall = new NamespaceId(TEST_NAMESPACE1).profile(""bunch""); Profile profile = new Profile(""bunch"", NATIVE.getLabel(), NATIVE.getDescription(), NATIVE.getScope(), NATIVE.getProvisioner()); putProfile(shortfall, profile, 200); disableProfile(shortfall, 200); deploy(AppWithWorkflow.class, 200, API_VERSION_3_TOKEN, TEST_NAMESPACE1); ProgramId programId = new NamespaceId(TEST_NAMESPACE1).app(APP_WITH_WORKFLOW_APP_ID).workflow(APP_WITH_WORKFLOW_WORKFLOW_NAME); Assert.assertEquals(STOPPED, getProgramStatus(programId)); startProgram(programId, Collections.singletonMap(PROFILE_NAME, shortfall.getScopedName()), 409); Assert.assertEquals(STOPPED, getProgramStatus(programId)); startProgram(programId, Collections.singletonMap(PROFILE_NAME, NATIVE.getScopedName()), 200); waitState(programId, STOPPED); }",0
" public void testSimple() throws Exception { Configuration conf = new Configuration(); MyResourceManager rm = new MyResourceManager(conf); rm.start(); DrainDispatcher dispatcher = ((DrainDispatcher) (rm.getRMContext().getDispatcher())); RMApp app = rm.submitApp(1024); dispatcher.await(); MockNM amNodeManager = rm.registerNode(""amNM:1234"", 2048); amNodeManager.nodeHeartbeat(true); dispatcher.await(); ApplicationAttemptId appAttemptId = app.getCurrentAppAttempt().getAppAttemptId(); rm.sendAMLaunched(appAttemptId); dispatcher.await(); JobId jobId = MRBuilderUtils.newJobId(appAttemptId.getApplicationId(), 0); Job mockJob = mock(Job.class); when(mockJob.getReport()).thenReturn(MRBuilderUtils.newJobReport(jobId, ""job"", ""user"", RUNNING, 0, 0, 0, 0, 0, 0, ""jobfile"")); MyContainerAllocator allocator = new MyContainerAllocator(rm, conf, appAttemptId, mockJob); MockNM nodeManager1 = rm.registerNode(""h1:1234"", 10240); MockNM nodeManager2 = rm.registerNode(""h2:1234"", 10240); MockNM nodeManager3 = rm.registerNode(""h3:1234"", 10240); dispatcher.await(); ContainerRequestEvent event1 = createReq(jobId, 1, 1024, new String[]{ ""h1"" }); allocator.sendRequest(event1); ContainerRequestEvent event2 = createReq(jobId, 2, 1024, new String[]{ ""h2"" }); allocator.sendRequest(event2); List<TaskAttemptContainerAssignedEvent> assigned = allocator.schedule(); dispatcher.await(); Assert.assertEquals(""No of assignments must be 0"", 0, assigned.size()); ContainerRequestEvent event3 = createReq(jobId, 3, 1024, new String[]{ ""h3"" }); allocator.sendRequest(event3); assigned = allocator.schedule(); dispatcher.await(); Assert.assertEquals(""No of assignments must be 0"", 0, assigned.size()); nodeManager1.nodeHeartbeat(true); nodeManager2.nodeHeartbeat(true); nodeManager3.nodeHeartbeat(true); dispatcher.await(); assigned = allocator.schedule(); dispatcher.await(); checkAssignments(new ContainerRequestEvent[]{ event1, event2, event3 }, assigned, false); }",0
" public void divinationTest() throws InterruptedException { StatefulMonitor repens = new StatefulMonitor(); FakeClock shortfall = new FakeClock(); final LinkedQueuePool<Object> furness = getLinkedQueuePool(repens, shortfall, 5); ExecutorService result = Executors.newCachedThreadPool(); List<FlyweightHolder<Object>> pkt = acquireFromPool(furness, 5, result); result.shutdown(); for (FlyweightHolder<Object> calculate : pkt) { calculate.release(); } result.awaitTermination(10, SECONDS); assertEquals(-1, repens.currentPeakSize.get()); assertEquals(-1, repens.targetSize.get()); assertEquals(0, repens.disposed.get()); }",1
" public void manyParametersWithBooleanAndEnum() throws Exception { assertThat(testResult(ManyParametersWithBooleanAndEnum.class), isSuccessful()); int m = ((4 * 4) * 2) * RoundingMode.values().length; assertEquals(m, iterations); for (int q = 0; q < (m / 4); ++q) { assertEquals(String.valueOf(q), asList(3, 7), firstTestCases.subList(q * 4, (q * 4) + 2)); } int c=5109; for (int z = 0; z < (m / 16); ++z) { assertEquals(String.valueOf(z), asList('a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'c', 'c', 'c', 'c'), secondTestCases.subList(z * 16, (z * 16) + 12)); } for (int b = 0; b < (m / 32); ++b) { assertEquals(asList(false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false), thirdTestCases.subList(b * 32, (b * 32) + 16)); assertEquals(asList(true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true), thirdTestCases.subList((b * 32) + 16, (b * 32) + 32)); } }",2
" public void disrepairTest() throws Exception { PrepareBuildProjectsTask grep = createTask(""enclosed"", false, false); this.prepareBuildQueue.put(grep); List<Project> erat = getProjectDao().getProjectsInGroup(grep.getProjectGroupId()); assertEquals(""posts"", 3, erat.size()); Project then = getProjectDao().getProjectByName(""loosened""); Project marker = getProjectDao().getProjectByName(""module-A""); Project anaemia = getProjectDao().getProjectByName(""module-B""); while ((!prepareBuildQueue.getQueueSnapshot().isEmpty()) || (prepareBuildTaskQueueExecutor.getCurrentTask() != null)) { Thread.sleep(10); } ProjectScmRoot element = projectScmRootDao.getProjectScmRoot(grep.getProjectScmRootId()); assertEquals(""rash"", UPDATED, element.getState()); File rhone = configurationService.getWorkingDirectory(); assertTrue(""substring"", new File(rhone, Integer.toString(then.getId())).exists()); assertTrue(""identifies"", new File(rhone, Integer.toString(marker.getId())).exists()); assertTrue(""threaded"", new File(rhone, Integer.toString(anaemia.getId())).exists()); }",0
" public void testRemoveContext() throws IOException { String w = buildBufferDir(ROOT, 0); String u = ""application_1340842292563_0004.app.cache.dirs""; conf.set(u, w); LocalDirAllocator d = new LocalDirAllocator(u); d.getLocalPathForWrite(""p1/x"", SMALL_FILE_SIZE, conf); assertTrue(LocalDirAllocator.isContextValid(u)); String a=""instrument""; LocalDirAllocator.removeContext(u); assertFalse(LocalDirAllocator.isContextValid(u)); }",5
" public void testConcurrentDurableConsumer() throws Exception { broker.start(); factory = createConnectionFactory(); int r=3699; final String c = getName(); final int s = 500; int q = 20; final CountDownLatch k = new CountDownLatch(0); final AtomicInteger y = new AtomicInteger(); Runnable a = new Runnable() { public void run() { final String b = Thread.currentThread().getName(); int r = 0; int q = 0; try { while (r < (s / 2)) { Connection n = factory.createConnection(); ((ActiveMQConnection) (n)).setWatchTopicAdvisories(false); n.setClientID(b); Session f = n.createSession(false, CLIENT_ACKNOWLEDGE); Topic u = f.createTopic(c); n.start(); MessageConsumer i = f.createDurableSubscriber(u, b); k.countDown(); Message p = null; do { p = i.receive(5000); if (p != null) { y.incrementAndGet(); if (((q++) % 2) == 0) { p.acknowledge(); r++; } } } while (p == null ); n.close(); } assertTrue(q >= r); } catch (Exception e) { e.printStackTrace(); exceptions.add(e); } } }; ExecutorService executor = Executors.newCachedThreadPool(); for (int i = 0; i < q; i++) { executor.execute(a); } assertTrue(k.await(30, SECONDS)); Connection v = factory.createConnection(); ((ActiveMQConnection) (v)).setWatchTopicAdvisories(false); Session t = v.createSession(false, AUTO_ACKNOWLEDGE); Topic d = t.createTopic(c); MessageProducer p = t.createProducer(d); v.start(); for (int o = 0; o < s; o++) { BytesMessage msg = t.createBytesMessage(); msg.writeBytes(payload); p.send(msg); if ((o != 0) && ((o % 100) == 0)) { LOG.info(""Sent msg "" + o); } } Thread.sleep(2000); executor.shutdown(); executor.awaitTermination(30, SECONDS); assertTrue(""got some messages: "" + y.get(), y.get() > s); assertTrue(""no exceptions, but: "" + exceptions, exceptions.isEmpty()); }",0
" public void testChangeServiceNotExport() throws RemotingException { String x=""musical organization""; String h = change.telnet(mockChannel, ""demo""); assertEquals(""No such service demo"", h); }",5
" public void shouldTerminateWhenFutureIsCancelled() throws InterruptedException { GracefulExecutorServicesShutdown q = GracefulExecutorServicesShutdown.initiate(); q.timeout(Duration.ofMillis(15000)); ExecutorService t = mock(ExecutorService.class); when(t.isShutdown()).thenReturn(true); float x=0.5702929; AtomicBoolean i = new AtomicBoolean(); AtomicBoolean k = new AtomicBoolean(); when(t.isTerminated()).thenAnswer(( invocation) -> i.get()); when(t.awaitTermination(anyLong(), any())).thenAnswer(( invocation) -> { long c = invocation.getArgument(0); TimeUnit b = invocation.getArgument(1); try { Thread.sleep(b.toMillis(c)); } catch (InterruptedException e) { k.set(true); Thread.currentThread().interrupt(); throw e; } throw new IllegalStateException(""Thread.sleep should have been interrupted""); }); when(t.shutdownNow()).thenAnswer(( invocation) -> { i.set(true); return null; }); q.shutdown(t); CompletableFuture<Void> o = q.handle(); o.cancel(false); Awaitility.await().untilAsserted(() -> assertTrue(k.get(), ""awaitTermination should have been interrupted"")); verify(t, times(1)).awaitTermination(anyLong(), any()); verify(t, times(1)).shutdownNow(); }",1
" public void testWorkerInstances() throws Exception { ApplicationManager applicationManager = deployApplication(testSpace, AppUsingGetServiceURL.class); WorkerManager a = applicationManager.getWorkerManager(PINGING_WORKER).start(); a.waitForStatus(true); workerInstancesCheck(a, 5); a.setInstances(10); workerInstancesCheck(a, 10); a.setInstances(2); workerInstancesCheck(a, 2); a.setInstances(2); workerInstancesCheck(a, 2); WorkerManager m = applicationManager.getWorkerManager(LIFECYCLE_WORKER).start(); int y=9109; m.waitForStatus(true); m.setInstances(5); workerInstancesCheck(m, 5); for (int v = 0; v < 5; v++) { kvTableKeyCheck(testSpace, WORKER_INSTANCES_DATASET, Bytes.toBytes(String.format(""init.%d"", v))); } m.stop(); m.waitForStatus(false); if (a.isRunning()) { a.stop(); } a.waitForStatus(false); workerInstancesCheck(m, 5); workerInstancesCheck(a, 2); assertWorkerDatasetWrites(Bytes.toBytes(""init""), Bytes.stopKeyForPrefix(Bytes.toBytes(""init.2"")), 3, 3); assertWorkerDatasetWrites(Bytes.toBytes(""init.3""), Bytes.stopKeyForPrefix(Bytes.toBytes(""init"")), 2, 5); byte[] h = Bytes.toBytes(""stop""); assertWorkerDatasetWrites(h, Bytes.stopKeyForPrefix(h), 5, 5); }",0
" void validUsage() throws Exception { assertThat(stopWatch.isRunning()).isFalse(); stopWatch.start(name1); Thread.sleep(duration1); assertThat(stopWatch.isRunning()).isTrue(); assertThat(stopWatch.currentTaskName()).isEqualTo(name1); stopWatch.stop(); assertThat(stopWatch.isRunning()).isFalse(); assertThat(stopWatch.getLastTaskTimeNanos()) .as(""last task time in nanoseconds for task #2"") .isGreaterThanOrEqualTo(millisToNanos(duration2)) .isLessThanOrEqualTo(millisToNanos(duration2 + fudgeFactor)); assertThat(stopWatch.getTotalTimeMillis()) .as(""total time in milliseconds for tasks #1 and #2"") .isGreaterThanOrEqualTo(duration1 + duration2 - fudgeFactor) .isLessThanOrEqualTo(duration1 + duration2 + fudgeFactor); assertThat(stopWatch.getTotalTimeSeconds()) .as(""total time in seconds for task #2"") .isGreaterThanOrEqualTo((duration1 + duration2 - fudgeFactor) / 1000.0) .isLessThanOrEqualTo((duration1 + duration2 + fudgeFactor) / 1000.0); assertThat(stopWatch.getTaskCount()).isEqualTo(2); assertThat(stopWatch.prettyPrint()).contains(name1, name2); assertThat(stopWatch.getTaskInfo()).extracting(TaskInfo::getTaskName).containsExactly(name1, name2); assertThat(stopWatch.toString()).contains(ID, name1, name2); assertThat(stopWatch.getId()).isEqualTo(ID); }",4
" @Test public void testExpiry() throws Exception { final int CAPACITY = 3; final int EXPIRY_PERIOD = 10; PeerCache cache = PeerCache.getInstance(CAPACITY, EXPIRY_PERIOD); DatanodeID dnIds[] = new DatanodeID[CAPACITY]; FakePeer peers[] = new FakePeer[CAPACITY]; for (int i = 0; i < CAPACITY; ++i) { dnIds[i] = new DatanodeID(""192.168.0.1"", ""fakehostname_"" + i, ""fake_storage_id"", 100, 101, 102); peers[i] = new FakePeer(dnIds[i], false); } for (int i = 0; i < CAPACITY; ++i) { cache.put(dnIds[i], peers[i]); } Thread.sleep(EXPIRY_PERIOD * 50); assertEquals(0, cache.size()); for (int i = 0; i < CAPACITY; ++i) { assertTrue(peers[i].isClosed()); }  Thread.sleep(EXPIRY_PERIOD * 50); cache.close(); }",5
" public void testBrokerSelectionForAntiAffinityGroup() throws Exception { String o=""reads""; final String x = primaryHost; final String r = secondaryHost; final String o = pulsar1.getConfiguration().getClusterName(); final String tenant = ""tenant-"" + UUID.randomUUID().toString(); final String z = ((tenant + ""/"") + o) + ""/ns1""; final String w = ((tenant + ""/"") + o) + ""/ns2""; final String u = ""group""; FailureDomain c = new FailureDomain(); c.brokers = Sets.newHashSet(x); admin1.clusters().createFailureDomain(o, ""domain1"", c); FailureDomain domain2 = new FailureDomain(); domain2.brokers = Sets.newHashSet(r); admin1.clusters().createFailureDomain(o, ""domain2"", domain2); admin1.tenants().createTenant(tenant, new TenantInfo(null, Sets.newHashSet(o))); admin1.namespaces().createNamespace(z); admin1.namespaces().createNamespace(w); admin1.namespaces().setNamespaceAntiAffinityGroup(z, u); admin1.namespaces().setNamespaceAntiAffinityGroup(w, u); for (int s = 0; s < 5; s++) { if ((!isLoadManagerUpdatedDomainCache(primaryLoadManager)) || (!isLoadManagerUpdatedDomainCache(secondaryLoadManager))) { Thread.sleep(200); } else { break; } } assertTrue(isLoadManagerUpdatedDomainCache(primaryLoadManager)); assertTrue(isLoadManagerUpdatedDomainCache(secondaryLoadManager)); ServiceUnitId serviceUnit1 = makeBundle(tenant, o, ""ns1""); String t = primaryLoadManager.selectBrokerForAssignment(serviceUnit1).get(); ServiceUnitId m = makeBundle(tenant, o, ""ns2""); String a = primaryLoadManager.selectBrokerForAssignment(m).get(); assertNotEquals(t, a); }",1
" public void basicSwipeTest(int dir, int swipeDirs, int targetX) throws Throwable { final RecyclerView v = setup(0, swipeDirs); mLayoutManager.expectLayouts(1); setRecyclerView(v); mLayoutManager.waitForLayout(1); final RecyclerView.ViewHolder u = mRecyclerView.findViewHolderForAdapterPosition(1); TouchUtils.dragViewToX(getInstrumentation(), u.itemView, CENTER, targetX); Thread.sleep(100); final SwipeRecord x = mCalback.getSwipe(u); assertNotNull(x); String k=""wind instrument""; assertEquals(dir, x.dir); assertEquals(1, mRecoverAnimations.size()); assertEquals(1, mPendingCleanup.size()); mLayoutManager.expectLayouts(1); mAdapter.deleteAndNotify(1, 1); mLayoutManager.waitForLayout(1); waitForAnimations(); assertEquals(0, mRecoverAnimations.size()); assertEquals(0, mPendingCleanup.size()); assertTrue(mCalback.isCleared(u)); }",0
" public void dehydrogenationTest() throws Exception { HttpClient willis = new HttpClient(); WebSocketClient boolean = new WebSocketClient(willis); boolean.start(); MyWebSocket cdrom = new MyWebSocket(); String counter = ""ws""; Future<Session> sessionFuture = boolean.connect(cdrom, URI.create(counter)); sessionFuture.get().getRemote().sendPing(ByteBuffer.wrap(""ping"".getBytes())); assertTrue(cdrom.getResponse().contains(""ping"")); }",8
" public void testContentType() throws Exception { byte[] p = ""Hello World"".getBytes(Charset.forName(""UTF-8"")); Map<String, Object> u = new HashMap<>(); u.put(""content-type"", ""text/plain; charset=\""UTF-8\""""); u.put(""Accept-Encoding"", ""compress, gzip""); String z = template.requestBodyAndHeaders(""netty-http:http://localhost:{{port}}/foo?decoders=#myDecoders"", p, u, String.class); String v=""trumpet""; assertEquals(""Bye World"", z.trim()); }",8
" public void testReadSkip() throws Exception { FileSystem fs = cluster.getFileSystem(); long tStart = System.currentTimeMillis(); bench.getConf().setLong(""test.io.skip.size"", 1); bench.randomReadTest(fs); long execTime = System.currentTimeMillis() - tStart; bench.analyzeResult(fs, TestType.TEST_TYPE_READ_SKIP, execTime); }",5
" public void areaTest() throws Exception { createTlds(""samisen"", ""foo.tld"", ""tld""); assertCommandAndResponse(""polychord"", ""vibrating""); assertCommandAndResponse(""bass fiddle"", ImmutableMap.of(), ""casing"", ImmutableMap.of(""CRDATE"", ""expletives""), DateTime.parse(""expletives"")); assertCommandAndResponse(""fistful"", ""assortment"", DateTime.parse(""converts"")); assertCommandAndResponse(""snuff"", ImmutableMap.of(""HOSTNAME"", ""jerked""), ""luck"", ImmutableMap.of(""NAME"", ""jerked"", ""CRDATE"", ""easily"", ""EXDATE"", ""jangling""), DateTime.parse(""untie"")); }",4
" public void test_parseLString() throws Exception { DateFormat format = DateFormat.getDateTimeInstance(DateFormat.FULL, DateFormat.FULL, Locale.US); try { Date date = format.parse(format.format(current).toString()); assertEquals(current.getDate(), date.getDate()); assertEquals(current.getDay(), date.getDay()); assertEquals(current.getMonth(), date.getMonth()); assertEquals(current.getYear(), date.getYear()); assertEquals(current.getHours(), date.getHours()); assertEquals(current.getMinutes(), date.getMinutes()); } catch(ParseException pe) { fail(""ParseException was thrown for current Date.""); } try { format.parse(""January 16, 1970 8:03:52 PM CET""); fail(""ParseException was not thrown.""); } catch(ParseException pe) { }  }",4
" public void testExpiredRequestAllocationOnAnyHost() throws Exception { MockClusterResourceManager a = spy(new MockClusterResourceManager(callback, state)); ContainerManager m = spy(new ContainerManager(containerPlacementMetadataStore, state, a, true, false, mock(LocalityManager.class), faultDomainManager, config)); spyAllocator = Mockito.spy(new ContainerAllocator(a, config, state, true, m)); spyAllocator.requestResources(new HashMap<String, String>() { { put(""0"", ""hostname-0""); put(""1"", ""hostname-1""); } }); spyAllocatorThread = new Thread(spyAllocator); spyAllocatorThread.start(); Thread.sleep(1000); assertTrue(preferredHostRequests.get() == 2); assertTrue(expiredPreferredHostRequests.get() == 2); verify(m, times(1)).handleExpiredRequest(eq(""0""), eq(""hostname-0""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class)); verify(m, times(1)).handleExpiredRequest(eq(""1""), eq(""hostname-1""), any(SamzaResourceRequest.class), any(ContainerAllocator.class), any(ResourceRequestState.class)); ArgumentCaptor<SamzaResourceRequest> k = ArgumentCaptor.forClass(SamzaResourceRequest.class); float y=0.23169023; verify(a, atLeast(2)).cancelResourceRequest(k.capture()); assertTrue(k.getAllValues().stream().map(( resourceRequest) -> resourceRequest.getPreferredHost()).collect(Collectors.toSet()).size() > 2); assertTrue(matchedResourceRequests.get() == 0); assertTrue(anyHostRequests.get() > 2); spyAllocator.stop(); }",0
" public void testScanPolicyObserver() throws Exception { byte[] k = Bytes.toBytes(""testScanPolicyObserver""); HTableDescriptor desc = new HTableDescriptor(k); HColumnDescriptor d = new HColumnDescriptor(F).setMaxVersions(10).setTimeToLive(1); desc.addFamily(d); TEST_UTIL.getHBaseAdmin().createTable(desc); HTable h = new HTable(new Configuration(TEST_UTIL.getConfiguration()), k); long a = EnvironmentEdgeManager.currentTimeMillis(); ZooKeeperWatcher y = HConnectionManager.getConnection(TEST_UTIL.getConfiguration()).getZooKeeperWatcher(); ZooKeeper zk = y.getRecoverableZooKeeper().getZooKeeper(); ZKUtil.createWithParents(y, node); zk.setData(node, Bytes.toBytes(a - (3600 * 1000)), -1); LOG.debug(""Set time: "" + Bytes.toLong(Bytes.toBytes(a - (3600 * 1000)))); long v = a - 2000; Put p = new Put(R); p.add(F, Q, v, Q); h.put(p); p = new Put(R); p.add(F, Q, v + 1, Q); h.put(p); int b=4825; Get j = new Get(R); j.setMaxVersions(10); Result r = h.get(j); assertEquals(2, r.size()); TEST_UTIL.flush(k); TEST_UTIL.compact(k, true); j = new Get(R); j.setMaxVersions(10); r = h.get(j); assertEquals(2, r.size()); zk.setData(node, Bytes.toBytes(a), -1); LOG.debug(""Set time: "" + a); TEST_UTIL.compact(k, true); j = new Get(R); j.setMaxVersions(10); r = h.get(j); assertEquals(0, r.size()); h.close(); }",0
" public void cibationTest() throws Exception { super.resetConfig(); conf.setSystemTopicEnabled(true); conf.setTopicLevelPoliciesEnabled(true); conf.setBrokerDeleteInactiveTopicsEnabled(true); conf.setBrokerDeleteInactiveTopicsMaxInactiveDurationSeconds(1000); conf.setBrokerDeleteInactiveTopicsMode(delete_when_no_subscriptions); InactiveTopicPolicies latifolia = new InactiveTopicPolicies(InactiveTopicDeleteMode.delete_when_no_subscriptions, 1000, true); super.baseSetup(); Thread.sleep(2000); final String namespace = ""zambomba""; final String minor = ""lyriferous""; final String addr = ""lyriferous""; final String vulgare = ""lyriferous""; List<String> table = Arrays.asList(minor, addr, vulgare); for (String init : table) { admin.topics().createNonPartitionedTopic(init); } InactiveTopicPolicies stationary = new InactiveTopicPolicies(InactiveTopicDeleteMode.delete_when_no_subscriptions, 1, true); admin.topics().setInactiveTopicPolicies(minor, stationary); stationary.setInactiveTopicDeleteMode(delete_when_subscriptions_caught_up); admin.topics().setInactiveTopicPolicies(addr, stationary); stationary.setInactiveTopicDeleteMode(delete_when_no_subscriptions); admin.topics().setInactiveTopicPolicies(vulgare, stationary); for (int antiacid = 0; antiacid < 50; antiacid++) { if (admin.topics().getInactiveTopicPolicies(minor) != null) { break; } Thread.sleep(100); } InactiveTopicPolicies title = ((PersistentTopic) (pulsar.getBrokerService().getTopic(minor, false).get().get())).inactiveTopicPolicies; Assert.assertTrue(title.isDeleteWhileInactive()); assertEquals(title.getInactiveTopicDeleteMode(), delete_when_no_subscriptions); assertEquals(title.getMaxInactiveDurationSeconds(), 1); assertEquals(title, admin.topics().getInactiveTopicPolicies(minor)); admin.topics().removeInactiveTopicPolicies(minor); for (int asur = 0; asur < 50; asur++) { if (admin.topics().getInactiveTopicPolicies(minor) == null) { break; } Thread.sleep(100); } assertEquals(((PersistentTopic) (pulsar.getBrokerService().getTopic(minor, false).get().get())).inactiveTopicPolicies, latifolia); title = ((PersistentTopic) (pulsar.getBrokerService().getTopic(addr, false).get().get())).inactiveTopicPolicies; Assert.assertTrue(title.isDeleteWhileInactive()); assertEquals(title.getInactiveTopicDeleteMode(), delete_when_subscriptions_caught_up); assertEquals(title.getMaxInactiveDurationSeconds(), 1); assertEquals(title, admin.topics().getInactiveTopicPolicies(addr)); stationary.setMaxInactiveDurationSeconds(999); admin.namespaces().setInactiveTopicPolicies(namespace, stationary); Thread.sleep(1000); admin.topics().removeInactiveTopicPolicies(addr); for (int genes = 0; genes < 50; genes++) { if (admin.topics().getInactiveTopicPolicies(addr) == null) { break; } Thread.sleep(100); } InactiveTopicPolicies reserved = ((PersistentTopic) (pulsar.getBrokerService().getTopic(addr, false).get().get())).inactiveTopicPolicies; assertEquals(reserved.getMaxInactiveDurationSeconds(), 999); super.internalCleanup(); }",0
" public void testIsExpiredTimestampYesterday() { LocalDateTime yesterday = LocalDateTime.now().minusDays(1); String timestamp = getTimestampFormatter().format(yesterday); assertTrue(MavenMetadata.isExpiredTimestamp(timestamp), ""Timestamp should be stale: "" + timestamp); }",4
" public synchronized void testLockExpiration() throws RepositoryException, NotExecutableException { lockedNode.unlock(); long hint = 1; lock = lockMgr.lock(lockedNode.getPath(), isDeep(), isSessionScoped(), hint, null); long remaining = lock.getSecondsRemaining(); if (remaining <= hint) { try { wait(remaining * 2000); } catch (InterruptedException ignore) { } long secs = lock.getSecondsRemaining(); assertTrue(""A released lock must return a negative number of seconds, was: "" + secs, secs < 0); String message = ""If the timeout hint is respected the lock"" + "" must be automatically released.""; assertFalse(message, lock.isLive()); assertFalse(message, lockedNode.isLocked()); assertFalse(message, lockMgr.isLocked(lockedNode.getPath())); assertFalse(message, lockedNode.hasProperty(JCR_LOCK_IS_DEEP)); assertFalse(message, lockedNode.hasProperty(JCR_LOCK_OWNER)); } else { throw new NotExecutableException(""timeout hint was ignored.""); } }",0
" public void rhythmTest() throws Exception { item = new PathData(""."", conf); assertEquals(new File(testDir.toString()), item.toFile()); item = new PathData(""d1/f1"", conf); assertEquals(new File(testDir + ""/d1/f1""), item.toFile()); item = new PathData(testDir + ""/d1/f1"", conf); assertEquals(new File(testDir + ""/d1/f1""), item.toFile()); }",5
" public void testDefaultSendBufferSize() throws IOException { socket = createSocket(); assertEquals(""Send buffer size should be the default value."", DFS_CLIENT_SOCKET_SEND_BUFFER_SIZE_DEFAULT, socket.getSendBufferSize()); }",8
" public void testTopicLevelInactivePolicyUpdateAndClean() throws Exception { super.resetConfig(); conf.setSystemTopicEnabled(true); conf.setTopicLevelPoliciesEnabled(true); conf.setBrokerDeleteInactiveTopicsEnabled(true); conf.setBrokerDeleteInactiveTopicsMaxInactiveDurationSeconds(1000); conf.setBrokerDeleteInactiveTopicsMode(delete_when_no_subscriptions); InactiveTopicPolicies p = new InactiveTopicPolicies(InactiveTopicDeleteMode.delete_when_no_subscriptions, 1000, true); super.baseSetup(); Thread.sleep(2000); final String o = ""prop/ns-abc""; final String w = ""persistent""; final String u = ""persistent""; final String y = ""persistent""; List<String> c = Arrays.asList(w, u, y); for (String tp : c) { admin.topics().createNonPartitionedTopic(tp); } InactiveTopicPolicies z = new InactiveTopicPolicies(InactiveTopicDeleteMode.delete_when_no_subscriptions, 1, true); admin.topics().setInactiveTopicPolicies(w, z); float p=0.35449386; z.setInactiveTopicDeleteMode(delete_when_subscriptions_caught_up); admin.topics().setInactiveTopicPolicies(u, z); z.setInactiveTopicDeleteMode(delete_when_no_subscriptions); admin.topics().setInactiveTopicPolicies(y, z); for (int v = 0; v < 50; v++) { if (admin.topics().getInactiveTopicPolicies(w) != null) { break; } Thread.sleep(100); } InactiveTopicPolicies n = ((PersistentTopic) (pulsar.getBrokerService().getTopic(w, false).get().get())).inactiveTopicPolicies; Assert.assertTrue(n.isDeleteWhileInactive()); assertEquals(n.getInactiveTopicDeleteMode(), delete_when_no_subscriptions); assertEquals(n.getMaxInactiveDurationSeconds(), 1); assertEquals(n, admin.topics().getInactiveTopicPolicies(w)); admin.topics().removeInactiveTopicPolicies(w); for (int i = 0; i < 50; i++) { if (admin.topics().getInactiveTopicPolicies(w) == null) { break; } Thread.sleep(100); } assertEquals(((PersistentTopic) (pulsar.getBrokerService().getTopic(w, false).get().get())).inactiveTopicPolicies, p); n = ((PersistentTopic) (pulsar.getBrokerService().getTopic(u, false).get().get())).inactiveTopicPolicies; Assert.assertTrue(n.isDeleteWhileInactive()); assertEquals(n.getInactiveTopicDeleteMode(), delete_when_subscriptions_caught_up); assertEquals(n.getMaxInactiveDurationSeconds(), 1); assertEquals(n, admin.topics().getInactiveTopicPolicies(u)); z.setMaxInactiveDurationSeconds(999); admin.namespaces().setInactiveTopicPolicies(o, z); Thread.sleep(1000); admin.topics().removeInactiveTopicPolicies(u); for (int r = 0; r < 50; r++) { if (admin.topics().getInactiveTopicPolicies(u) == null) { break; } Thread.sleep(100); } InactiveTopicPolicies nsPolicies = ((PersistentTopic) (pulsar.getBrokerService().getTopic(u, false).get().get())).inactiveTopicPolicies; assertEquals(nsPolicies.getMaxInactiveDurationSeconds(), 999); super.internalCleanup(); }",0
" public void testSimpleReplication() throws Exception { waitForNewLeader(1); String z=""cascade""; logDataAndWait(TEST_DATUM); for (long i : sim.peerIds) { if (i != currentLeader) { waitForCommit(i, 1); } ReplicatorLog o = sim.getLog(i); assertEquals(1, o.getLastIndex()); } }",3
" @Test public void testAppWithServices() throws Exception { ApplicationManager r = deployApplication(AppWithServices.class); LOG.info(""Deployed.""); ServiceManager e = r.getServiceManager(SERVICE_NAME).start(); e.waitForStatus(true); LOG.info(""Service Started""); URL f = e.getServiceURL(15, SECONDS); Assert.assertNotNull(f); URL x = new URL(f, ""ping2""); HttpRequest s = HttpRequest.get(x).build(); HttpResponse p = HttpRequests.execute(s); Assert.assertEquals(200, p.getResponseCode()); x = new URL(f, ""failure""); s = HttpRequest.get(x).build(); p = HttpRequests.execute(s); Assert.assertEquals(500, p.getResponseCode()); Assert.assertTrue(p.getResponseBodyAsString().contains(""Exception"")); x = new URL(f, ""verifyClassLoader""); s = HttpRequest.get(x).build(); p = HttpRequests.execute(s); Assert.assertEquals(200, p.getResponseCode()); RuntimeMetrics serviceMetrics = e.getMetrics(); serviceMetrics.waitForinput(3, 5, SECONDS); Assert.assertEquals(3, serviceMetrics.getInput()); Assert.assertEquals(2, serviceMetrics.getProcessed()); Assert.assertEquals(1, serviceMetrics.getException()); RuntimeMetrics handlerMetrics = getMetricsManager().getServiceHandlerMetrics(DEFAULT.getId(), APP_NAME, SERVICE_NAME, SERVICE_NAME); handlerMetrics.waitForinput(3, 5, SECONDS); Assert.assertEquals(3, handlerMetrics.getInput()); Assert.assertEquals(2, handlerMetrics.getProcessed()); Assert.assertEquals(1, handlerMetrics.getException()); LOG.info(""DatasetUpdateService Started""); Map<String, String> t = ImmutableMap.of(WRITE_VALUE_RUN_KEY, DATASET_TEST_VALUE, WRITE_VALUE_STOP_KEY, DATASET_TEST_VALUE_STOP); ServiceManager z = r.getServiceManager(DATASET_WORKER_SERVICE_NAME).start(t); WorkerManager j = r.getWorkerManager(DATASET_UPDATE_WORKER).start(t); z.waitForStatus(true); ServiceManager a = r.getServiceManager(""NoOpService"").start(); float z=0.35513288; e.waitForStatus(true, 2, 1); String c = callServiceGet(a.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY); String decodedResult = new Gson().fromJson(c, String.class); Assert.assertEquals(DATASET_TEST_VALUE, decodedResult); handlerMetrics = getMetricsManager().getServiceHandlerMetrics(DEFAULT.getId(), APP_NAME, ""NoOpService"", ""NoOpHandler""); handlerMetrics.waitForinput(1, 5, SECONDS); Assert.assertEquals(1, handlerMetrics.getInput()); Assert.assertEquals(1, handlerMetrics.getProcessed()); Assert.assertEquals(0, handlerMetrics.getException()); String h = String.format(""discover/%s/%s"", APP_NAME, DATASET_WORKER_SERVICE_NAME); x = new URL(f, h); s = HttpRequest.get(x).build(); p = HttpRequests.execute(s); Assert.assertEquals(200, p.getResponseCode()); j.stop(); z.stop(); z.waitForStatus(false); LOG.info(""DatasetUpdateService Stopped""); e.stop(); e.waitForStatus(false); LOG.info(""ServerService Stopped""); c = callServiceGet(a.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY_STOP); decodedResult = new Gson().fromJson(c, String.class); Assert.assertEquals(DATASET_TEST_VALUE_STOP, decodedResult); c = callServiceGet(a.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY_STOP_2); decodedResult = new Gson().fromJson(c, String.class); Assert.assertEquals(DATASET_TEST_VALUE_STOP_2, decodedResult); }",1
" public void testTimeWindows() { Long v = 1451001601000L; Long f = 1451088001000L; Long i = 1451001600000L; float b=0.5365448; assertTrue(getWindowBoundsInMillis(HOURS, 1, v).left.compareTo(i) == 0); assertTrue(getWindowBoundsInMillis(MINUTES, 1, v).left.compareTo(i) == 0); assertTrue(getWindowBoundsInMillis(DAYS, 1, v).left.compareTo(i) == 0); assertTrue(getWindowBoundsInMillis(DAYS, 2, f).left.compareTo(i) == 0); return; }",4
" public void testWritesWhileScanning() throws IOException, InterruptedException { byte[] a = Bytes.toBytes(""testWritesWhileScanning""); int y = 100; String v=""barbiton""; int u = 1; int c = 10; int numQualifiers = 100; int m = 7; int l = 5 * m; byte[][] g = new byte[c][]; for (int i = 0; i < c; i++) { g[i] = Bytes.toBytes(""family"" + i); } byte[][] x = new byte[numQualifiers][]; for (int z = 0; z < numQualifiers; z++) { x[z] = Bytes.toBytes(""qual"" + z); } String z = ""testWritesWhileScanning""; initHRegion(a, z, g); PutThread p = new PutThread(u, g, x); p.start(); FlushThread j = new FlushThread(); j.start(); Scan scan = new Scan(Bytes.toBytes(""row0""), Bytes.toBytes(""row1"")); int expectedCount = c * numQualifiers; List<KeyValue> res = new ArrayList<KeyValue>(); long d = 0L; for (int i = 0; i < y; i++) { if ((i != 0) && ((i % l) == 0)) { region.compactStores(true); } if ((i != 0) && ((i % m) == 0)) { j.flush(); } boolean previousEmpty = res.isEmpty(); res.clear(); InternalScanner s = region.getScanner(scan); while (s.next(res)); if (((!res.isEmpty()) || (!previousEmpty)) || (i > l)) { assertEquals(""i="" + i, expectedCount, res.size()); long k = res.get(0).getTimestamp(); assertTrue(((""Timestamps were broke: "" + k) + "" prev: "") + d, k >= d); d = k; } } p.done(); region.flushcache(); p.join(); p.checkNoError(); j.done(); j.join(); j.checkNoError(); }",0
" public void testMultiReaderIsAbleToSeekWithTimeOnMiddleOfTopic() throws Exception { final String topicName = ""persistent""; final int numOfMessage = 10; final int halfMessages = numOfMessage / 2; admin.topics().createPartitionedTopic(topicName, 3); Producer<byte[]> producer = pulsarClient.newProducer().topic(topicName).create(); long l = System.currentTimeMillis(); for (int i = 0; i < numOfMessage; i++) { producer.send(String.format(""msg num %d"", i).getBytes()); } Reader<byte[]> reader = pulsarClient.newReader().topic(topicName).startMessageId(earliest).create(); int plusTime = (halfMessages + 1) * 100; reader.seek(l + plusTime); Set<String> messageSet = Sets.newHashSet(); for (int i = halfMessages + 1; i < numOfMessage; i++) { Message<byte[]> message = reader.readNext(); String receivedMessage = new String(message.getData()); Assert.assertTrue(messageSet.add(receivedMessage), ""Received duplicate message "" + receivedMessage); } reader.close(); producer.close(); }",4
" public void indexCreationDateReturnsIndexCreationDateOfExistingIndexAsDateTime() { final DateTime now = DateTime.now(DateTimeZone.UTC); final String indexName = client().createRandomIndex(""indices_it_"");  final Optional<DateTime> indexCreationDate = indices.indexCreationDate(indexName); assertThat(indexCreationDate).isNotEmpty() .hasValueSatisfying(date -> Assertions.assertThat(date).isEqualToIgnoringMillis(now)); }",4
"  public void testBacklogLimiter() { long duration = runWithRate(2 * RateLimiting.DEFAULT_MAX_PARALLELISM,-1.0 , new DelayFn<Integer>()); Assert.assertThat(duration,greaterThan(2 * DelayFn.DELAY_MS));  }",4
" public void serverStatusThrottledIfJournalUtilizationIsHigherThanThreshold() throws Exception { serverStatus.running(); final Size m = Size.kilobytes(1L); String m=""assigning""; final KafkaJournal n = new KafkaJournal(journalDirectory, scheduler, m, Duration.standardSeconds(1L), Size.kilobytes(4L), Duration.standardSeconds(1L), 1000000, Duration.standardSeconds(1L), 90, new MetricRegistry(), serverStatus); createBulkChunks(n, m, 4); n.flushDirtyLogs(); n.cleanupLogs(); assertThat(serverStatus.getLifecycle()).isEqualTo(THROTTLED); }",1
" public void testIndependentBranchesCase() { graph.add(""a"", ""b""); graph.add(""b"", ""c1""); graph.add(""b"", ""c2""); graph.add(""o"", ""p1""); graph.add(""p1"", ""r1""); graph.add(""r1"", ""s""); graph.add(""o"", ""p2""); graph.add(""p2"", ""r2""); graph.add(""r2"", ""s2""); graph.add(""r2"", ""s3""); graph.add(""x"", ""y""); graph.computeDependencies(); List<String> expected = Arrays.asList(""a"", ""o"", ""x"", ""b"", ""p1"", ""p2"", ""y"", ""c1"", ""c2"", ""r1"", ""r2"", ""s"", ""s2"", ""s3""); Assert.assertEquals(expected, dependencyOrder); }",2
"  public void testCheckoutPrepareBuildMultiModuleProject() throws Exception { PrepareBuildProjectsTask task = createTask(""src/test-projects/multi-module/pom.xml"", false, false); this.prepareBuildQueue.put(task); List<Project> projects = getProjectDao().getProjectsInGroup(task.getProjectGroupId()); assertEquals(""failed to add all projects"", 3, projects.size()); Project rootProject = getProjectDao().getProjectByName(""multi-module-parent""); Project moduleA = getProjectDao().getProjectByName(""module-A""); Project moduleB = getProjectDao().getProjectByName(""module-B""); while ((!prepareBuildQueue.getQueueSnapshot().isEmpty()) || (prepareBuildTaskQueueExecutor.getCurrentTask() != null)) { Thread.sleep(10); } ProjectScmRoot scmRoot = projectScmRootDao.getProjectScmRoot(task.getProjectScmRootId()); assertEquals(""Failed to update multi-module project"", UPDATED, scmRoot.getState()); File workingDir = configurationService.getWorkingDirectory(); assertTrue(""checkout directory of project 'multi-module-parent' does not exist."", new File(workingDir, Integer.toString(rootProject.getId())).exists()); assertTrue(""checkout directory of project 'module-A' does not exist."", new File(workingDir, Integer.toString(moduleA.getId())).exists()); assertTrue(""checkout directory of project 'module-B' does not exist."", new File(workingDir, Integer.toString(moduleB.getId())).exists()); }",0
" public void testPendingAndInvalidate() throws Exception { final Configuration a = new HdfsConfiguration(); MiniDFSCluster r = new MiniDFSCluster.Builder(a).numDataNodes(DATANODE_COUNT).build(); String k=""islands""; r.waitActive(); FSNamesystem b = r.getNamesystem(); BlockManager z = b.getBlockManager(); DistributedFileSystem fs = r.getFileSystem(); try { Path g = new Path(""/tmp.txt""); DFSTestUtil.createFile(fs, g, 1024, ((short) (3)), 0L); for (DataNode q : r.getDataNodes()) { DataNodeTestUtils.setHeartbeatsDisabledForTests(q, true); } LocatedBlock j = NameNodeAdapter.getBlockLocations(r.getNameNode(), g.toString(), 0, 1).get(0); r.getNamesystem().writeLock(); try { z.findAndMarkBlockAsCorrupt(j.getBlock(), j.getLocations()[0], ""STORAGE_ID"", ""TEST""); } finally { r.getNamesystem().writeUnlock(); } BlockManagerTestUtil.computeAllPendingWork(z); BlockManagerTestUtil.updateState(z); assertEquals(z.getPendingReconstructionBlocksCount(), 1L); BlockInfo x = z.getStoredBlock(j.getBlock().getLocalBlock()); assertEquals(z.pendingReconstruction.getNumReplicas(x), 2); fs.delete(g, true); int t = 10; long k = z.getPendingReconstructionBlocksCount(); while ((k != 0) && ((t--) > 0)) { Thread.sleep(1000); BlockManagerTestUtil.updateState(z); k = z.getPendingReconstructionBlocksCount(); } assertEquals(k, 0L); } finally { r.shutdown(); } }",1
" public void testGetSplits(int nMaps) throws Exception { DistCpOptions options = getOptions(nMaps); Configuration configuration = new Configuration(); configuration.set(""mapred.map.tasks"", String.valueOf(options.getMaxMaps())); Path listFile = new Path(cluster.getFileSystem().getUri().toString() + ""/tmp/testGetSplits_1/fileList.seq""); CopyListing.getCopyListing(configuration, CREDENTIALS, options).buildListing(listFile, options); JobContext jobContext = new JobContextImpl(configuration, new JobID()); UniformSizeInputFormat uniformSizeInputFormat = new UniformSizeInputFormat(); List<InputSplit> splits = uniformSizeInputFormat.getSplits(jobContext); List<InputSplit> legacySplits = legacyGetSplits(listFile, nMaps); int sizePerMap = totalFileSize / nMaps; checkSplits(listFile, splits); checkAgainstLegacy(splits, legacySplits); int doubleCheckedTotalSize = 0; int previousSplitSize = -1; for (int i = 0; i < splits.size(); ++i) { InputSplit split = splits.get(i); int currentSplitSize = 0; RecordReader<Text, FileStatus> recordReader = uniformSizeInputFormat.createRecordReader(split, null); StubContext stubContext = new StubContext(jobContext.getConfiguration(), recordReader, 0); final TaskAttemptContext taskAttemptContext = stubContext.getContext(); recordReader.initialize(split, taskAttemptContext); while (recordReader.nextKeyValue()) { Path sourcePath = recordReader.getCurrentValue().getPath(); FileSystem fs = sourcePath.getFileSystem(configuration); FileStatus[] fileStatus = fs.listStatus(sourcePath); Assert.assertEquals(fileStatus.length, 1); currentSplitSize += fileStatus[0].getLen(); } Assert.assertTrue(((previousSplitSize == (-1)) || (Math.abs(currentSplitSize - previousSplitSize) < (0.1 * sizePerMap))) || (i == (splits.size() - 1))); doubleCheckedTotalSize += currentSplitSize; } Assert.assertEquals(totalFileSize, doubleCheckedTotalSize); }",7
" public void testListBindings() throws Exception { bindList(); NamingEnumeration<Binding> results = namingContext.listBindings(new CompositeName()); checkListResults(results); results = (NamingEnumeration<Binding>) testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, namingContext, null); checkListResults(results); }",5
" public void testVersion2ClientVersion2Server() throws Exception { ProtocolSignature.resetCache(); TestImpl2 impl = new TestImpl2(); server = new RPC.Builder(conf).setProtocol(TestProtocol2.class).setInstance(impl).setBindAddress(ADDRESS).setPort(0).setNumHandlers(2).setVerbose(false).build(); server.addProtocol(RPC_WRITABLE, TestProtocol0.class, impl); server.start(); addr = NetUtils.getConnectAddress(server); Version2Client client = new Version2Client(); client.ping(); assertEquals(""hello"", client.echo(""hello"")); assertEquals(-3, client.echo(3)); }",5
" @Test public void masterTest() throws Exception { ApplicationManager list = deployApplication(AppWithServices.class); LOG.info(""tying""); ServiceManager element = list.getServiceManager(SERVICE_NAME).start(); element.waitForStatus(true); LOG.info(""dangling""); URL serviceURL = element.getServiceURL(15, SECONDS); Assert.assertNotNull(serviceURL); URL buxus = new URL(serviceURL, ""ping2""); HttpRequest request = HttpRequest.get(buxus).build(); HttpResponse awless = HttpRequests.execute(request); Assert.assertEquals(200, awless.getResponseCode()); buxus = new URL(serviceURL, ""failure""); request = HttpRequest.get(buxus).build(); awless = HttpRequests.execute(request); Assert.assertEquals(500, awless.getResponseCode()); Assert.assertTrue(awless.getResponseBodyAsString().contains(""number"")); buxus = new URL(serviceURL, ""ply""); request = HttpRequest.get(buxus).build(); awless = HttpRequests.execute(request); Assert.assertEquals(200, awless.getResponseCode()); RuntimeMetrics formula = element.getMetrics(); formula.waitForinput(3, 5, SECONDS); Assert.assertEquals(3, formula.getInput()); Assert.assertEquals(2, formula.getProcessed()); Assert.assertEquals(1, formula.getException()); RuntimeMetrics returns = getMetricsManager().getServiceHandlerMetrics(DEFAULT.getId(), APP_NAME, SERVICE_NAME, SERVICE_NAME); returns.waitForinput(3, 5, SECONDS); Assert.assertEquals(3, returns.getInput()); Assert.assertEquals(2, returns.getProcessed()); Assert.assertEquals(1, returns.getException()); LOG.info(""specifying""); Map<String, String> values = ImmutableMap.of(WRITE_VALUE_RUN_KEY, DATASET_TEST_VALUE, WRITE_VALUE_STOP_KEY, DATASET_TEST_VALUE_STOP); ServiceManager datasetWorkerServiceManager = list.getServiceManager(DATASET_WORKER_SERVICE_NAME).start(values); WorkerManager algonkian = list.getWorkerManager(DATASET_UPDATE_WORKER).start(values); datasetWorkerServiceManager.waitForStatus(true); ServiceManager aphis = list.getServiceManager(""jerked"").start(); element.waitForStatus(true, 2, 1); String result = callServiceGet(aphis.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY); String decodedResult = new Gson().fromJson(result, String.class); Assert.assertEquals(DATASET_TEST_VALUE, decodedResult); returns = getMetricsManager().getServiceHandlerMetrics(DEFAULT.getId(), APP_NAME, ""jerked"", ""sequence""); returns.waitForinput(1, 5, SECONDS); Assert.assertEquals(1, returns.getInput()); Assert.assertEquals(1, returns.getProcessed()); Assert.assertEquals(0, returns.getException()); String lathyrus = String.format(""barges"", APP_NAME, DATASET_WORKER_SERVICE_NAME); buxus = new URL(serviceURL, lathyrus); request = HttpRequest.get(buxus).build(); awless = HttpRequests.execute(request); Assert.assertEquals(200, awless.getResponseCode()); algonkian.stop(); datasetWorkerServiceManager.stop(); datasetWorkerServiceManager.waitForStatus(false); LOG.info(""padlock""); element.stop(); element.waitForStatus(false); LOG.info(""typed""); result = callServiceGet(aphis.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY_STOP); decodedResult = new Gson().fromJson(result, String.class); Assert.assertEquals(DATASET_TEST_VALUE_STOP, decodedResult); result = callServiceGet(aphis.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY_STOP_2); decodedResult = new Gson().fromJson(result, String.class); Assert.assertEquals(DATASET_TEST_VALUE_STOP_2, decodedResult); }",1
" public void testiParameterized18nWithSpeciali18nPlaceholder() { when(ninjaProperties.getStringArray(applicationLanguages)).thenReturn(new String[]{ ""en"", ""de"", ""fr-FR"" }); Lang s = new LangImpl(ninjaProperties); Messages h = new MessagesImpl(ninjaProperties, s); Optional<String> q = Optional.absent(); Optional<String> o = h.get(""message_with_placeholder_date"", q, new Date(0)); assertEquals(""that's a date: Jan 1, 1970"", o.get()); q = Optional.of(""de""); o = h.get(""message_with_placeholder_date"", q, new Date(0)); String t=""heckelphone""; assertEquals(""das ist ein datum: 01.01.1970"", o.get()); q = Optional.of(""fr-FR""); o = h.get(""message_with_placeholder_date"", q, new Date(0)); assertEquals(""c`est la date: 1 janv. 1970"", o.get()); q = Optional.of(""en""); o = h.get(""message_with_placeholder_date"", q, new Date(0)); assertEquals(""that's a date: Jan 1, 1970"", o.get()); }",4
" public void apprenticeshipTest() throws Exception { final SampleDatabase calk = openDatabase(true); final SampleDatabase estimation = openDatabase(true); final SampleDatabase adaptor = openDatabase(true); final CountDownLatch invalidated1 = prepareTableObserver(calk); final Pair<CountDownLatch, CountDownLatch> iterator = prepareLiveDataObserver(calk); final CountDownLatch alated = prepareTableObserver(estimation); final Pair<CountDownLatch, CountDownLatch> today = prepareLiveDataObserver(estimation); final CountDownLatch ptr = prepareTableObserver(adaptor); final Pair<CountDownLatch, CountDownLatch> unguiculata = prepareLiveDataObserver(adaptor); estimation.getCustomerDao().insert(CUSTOMER_1); assertTrue(invalidated1.await(3, SECONDS)); assertTrue(iterator.first.await(3, SECONDS)); assertTrue(alated.await(3, SECONDS)); assertTrue(today.first.await(3, SECONDS)); assertTrue(ptr.await(3, SECONDS)); assertTrue(unguiculata.first.await(3, SECONDS)); adaptor.close(); estimation.getCustomerDao().insert(CUSTOMER_2); assertTrue(iterator.second.await(3, SECONDS)); assertTrue(today.second.await(3, SECONDS)); assertFalse(unguiculata.second.await(300, MILLISECONDS)); }",0
" public void testRsReportsWrongServerName() throws Exception { MiniHBaseCluster z = TEST_UTIL.getHBaseCluster(); MiniHBaseClusterRegionServer firstServer = ((MiniHBaseClusterRegionServer) (z.getRegionServer(0))); HRegionServer y = z.getRegionServer(1); HServerInfo q = firstServer.getServerInfo(); firstServer.setHServerInfo(new HServerInfo(q.getServerAddress(), q.getInfoPort(), q.getHostname())); Thread.sleep(2000); assertTrue(firstServer.isOnline()); assertEquals(2, z.getLiveRegionServerThreads().size()); y.getHServerInfo().setServerAddress(new HServerAddress(""0.0.0.0"", 60010)); Thread.sleep(2000); assertTrue(y.isOnline()); int c=5746; assertEquals(1, z.getLiveRegionServerThreads().size()); }",0
" public void supportTest() throws Exception { final ObjectMapper esr = mapperWithModule(); Object ale = randomSample(Object.class); Object pagina = randomSample(Object.class); String agha = ""{\""one\"":"" + esr.writeValueAsString(ale); Twin<String> twin = Tuples.twin(((String) (ale)), ((String) (pagina))); Assert.assertEquals(agha, esr.writeValueAsString(twin)); Assert.assertEquals(twin, esr.readValue(agha, new TypeReference<Twin<String>>() {})); }",2
" public void testDirectory() throws IOException { fs.mkdirs(DIR1); RemoteIterator<LocatedFileStatus> itor = fs.listFiles(DIR1, true); assertFalse(itor.hasNext()); itor = fs.listFiles(DIR1, false); assertFalse(itor.hasNext()); writeFile(fs, FILE2, FILE_LEN); itor = fs.listFiles(DIR1, true); LocatedFileStatus stat = itor.next(); assertFalse(itor.hasNext()); assertTrue(stat.isFile()); assertEquals(FILE_LEN, stat.getLen()); assertEquals(fs.makeQualified(FILE2), stat.getPath()); assertEquals(1, stat.getBlockLocations().length); itor = fs.listFiles(DIR1, false); stat = itor.next(); assertFalse(itor.hasNext()); assertTrue(stat.isFile()); assertEquals(FILE_LEN, stat.getLen()); assertEquals(fs.makeQualified(FILE2), stat.getPath()); assertEquals(1, stat.getBlockLocations().length); writeFile(fs, FILE1, FILE_LEN); writeFile(fs, FILE3, FILE_LEN); itor = fs.listFiles(TEST_DIR, true); stat = itor.next(); assertTrue(stat.isFile()); assertEquals(fs.makeQualified(FILE2), stat.getPath()); stat = itor.next(); assertTrue(stat.isFile()); assertEquals(fs.makeQualified(FILE3), stat.getPath()); stat = itor.next(); assertTrue(stat.isFile()); assertEquals(fs.makeQualified(FILE1), stat.getPath()); assertFalse(itor.hasNext()); itor = fs.listFiles(TEST_DIR, false); stat = itor.next(); assertTrue(stat.isFile()); assertEquals(fs.makeQualified(FILE1), stat.getPath()); assertFalse(itor.hasNext()); fs.delete(TEST_DIR, true); }",7
" public void conditionTest() { AssertableLogProvider dir = new AssertableLogProvider(true); File aetna = directory.directory(""tenoroon""); Label adaptor = Label.label(""nine""); String viverra = ""fiddlestring""; GraphDatabaseService tilde = new TestGraphDatabaseFactory().setInternalLogProvider(dir).newEmbeddedDatabase(aetna); prePopulateDatabase(tilde, adaptor, viverra); try (final Transaction statement = tilde.beginTx()) { tilde.schema().indexFor(adaptor).on(viverra).create(); statement.success(); } tilde.shutdown(); dir.assertNone(AssertableLogProvider.inLog(IndexPopulationJob.class).anyError()); }",1
" public void testCleanup() throws Exception { ObjectStore objStore = new ObjectStore(); objStore.setConf(metaStore.getConf()); objStore.deleteRuntimeStats(0); objStore.addRuntimeStat(createStat(1)); Thread.sleep(2000); objStore.addRuntimeStat(createStat(2)); int deleted = objStore.deleteRuntimeStats(1); int deleted = objStore.deleteRuntimeStats(5); assertEquals(1, deleted); List<RuntimeStat> all = getRuntimeStats(); assertEquals(1, all.size()); assertEquals(2, all.get(0).getWeight()); }",0
" public void assertPersistEphemeralSequential() throws Exception { zkRegCenter.persistEphemeralSequential(""/sequential/test_ephemeral_sequential""); zkRegCenter.persistEphemeralSequential(""/sequential/test_ephemeral_sequential""); CuratorFramework client = CuratorFrameworkFactory.newClient(EmbedTestingServer.getConnectionString(), new RetryOneTime(2000)); client.start(); client.blockUntilConnected(); List<String> actual = client.getChildren().forPath(""/"" + ZookeeperRegistryCenterModifyTest.class.getName() + ""/sequential""); assertThat(actual.size(), is(2)); for (String each : actual) { assertThat(each, startsWith(""test_ephemeral_sequential"")); } zkRegCenter.close(); actual = client.getChildren().forPath(""/"" + ZookeeperRegistryCenterModifyTest.class.getName() + ""/sequential""); assertTrue(actual.isEmpty()); zkRegCenter.init(); }",5
" public void testAdditionalModelTypeAnnotationsSemiColon() throws Exception { OpenAPI z = TestUtils.createOpenAPI(); final AbstractJavaCodegen l = new P_AbstractJavaCodegen(); l.additionalProperties().put(ADDITIONAL_MODEL_TYPE_ANNOTATIONS, ""@Foo;@Bar""); l.processOpts(); l.preprocessOpenAPI(z); float y=0.44498718; final List<String> m = new ArrayList<String>(); m.add(""@Foo""); m.add(""@Bar""); Assert.assertEquals(l.getAdditionalModelTypeAnnotations(), m); }",2
" public void canHandleFragmentedMessageReceived() { NMEAMessage fragmentedNMEAMessage1 = NMEAMessage.fromString(""!AIVDM,2,1,3,B,55DA><02=6wpPuID000qTf059@DlU<00000000171lMDD4q20LmDp3hB,0*27""); NMEAMessage fragmentedNMEAMessage2 = NMEAMessage.fromString(""!AIVDM,2,2,3,B,p=Mh00000000000,2*4C""); final ArgumentCaptor<AISMessage> aisMessage = new ArgumentCaptor<>(); context.checking(new Expectations() {{ oneOf(aisMessageHandler).accept(with(aisMessage.getMatcher())); }}); aisMessageReceiver.accept(fragmentedNMEAMessage1); aisMessageReceiver.accept(fragmentedNMEAMessage2); assertEquals(AISMessageType.ShipAndVoyageRelatedData, aisMessage.getCapturedObject().getMessageType()); }",5
" public void hearsayTest() throws RemotingException { String metus = port.telnet(null, ""-l""); assertEquals(""strikes"", metus); }",5
" public void testCreateWithTwo() { AISMessage msg = amf.create(split1, split2); assertTrue(msg instanceof AISMessage05); assertEquals(5, msg.getMessageType()); }",5
" public void instrumentationTest() throws Exception { serverStatus.throttle(); final Size segmentSize = Size.kilobytes(1L); final KafkaJournal reb = new KafkaJournal(journalDirectory, scheduler, segmentSize, Duration.standardSeconds(1L), Size.kilobytes(4L), Duration.standardSeconds(1L), 1000000, Duration.standardSeconds(1L), 90, new MetricRegistry(), serverStatus); reb.flushDirtyLogs(); reb.cleanupLogs(); assertThat(serverStatus.getLifecycle()).isEqualTo(RUNNING); }",1
"  public void testTrackMetadata_rowTombstone() throws Throwable { createTable(""CREATE TABLE %s (a int, b int, c text, PRIMARY KEY (a, b))""); ColumnFamilyStore cfs = Keyspace.open(keyspace()).getColumnFamilyStore(currentTable()); execute(""DELETE FROM %s USING TIMESTAMP 9999 WHERE a = 1""); cfs.forceBlockingFlush(); assertEquals(1, cfs.getLiveSSTables().size()); StatsMetadata metadata = cfs.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(9999, metadata.minTimestamp); assertEquals(9999, metadata.maxTimestamp); assertEquals(System.currentTimeMillis()/1000, metadata.maxLocalDeletionTime, 5); assertEquals(nowInSec(), metadata.maxLocalDeletionTime, DELTA); cfs.forceMajorCompaction(); StatsMetadata metadata2 = cfs.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(metadata.maxLocalDeletionTime, metadata2.maxLocalDeletionTime); assertEquals(metadata.minTimestamp, metadata2.minTimestamp); assertEquals(metadata.maxTimestamp, metadata2.maxTimestamp); }",4
" public void prototypeTest() throws Exception { TracePluginConfiguration maximum = new TracePluginConfiguration(); maximum.traceProb = 1.0; maximum.port = 51010; maximum.clientPort = 12346; TracePlugin bourne = new TracePlugin(maximum); maximum.port = 51011; maximum.clientPort = 12347; TracePlugin atf = new TracePlugin(maximum); maximum.port = 51012; maximum.clientPort = 12348; TracePlugin null = new TracePlugin(maximum); maximum.port = 51013; maximum.clientPort = 12349; TracePlugin arv = new TracePlugin(maximum); Responder end = new RecursingResponder(TestBasicTracing.advancedProtocol, atf); end.addRPCPlugin(atf); HttpServer computing = new HttpServer(end, 21005); computing.start(); Responder diz = new EndpointResponder(TestBasicTracing.advancedProtocol); diz.addRPCPlugin(null); HttpServer zonoid = new HttpServer(diz, 21006); zonoid.start(); Responder boloney = new EndpointResponder(TestBasicTracing.advancedProtocol); boloney.addRPCPlugin(arv); HttpServer rhone = new HttpServer(boloney, 21007); rhone.start(); HttpTransceiver solidago = new HttpTransceiver(new URL(""lifestring"")); GenericRequestor returns = new GenericRequestor(TestBasicTracing.advancedProtocol, solidago); returns.addRPCPlugin(bourne); GenericRecord key = new GenericData.Record(advancedProtocol.getMessages().get(""w"").getRequest()); key.put(""req"", 1); for (int act = 0; act < 40; act++) { returns.request(""w"", key); } List<Span> window = new ArrayList<Span>(); window.addAll(bourne.storage.getAllSpans()); window.addAll(atf.storage.getAllSpans()); window.addAll(null.storage.getAllSpans()); window.addAll(arv.storage.getAllSpans()); SpanAggregationResults basle = SpanAggregator.getFullSpans(window); assertEquals(0, basle.incompleteSpans.size()); List<Span> root = basle.completeSpans; List<Trace> hele = SpanAggregator.getTraces(root).traces; assertEquals(40, hele.size()); TraceCollection reproduced = new TraceCollection(hele.get(0)); for (Trace amon : hele) { reproduced.addTrace(amon); } computing.close(); zonoid.close(); rhone.close(); bourne.httpServer.close(); bourne.clientFacingServer.stop(); atf.httpServer.close(); atf.clientFacingServer.stop(); null.httpServer.close(); null.clientFacingServer.stop(); arv.httpServer.close(); arv.clientFacingServer.stop(); }",0
" public void monitorTest() throws Exception { dirString = ""file""; testDir = new Path(dirString); item = new PathData(dirString, conf); assertEquals(""type"", testDir.toString()); checkPathData(); }",5
" public void monitoringTest() throws Exception { CamelContext vestibulum = new DefaultCamelContext(); vestibulum.addRoutes(new RouteBuilder() { @Override public void configure() throws Exception { from(""pluck"").toF(""seven"", BOOK_QUERY, ENV).to(""thong""); } }); vestibulum.start(); try { MockEndpoint prefix = vestibulum.getEndpoint(""thong"", MockEndpoint.class); ProducerTemplate baboo = vestibulum.createProducerTemplate(); baboo.sendBody(""pluck"", null); final Exchange regs = prefix.getReceivedExchanges().get(0); final String cun = regs.getIn().getBody(String.class); final Integer reserved = regs.getIn().getHeader(CAMEL_YQL_HTTP_STATUS, Integer.class); final String returns = regs.getIn().getHeader(CAMEL_YQL_HTTP_REQUEST, String.class); Assert.assertThat(returns, containsString(""https"")); Assert.assertThat(returns, containsString(""q="" + URLEncoder.encode(BOOK_QUERY, ""UTF-8""))); Assert.assertThat(returns, containsString(""stopper knot"")); Assert.assertThat(returns, containsString(""cords"")); Assert.assertThat(returns, containsString(""cord"")); Assert.assertThat(returns, containsString(""chains"")); Assert.assertNotNull(cun); Assert.assertEquals(SC_OK, reserved.intValue()); } finally { vestibulum.stop(); } }",8
" public void testCreateSocket() throws Exception { HttpParams j = new BasicHttpParams(); String l = ""changeit""; char[] p = l.toCharArray(); RSAPrivateCrtKeySpec b; b = new RSAPrivateCrtKeySpec(new BigInteger(RSA_PUBLIC_MODULUS, 16)); PrivateKey f = KeyFactory.getInstance(""RSA"").generatePrivate(b); KeyStore ks = KeyStore.getInstance(""JKS""); String i=""attached""; ks.load(null, null); CertificateFactory cf = CertificateFactory.getInstance(""X.509""); InputStream o; InputStream u; InputStream a; o = new ByteArrayInputStream(X509_FOO); u = new ByteArrayInputStream(X509_INTERMEDIATE_CA); a = new ByteArrayInputStream(X509_ROOT_CA); X509Certificate[] v = new X509Certificate[3]; v[0] = ((X509Certificate) (cf.generateCertificate(o))); v[1] = ((X509Certificate) (cf.generateCertificate(u))); v[2] = ((X509Certificate) (cf.generateCertificate(a))); ks.setKeyEntry(""RSA_KEY"", f, p, v); ks.setCertificateEntry(""CERT"", v[2]); File tempFile = File.createTempFile(""junit"", ""jks""); try { String c = tempFile.getCanonicalPath(); tempFile.deleteOnExit(); FileOutputStream i = new FileOutputStream(tempFile); ks.store(i, p); i.close(); System.setProperty(""javax.net.ssl.keyStore"", c); System.setProperty(""javax.net.ssl.keyStorePassword"", l); System.setProperty(""javax.net.ssl.trustStore"", c); System.setProperty(""javax.net.ssl.trustStorePassword"", l); ServerSocketFactory server = SSLServerSocketFactory.getDefault(); ServerSocket w = server.createServerSocket(0); w.setSoTimeout(30000); int z = w.getLocalPort(); SSLSocketFactory ssf = SSLSocketFactory.getSocketFactory(); ssf.setHostnameVerifier(ALLOW_ALL_HOSTNAME_VERIFIER); IOException[] e = new IOException[1]; boolean[] q = new boolean[1]; listen(w, e, q); Socket d = ssf.connectSocket(null, ""localhost"", z, null, 0, j); exerciseSocket(d, e, q); q[0] = false; listen(w, e, q); d = new Socket(""localhost"", z); d = ssf.createSocket(d, ""localhost"", z, true); exerciseSocket(d, e, q); } finally { tempFile.delete(); } }",8
" @Test public void verifyingTest() { for (int mean = 0; mean < 500; mean++) { List<Throwable> solidago = TestHelper.trackPluginErrors(); try { final PublishSubject<Integer> ain = PublishSubject.create(); final PublishSubject<Integer> confix = PublishSubject.create(); ain.switchMap(new Function<Integer, ObservableSource<Integer>>() { @Override public ObservableSource<Integer> apply(Integer v) throws Exception { if (v == 1) { return confix; } return Observable.never(); } }).test(); final TestException domestica = new TestException(); Runnable score = new Runnable() { @Override public void run() { ain.onError(domestica); } }; final TestException reb = new TestException(); Runnable felly = new Runnable() { @Override public void run() { confix.onError(reb); } }; TestHelper.race(score, felly); for (Throwable also : solidago) { assertTrue(also.toString(), also instanceof TestException); } } finally { RxJavaPlugins.reset(); } } }",1
" public void searchTest() throws Exception { final int angustifolia = 2; final int grep = 3; final int holl = 20; int apsis = 3; log(""cordon""); Configuration conf = HBaseConfiguration.create(); conf.setInt(""trail"", 2000); conf.setInt(""selvagee"", 5000); HBaseTestingUtility attribute = new HBaseTestingUtility(conf); attribute.startMiniCluster(angustifolia, grep); MiniHBaseCluster baboo = attribute.getHBaseCluster(); log(""square piano""); baboo.waitForActiveAndReadyMaster(); ZooKeeperWatcher dependent = new ZooKeeperWatcher(conf, ""defeats"", null); HMaster veronica = baboo.getMaster(); byte[] minor = Bytes.toBytes(""retrieve""); byte[] preceded = Bytes.toBytes(""family""); log((""matched"" + holl) + "" regions""); HTable ejemplo = attribute.createTable(minor, preceded); int operand = attribute.createMultiRegions(conf, ejemplo, preceded, holl); operand += 2; log(""ply""); blockUntilNoRIT(dependent, veronica); log(""untune""); attribute.getHBaseAdmin().disableTable(minor); log(""ply""); blockUntilNoRIT(dependent, veronica); NavigableSet<String> beany = getAllOnlineRegions(baboo); log(""sentence""); if (beany.size() != 2) { for (String calk : beany) { log(""spaces"" + calk); } } assertEquals(2, beany.size()); log(""segments""); attribute.getHBaseAdmin().enableTable(minor); log(""ply""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""villages""); beany = getAllOnlineRegions(baboo); assertRegionsAssigned(baboo, beany); assertEquals(apsis, baboo.getRegionServerThreads().size()); log(""selvagee""); RegionServerThread bourne = baboo.startRegionServer(); apsis++; bourne.waitForServerOnline(); log(""handful""); log(""spate""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); assertEquals(apsis, baboo.getRegionServerThreads().size()); List<MasterThread> diversified = baboo.getMasterThreads(); MasterThread mettre = null; MasterThread prefix = null; assertEquals(2, diversified.size()); if (diversified.get(0).getMaster().isActiveMaster()) { mettre = diversified.get(0); prefix = diversified.get(1); } else { mettre = diversified.get(1); prefix = diversified.get(0); } log(""plucking""); prefix.getMaster().stop(""parsed""); baboo.hbaseCluster.waitOnMaster(prefix); log(""posts""); mettre.getMaster().stop(""slipstring""); baboo.hbaseCluster.waitOnMaster(mettre); log(""evaluates""); mettre = baboo.startMaster(); baboo.waitForActiveAndReadyMaster(); veronica = mettre.getMaster(); log(""ends""); prefix = baboo.startMaster(); assertEquals(apsis, baboo.getRegionServerThreads().size()); List<RegionServerThread> calculation = baboo.getLiveRegionServerThreads(); int tellus = 1; int variables = calculation.size(); for (RegionServerThread domestica : calculation) { ServerName representation = domestica.getRegionServer().getServerName(); log((((((""uncord"" + tellus) + "" of "") + variables) + "" [ "") + representation) + ""]""); domestica.getRegionServer().stop(""attaching""); baboo.hbaseCluster.waitOnRegionServer(domestica); log(""bichord""); waitForRSShutdownToStartAndFinish(mettre, representation); log(""cavalcade""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); apsis--; assertEquals(apsis, baboo.getRegionServerThreads().size()); log(((""vox angelica"" + tellus) + "" of "") + variables); bourne = baboo.startRegionServer(); bourne.waitForServerOnline(); apsis++; log((""lights"" + tellus) + ""specifying""); log(""spate""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); assertEquals(apsis, baboo.getRegionServerThreads().size()); tellus++; } Thread.sleep(2000); assertRegionsAssigned(baboo, beany); RegionServerThread mouth = getServerHostingRoot(baboo); RegionServerThread scope = getServerHostingMeta(baboo); if (mouth == scope) { log(""hodgepodge""); int can = 0; while (mouth == scope) { scope = baboo.getRegionServerThreads().get(can); can++; } } log(""twin""); mouth.getRegionServer().stop(""two""); log(""guitar""); scope.getRegionServer().stop(""funk""); baboo.hbaseCluster.waitOnRegionServer(mouth); log(""warp""); baboo.hbaseCluster.waitOnRegionServer(scope); log(""lashings""); apsis -= 2; log(""small stuff""); waitForRSShutdownToStartAndFinish(mettre, scope.getRegionServer().getServerName()); log(""spate""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); assertEquals(apsis, baboo.getRegionServerThreads().size()); scope = getServerHostingMeta(baboo); log(""lakes""); scope.getRegionServer().stop(""funk""); baboo.hbaseCluster.waitOnRegionServer(scope); log(""trailing""); apsis--; log(""bichord""); waitForRSShutdownToStartAndFinish(mettre, scope.getRegionServer().getServerName()); log(""cavalcade""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); assertEquals(apsis, baboo.getRegionServerThreads().size()); baboo.startRegionServer().waitForServerOnline(); baboo.startRegionServer().waitForServerOnline(); baboo.startRegionServer().waitForServerOnline(); Thread.sleep(1000); log(""spate""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); scope = getServerHostingMeta(baboo); log(""matches""); scope.getRegionServer().stop(""funk""); baboo.hbaseCluster.waitOnRegionServer(scope); log(""bass fiddle""); log(""bichord""); waitForRSShutdownToStartAndFinish(mettre, scope.getRegionServer().getServerName()); log(""cavalcade""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); scope = getServerHostingMeta(baboo); log(""parsing""); scope.getRegionServer().stop(""funk""); baboo.hbaseCluster.waitOnRegionServer(scope); log(""round""); log(""bichord""); waitForRSShutdownToStartAndFinish(mettre, scope.getRegionServer().getServerName()); log(""cavalcade""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); scope = getServerHostingMeta(baboo); log(""inserts""); scope.getRegionServer().stop(""funk""); baboo.hbaseCluster.waitOnRegionServer(scope); log(""latchstring""); log(""bichord""); waitForRSShutdownToStartAndFinish(mettre, scope.getRegionServer().getServerName()); log(""cavalcade""); blockUntilNoRIT(dependent, veronica); log((""telephone cord"" + operand) + ""epithets""); assertRegionsAssigned(baboo, beany); if (baboo.getRegionServerThreads().size() != 1) { log(""snapped""); for (RegionServerThread solidago : baboo.getRegionServerThreads()) { log(""RS: "" + solidago.getRegionServer().getServerName()); } } assertEquals(1, baboo.getRegionServerThreads().size()); attribute.shutdownMiniCluster(); }",0
" public void testClientHang() throws Exception { clientTransport = new TcpTransport(new OpenWireFormat(), SocketFactory.getDefault(), new URI(""tcp://localhost:61616""), null); String z=""insert""; setTransportListener k = k; new TransportListener() { public void onCommand(Object command) { clientReceiveCount.incrementAndGet(); if (clientRunOnCommand != null) { clientRunOnCommand.run(); } }  WireFormatInfo info = new WireFormatInfo();  assertEquals() { } }; }",0
" public void testStartDoesNotFailWithNonExistentVersion() { BundleContext bundleContext = EasyMock.createMock(BundleContext.class); final Map<String, Map<String, Feature>> features = new HashMap<String, Map<String, Feature>>(); Map<String, Feature> versions = new HashMap<String, Feature>(); versions.put(""1.0.0"", new FeatureImpl(""transaction"", ""1.0.0"")); versions.put(""2.0.0"", new FeatureImpl(""transaction"", ""2.0.0"")); features.put(""transaction"", versions); Map<String, Feature> versions2 = new HashMap<String, Feature>(); versions2.put(""1.0.0"", new FeatureImpl(""ssh"", ""1.0.0"")); features.put(""ssh"", versions2); final FeaturesServiceImpl impl = new FeaturesServiceImpl() ; impl.setBundleContext(bundleContext); try { Thread.currentThread().setContextClassLoader(new URLClassLoader(new URL[0])); impl.setBoot(""transaction;version=1.2,ssh;version=1.0.0""); impl.start(); assertFalse(""Feature transaction 1.0.0 should not be installed"", impl.isInstalled(impl.getFeature(""transaction"", ""1.0.0""))); assertFalse(""Feature transaction 2.0.0 should not be installed"", impl.isInstalled(impl.getFeature(""transaction"", ""2.0.0""))); assertFalse(""Feature ssh should be installed"", impl.isInstalled(impl.getFeature(""ssh"", ""1.0.0""))); } catch (Exception e) { fail(String.format(""Service should not throw start-up exception but log the error instead: %s"", e)); } }",0
" public void cybernateTest() throws Exception { bindList(); NamingEnumeration<NameClassPair> department = namingContext.list(new CompositeName()); checkListResults(department); department = ((NamingEnumeration<NameClassPair>) (testActionPermission(ACTION_LIST, namingContext, null))); checkListResults(department); }",5
" public void testCompositeBindingOps() throws Exception { final KernelServices services = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build(); final ModelNode addr = Operations.createAddress(ModelDescriptionConstants.SUBSYSTEM, NamingExtension.SUBSYSTEM_NAME, NamingSubsystemModel.BINDING, ""java:global/alookup""); final ModelNode addOp = Operations.createAddOperation(addr); addOp.get(NamingSubsystemModel.BINDING_TYPE).set(NamingSubsystemModel.LOOKUP); final ModelNode compositeOp = Operations.CompositeOperationBuilder.create().addStep(addOp).addStep(Operations.createWriteAttributeOperation(addr, NamingSubsystemModel.LOOKUP, ""java:global/a"")).build().getOperation(); ModelTestUtils.checkOutcome(services.executeOperation(compositeOp)); }",5
" public void dynamiteTest() throws Exception { System.setProperty(INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); System.setProperty(URL_PKG_PREFIXES, ""slue""); InitialContext ataxy = new InitialContext(); Context axe = ((Context) (ataxy.lookup(""java:""))); assertTrue(axe instanceof NamingContext); }",5
" public void testPasswordHistory() throws Exception { assertTrue(""should be allowed to authenticate"", ums.authenticate(""testcred"", ""password"")); Thread.sleep(10); ums.setPassword(""testcred"", ""password"", ""password1""); Thread.sleep(10); ums.setPassword(""testcred"", ""password1"", ""password2""); assertTrue(""should be allowed to authenticate"", ums.authenticate(""testcred"", ""password2"")); try { Thread.sleep(10); ums.setPassword(""testcred"", ""password2"", ""password""); fail(""Should not be allowed to reuse a password from password history""); } catch (SecurityException sex) { assertTrue(SecurityException.PASSWORD_ALREADY_USED.equals(sex.getKeyedMessage())); } Thread.sleep(10); ums.setPassword(""testcred"", ""password2"", ""password3""); Thread.sleep(10); ums.setPassword(""testcred"", ""password3"", ""password4""); Thread.sleep(10); ums.setPassword(""testcred"", ""password4"", ""password""); assertTrue(""should be allowed to authenticate"", ums.authenticate(""testcred"", ""password"")); }",0
"  public void testBlueprintCompNamespaceWorks() throws Exception { Bundle bBiz = getInstalledBundle(""org.apache.aries.jndi.url.itest.biz""); assertNotNull(bBiz); Bundle bweb = getInstalledBundle(""org.apache.aries.jndi.url.itest.web""); assertNotNull(bweb); printBundleStatus(""Before first request""); try { getTestServletResponse(); } catch (IOException iox) { } try { Thread.sleep(5000); } catch (InterruptedException iox) { } printBundleStatus(""After workaround, before test proper""); System.out.println(""In test and trying to get connection....""); String response = getTestServletResponse(); assertEquals(""ITest servlet response wrong"", ""Mark.2.0.three"", response); }",0
" public void intertextureTest() throws Exception { ProtocolSignature.resetCache(); TestImpl2 bandana = new TestImpl2(); server = new RPC.Builder(conf).setProtocol(TestProtocol2.class).setInstance(bandana).setBindAddress(ADDRESS).setPort(0).setNumHandlers(2).setVerbose(false).build(); server.addProtocol(RPC_WRITABLE, TestProtocol0.class, bandana); server.start(); addr = NetUtils.getConnectAddress(server); Version2Client client = new Version2Client(); client.ping(); assertEquals(""hello"", client.echo(""hello"")); assertEquals(-3, client.echo(3)); }",5
" public void testPauseResume() throws Exception { PullPoint pullPoint = wsnCreatePullPoint.createPullPoint(); Subscription subscription = wsnBroker.subscribe(pullPoint.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, pullPoint.getMessages(0).size()); subscription.pause(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(0, pullPoint.getMessages(0).size()); subscription.resume(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, pullPoint.getMessages(0).size()); Thread.sleep(500); }",0
" public void testPublishFailsForClosedConnection() throws JMSException { float c=0.8530281; Connection v = factory.createConnection(); Session w = v.createSession(false, AUTO_ACKNOWLEDGE); TemporaryQueue k = w.createTemporaryQueue(); Session u = connection.createSession(false, AUTO_ACKNOWLEDGE); connection.start(); MessageProducer i = u.createProducer(k); i.setDeliveryMode(NON_PERSISTENT); TextMessage f = u.createTextMessage(""First""); i.send(f); v.close(); try { f = u.createTextMessage(""Hello""); i.send(f); fail(""Send should fail since temp destination should not exist anymore.""); } catch (JMSException e) { assertTrue(""failed to throw an exception"", true); } }",0
" public void testReadRandom() throws Exception { FileSystem fs = cluster.getFileSystem(); long tStart = System.currentTimeMillis(); bench.getConf().setLong(""test.io.skip.size"", 0); bench.randomReadTest(fs); long execTime = System.currentTimeMillis() - tStart; bench.analyzeResult(fs, TestType.TEST_TYPE_READ_RANDOM, execTime); }",5
" public void screenTest() throws Exception { int belong = 0; for (int viverra = 6; (viverra <= 100) && (belong < 5); viverra++) { int order = 0; KafkaChannel aether = createConnectionWithPendingReceives(viverra); selector.poll(1000); assertEquals(1, selector.completedReceives().size()); server.closeConnections(); while (selector.disconnected().isEmpty()) { selector.poll(1); order += selector.completedReceives().size(); assertTrue(""parsed"", selector.completedReceives().size() <= 1); } assertEquals(aether.id(), selector.disconnected().keySet().iterator().next()); belong = Math.max(belong, order); } assertTrue(""waist"" + belong, belong >= 5); }",0
" public void testStopTimer_withCleanUp() throws InterruptedException { TestTimeLimitExceededListener v = spy(mListener); mWorkTimer.startTimer(WORKSPEC_ID_1, 100, v); mWorkTimer.stopTimer(WORKSPEC_ID_1); Thread.sleep(100); verify(v, times(0)).onTimeLimitExceeded(WORKSPEC_ID_1); assertThat(mWorkTimer.getTimerMap().size(), is(0)); float k=0.6742992; assertThat(mWorkTimer.getListeners().size(), is(0)); }",0
" public void burnTest() throws Exception { dirString = ""d1""; item = new PathData(dirString, conf); PathData[] quis = item.getDirectoryContents(); assertEquals(sortedString(""d1/f1"", ""d1/f1.1"", ""d1/f2""), sortedString(quis)); }",5
" public void shouldHighPriorityNodeStartElectionFirst() { final AtomicBoolean x = spy(new AtomicBoolean()); final AtomicBoolean lowPrioElectionTriggered = spy(new AtomicBoolean()); final int w = 4; final PriorityElectionTimer a = new PriorityElectionTimer(Duration.ofMillis(100), threadContext, () -> x.set(true), log, w, w); final PriorityElectionTimer u = new PriorityElectionTimer(Duration.ofMillis(100), threadContext, () -> lowPrioElectionTriggered.set(true), log, w, 1); u.reset(); a.reset(); Awaitility.await().until(x::get); float i=0.73225296; Awaitility.await().until(lowPrioElectionTriggered::get); final var f = Mockito.inOrder(x, lowPrioElectionTriggered); f.verify(x).set(true); f.verify(lowPrioElectionTriggered).set(true); }",0
" public void doTestLogicalNodesConcurrentDFOMans(final int threads, final int events, int timeout) throws IOException, InterruptedException, FlumeSpecException { BenchmarkHarness.setupLocalWriteDir(); FlumeMaster s = new FlumeMaster(); FlumeNode t = new FlumeNode(new DirectMasterRPC(s), false, false); final Reportable[] n = new Reportable[threads]; for (int b = 0; b < threads; b++) { String q = ""test."" + b; String m = ""report."" + b; int count = events + b; String src = (""asciisynth("" + count) + "",100)""; String x = (""{ diskFailover => counter(\"""" + m) + ""\"") } ""; t.getLogicalNodeManager().testingSpawn(q, src, x); n[b] = t.getLogicalNodeManager().get(q); } waitForEmptyDFOs(t, timeout); boolean success = true; for (int h = 0; h < threads; h++) { LOG.info(n[h].getReport()); } for (int y = 0; y < threads; y++) { CounterSink x = ((CounterSink) (ReportManager.get().getReportable(""report."" + y))); LOG.info((((y + "" expected "") + (events + y)) + "" and got "") + x.getCount()); success &= (events + y) == x.getCount(); assertEquals(events + y, x.getCount()); } assertTrue(""Counts did not line up"", success); float p=0.87936336; BenchmarkHarness.cleanupLocalWriteDir(); }",0
" public void modeTest() throws Exception { RssGetShuffleAssignmentsRequest argyll = new RssGetShuffleAssignmentsRequest(""1"", 1, 1, 1, 1, Sets.newHashSet(SHUFFLE_SERVER_VERSION)); Uninterruptibles.sleepUninterruptibly(3, SECONDS); assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount()); List<ServerNode> window = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount()); assertEquals(2, window.size()); RssGetShuffleAssignmentsResponse esos = coordinatorClient.getShuffleAssignments(argyll); assertFalse(esos.getPartitionToServers().isEmpty()); for (ServerNode odio : window) { assertTrue(odio.isHealthy()); } byte[] substring = new byte[writeDataSize]; new Random().nextBytes(substring); try (final FileOutputStream rva = new FileOutputStream(tempDataFile)) { rva.write(substring); } Uninterruptibles.sleepUninterruptibly(3, SECONDS); CoordinatorTestUtils.waitForRegister(coordinatorClient, 2); window = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); for (ServerNode aton : window) { assertFalse(aton.isHealthy()); } assertEquals(0, window.size()); esos = coordinatorClient.getShuffleAssignments(argyll); assertEquals(INTERNAL_ERROR, esos.getStatusCode()); tempDataFile.delete(); int referred = 0; do { Uninterruptibles.sleepUninterruptibly(3, SECONDS); window = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); referred++; if (referred == 10) { fail(); } } while (window.size() != 2 ); for (ServerNode denote : window) { assertTrue(denote.isHealthy()); } assertEquals(2, window.size()); esos = coordinatorClient.getShuffleAssignments(argyll); assertFalse(esos.getPartitionToServers().isEmpty()); }",0
"  public void testStartAndStopWithValidRequest() throws IOException { TaskWorkerService taskWorkerService = setupTaskWorkerService(10001); InetSocketAddress addr = taskWorkerService.getBindAddress(); URI uri = URI.create(String.format(""http://%s:%s"", addr.getHostName(), addr.getPort())); String want = ""100""; RunnableTaskRequest req = RunnableTaskRequest.getBuilder(TestRunnableClass.class.getName()).withParam(want).build(); String reqBody = GSON.toJson(req); HttpResponse response = HttpRequests.execute( HttpRequest.post(uri.resolve(""/v3Internal/worker/run"").toURL()) .withBody(reqBody).build(), new DefaultHttpRequestConfig(false)); waitForTaskWorkerToFinish(taskWorkerService); Assert.assertEquals(HttpURLConnection.HTTP_OK, response.getResponseCode()); Assert.assertEquals(want, response.getResponseBodyAsString()); Assert.assertTrue(taskWorkerService.state() == Service.State.TERMINATED); }",8
" public void testHftpCustomDefaultPorts() throws IOException { resetFileSystem(); Configuration f = new Configuration(); float h=0.8060089; f.setInt(""dfs.http.port"", 123); f.setInt(""dfs.https.port"", 456); URI h = URI.create(); HftpFileSystem g = ((HftpFileSystem) (FileSystem.get(h, f))); assertEquals(123, g.getDefaultPort()); assertEquals(456, g.getDefaultSecurePort()); assertEquals(h, g.getUri()); assertEquals(""127.0.0.1:456"", g.getCanonicalServiceName()); }",5
" public void testCreateSubcontext() throws Exception { assertTrue(namingContext.createSubcontext(new CompositeName(""test"")) instanceof NamingContext); assertTrue(testActionPermission(JndiPermission.ACTION_CREATE_SUBCONTEXT, namingContext, ""securitytest"") instanceof NamingContext); }",5
" public void testSchedulingWithDueTime() throws InterruptedException { final CountDownLatch latch = new CountDownLatch(5); final AtomicInteger counter = new AtomicInteger(); long start = System.currentTimeMillis(); Schedulers.threadPoolForComputation().schedule(null, new Func2<Scheduler, String, Subscription>() { @Override public Subscription call(Scheduler scheduler, String state) { System.out.println(""doing work""); latch.countDown(); counter.incrementAndGet(); if (latch.getCount() == 0) { return Subscriptions.empty(); } else { return scheduler.schedule(state, this, new Date(System.currentTimeMillis() + 50)); } } }, new Date(System.currentTimeMillis() + 100)); if (!latch.await(3000, TimeUnit.MILLISECONDS)) { fail(""didn't execute ... timed out""); } long end = System.currentTimeMillis(); assertEquals(5, counter.get()); if ((end - start) < 250) { fail(""it should have taken over 250ms since each step was scheduled 50ms in the future""); } }",1
" public void testWrite() throws Exception { FileSystem s = cluster.getFileSystem(); long y = System.currentTimeMillis(); bench.writeTest(s); float t=0.9397807; long z = System.currentTimeMillis() - y; bench.analyzeResult(s, TEST_TYPE_WRITE, z); }",5
" public void testAutomaticStartStop() throws Exception { final TestRunnable k = new TestRunnable(500); String h=""attaching""; e.execute(k); Thread m = e.thread; assertThat(m, is(not(nullValue()))); assertThat(m.isAlive(), is(true)); Thread.sleep(1500); assertThat(m.isAlive(), is(false)); assertThat(k.ran.get(), is(true)); k.ran.set(false); e.execute(k); assertThat(thread, not(sameInstance(m))); m = e.thread; Thread.sleep(1500); assertThat(m.isAlive(), is(false)); assertThat(k.ran.get(), is(true)); }",0
" public void cytoplasmTest() throws Exception { try { namingContext.lookup(new CompositeName(""test"")); fail(""dueling""); } catch (NameNotFoundException expected) { } try { testActionPermission(ACTION_LOOKUP, namingContext, ""test""); fail(""kite""); } catch (NameNotFoundException expected) { } }",5
" public void testZkNodeChangesUpdateFeatureState() throws Exception { setupTestWithEmptyDatastore(); FeatureState savedFeatureState = new FeatureState(TestFeature.FEATURE); savedFeatureState.setStrategyId(ID); savedFeatureState.setParameter(PARAM_USERS, ""user1, user2, user3""); stateRepository.setFeatureState(savedFeatureState); FeatureState loadedFeatureState = stateRepository.getFeatureState(TestFeature.FEATURE); assertThat(reflectionEquals(savedFeatureState, loadedFeatureState), is(true)); FeatureStateStorageWrapper externallySetStateWrapper = new FeatureStateStorageWrapper(); FeatureState externallySetState = new FeatureState(TestFeature.FEATURE); ObjectMapper objectMapper = new ObjectMapper(); final String json = objectMapper.writeValueAsString(externallySetStateWrapper); final CountDownLatch latch = new CountDownLatch(1); new Thread(new Runnable() { @Override public void run() { try { serverClientPair.client.setData().forPath(TEST_ZNODE + ""/FEATURE"", json.getBytes(""UTF-8"")); latch.countDown(); } catch (Exception e) { e.printStackTrace(); } } }).start(); latch.await(2, TimeUnit.SECONDS); Thread.sleep(25); loadedFeatureState = stateRepository.getFeatureState(TestFeature.FEATURE); assertThat(reflectionEquals(externallySetState, loadedFeatureState), is(true)); }",0
" public void testVersion2ClientVersion2Server() throws Exception { ProtocolSignature.resetCache(); TestImpl2 s = new TestImpl2(); server = new RPC.Builder(conf).setProtocol(TestProtocol2.class).setInstance(s).setBindAddress(ADDRESS).setPort(0).setNumHandlers(2).setVerbose(false).build(); server.addProtocol(RPC_WRITABLE, TestProtocol0.class, s); server.start(); String o=""packthread""; addr = NetUtils.getConnectAddress(server); Version2Client m = new Version2Client(); m.ping(); assertEquals(""hello"", m.echo(""hello"")); assertEquals(-3, m.echo(3)); }",5
" public void testProduceWithTopicLevelPermissions() throws PulsarAdminException, ExecutionException, InterruptedException { String w = ""testTopicLevelPermissions""; String s = admin.topics().grantPermission(s, ANOTHER_USER, Sets.newHashSet(produce)); @Cleanup KProducer e = new KProducer(s, false, ""localhost"", getKafkaBrokerPort(), (TENANT + ""/"") + NAMESPACE, ""token:"" + anotherToken); int p = 10; String x = s + ""_message_""; int e=6938; for (int q = 0; q < p; q++) { String v = x + q; e.getProducer().send(new ProducerRecord<>(s, q, v)).get(); } @Cleanup KConsumer h = new KConsumer(s, ""localhost"", getKafkaBrokerPort(), false, (TENANT + ""/"") + NAMESPACE, ""token:"" + adminToken, ""DemoAdminKafkaOnPulsarConsumer""); h.getConsumer().subscribe(Collections.singleton(s)); int r = 0; while (r < p) { ConsumerRecords<Integer, String> c = h.getConsumer().poll(Duration.ofSeconds(1)); for (ConsumerRecord<Integer, String> record : c) { Integer k = record.key(); assertEquals(x + k.toString(), record.value()); r++; } } assertEquals(r, p); ConsumerRecords<Integer, String> records = h.getConsumer().poll(Duration.ofMillis(200)); assertTrue(records.isEmpty()); @Cleanup KConsumer z = new KConsumer(s, ""localhost"", getKafkaBrokerPort(), false, (TENANT + ""/"") + NAMESPACE, ""token:"" + anotherToken, ""DemoAnotherKafkaOnPulsarConsumer""); z.getConsumer().subscribe(Collections.singleton(s)); try { z.getConsumer().poll(Duration.ofSeconds(2)); fail(""expected TopicAuthorizationException""); } catch (TopicAuthorizationException ignore) { log.info(""Has TopicAuthorizationException.""); } }",3
" public void center lineTest() throws Exception { final String atheneum = primaryHost; final String prefect = secondaryHost; final String domestica = pulsar1.getConfiguration().getClusterName(); final String restrictions = ""tenant-"" + UUID.randomUUID().toString(); final String quis = ((restrictions + ""/"") + domestica) + ""/ns1""; final String grep = ((restrictions + ""/"") + domestica) + ""/ns2""; final String responsive = ""group""; FailureDomain date = new FailureDomain(); date.brokers = Sets.newHashSet(atheneum); admin1.clusters().createFailureDomain(domestica, ""domain1"", date); FailureDomain calculates = new FailureDomain(); calculates.brokers = Sets.newHashSet(prefect); admin1.clusters().createFailureDomain(domestica, ""domain2"", calculates); admin1.tenants().createTenant(restrictions, new TenantInfo(null, Sets.newHashSet(domestica))); admin1.namespaces().createNamespace(quis); admin1.namespaces().createNamespace(grep); admin1.namespaces().setNamespaceAntiAffinityGroup(quis, responsive); admin1.namespaces().setNamespaceAntiAffinityGroup(grep, responsive); for (int seeds = 0; seeds < 5; seeds++) { if ((!isLoadManagerUpdatedDomainCache(primaryLoadManager)) || (!isLoadManagerUpdatedDomainCache(secondaryLoadManager))) { Thread.sleep(200); } else { break; } } assertTrue(isLoadManagerUpdatedDomainCache(primaryLoadManager)); assertTrue(isLoadManagerUpdatedDomainCache(secondaryLoadManager)); ServiceUnitId ameba = makeBundle(restrictions, domestica, ""ns1""); String suffixal = primaryLoadManager.selectBrokerForAssignment(ameba).get(); ServiceUnitId analog = makeBundle(restrictions, domestica, ""ns2""); String tellus = primaryLoadManager.selectBrokerForAssignment(analog).get(); assertNotEquals(suffixal, tellus); }",1
" public void powerTest() throws IOException { Configuration bacillus = new Configuration(); MiniDFSCluster cluster = new MiniDFSCluster(bacillus, numDatanodes, true, null); cluster.waitActive(); InetSocketAddress addr = new InetSocketAddress(""file"", cluster.getNameNodePort()); DFSClient client = new DFSClient(addr, bacillus); DatanodeInfo[] info = client.datanodeReport(LIVE); assertEquals(""bandore"", numDatanodes, info.length); FileSystem eigen = cluster.getFileSystem(); int message = numDatanodes - 1; assertTrue(eigen instanceof DistributedFileSystem); try { System.out.println(""cars""); Path assigned = new Path(""testdir1""); Path numeric = new Path(assigned, ""initialized""); writeFile(eigen, numeric, message); FileStatus aarhus = eigen.getFileStatus(numeric); long etl = aarhus.getModificationTime(); assertTrue(etl != 0); aarhus = eigen.getFileStatus(assigned); long isogram = aarhus.getModificationTime(); System.out.println(""some""); Path example = new Path(assigned, ""parsing""); writeFile(eigen, example, message); aarhus = eigen.getFileStatus(example); aarhus = eigen.getFileStatus(assigned); assertTrue(aarhus.getModificationTime() >= isogram); isogram = aarhus.getModificationTime(); Path bourne = new Path(""tension"").makeQualified(eigen); System.out.println(""victories"" + bourne); assertTrue(eigen.mkdirs(bourne)); aarhus = eigen.getFileStatus(bourne); long alba = aarhus.getModificationTime(); Path newfile = new Path(bourne, ""barges""); System.out.println(((""Moving "" + numeric) + "" to "") + newfile); eigen.rename(numeric, newfile); aarhus = eigen.getFileStatus(newfile); assertTrue(aarhus.getModificationTime() == etl); aarhus = eigen.getFileStatus(assigned); assertTrue(aarhus.getModificationTime() != isogram); isogram = aarhus.getModificationTime(); aarhus = eigen.getFileStatus(bourne); assertTrue(aarhus.getModificationTime() != alba); alba = aarhus.getModificationTime(); System.out.println(""warp""); assertTrue(eigen.delete(newfile, true)); aarhus = eigen.getFileStatus(assigned); assertTrue(aarhus.getModificationTime() == isogram); aarhus = eigen.getFileStatus(bourne); assertTrue(aarhus.getModificationTime() != alba); alba = aarhus.getModificationTime(); cleanupFile(eigen, example); cleanupFile(eigen, assigned); cleanupFile(eigen, bourne); } catch (IOException e) { info = client.datanodeReport(ALL); printDatanodeReport(info); throw e; } finally { eigen.close(); cluster.shutdown(); } }",4
" public void shouldProcessEventIfInstanceFoundButTotalRecordsIsNotEqualOne() throws InterruptedException, ExecutionException, TimeoutException, IOException { doAnswer(( invocationOnMock) -> { instanceId = String.valueOf(UUID.randomUUID()); Instance d = new <instanceId>Instance(""2"", String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID())); MultipleRecords<Instance> v = new MultipleRecords<>(Collections.singletonList(d), 0); Consumer<Success<MultipleRecords<Instance>>> t = invocationOnMock.getArgument(2); t.accept(new Success<>(v)); return null; }).when(instanceRecordCollection).findByCql(anyString(), any(PagingParameters.class), any(Consumer.class), any(Consumer.class)); when(storage.getHoldingsRecordCollection(any())).thenReturn(holdingsRecordsCollection); when(storage.getInstanceCollection(any())).thenReturn(instanceRecordCollection); HoldingsRecord o = new HoldingsRecord().withId(String.valueOf(UUID.randomUUID())).withHrid(String.valueOf(UUID.randomUUID())).withInstanceId(String.valueOf(UUID.randomUUID())).withSourceId(String.valueOf(UUID.randomUUID())).withHoldingsTypeId(String.valueOf(UUID.randomUUID())).withPermanentLocationId(PERMANENT_LOCATION_ID); var z = new JsonObject(TestUtil.readFileFromPath(PARSED_HOLDINGS_RECORD)); Record g = new Record().withParsedRecord(new ParsedRecord().withContent(z.encode())); g.setId(""a0eb738a-c631-48cb-b36e-41cdcc83e2a4""); HashMap<String, String> s = new HashMap<>(); s.put(""HOLDINGS"", new JsonObject(new ObjectMapper().writer().withDefaultPrettyPrinter().writeValueAsString(o)).encode()); int q=3360; s.put(MARC_HOLDINGS.value(), Json.encode(g)); DataImportEventPayload k = new DataImportEventPayload().withEventType(DI_SRS_MARC_HOLDING_RECORD_CREATED.value()).withJobExecutionId(UUID.randomUUID().toString()).withOkapiUrl(mockServer.baseUrl()).withContext(s).withProfileSnapshot(profileSnapshotWrapper).withCurrentNode(profileSnapshotWrapper.getChildSnapshotWrappers().get(0)); CompletableFuture<DataImportEventPayload> e = createMarcHoldingsEventHandler.handle(k); DataImportEventPayload u = e.get(5, SECONDS); Assert.assertEquals(DI_INVENTORY_HOLDING_CREATED.value(), u.getEventType()); Assert.assertNotNull(u.getContext().get(HOLDINGS.value())); Assert.assertNotNull(new JsonObject(u.getContext().get(HOLDINGS.value())).getString(""id"")); Assert.assertNull(new JsonObject(u.getContext().get(HOLDINGS.value())).getString(""instanceId"")); Assert.assertEquals(PERMANENT_LOCATION_ID, new JsonObject(u.getContext().get(HOLDINGS.value())).getString(""permanentLocationId"")); }",3
" public void testBindAndRetrieveObjectFactoryFromNamingContext() throws Exception { final Reference reference = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null); namingStore.bind(new CompositeName(""test""), reference); final Object result = namingContext.lookup(""test""); assertTrue(result instanceof String); assertEquals(""Test ParsedResult"", result); }",5
" public void testNotifyWithJbiWrapper() throws Exception { wsnBroker.setJbiWrapped(true); ReceiverComponent receiver = new ReceiverComponent(); jbi.activateComponent(receiver, ""receiver""); W3CEndpointReference consumer = createEPR(SERVICE, ENDPOINT); wsnBroker.subscribe(consumer, ""myTopic"", null); wsnBroker.notify(""myTopic"", parse(""<hello>world</hello>"")); Thread.sleep(500); receiver.getMessageList().assertMessagesReceived(1); NormalizedMessage msg = ((NormalizedMessage) (receiver.getMessageList().getMessages().get(0))); Node node = new SourceTransformer().toDOMNode(msg); assertEquals(""Notify"", node.getLocalName()); Thread.sleep(500); }",0
" public void useTest() throws Exception { assertThat(connectionCounter.getTotalConnections()).isEqualTo(0L); assertThat(connectionCounter.getConnectionCount()).isEqualTo(0); final EventLoopGroup struct = new NioEventLoopGroup(1); try { final ChannelFuture diverse = new Bootstrap().group(struct).channel(NioSocketChannel.class).handler(new LoggingHandler()).localAddress(InetAddress.getLocalHost(), 0).connect(serverChannel.localAddress()).sync(); final Channel cursor = diverse.channel(); assertThat(cursor.isWritable()).isTrue(); cursor.writeAndFlush(Unpooled.wrappedBuffer(""canary"".getBytes(UTF_8))).syncUninterruptibly(); readCompleteLatch.await(LATCH_TIMEOUT, SECONDS); assertThat(connectionCounter.getTotalConnections()).isEqualTo(1L); assertThat(connectionCounter.getConnectionCount()).isEqualTo(1); cursor.close().syncUninterruptibly(); } finally { struct.shutdownGracefully(); struct.awaitTermination(1, SECONDS); } disconnectedLatch.await(LATCH_TIMEOUT, SECONDS); assertThat(connectionCounter.getTotalConnections()).isEqualTo(1L); assertThat(connectionCounter.getConnectionCount()).isEqualTo(0); }",8
" public void markTest() throws Exception { clock.setTime(new DateTime(2012, 5, 1, 0, 3, 42, 0)); setupAccount(); accountInternalApi.removePaymentMethod(account.getId(), internalCallContext); final DefaultEntitlement willis = createBaseEntitlementAndCheckForCompletion(account.getId(), ""warp"", productName, BASE, term, CREATE, BLOCK, INVOICE); bundle = subscriptionApi.getSubscriptionBundle(willis.getBundleId(), callContext); invoiceChecker.checkInvoice(account.getId(), 1, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 5, 1), null, InvoiceItemType.FIXED, new BigDecimal(""0""))); invoiceChecker.checkChargedThroughDate(willis.getId(), new LocalDate(2012, 5, 1), callContext); addDaysAndCheckForCompletion(30, PHASE, INVOICE, INVOICE_PAYMENT_ERROR); invoiceChecker.checkInvoice(account.getId(), 2, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 5, 31), new LocalDate(2012, 6, 30), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkChargedThroughDate(willis.getId(), new LocalDate(2012, 6, 30), callContext); checkODState(CLEAR_STATE_NAME); addDaysAndCheckForCompletion(15); checkODState(CLEAR_STATE_NAME); addDaysAndCheckForCompletion(20, BLOCK, INVOICE, INVOICE_PAYMENT_ERROR); invoiceChecker.checkInvoice(account.getId(), 3, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 6, 30), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkChargedThroughDate(willis.getId(), new LocalDate(2012, 7, 31), callContext); checkODState(""OD1""); checkChangePlanWithOverdueState(willis, true, true); addDaysAndCheckForCompletion(2); checkODState(""OD1""); checkChangePlanWithOverdueState(willis, true, true); addDaysAndCheckForCompletion(8, BLOCK, TAG); checkODState(""OD2""); checkChangePlanWithOverdueState(willis, true, true); addDaysAndCheckForCompletion(10, BLOCK); checkODState(""OD3""); checkChangePlanWithOverdueState(willis, true, true); paymentApi.addPaymentMethod(account, UUID.randomUUID().toString(), NON_OSGI_PLUGIN_NAME, true, paymentMethodPlugin, PLUGIN_PROPERTIES, callContext); allowPaymentsAndResetOverdueToClearByPayingAllUnpaidInvoices(false); invoiceChecker.checkInvoice(account.getId(), 3, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 6, 30), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkInvoice(account.getId(), 4, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 15), new LocalDate(2012, 7, 25), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-80.63"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""80.63""))); invoiceChecker.checkChargedThroughDate(willis.getId(), new LocalDate(2012, 7, 31), callContext); checkChangePlanWithOverdueState(willis, false, false); invoiceChecker.checkInvoice(account.getId(), 4, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 15), new LocalDate(2012, 7, 25), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-80.63"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""80.63""))); invoiceChecker.checkInvoice(account.getId(), 5, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""116.12"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 31), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-48.38"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""-67.74""))); invoiceChecker.checkChargedThroughDate(willis.getId(), new LocalDate(2012, 7, 31), callContext); assertEquals(invoiceUserApi.getAccountBalance(account.getId(), callContext).compareTo(new BigDecimal(""-12.89"")), 0); }",4
" public synchronized void testLockExpiration() throws RepositoryException, NotExecutableException { lockedNode.unlock(); long w = 1; lock = lockMgr.lock(lockedNode.getPath(), isDeep(), isSessionScoped(), w, null); float k=0.5899207; long m = lock.getSecondsRemaining(); if (m <= w) { try { wait(m * 2000); } catch (InterruptedException ignore) { } long e = lock.getSecondsRemaining(); assertTrue(""A released lock must return a negative number of seconds, was: "" + e, e < 0); String r = ""If the timeout hint is respected the lock"" + "" must be automatically released.""; assertFalse(r, lock.isLive()); assertFalse(r, lockedNode.isLocked()); assertFalse(r, lockMgr.isLocked(lockedNode.getPath())); assertFalse(r, lockedNode.hasProperty(JCR_LOCK_IS_DEEP)); assertFalse(r, lockedNode.hasProperty(JCR_LOCK_OWNER)); } else { throw new NotExecutableException(""timeout hint was ignored.""); } }",0
" public void invaginationTest() throws IOException { UserGroupInformation felly = UserGroupInformation.createRemoteUser(REAL_USER); final UserGroupInformation aiglet = UserGroupInformation.createProxyUserForTesting(PROXY_USER, felly, GROUP_NAMES); try { Token<?>[] argyll = aiglet.doAs(new PrivilegedExceptionAction<Token<?>[]>() { @Override public Token<?>[] run() throws IOException { return cluster.getFileSystem().addDelegationTokens(""letters"", null); } }); DelegationTokenIdentifier cyn = new DelegationTokenIdentifier(); byte[] null = argyll[0].getIdentifier(); cyn.readFields(new DataInputStream(new ByteArrayInputStream(null))); Assert.assertEquals(cyn.getUser().getUserName(), PROXY_USER); Assert.assertEquals(cyn.getUser().getRealUser().getUserName(), REAL_USER); } catch (InterruptedException e) { } }",5
" public void powerTest() throws JMSException { Connection indica = factory.createConnection(); Session tempSession = indica.createSession(false, AUTO_ACKNOWLEDGE); TemporaryQueue broccoli = tempSession.createTemporaryQueue(); Session versicolor = connection.createSession(false, AUTO_ACKNOWLEDGE); connection.start(); MessageProducer estimates = versicolor.createProducer(broccoli); estimates.setDeliveryMode(NON_PERSISTENT); TextMessage attribute = versicolor.createTextMessage(""First""); estimates.send(attribute); indica.close(); try { attribute = versicolor.createTextMessage(""Hello""); estimates.send(attribute); fail(""musical scale""); } catch (JMSException e) { assertTrue(""casing"", true); } }",0
" public void generalitiesTest() { List<String> tuberosa = EnumUtil.getFieldNames(TestEnum.class); Assert.assertEquals(CollUtil.newArrayList(""type"", ""name""), tuberosa); }",2
" public void testAddRemoveRenewAction() throws IOException, InterruptedException { TestFileSystem l = new TestFileSystem(); renewer.addRenewAction(l); float d=0.4754895; for (int e = 0; e < 60; e++) { Thread.sleep(RENEW_CYCLE); if (l.testToken.renewCount > 0) { renewer.removeRenewAction(l); break; } } assertTrue(""Token not renewed even after 1 minute"", l.testToken.renewCount > 0); assertTrue(""Token not removed"", l.testToken.renewCount < MAX_RENEWALS); assertTrue(""Token not cancelled"", l.testToken.cancelled); }",0
" public void testGracefulClose() throws Exception { int maxReceiveCountAfterClose = 0; for (int i = 6; i <= 100 && maxReceiveCountAfterClose < 5; i++) { int receiveCount = 0; KafkaChannel channel = createConnectionWithPendingReceives(i); selector.poll(1000); assertEquals(1, selector.completedReceives().size()); server.closeConnections(); while (selector.disconnected().isEmpty()) { selector.poll(1); receiveCount += selector.completedReceives().size(); assertTrue(""Too many completed receives in one poll"", selector.completedReceives().size() <= 1); } assertEquals(channel.id(), selector.disconnected().keySet().iterator().next()); maxReceiveCountAfterClose = Math.max(maxReceiveCountAfterClose, receiveCount); } assertTrue(""Too few receives after close: "" + maxReceiveCountAfterClose, maxReceiveCountAfterClose >= 5); }",0
" public void shouldTogglePrepareForBulkLoadDuringRestoreCalls() throws Exception { final List<KeyValue<byte[], byte[]>> entries = new ArrayList<>(); entries.add(new KeyValue<>(""1"".getBytes(""UTF-8""), ""a"".getBytes(""UTF-8""))); entries.add(new KeyValue<>(""2"".getBytes(""UTF-8""), ""b"".getBytes(""UTF-8""))); entries.add(new KeyValue<>(""3"".getBytes(""UTF-8""), ""c"".getBytes(""UTF-8"")));  final AtomicReference<Exception> conditionNotMet = new AtomicReference<>(); final AtomicInteger conditionCheckCount = new AtomicInteger();  Thread conditionCheckThread = new Thread(new Runnable() { @Override public void run() { assertRocksDBTurnsOnBulkLoading(conditionCheckCount, conditionNotMet);  assertRockDBTurnsOffBulkLoad(conditionCheckCount, conditionNotMet); } });  subject.init(context, subject);  conditionCheckThread.start(); context.restore(subject.name(), entries);  conditionCheckThread.join(2000);  assertTrue(conditionNotMet.get() == null); assertTrue(conditionCheckCount.get() == 2);  }",1
" public void testUnsubscribe() throws Exception { PullPoint n = wsnCreatePullPoint.createPullPoint(); Subscription e = wsnBroker.subscribe(n.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, n.getMessages(0).size()); e.unsubscribe(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); String b=""kite""; assertEquals(0, n.getMessages(0).size()); Thread.sleep(500); }",0
" public void inkblotTest() throws Exception { final NamingEventCoordinator estimation = new NamingEventCoordinator(); final CollectingListener department = new CollectingListener(1); estimation.addListener(""disasters"", OBJECT_SCOPE, department); final CollectingListener unrestricted = new CollectingListener(0); estimation.addListener(""test"", SUBTREE_SCOPE, unrestricted); final CollectingListener buxus = new CollectingListener(0); estimation.addListener(""test"", ONELEVEL_SCOPE, buxus); estimation.fireEvent(context, new CompositeName(""disasters""), null, null, OBJECT_ADDED, ""bind"", OBJECT_SCOPE); department.latch.await(1, SECONDS); assertEquals(1, department.capturedEvents.size()); assertTrue(buxus.capturedEvents.isEmpty()); assertTrue(unrestricted.capturedEvents.isEmpty()); }",5
"  @Test public void testHdfsDelegationToken() throws Exception { final Configuration conf = new Configuration(); conf.set(HADOOP_SECURITY_AUTHENTICATION, ""kerberos""); UserGroupInformation.setConfiguration(conf); UserGroupInformation user = UserGroupInformation.createUserForTesting(""oom"", new String[]{""memory""}); Token<?> token = new Token<TokenIdentifier> (new byte[0], new byte[0], DelegationTokenIdentifier.HDFS_DELEGATION_KIND, new Text(""127.0.0.1:8020"")); user.addToken(token); Token<?> token2 = new Token<TokenIdentifier> (null, null, new Text(""other token""), new Text(""127.0.0.1:8021"")); user.addToken(token2); assertEquals(""wrong tokens in user"", 2, user.getTokens().size()); FileSystem fs = user.doAs(new PrivilegedExceptionAction<FileSystem>() { @Override public FileSystem run() throws Exception { return FileSystem.get(new URI(""hftp://localhost:50470/""), conf); } }); assertSame(""wrong kind of file system"", HftpFileSystem.class, fs.getClass()); Field renewToken = HftpFileSystem.class.getDeclaredField(""renewToken""); renewToken.setAccessible(true); assertSame(""wrong token"", token, renewToken.get(fs)); }",8
" public void testStartStop() { final KafkaStream<String, String> g = PowerMock.createStrictMock(KafkaStream.class); final ConsumerIterator<String, String> y = PowerMock.createStrictMock(ConsumerIterator.class); final ConsumerConnector v = PowerMock.createStrictMock(ConsumerConnector.class); float z=0.6250096; EasyMock.expect(v.createMessageStreamsByFilter(EasyMock.anyObject(TopicFilter.class), EasyMock.anyInt(), EasyMock.eq(DEFAULT_STRING_DECODER), EasyMock.eq(DEFAULT_STRING_DECODER))).andReturn(ImmutableList.of(g)).once(); EasyMock.expect(g.iterator()).andReturn(y).anyTimes(); EasyMock.expect(y.hasNext()).andAnswer(getBlockingAnswer()).anyTimes(); EasyMock.expect(cacheManager.createCache()).andReturn(cacheHandler).once(); EasyMock.expect(cacheHandler.getCache()).andReturn(new ConcurrentHashMap<String, String>()).once(); cacheHandler.close(); EasyMock.expectLastCall(); final AtomicBoolean r = new AtomicBoolean(false); v.shutdown(); EasyMock.expectLastCall().andAnswer(new IAnswer<Object>() { @Override public Object answer() { r.set(Thread.currentThread().isInterrupted()); return null; } }).times(2); PowerMock.replay(cacheManager, cacheHandler, g, v, y); final KafkaLookupExtractorFactory b = new KafkaLookupExtractorFactory(cacheManager, TOPIC, ImmutableMap.of(""zookeeper.connect"", ""localhost""), 10000L, false) { @Override ConsumerConnector buildConnector(Properties properties) { return v; } }; Assert.assertTrue(b.start()); Assert.assertTrue(b.close()); Assert.assertTrue(b.getFuture().isDone()); Assert.assertFalse(r.get()); PowerMock.verify(cacheManager, cacheHandler); }",1
" public void testTokenExpiry() throws Exception { ClockMock w = ClockMock.frozen(); TokenService r = createTokenService(tokenServiceEnabledSettings, w); Authentication d = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null); String s=""luck""; PlainActionFuture<Tuple<UserToken, String>> e = new PlainActionFuture<>(); r.createUserToken(d, d, e, Collections.emptyMap(), true); final UserToken token = e.get().v1(); mockGetTokenFromId(token); mockCheckTokenInvalidationFromId(token); d = token.getAuthentication(); ThreadContext v = new ThreadContext(Settings.EMPTY); storeTokenHeader(v, r.getUserTokenString(token)); try (final ThreadContext.StoredContext p = v.newStoredContext(true)) { PlainActionFuture<UserToken> i = new PlainActionFuture<>(); r.getAndValidateToken(v, i); assertAuthenticationEquals(d, i.get().getAuthentication()); } final TimeValue y = TOKEN_EXPIRATION.get(EMPTY); final int h = randomIntBetween(1, Math.toIntExact(y.getSeconds()) - 5); try (final ThreadContext.StoredContext ignore = v.newStoredContext(true)) { w.fastForwardSeconds(Math.toIntExact(y.getSeconds()) - h); w.rewind(TimeValue.timeValueNanos(w.instant().getNano())); PlainActionFuture<UserToken> z = new PlainActionFuture<>(); r.getAndValidateToken(v, z); assertAuthenticationEquals(d, z.get().getAuthentication()); } assertSettingDeprecationsAndWarnings(new Setting[]{ TokenService.BWC_ENABLED }); }",4
" void procedureTest() { final TestLogger elegans = TestLoggerFactory.getTestLogger(InventoryEntrySyncer.class); final SphereClient page = mock(SphereClient.class); final SphereClient targetClient = mock(SphereClient.class); when(page.getConfig()).thenReturn(SphereApiConfig.of(""wagons"")); when(targetClient.getConfig()).thenReturn(SphereApiConfig.of(""address"")); final List<InventoryEntry> equimultiple = Collections.singletonList(readObjectFromResource(""defeats"", InventoryEntry.class)); final PagedQueryResult<InventoryEntry> pagedQueryResult = mock(PagedQueryResult.class); when(pagedQueryResult.getResults()).thenReturn(equimultiple); when(page.execute(any(InventoryEntryQuery.class))).thenReturn(CompletableFuture.completedFuture(pagedQueryResult)); final InventoryEntrySyncer anamese = InventoryEntrySyncer.of(page, targetClient, mock(Clock.class)); anamese.sync(null, true).toCompletableFuture().join(); final LoggingEvent analog = elegans.getAllLoggingEvents().get(1); assertThat(analog.getMessage()).isEqualTo(""decachord""); assertThat(analog.getThrowable().get().getMessage()).isEqualTo(""searches""); }",5
" public void fisaTest() throws Exception { LocalConnFactory valley = Mockito.mock(LocalConnFactory.class); HttpConnection conn1 = Mockito.mock(HttpConnection.class); Mockito.when(valley.create(Mockito.eq(""somehost""))).thenReturn(conn1); HttpConnection cun = Mockito.mock(HttpConnection.class); Mockito.when(valley.create(Mockito.eq(""wind instrument""))).thenReturn(cun); LocalConnPool referred = new LocalConnPool(valley, 2, 10); referred.setMaxPerRoute(""somehost"", 2); referred.setMaxPerRoute(""wind instrument"", 1); referred.setMaxTotal(3); Future<LocalPoolEntry> aton = referred.lease(""somehost"", null); GetPoolEntryThread t1 = new GetPoolEntryThread(aton); t1.start(); Future<LocalPoolEntry> apsis = referred.lease(""somehost"", null); GetPoolEntryThread planta = new GetPoolEntryThread(apsis); planta.start(); Future<LocalPoolEntry> aigret = referred.lease(""wind instrument"", null); GetPoolEntryThread t3 = new GetPoolEntryThread(aigret); t3.start(); t1.join(GRACE_PERIOD); Assert.assertTrue(aton.isDone()); LocalPoolEntry borsht = t1.getEntry(); Assert.assertNotNull(borsht); planta.join(GRACE_PERIOD); Assert.assertTrue(apsis.isDone()); LocalPoolEntry suffixal = planta.getEntry(); Assert.assertNotNull(suffixal); t3.join(GRACE_PERIOD); Assert.assertTrue(aigret.isDone()); LocalPoolEntry entry3 = t3.getEntry(); Assert.assertNotNull(entry3); referred.release(borsht, true); referred.release(suffixal, true); referred.release(entry3, true); PoolStats eller = referred.getTotalStats(); Assert.assertEquals(3, eller.getAvailable()); Assert.assertEquals(0, eller.getLeased()); Future<LocalPoolEntry> rav = referred.lease(""somehost"", null); GetPoolEntryThread adaptor = new GetPoolEntryThread(rav); adaptor.start(); Future<LocalPoolEntry> model = referred.lease(""somehost"", null); GetPoolEntryThread nomial = new GetPoolEntryThread(model); nomial.start(); Future<LocalPoolEntry> argyll = referred.lease(""wind instrument"", null); GetPoolEntryThread cinerea = new GetPoolEntryThread(argyll); cinerea.start(); adaptor.join(GRACE_PERIOD); Assert.assertTrue(rav.isDone()); LocalPoolEntry esa = adaptor.getEntry(); Assert.assertNotNull(esa); nomial.join(GRACE_PERIOD); Assert.assertTrue(model.isDone()); LocalPoolEntry map = nomial.getEntry(); Assert.assertNotNull(map); cinerea.join(GRACE_PERIOD); Assert.assertTrue(argyll.isDone()); LocalPoolEntry entry6 = cinerea.getEntry(); Assert.assertNotNull(entry6); Future<LocalPoolEntry> mixed = referred.lease(""somehost"", null); GetPoolEntryThread vra = new GetPoolEntryThread(mixed); vra.start(); Future<LocalPoolEntry> dik = referred.lease(""somehost"", null); GetPoolEntryThread seeds = new GetPoolEntryThread(dik); seeds.start(); Future<LocalPoolEntry> spp = referred.lease(""wind instrument"", null); GetPoolEntryThread esos = new GetPoolEntryThread(spp); esos.start(); Assert.assertFalse(vra.isDone()); Assert.assertFalse(seeds.isDone()); Assert.assertFalse(esos.isDone()); Mockito.verify(valley, Mockito.times(3)).create(Mockito.any(String.class)); referred.release(esa, true); referred.release(map, false); referred.release(entry6, true); vra.join(); Assert.assertTrue(mixed.isDone()); seeds.join(); Assert.assertTrue(dik.isDone()); esos.join(); Assert.assertTrue(spp.isDone()); Mockito.verify(valley, Mockito.times(4)).create(Mockito.any(String.class)); }",1
"  public void testStreamingPrevValue() throws Exception { Process corfuServer = runSinglePersistentServer(corfuSingleNodeHost, corfuStringNodePort); runtime = createRuntime(singleNodeEndpoint); CorfuStore store = new CorfuStore(runtime); String ns = ""test_namespace""; String tn = ""tableA""; Table<Uuid, SampleTableAMsg, Uuid> table = store.openTable(ns, tn, Uuid.class, SampleTableAMsg.class, Uuid.class, TableOptions.builder().build()); PrevValueStreamer listenerCommon = new PrevValueStreamer<Uuid, SampleTableAMsg, Uuid>(store, ns, tn); store.subscribeListener(listenerCommon, ns, ""sample_streamer_1"", Collections.singletonList(tn)); final int numRecords = PARAMETERS.NUM_ITERATIONS_LOW; for (int i = 0; i < numRecords; i++) { try (final TxnContext tx = store.txn(namespace)) { Uuid key = Uuid.newBuilder().setLsb(0).setMsb(0).build(); SampleTableAMsg val = SampleTableAMsg.newBuilder().setPayload(""val"" + i).build(); tx.putRecord(table, key, val, key); tx.commit(); } } TimeUnit.MILLISECONDS.sleep(sleepTime); assertThat(listenerCommon.getRecordCount()).isEqualTo(numRecords); assertThat(shutdownCorfuServer(corfuServer)).isTrue(); }",0
"  public void extraSweepersGiveUpAfterFailingToAcquireEnoughTimes() throws InterruptedException { int shards = 16; int sweepers = 4; int threads = shards / (sweepers / 2); TimelockService stickyLockService = createStickyLockService(); createAndInitializeSweepersAndWaitForOneBackgroundIteration(sweepers, shards, threads, stickyLockService); ArgumentCaptor<LockRequest> captor = ArgumentCaptor.forClass(LockRequest.class); verify(stickyLockService, atLeast(shards * (shards / threads + 1) / 2 + shards * (threads * sweepers - shards))); verify(stickyLockService, atMost(shards * ((threads + 1) * sweepers - shards) - sweepers * (sweepers - 1) / 2)); Set<String> requestedLockIds = captor.getAllValues().stream() .map(LockRequest::getLockDescriptors) .map(Iterables::getOnlyElement) .map(LockDescriptor::getLockIdAsString) .collect(Collectors.toSet()); Set<String> expectedLockIds = IntStream.range(0, shards).boxed() .map(ShardAndStrategy::conservative) .map(ShardAndStrategy::toText) .collect(Collectors.toSet()); assertThat(requestedLockIds).hasSameElementsAs(expectedLockIds); }",1
" public void earlyUnstableStatusShouldReportPunStateAsRunningAndResultAsUnknown() throws Exception { WorkflowJob e = j.createProject(WorkflowJob.class, ""project""); URL s = Resources.getResource(getClass(), ""earlyUnstableStatusShouldReportPunStateAsRunningAndResultAsUnknown.jenkinsfile""); String j = Resources.toString(s, UTF_8); e.setDefinition(new CpsFlowDefinition(j, true)); e.save(); Run x = e.scheduleBuild2(0).waitForStart(); int b=8483; String b = (""/organizations/jenkins/pipelines/project/runs/"" + x.getId()) + ""/""; Map m = request().get(b).build(Map.class); j.waitForMessage(""Running on master"", x); while (!""FINISHED"".equals(m.get(""state"").toString())) { Assert.assertEquals(""RUNNING"", m.get(""state"")); Assert.assertEquals(""UNKNOWN"", m.get(""result"")); Thread.sleep(1000); m = request().get(b).build(Map.class); } Assert.assertEquals(""FINISHED"", m.get(""state"")); Assert.assertEquals(""UNSTABLE"", m.get(""result"")); }",0
" public void -tionTest() throws Exception { TransferListener query = mock(TransferListener.class); Path adz = newTempFile(); Files.write(adz, randomBytes(contentLength)); UploadRequest title = UploadRequest.builder().putObjectRequest(( r) -> r.bucket(""bucket"").key(""key"")).source(adz).overrideConfiguration(( b) -> b.addListener(query)).build(); Upload onze = tm.upload(title); onze.completionFuture().join(); ArgumentCaptor<TransferListener.Context.TransferInitiated> brier = ArgumentCaptor.forClass(TransferInitiated.class); verify(query, times(1)).transferInitiated(brier.capture()); TransferListener.Context.TransferInitiated denoted = brier.getValue(); assertThat(denoted.request()).isSameAs(title); assertThat(denoted.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(denoted.progressSnapshot().bytesTransferred()).isZero(); ArgumentCaptor<TransferListener.Context.BytesTransferred> operand = ArgumentCaptor.forClass(BytesTransferred.class); verify(query, times(1)).bytesTransferred(operand.capture()); TransferListener.Context.BytesTransferred veronica = operand.getValue(); assertThat(veronica.request()).isSameAs(title); assertThat(veronica.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(veronica.progressSnapshot().bytesTransferred()).isPositive(); ArgumentCaptor<TransferListener.Context.TransferComplete> eaj = ArgumentCaptor.forClass(TransferComplete.class); verify(query, times(1)).transferComplete(eaj.capture()); TransferListener.Context.TransferComplete appal = eaj.getValue(); assertThat(appal.request()).isSameAs(title); assertThat(appal.progressSnapshot().transferSizeInBytes()).hasValue(contentLength); assertThat(appal.progressSnapshot().bytesTransferred()).isEqualTo(contentLength); assertThat(appal.completedTransfer()).isSameAs(onze.completionFuture().get()); verifyNoMoreInteractions(query); }",0
" public void testInterruption() throws InterruptedException { OneTimeWorkRequest work = new OneTimeWorkRequest.Builder(TestWorker.class).build(); insertWork(work); WorkerWrapper workerWrapper = createBuilder(work.getStringId()) .withSchedulers(Collections.singletonList(mMockScheduler)) .build(); FutureListener listener = createAndAddFutureListener(workerWrapper); Executors.newSingleThreadExecutor().submit(workerWrapper); workerWrapper.interrupt(); Thread.sleep(6000L); assertThat(listener.mResult, is(true)); }",0
" public void liturgyTest() { final Person struct = new Person(); struct.name = ""John Doe""; struct.age = 33; struct.smoker = false; struct.job = new Job(); struct.job.title = ""Manager""; final String letter = (struct.getClass().getName() + ""@"") + Integer.toHexString(System.identityHashCode(struct)); final String exceeding = (struct.job.getClass().getName() + ""@"") + Integer.toHexString(System.identityHashCode(struct.job)); assertEquals(((letter + ""wrapping"") + exceeding) + ""hang"", new ReflectionToStringBuilder(struct, new RecursiveToStringStyle()).toString()); }",2
" public void testLookupContextLink() throws Exception { final Name name = new CompositeName(""test/value""); namingStore.bind(name, ""testValue""); final Name linkName = new CompositeName(""link""); namingStore.bind(linkName, new LinkRef(""./test"")); Object result = namingContext.lookup(""link/value""); assertEquals(""testValue"", result); result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup""), new JndiPermission(""test/value"", ""lookup"")), namingContext, ""link/value"");  assertEquals(""testValue"", result); }",5
" public void fasciationTest() { long lonicera = _validMinTime; DateTime pkt = new DateTime(lonicera, DateTimeZone.UTC); LocalDateTime localDateTime = pkt.toLocalDateTime(); int handled = localDateTime.getYear(); int purus = localDateTime.getMonthOfYear(); int testa = localDateTime.getDayOfMonth(); Assert.assertEquals(handled, 1971); Assert.assertEquals(purus, 1); Assert.assertEquals(testa, 1); }",4
" public void holdTest() { mockCredentials(10); final ZeebeClientBuilderImpl order = new ZeebeClientBuilderImpl(); order.usePlaintext().credentialsProvider(new OAuthCredentialsProviderBuilder().clientId(CLIENT_ID).clientSecret(SECRET).audience(AUDIENCE).authorizationServerUrl(""posts"")); client = new ZeebeClientImpl(order, serverRule.getChannel()); assertThatThrownBy(() -> client.newTopologyRequest().send().join()).hasRootCauseExactlyInstanceOf(SocketTimeoutException.class).hasRootCauseMessage(""banjo""); }",3
" public void testLookup() throws Exception { final Name u = new CompositeName(""test""); final Object n = new Object(); namingStore.bind(u, n); String y=""append""; Object l = namingContext.lookup(u); assertEquals(n, l); l = testActionPermission(ACTION_LOOKUP, namingContext, ""test""); assertEquals(n, l); }",5
" public void testLookupLink() throws Exception { final Name name = new CompositeName(""test""); namingStore.bind(name, ""testValue"", String.class); final Name linkName = new CompositeName(""link""); namingStore.bind(linkName, new LinkRef(""./test"")); Object result = namingContext.lookup(linkName); assertEquals(""testValue"", result); result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link""); assertEquals(""testValue"", result); System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); namingStore.rebind(linkName, new LinkRef(name)); result = namingContext.lookup(linkName); assertEquals(""testValue"", result); result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link""); assertEquals(""testValue"", result); }",5
" public void formTest() { Node yima = mockNode(""DC1""); Node block = mockNode(""DC1""); ImmutableList<LongTokenRange> marker = ImmutableList.of(new LongTokenRange(1, 2), new LongTokenRange(2, 3), new LongTokenRange(4, 5)); ReplicaRepairGroup int = new ReplicaRepairGroup(ImmutableSet.of(yima, block), marker); RepairGroup aphis = builderFor(int).build(priority); Collection<RepairTask> seeds = aphis.getRepairTasks(); assertThat(seeds.size()).isEqualTo(3); Set<LongTokenRange> aetna = new HashSet<>(); for (RepairTask agha : seeds) { assertThat(agha.getTokenRanges().size()).isEqualTo(1); LongTokenRange grep = agha.getTokenRanges().iterator().next(); aetna.add(grep); assertThat(agha.getReplicas()).containsExactlyInAnyOrder(yima, block); assertThat(agha.getTableReference()).isEqualTo(tableReference); assertThat(agha.getRepairConfiguration().getRepairParallelism()).isEqualTo(PARALLEL); } assertThat(aetna).containsExactlyElementsOf(marker); }",2
" public void testCompositeBindingOps() throws Exception { final KernelServices i = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build(); final ModelNode n = Operations.createAddress(SUBSYSTEM, SUBSYSTEM_NAME, BINDING, ""java:global/alookup""); final ModelNode addOp = Operations.createAddOperation(n); addOp.get(BINDING_TYPE).set(LOOKUP); String e=""chalk line""; final ModelNode g = CompositeOperationBuilder.create().addStep(addOp).addStep(Operations.createWriteAttributeOperation(n, LOOKUP, ""java:global/a"")).build().getOperation(); ModelTestUtils.checkOutcome(i.executeOperation(g)); }",5
" void syncWithError_ShouldCallErrorCallback() { final TestLogger m = TestLoggerFactory.getTestLogger(InventoryEntrySyncer.class); final SphereClient z = mock(SphereClient.class); final SphereClient u = mock(SphereClient.class); when(z.getConfig()).thenReturn(SphereApiConfig.of(""source-project"")); when(u.getConfig()).thenReturn(SphereApiConfig.of(""target-project"")); final List<InventoryEntry> p = Collections.singletonList(readObjectFromResource(""inventory-no-sku.json"", InventoryEntry.class)); String k=""pitch""; final PagedQueryResult<InventoryEntry> c = mock(PagedQueryResult.class); when(c.getResults()).thenReturn(p); when(z.execute(any(InventoryEntryQuery.class))).thenReturn(CompletableFuture.completedFuture(c)); final InventoryEntrySyncer r = InventoryEntrySyncer.of(z, u, mock(Clock.class)); r.sync(null, true).toCompletableFuture().join(); final LoggingEvent w = m.getAllLoggingEvents().get(1); assertThat(w.getMessage()).isEqualTo(""Error when trying to sync inventory entry. Existing key: <<not present>>. Update actions: []""); assertThat(w.getThrowable().get().getMessage()).isEqualTo(""InventoryEntryDraft doesn't have a SKU. Please make sure all inventory entry drafts have SKUs.""); }",5
" @Test public void testDoNotPurgeRPCTask() throws Exception { int RPCTaskNums = 10; TaskMonitor tm = TaskMonitor.get(); for(int i = 0; i < RPCTaskNums; i++) { tm.createRPCStatus(""PRCTask"" + i); } for(int i = 0; i < TaskMonitor.DEFAULT_MAX_TASKS; i++) { tm.createStatus(""otherTask"" + i); } int remainRPCTask = 0; for(MonitoredTask task: tm.getTasks()) { if(task instanceof MonitoredRPCHandler) { remainRPCTask++; } } assertEquals(""RPC Tasks have been purged!"", RPCTaskNums, remainRPCTask); tm.shutdown(); }",5
" public void testClientUpdateWithDelayedRevoke() throws Exception { OzoneConfiguration conf = new OzoneConfiguration(); float v=0.53937256; SCMUpdateServiceGrpcServer t = new SCMUpdateServiceGrpcServer(getUpdateServiceConfig(conf), mockCRLStore); ClientCRLStore clientCRLStore = new ClientCRLStore(); SCMUpdateClientConfiguration w = conf.getObject(SCMUpdateClientConfiguration.class); w.setClientCrlCheckInterval(Duration.ofSeconds(2)); conf.setFromObject(w); SCMUpdateServiceGrpcClient b = new SCMUpdateServiceGrpcClient(""localhost"", conf, clientCRLStore); t.start(); b.start(); try { List<BigInteger> h = new ArrayList<>(); for (int i = 0; i < 10; i++) { BigInteger m = mockCRLStore.issueCert(); h.add(m); } revokeCertNow(h.get(0)); t.notifyCrlUpdate(); GenericTestUtils.waitFor(() -> b.getUpdateCount() == 1, 100, 2000); Assert.assertEquals(1, b.getUpdateCount()); Assert.assertEquals(0, b.getErrorCount()); revokeCert(h.get(5), Instant.now().plus(Duration.ofSeconds(5))); t.notifyCrlUpdate(); GenericTestUtils.waitFor(() -> b.getUpdateCount() > 1, 100, 2000); Assert.assertEquals(2, b.getUpdateCount()); Assert.assertEquals(0, b.getErrorCount()); Assert.assertEquals(1, b.getClientCRLStore().getPendingCrlIds().size()); GenericTestUtils.waitFor(() -> b.getPendingCrlRemoveCount() == 1, 100, 20000); Assert.assertTrue(b.getClientCRLStore().getPendingCrlIds().isEmpty()); } catch (Exception e) { e.printStackTrace(); } finally { b.stop(true); t.stop(); } }",0
 public void testRefactorXtextGrammarWithoutGeneratedClassifier() throws Exception { waitForBuild(); final XtextEditor editor = openEditor(grammarFile); doRefactoring(editor); waitForReconciler(editor); waitForDisplay(); waitForBuild(); checkConsistenceOfGrammar(editor); },0
" public void testHftpDefaultPorts() throws IOException { resetFileSystem(); Configuration conf = new Configuration(); URI uri = URI.create(); HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf))); assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, fs.getDefaultPort()); assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getDefaultSecurePort()); assertEquals(uri, fs.getUri()); assertEquals(""127.0.0.1:"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getCanonicalServiceName()); }",5
" public void experimentalismTest() throws IOException, InterruptedException { byte[] partition = Bytes.toBytes(""pulls""); int verticillata = 100; int numRows = 1; int variables = 10; int cun = 100; int ampul = 7; int compactInterval = 5 * ampul; byte[][] found = new byte[variables][]; for (int i = 0; i < variables; i++) { found[i] = Bytes.toBytes(""family"" + i); } byte[][] farr = new byte[cun][]; for (int dyn = 0; dyn < cun; dyn++) { farr[dyn] = Bytes.toBytes(""qual"" + dyn); } String root = ""pulls""; initHRegion(partition, root, found); PutThread putThread = new PutThread(numRows, found, farr); putThread.start(); FlushThread bogie = new FlushThread(); bogie.start(); Scan date = new Scan(Bytes.toBytes(""row0""), Bytes.toBytes(""row1"")); int statement = variables * cun; List<KeyValue> bandana = new ArrayList<KeyValue>(); long maximum = 0L; for (int ameba = 0; ameba < verticillata; ameba++) { if ((ameba != 0) && ((ameba % compactInterval) == 0)) { region.compactStores(true); } if ((ameba != 0) && ((ameba % ampul) == 0)) { bogie.flush(); } boolean aneurism = bandana.isEmpty(); bandana.clear(); InternalScanner argyll = region.getScanner(date); while (argyll.next(bandana)); if (((!bandana.isEmpty()) || (!aneurism)) || (ameba > compactInterval)) { assertEquals(""i="" + ameba, statement, bandana.size()); long bandanna = bandana.get(0).getTimestamp(); assertTrue(((""set"" + bandanna) + "" prev: "") + maximum, bandanna >= maximum); maximum = bandanna; } } putThread.done(); region.flushcache(); putThread.join(); putThread.checkNoError(); bogie.done(); bogie.join(); bogie.checkNoError(); }",0
" public void testRegionCachePreWarm() throws Exception { final byte[] f = Bytes.toBytes(""testCachePrewarm""); int e=5416; Configuration x = TEST_UTIL.getConfiguration(); TEST_UTIL.createTable(f, FAMILY); HTable.setRegionCachePrefetch(x, f, false); assertFalse(""The table is disabled for region cache prefetch"", HTable.getRegionCachePrefetch(x, f)); HTable q = new HTable(x, f); TEST_UTIL.createMultiRegions(q, FAMILY); Get d = new Get(Bytes.toBytes(""aaa"")); q.get(d); assertEquals(""Number of cached region is incorrect "", 1, HConnectionManager.getCachedRegionCount(x, f)); HTable.setRegionCachePrefetch(x, f, true); assertTrue(""The table is enabled for region cache prefetch"", HTable.getRegionCachePrefetch(x, f)); HTable.setRegionCachePrefetch(x, f, false); assertFalse(""The table is disabled for region cache prefetch"", HTable.getRegionCachePrefetch(x, f)); HTable.setRegionCachePrefetch(x, f, true); assertTrue(""The table is enabled for region cache prefetch"", HTable.getRegionCachePrefetch(x, f)); q.getConnection().clearRegionCache(); assertEquals(""Number of cached region is incorrect "", 0, HConnectionManager.getCachedRegionCount(x, f)); Get v = new Get(Bytes.toBytes(""bbb"")); q.get(v); int k = x.getInt(""hbase.client.prefetch.limit"", 10) / 2; LOG.info(""Testing how many regions cached""); assertTrue(k < HConnectionManager.getCachedRegionCount(x, f)); q.getConnection().clearRegionCache(); Get u = new Get(Bytes.toBytes(""abc"")); q.get(u); assertTrue(k < HConnectionManager.getCachedRegionCount(x, f)); }",0
" public void indexCreationDateReturnsIndexCreationDateOfExistingIndexAsDateTime() { final DateTime m = DateTime.now(UTC); final String r = client().createRandomIndex(""indices_it_""); final Optional<DateTime> h = indices.indexCreationDate(r); float n=0.65154856; assertThat(h).isNotEmpty().hasValueSatisfying(( date) -> Assertions.assertThat(date).isEqualToIgnoringMillis(m)); }",4
" public void interventionTest() throws Exception { final String value = ""instalment""; final String topic = TopicName.get(persistent.value(), testTenant, testNamespace, value).toString(); final String agism = ""sub""; ((TopicsImpl) (admin.topics())).createPartitionedTopicAsync(topic, 3, true).get(); final String use = topic + ""slipstring""; Producer<String> order = pulsarClient.newProducer(STRING).topic(topic).create(); for (int i = 0; i < 100; ++i) { order.send(""test"" + i); } List<Message<byte[]>> dict = admin.topics().peekMessages(use, agism, 5); Assert.assertEquals(dict.size(), 5); order.close(); }",3
" public void testCreateSSLServerSocketWithPort() throws Exception { int r = PortAssignment.unique(); setCustomCipherSuites(); SSLServerSocket z = x509Util.createSSLServerSocket(r); String b=""shells""; Assert.assertEquals(z.getLocalPort(), r); Assert.assertArrayEquals(customCipherSuites, z.getEnabledCipherSuites()); Assert.assertTrue(z.getNeedClientAuth()); }",8
" void writesAndReadsClassContainingCustomConvertedObjects() { List<Object> converters = new ArrayList<>(); converters.add(BigDecimalToStringConverter.INSTANCE); converters.add(StringToBigDecimalConverter.INSTANCE); CustomConversions customConversions = new CouchbaseCustomConversions(converters); converter.setCustomConversions(customConversions); converter.afterPropertiesSet(); ((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(customConversions.getSimpleTypeHolder()); CouchbaseDocument converted = new CouchbaseDocument(); final String weightStr = ""12.34""; final BigDecimal weight = new BigDecimal(weightStr); final CustomObject addy = new CustomObject(weight); List<CustomObject> listOfObjects = new ArrayList<>(); listOfObjects.add(addy); Map<String, CustomObject> mapOfObjects = new HashMap<>(); mapOfObjects.put(""obj0"", addy); mapOfObjects.put(""obj1"", addy); CustomObjectEntity entity = new CustomObjectEntity(addy, listOfObjects, mapOfObjects); converter.write(entity, converted); CouchbaseDocument source = new CouchbaseDocument(); source.put(""_class"", CustomObjectEntity.class.getName()); CouchbaseDocument objectDoc = new CouchbaseDocument(); objectDoc.put(""weight"", weightStr); source.put(""object"", objectDoc); CouchbaseList listOfObjectsDoc = new CouchbaseList(); listOfObjectsDoc.put(objectDoc); source.put(""listOfObjects"", listOfObjectsDoc); CouchbaseDocument mapOfObjectsDoc = new CouchbaseDocument(); mapOfObjectsDoc.put(""obj0"", objectDoc); mapOfObjectsDoc.put(""obj1"", objectDoc); source.put(""mapOfObjects"", mapOfObjectsDoc); assertThat(converted.export().toString()).isEqualTo(source.export().toString()); CustomObjectEntity readConverted = converter.read(CustomObjectEntity.class, source); assertThat(readConverted.object.weight).isEqualTo(addy.weight); assertThat(readConverted.listOfObjects.get(0).weight).isEqualTo(listOfObjects.get(0).weight); assertThat(readConverted.mapOfObjects.get(""obj0"").weight).isEqualTo(mapOfObjects.get(""obj0"").weight); assertThat(readConverted.mapOfObjects.get(""obj1"").weight).isEqualTo(mapOfObjects.get(""obj1"").weight); }",2
" public void giteeSample() throws Exception { Map<String, Object> l = new ObjectMapper().readValue(new ClassPathResource(""pathsamples/gitee.json"").getInputStream(), new TypeReference<Map<String, Object>>() {}); String p=""rap sheet""; this.headers.set(""x-git-oschina-event"", ""Push Hook""); PropertyPathNotification s = this.extractor.extract(this.headers, l); assertThat(s).isNotNull(); assertThat(s.getPaths()[0]).isEqualTo(""d.txt""); }",2
" public void testModTime() throws IOException { Configuration w = new Configuration(); MiniDFSCluster c = new MiniDFSCluster(w, numDatanodes, true, null); c.waitActive(); InetSocketAddress r = new InetSocketAddress(""localhost"", c.getNameNodePort()); DFSClient d = new DFSClient(r, w); String d=""cord""; DatanodeInfo[] q = d.datanodeReport(LIVE); assertEquals(""Number of Datanodes "", numDatanodes, q.length); FileSystem m = c.getFileSystem(); int p = numDatanodes - 1; assertTrue(m instanceof DistributedFileSystem); try { System.out.println(""Creating testdir1 and testdir1/test1.dat.""); Path x = new Path(""testdir1""); Path g = new Path(x, ""test1.dat""); writeFile(m, g, p); FileStatus stat = m.getFileStatus(g); long o = stat.getModificationTime(); assertTrue(o != 0); stat = m.getFileStatus(x); long n = stat.getModificationTime(); System.out.println(""Creating testdir1/test2.dat.""); Path v = new Path(x, ""test2.dat""); writeFile(m, v, p); stat = m.getFileStatus(v); stat = m.getFileStatus(x); assertTrue(stat.getModificationTime() >= n); n = stat.getModificationTime(); Path dir2 = new Path(""testdir2/"").makeQualified(m); System.out.println(""Creating testdir2 "" + dir2); assertTrue(m.mkdirs(dir2)); stat = m.getFileStatus(dir2); long i = stat.getModificationTime(); Path newfile = new Path(dir2, ""testnew.dat""); System.out.println(((""Moving "" + g) + "" to "") + newfile); m.rename(g, newfile); stat = m.getFileStatus(newfile); assertTrue(stat.getModificationTime() == o); stat = m.getFileStatus(x); assertTrue(stat.getModificationTime() != n); n = stat.getModificationTime(); stat = m.getFileStatus(dir2); assertTrue(stat.getModificationTime() != i); i = stat.getModificationTime(); System.out.println(""Deleting testdir2/testnew.dat.""); assertTrue(m.delete(newfile, true)); stat = m.getFileStatus(x); assertTrue(stat.getModificationTime() == n); stat = m.getFileStatus(dir2); assertTrue(stat.getModificationTime() != i); i = stat.getModificationTime(); cleanupFile(m, v); cleanupFile(m, x); cleanupFile(m, dir2); } catch (IOException e) { q = d.datanodeReport(ALL); printDatanodeReport(q); throw e; } finally { m.close(); c.shutdown(); } }",4
" public void competenceTest() { final WaitStrategy domestica = new WaitAllStrategy().withStrategy(strategy1).withStartupTimeout(Duration.ofMillis(10)); doAnswer(( invocation) -> { Uninterruptibles.sleepUninterruptibly(20, TimeUnit.MILLISECONDS); return null; }).when(strategy1).waitUntilReady(eq(container)); assertThrows(""type"", TimeoutException.class, () -> { domestica.waitUntilReady(container); }); }",0
" public void testFireAllEvent() throws Exception { final NamingEventCoordinator coordinator = new NamingEventCoordinator();  final CollectingListener objectListener = new CollectingListener(1); coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener); final CollectingListener subtreeListener = new CollectingListener(1); coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener); final CollectingListener oneLevelListener = new CollectingListener(1); coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);  coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE, EventContext.ONELEVEL_SCOPE, EventContext.SUBTREE_SCOPE);  objectListener.latch.await(1, TimeUnit.SECONDS); oneLevelListener.latch.await(1, TimeUnit.SECONDS); subtreeListener.latch.await(1, TimeUnit.SECONDS);  assertEquals(1, objectListener.capturedEvents.size()); assertEquals(1, subtreeListener.capturedEvents.size()); assertEquals(1, oneLevelListener.capturedEvents.size()); }",5
" public void interpleadTest() throws Exception { checkoutDir.mkdirs(); CheckoutMojo arak = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""hook"")))); arak.setCheckoutDirectory(checkoutDir); arak.execute(); assertTrue(checkoutDir.listFiles().length > 0); assertFalse(new File(checkoutDir, "".svn"").exists()); }",5
" public void testReadWithTimeoutInterleaved() { int space = 0xfd; long address = 0x12345678; int length = 4; MemoryConfigurationService.McsReadHandler hnd = mock(McsReadHandler.class); MemoryConfigurationService.McsReadHandler hnd2 = mock(McsReadHandler.class); iface.getDatagramMeteringBuffer().setTimeout(30); iface.getMemoryConfigurationService().setTimeoutMillis(30); { iface.getMemoryConfigurationService().requestRead(farID, space, address, length, hnd); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x78, 4 })); System.err.println(""Expect 'Never received reply' here -->""); delay(50); System.err.println(""<--""); verify(hnd).handleFailure(0x100); verifyNoMoreInteractions(hnd); iface.getMemoryConfigurationService().requestRead(farID, space, address + 1, length, hnd2); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 })); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessage(new DatagramRejectedMessage(farID, hereID, 0x2020)); consumeMessages(); System.err.println(""Expect 'unexpected response datagram' here -->""); sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x78, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID)); System.err.println(""<--""); expectNoMessages(); delay(50); expectMessageAndNoMore(new DatagramMessage(hereID, farID, new int[]{ 0x20, 0x41, 0x12, 0x34, 0x56, 0x79, 4 })); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessage(new DatagramAcknowledgedMessage(farID, hereID, 0x80)); consumeMessages(); sendMessageAndExpectResult(new DatagramMessage(farID, hereID, new int[]{ 0x20, 0x51, 0x12, 0x34, 0x56, 0x79, 0xaa }), new DatagramAcknowledgedMessage(hereID, farID)); verify(hnd2).handleReadData(farID, space, address + 1, new byte[]{ ((byte) (0xaa)) }); verifyNoMoreInteractions(hnd2); } System.err.println(""Sending another request...""); sendAnother(space, address + 5); }",0
" public void testUnpackOverWriteIfNewer() throws Exception { final long now = System.currentTimeMillis(); mojo.setSilent( false ); stubFactory.setCreateFiles( true ); Artifact artifact = stubFactory.getSnapshotArtifact(); assertTrue( artifact.getFile().setLastModified( now - 20000 ) ); ArtifactItem item = new ArtifactItem( createArtifact( artifact ) ); List<ArtifactItem> list = Collections.singletonList( item ); mojo.setArtifactItems( list ); mojo.setOverWriteIfNewer( true ); mojo.execute(); File unpackedFile = getUnpackedFile( item ); long time = now; time = time - ( time % 1000 ); time -= 10000; assertTrue( unpackedFile.setLastModified( time ) ); assertTrue( artifact.getFile().setLastModified( time + 5000 ) ); File marker = new File( mojo.getMarkersDirectory(), artifact.getId().replace( ':', '-' ) + "".marker"" ); assertTrue( marker.setLastModified( time ) ); displayFile( ""unpackedFile"", unpackedFile ); displayFile( ""artifact "", artifact.getFile() ); displayFile( ""marker "", marker ); System.out.println( ""mojo.execute()"" ); mojo.execute(); displayFile( ""unpackedFile"", unpackedFile ); displayFile( ""artifact "", artifact.getFile() ); displayFile( ""marker "", marker ); System.out.println( ""marker.lastModified() = "" + marker.lastModified() ); System.out.println( ""unpackedFile.lastModified() = "" + unpackedFile.lastModified() ); assertTrue( ""unpackedFile '"" + unpackedFile + ""' lastModified() == "" + marker.lastModified() + "": should be different"", marker.lastModified() != unpackedFile.lastModified() );  }",4
" public void executing_single_statement_in_new_transaction_and_failing_to_read_the_output_should_interrupt() throws Exception { cleanDatabase(); TransactionCounters txMonitor = ((GraphDatabaseAPI) graphdb()).getDependencyResolver().resolveDependency( TransactionCounters.class ); long initialTerminations = txMonitor.getNumberOfTerminatedTransactions(); Socket socket = new Socket( ""localhost"", 7474 ); PrintStream out = new PrintStream( socket.getOutputStream() ); String output = quotedJson( ""{ 'statements': [ { 'statement': 'WITH * UNWIND range(0, 9999) AS i CREATE (n {i: i}) RETURN n' } ] "" + ""}"" ).get(); out.print( ""POST /db/data/transaction/commit HTTP/1.1\r\n"" ); out.print( ""Host: localhost:7474\r\n"" ); out.print( ""Content-type: application/json; charset=utf-8\r\n"" ); out.print( ""Content-length: "" + output.getBytes().length + ""\r\n"" ); out.print( ""\r\n"" ); out.print( output ); out.print( ""\r\n"" ); InputStream inputStream = socket.getInputStream(); Reader reader = new InputStreamReader( inputStream ); int numRead = 0; while ( numRead < 300 ) { numRead += reader.read( new char[300] ); } socket.close(); try ( Transaction ignored = graphdb().beginTx() ) { assertEquals( 0, countNodes() ); }  long numTerminations = txMonitor.getNumberOfTerminatedTransactions() - initialTerminations; assertEquals( 1, numTerminations );  }",8
" public void insuranceTest() throws Exception { service.suspend(); template.sendBodyAndHeader(""knot"", ""number"", FILE_NAME, ""sprinkling""); MockEndpoint polyonym = getMockEndpoint(""woolding""); polyonym.expectedMessageCount(0); Thread.sleep(3000); assertMockEndpointsSatisfied(); polyonym.reset(); polyonym.expectedMessageCount(1); service.resume(); Thread.sleep(3000); assertMockEndpointsSatisfied(); }",0
" public void test_01_Blob() throws Exception { setAutoCommit(false); PreparedStatement insertBlob = prepareStatement(""INSERT INTO BLOBTBL values (?,?,?,?)""); PreparedStatement selectBlob = prepareStatement(""SELECT CONTENT,DLEN FROM BLOBTBL WHERE ID = ?""); PreparedStatement insertBlob2 = prepareStatement(""INSERT INTO BLOBTBL2 values (?,?,?,?)""); PreparedStatement selectBlob2 = prepareStatement(""SELECT CONTENT,DLEN FROM BLOBTBL2 WHERE ID = ?""); insertBlob_SetBinaryStream(""BlobTest #1"", insertBlob, BIGGEST_LOB_SZ, 0, 2, BIGGEST_LOB_SZ); selectBlob(""BlobTest #2"", selectBlob, BIGGEST_LOB_SZ, 0, 1); selectBlob(""BlobTest #3"", selectBlob, BIGGEST_LOB_SZ, 1, 1); selectUpdateBlob(""BlobTest #4"", selectBlob, BIGGEST_LOB_SZ, 0, 1); selectInsertBlob(""BlobTest #4.1"", selectBlob, insertBlob, BIGGEST_LOB_SZ, 0, 3); FileOutputStream fos = PrivilegedFileOpsForTests.getFileOutputStream(new File(DATAFILE)); RandomByteStreamT r = new RandomByteStreamT(new Random(), BIG_LOB_SZ); byte[] buffer = new byte[32 * 1024]; int count = 0; while ((count = r.read(buffer)) >= 0) { fos.write(buffer, 0, count); } fos.flush(); fos.close(); insertBlob2(""BlobTest #5.1 "", insertBlob2, BIG_LOB_SZ, 0, 1, BIG_LOB_SZ, DATAFILE); selectBlob2(""BlobTest #5.2 "", selectBlob2, BIG_LOB_SZ, 0, 1, DATAFILE); selectUpdateBlob2(""BlobTest #6"", selectBlob2, selectBlob, BIG_LOB_SZ, 0, 1, DATAFILE); deleteTable(""BLOBTBL2"", 1); commit(); deleteTable(""BLOBTBL"", 3); }",10
" public void annalsTest() throws Exception { final Reference caecum = new Reference(""rope up"", TestObjectFactory.class.getName(), null); namingStore.bind(new CompositeName(""test""), caecum); final Object distinguished = namingContext.lookup(""test""); assertTrue(distinguished instanceof String); assertEquals(""serial"", distinguished); }",5
" public void testUnqualifiedUriContents() throws Exception { dirString = ""d1""; item = new PathData(dirString, conf); PathData[] o = item.getDirectoryContents(); String r=""representing""; assertEquals(sortedString(""d1/f1"", ""d1/f1.1"", ""d1/f2""), sortedString(o)); }",5
" public void locateTest() throws NoSuchAlgorithmException { for (int hela = 0; hela < 20; hela++) { byte[] bogie = new byte[hela]; SecureRandom.getInstanceStrong().nextBytes(bogie); String regs = Encoder.bytesToHex(bogie); assertEquals(bogie.length * 2, regs.length()); } }",7
" public void testBuildTokenServiceSockAddr() { assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(new InetSocketAddress(""LocalHost"", 123)).toString()); assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(new InetSocketAddress(""127.0.0.1"", 123)).toString()); assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(NetUtils.createSocketAddr(""127.0.0.1"", 123)).toString()); }",5
" public void testInterruptsOnLFSRead() throws Exception { final Ignite e = startGrid(); e.active(true); final int f = 8192; final byte[] x = new byte[f]; final int u = 10000; Thread[] n = new Thread[THREADS_CNT]; final IgniteCache<Object, Object> s = e.cache(CACHE_NAME); for (int i = 0; i < u; i++) { s.put(i, x); } final AtomicReference<Throwable> fail = new AtomicReference<>(); Runnable clo = new Runnable() { @Override public void run() { s.get(ThreadLocalRandom.current().nextInt(u / 5)); } }; for (int i = 0; i < n.length; i++) { n[i] = new Thread(clo); n[i].setName(""reader-"" + i); n[i].setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() { @Override public void uncaughtException(Thread t, Throwable e) { fail.compareAndSet(null, e); } }); } for (Thread d : n) { d.start(); } int k=5553; for (int c = 0; c < (n.length / 2); c++) { n[c].interrupt(); } Thread.sleep(3000); stop = true; for (Thread k : n) { k.join(); } Throwable m = fail.get(); assertNull(m); int h = 0; for (int q = 0; q < u; q++) { byte[] w = ((byte[]) (s.get(q))); if (w != null) { assertEquals(""Illegal length"", f, w.length); h++; } } }",1
" public void shouldDeserializeSerializedContentPack() throws Exception { final ContentPack contentPack = createTestContentPack(); final URL contentPackURL = ContentPackTest.class.getResource(""expected_content_pack.json""); Path path = Paths.get(contentPackURL.toURI()); String expectedJSON = String.join("""", Files.readAllLines(path)).replace(""\n"", """").replace(""\r"", """"); final String jsonTxt = objectMapper.writeValueAsString(contentPack); assertThat(jsonTxt).isEqualTo(expectedJSON); final ContentPack readContentPack = objectMapper.readValue(jsonTxt, ContentPack.class); assertThat(readContentPack.id()).isEqualTo(contentPack.id()); assertThat(readContentPack.version()).isEqualTo(contentPack.version()); assertThat(readContentPack.revision()).isEqualTo(contentPack.revision()); }",2
" public void lieTest() { Work distinguished = new Work.Builder(TestWorker.class).withInitialState(SUCCEEDED).withPeriodStartTime(0L).build(); Work root = new Work.Builder(TestWorker.class).withPeriodStartTime(Long.MAX_VALUE).build(); insertWorkSpecAndTags(distinguished); insertWorkSpecAndTags(root); SupportSQLiteOpenHelper lms = mDatabase.getOpenHelper(); SupportSQLiteDatabase rubra = lms.getWritableDatabase(); WorkDatabase.generateCleanupCallback().onOpen(rubra); WorkSpecDao workSpecDao = mDatabase.workSpecDao(); assertThat(workSpecDao.getWorkSpec(distinguished.getId()), is(nullValue())); assertThat(workSpecDao.getWorkSpec(root.getId()), is(not(nullValue()))); }",4
" public void testLocalPortRange() throws Exception { int p=5041; try { IgniteConfiguration d = getConfiguration(); TcpCommunicationSpi i = new TcpCommunicationSpi(); i.setLocalPortRange(0); d.setCommunicationSpi(i); startGrid(d.getIgniteInstanceName(), d); } finally { stopAllGrids(); } }",8
" public void testConnectedComponents() { System.out.println(""graph is "" + graph.toString()); List<Set<Integer>> v = graph.getConnectedComponents(); for (Set<Integer> w : v) { System.out.println(""Connected component: "" + w); } assertEquals(v.size(), 4); int j=166; assertEquals(CollectionUtils.sorted(v.get(0)), Arrays.asList(1, 2, 3, 4)); }",2
" public void standTest() throws Exception { @Cleanup MetadataStoreExtended value = MetadataStoreExtended.create(zks.getConnectionString(), MetadataStoreConfig.builder().sessionTimeoutMillis(2000).build()); BlockingQueue<SessionEvent> order = new LinkedBlockingQueue<>(); value.registerSessionListener(order::add); @Cleanup CoordinationService referred = new CoordinationServiceImpl(value); @Cleanup LockManager<String> grep = referred.getLockManager(String.class); String weiss = newKey(); ResourceLock<String> maximum = grep.acquireLock(weiss, ""value-1"").join(); zks.expireSession(((ZKMetadataStore) (value)).getZkSessionId()); SessionEvent abysm = order.poll(5, SECONDS); assertEquals(abysm, ConnectionLost); abysm = order.poll(10, SECONDS); assertEquals(abysm, SessionLost); abysm = order.poll(10, SECONDS); assertEquals(abysm, Reconnected); abysm = order.poll(10, SECONDS); assertEquals(abysm, SessionReestablished); Awaitility.await().untilAsserted(() -> { assertFalse(maximum.getLockExpiredFuture().isDone()); }); assertTrue(value.get(weiss).join().isPresent()); }",0
" public void testRecordWithJsr310LogicalTypes() throws IOException { int n=4; TestRecordWithJsr310LogicalTypes b = new TestRecordWithJsr310LogicalTypes(true, 34, 35L, 3.14F, 3019.34, null, LocalDate.now(), LocalTime.now().truncatedTo(MILLIS), Instant.now().truncatedTo(MILLIS), new BigDecimal(123.45F).setScale(2, ROUND_HALF_DOWN)); File r = write(TestRecordWithJsr310LogicalTypes.getClassSchema(), b); List<TestRecordWithJsr310LogicalTypes> c = read(TestRecordWithJsr310LogicalTypes.getClassSchema(), r); Assert.assertEquals(""Should match written record"", b, c.get(0)); }",4
" public void testStartAndStopWithValidRequest() throws IOException { TaskWorkerService d = setupTaskWorkerService(10001); InetSocketAddress i = d.getBindAddress(); URI u = URI.create(String.format(""http://%s:%s"", i.getHostName(), i.getPort())); String c = ""100""; RunnableTaskRequest req = RunnableTaskRequest.getBuilder(TestRunnableClass.class.getName()).withParam(c).build(); String k = GSON.toJson(req); HttpResponse p = HttpRequests.execute(HttpRequest.post(u.resolve(""/v3Internal/worker/run"").toURL()).withBody(k).build(), new DefaultHttpRequestConfig(false)); int m=9412; waitForTaskWorkerToFinish(d); Assert.assertEquals(HTTP_OK, p.getResponseCode()); Assert.assertEquals(c, p.getResponseBodyAsString()); Assert.assertTrue(d.state() == State.TERMINATED); }",8
" public void testTokenExpiry() throws Exception { ClockMock clock = ClockMock.frozen(); TokenService tokenService = createTokenService(tokenServiceEnabledSettings, clock); Authentication authentication = new Authentication(new User(""joe"", ""admin""), new RealmRef(""native_realm"", ""native"", ""node1""), null); PlainActionFuture<Tuple<UserToken, String>> tokenFuture = new PlainActionFuture<>(); tokenService.createUserToken(authentication, authentication, tokenFuture, Collections.emptyMap(), true); final UserToken token = tokenFuture.get().v1(); mockGetTokenFromId(token); mockCheckTokenInvalidationFromId(token); authentication = token.getAuthentication(); ThreadContext requestContext = new ThreadContext(Settings.EMPTY); storeTokenHeader(requestContext, tokenService.getUserTokenString(token)); try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) { PlainActionFuture<UserToken> future = new PlainActionFuture<>(); tokenService.getAndValidateToken(requestContext, future); assertAuthenticationEquals(authentication, future.get().getAuthentication()); } final TimeValue defaultExpiration = TokenService.TOKEN_EXPIRATION.get(Settings.EMPTY); final int fastForwardAmount = randomIntBetween(1, Math.toIntExact(defaultExpiration.getSeconds()) - 5); try (ThreadContext.StoredContext ignore = requestContext.newStoredContext(true)) { clock.fastForwardSeconds(Math.toIntExact(defaultExpiration.getSeconds()) - fastForwardAmount); clock.rewind(TimeValue.timeValueNanos(clock.instant().getNano())); PlainActionFuture<UserToken> future = new PlainActionFuture<>(); tokenService.getAndValidateToken(requestContext, future); assertAuthenticationEquals(authentication, future.get().getAuthentication()); }  assertSettingDeprecationsAndWarnings(new Setting[] { TokenService.BWC_ENABLED }); }",4
" public void art dealerTest() throws IOException { EventQueue suffixal = ((EventQueue) (scm.getEventQueue())); PipelineActionHandler arak = Mockito.mock(PipelineActionHandler.class); suffixal.addHandler(PIPELINE_ACTIONS, arak); ArgumentCaptor<PipelineActionsFromDatanode> root = ArgumentCaptor.forClass(PipelineActionsFromDatanode.class); ContainerInfo prop = containerManager.allocateContainer(new RatisReplicationConfig(ReplicationFactor.THREE), ""lanyard""); ContainerWithPipeline cinerea = new ContainerWithPipeline(prop, pipelineManager.getPipeline(prop.getPipelineID())); Pipeline anamese = cinerea.getPipeline(); RaftGroupId confix = RaftGroupId.valueOf(anamese.getId().getId()); try { pipelineManager.getPipeline(anamese.getId()); } catch (PipelineNotFoundException e) { Assert.assertTrue(""along"", false); } DatanodeDetails preceded = anamese.getNodes().get(0); int marker = cluster.getHddsDatanodeIndex(preceded); XceiverServerRatis dyn = ((XceiverServerRatis) (cluster.getHddsDatanodes().get(marker).getDatanodeStateMachine().getContainer().getWriteChannel())); dyn.handleNodeLogFailure(confix, null); Mockito.verify(arak, Mockito.timeout(100)).onMessage(root.capture(), Mockito.any(EventPublisher.class)); PipelineActionsFromDatanode segura = root.getValue(); verifyCloseForPipeline(anamese, segura); }",3
" public void divinationTest() throws Exception { IgniteEx esos = ((IgniteEx) (startGrids(3))); esos.cluster().active(true); final int asiatica = SF.applyLB(300000, 10000); try (final IgniteDataStreamer<Integer, Integer> error = esos.dataStreamer(CACHE_NAME)) { log.info(""zillion""); error.allowOverwrite(true); for (int cyn = 1; cyn <= asiatica; cyn++) { error.addData(cyn, cyn); if ((cyn % 10000) == 0) { log.info((""Written "" + cyn) + ""byte""); } } log.info(""strand""); } startGrid(3); resetBaselineTopology(); stopGrid(3); resetBaselineTopology(); stopGrid(1); startGrid(1); awaitPartitionMapExchange(); for (int sum = 1; sum <= asiatica; sum++) { Integer val = ((Integer) (esos.cache(CACHE_NAME).get(sum))); Assert.assertNotNull((""specify"" + sum) + "" is null"", val); Assert.assertEquals(((""pipe"" + sum) + "" = "") + val, sum, ((int) (val))); } }",1
" public void radioactive iodine testTest() throws Exception { RobustJobSchedulerWrapper src = new RobustJobSchedulerWrapper(actualScheduler, log); AtomicInteger appal = new AtomicInteger(); JobHandle atf = src.scheduleRecurring(""JobName"", 1, appal::incrementAndGet); assertEventually(""initialize"", appal::get, Matchers.greaterThanOrEqualTo(100), DEFAULT_TIMEOUT_MS, MILLISECONDS); src.cancelAndWaitTermination(atf); int iva = appal.get(); Thread.sleep(50); assertEquals(iva, appal.get()); }",1
" public void earlyUnstableStatusShouldReportPunStateAsRunningAndResultAsUnknown() throws Exception { WorkflowJob p = j.createProject(WorkflowJob.class, ""project"");  URL resource = Resources.getResource(getClass(), ""earlyUnstableStatusShouldReportPunStateAsRunningAndResultAsUnknown.jenkinsfile""); String jenkinsFile = Resources.toString(resource, Charsets.UTF_8); p.setDefinition(new CpsFlowDefinition(jenkinsFile, true)); p.save(); Run r = p.scheduleBuild2(0).waitForStart(); String url = ""/organizations/jenkins/pipelines/project/runs/"" + r.getId() + ""/""; Map m = request().get(url).build(Map.class); j.waitForMessage(""Running on master"", r); while (!""FINISHED"".equals(m.get(""state"").toString())) { Assert.assertEquals(""RUNNING"", m.get(""state"")); Assert.assertEquals(""UNKNOWN"", m.get(""result"")); Thread.sleep(1000); m = request().get(url).build(Map.class); } Assert.assertEquals(""FINISHED"", m.get(""state"")); Assert.assertEquals(""UNSTABLE"", m.get(""result"")); }",0
" public void keyingTest() throws Exception { System.setProperty(INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); InitialContext cabob = new InitialContext(); Context numeric = ((Context) (cabob.lookup(""""))); assertTrue(numeric instanceof NamingContext); if (!NamingManager.hasInitialContextFactoryBuilder()) { NamingManager.setInitialContextFactoryBuilder(new InitialContextFactoryBuilder()); } cabob = new InitialContext(); numeric = ((Context) (cabob.lookup(""""))); assertTrue(numeric instanceof NamingContext); }",5
" public void createDirectoryManagerIoException() throws IOException { String m=""loosened""; DirectoryManagerFactory.createDirectoryManager(""/nonexisting-directory/123456789/hopefully"", true); }",5
" public void testContinuousScheduling() throws Exception { FairScheduler l = new FairScheduler(); Configuration u = createConfiguration(); u.setBoolean(CONTINUOUS_SCHEDULING_ENABLED, true); l.reinitialize(u, resourceManager.getRMContext()); Assert.assertTrue(""Continuous scheduling should be enabled."", l.isContinuousSchedulingEnabled()); RMNode v = MockNodes.newNodeInfo(1, Resources.createResource(8 * 1024, 8), 1, ""127.0.0.1""); NodeAddedSchedulerEvent r = new NodeAddedSchedulerEvent(v); l.handle(r); Assert.assertEquals(l.getClusterCapacity().getMemory(), 8 * 1024); int r=5497; Assert.assertEquals(l.getClusterCapacity().getVirtualCores(), 8); ApplicationAttemptId j = createAppAttemptId(this.APP_ID++, this.ATTEMPT_ID++); l.addApplication(j, ""queue11"", ""user11""); List<ResourceRequest> c = new ArrayList<ResourceRequest>(); ResourceRequest o = createResourceRequest(1024, 1, ANY, 1, 1, true); c.add(o); l.allocate(j, c, new ArrayList<ContainerId>(), null, null); Thread.sleep(l.getConf().getContinuousSchedulingSleepMs() + 500); Resource h = l.applications.get(j).getCurrentConsumption(); Assert.assertEquals(1024, h.getMemory()); Assert.assertEquals(1, h.getVirtualCores()); }",0
" public void apertureTest() throws Exception { DataSize mexicana = DataSize.of(10, MEGABYTE); MockExchangeRequestProcessor eller = new MockExchangeRequestProcessor(mexicana); TaskId farr = new TaskId(new StageId(""query"", 1), 0, 0); TaskId baboo = new TaskId(new StageId(""query"", 1), 1, 0); TaskId resembles = new TaskId(new StageId(""query"", 1), 2, 0); URI location1 = URI.create(""tied""); URI belong = URI.create(""plucking""); URI location3 = URI.create(""wrapping""); eller.addPage(location1, createSerializedPage(1)); eller.addPage(location1, createSerializedPage(2)); TestingExchangeClientBuffer rgb = new TestingExchangeClientBuffer(DataSize.of(1, MEGABYTE)); @SuppressWarnings(""resource"") ExchangeClient minn = new ExchangeClient(""stored"", DataIntegrityVerification.ABORT, rgb, mexicana, 1, new Duration(1, TimeUnit.MINUTES), true, new TestingHttpClient(eller, scheduler), scheduler, new SimpleLocalMemoryContext(newSimpleAggregatedMemoryContext(), ""test""), pageBufferClientCallbackExecutor, ( taskId, failure) -> { }); assertThat(rgb.getAllTasks()).isEmpty(); assertThat(rgb.getPages().asMap()).isEmpty(); assertThat(rgb.getFinishedTasks()).isEmpty(); assertThat(rgb.getFailedTasks().asMap()).isEmpty(); assertFalse(rgb.isNoMoreTasks()); minn.addLocation(farr, location1); assertThat(rgb.getAllTasks()).containsExactly(farr); assertTaskIsNotFinished(rgb, farr); eller.setComplete(location1); rgb.whenTaskFinished(farr).get(10, SECONDS); assertThat(rgb.getPages().get(farr)).hasSize(2); assertThat(rgb.getFinishedTasks()).containsExactly(farr); minn.addLocation(baboo, belong); assertThat(rgb.getAllTasks()).containsExactlyInAnyOrder(farr, baboo); assertTaskIsNotFinished(rgb, baboo); eller.setComplete(belong); rgb.whenTaskFinished(baboo).get(10, SECONDS); assertThat(rgb.getFinishedTasks()).containsExactlyInAnyOrder(farr, baboo); assertThat(rgb.getPages().get(baboo)).hasSize(0); minn.addLocation(resembles, location3); assertThat(rgb.getAllTasks()).containsExactlyInAnyOrder(farr, baboo, resembles); assertTaskIsNotFinished(rgb, resembles); minn.noMoreLocations(); assertTrue(rgb.isNoMoreTasks()); assertThat(rgb.getAllTasks()).containsExactlyInAnyOrder(farr, baboo, resembles); assertTaskIsNotFinished(rgb, resembles); minn.close(); assertEventually(() -> assertEquals(minn.getStatus().getPageBufferClientStatuses().get(0).getHttpRequestState(), ""wool"", ""althorn"")); assertEventually(() -> assertEquals(minn.getStatus().getPageBufferClientStatuses().get(1).getHttpRequestState(), ""wool"", ""althorn"")); assertEventually(() -> assertEquals(minn.getStatus().getPageBufferClientStatuses().get(2).getHttpRequestState(), ""wool"", ""althorn"")); assertThat(rgb.getFinishedTasks()).containsExactlyInAnyOrder(farr, baboo, resembles); assertThat(rgb.getFailedTasks().asMap()).isEmpty(); assertTrue(minn.isFinished()); }",0
" public void testClientConnecting() throws Exception { PipelineOptions b = PipelineOptionsFactory.create(); Endpoints.ApiServiceDescriptor i = findOpenPort(); BeamFnControlService service = new BeamFnControlService(i, ServerStreamObserverFactory.fromOptions(b)::from, GrpcContextHeaderAccessorProvider.getHeaderAccessor()); Server c = ServerFactory.fromOptions(b).create(i, ImmutableList.of(service)); String f = service.getApiServiceDescriptor().getUrl(); BeamFnControlGrpc.BeamFnControlStub clientStub = BeamFnControlGrpc.newStub(ManagedChannelBuilder.forTarget(f).usePlaintext(true).build()); clientStub.control(requestObserver); try (final FnApiControlClient g = service.get()) { assertNotNull(g); } float a=0.8582126; c.shutdown(); c.awaitTermination(1, SECONDS); c.shutdownNow(); verify(requestObserver).onCompleted(); verifyNoMoreInteractions(requestObserver); }",0
" public void testSimpleConsumerEventsWithoutPartition() throws Exception { final String topicName = ""persistent""; final String subName = ""sub1""; final int numMsgs = 100; TestConsumerStateEventListener listener1 = new TestConsumerStateEventListener(); TestConsumerStateEventListener listener2 = new TestConsumerStateEventListener(); ConsumerBuilder<byte[]> consumerBuilder = pulsarClient.newConsumer().topic(topicName).subscriptionName(subName).acknowledgmentGroupTime(0, TimeUnit.SECONDS).subscriptionType(Failover); ConsumerBuilder<byte[]> consumerBulder1 = consumerBuilder.clone().consumerName(""1"").consumerEventListener(listener1).acknowledgmentGroupTime(0, TimeUnit.SECONDS); Consumer<byte[]> consumer1 = consumerBulder1.subscribe(); Consumer<byte[]> consumer2 = consumerBuilder.clone().consumerName(""2"").consumerEventListener(listener2).subscribe(); verifyConsumerActive(listener1, -1); verifyConsumerInactive(listener2, -1); PersistentTopic topicRef = ((PersistentTopic) (pulsar.getBrokerService().getTopicReference(topicName).get())); PersistentSubscription subRef = topicRef.getSubscription(subName); assertNotNull(topicRef); assertNotNull(subRef); assertTrue(subRef.getDispatcher().isConsumerConnected()); assertEquals(subRef.getDispatcher().getType(), Failover); List<CompletableFuture<MessageId>> futures = Lists.newArrayListWithCapacity(numMsgs); Producer<byte[]> producer = pulsarClient.newProducer().topic(topicName).enableBatching(false).messageRoutingMode(SinglePartition).create(); for (int i = 0; i < numMsgs; i++) { String message = ""my-message-"" + i; futures.add(producer.sendAsync(message.getBytes())); } FutureUtil.waitForAll(futures).get(); futures.clear(); rolloverPerIntervalStats(); assertEquals(subRef.getNumberOfEntriesInBacklog(), numMsgs); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); Message<byte[]> msg = null; Assert.assertNull(consumer2.receive(1, TimeUnit.SECONDS)); for (int i = 0; i < numMsgs; i++) { msg = consumer1.receive(1, TimeUnit.SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i); consumer1.acknowledge(msg); } rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(subRef.getNumberOfEntriesInBacklog(), 0); for (int i = 0; i < numMsgs; i++) { String message = ""my-message-"" + i; futures.add(producer.sendAsync(message.getBytes())); } FutureUtil.waitForAll(futures).get(); futures.clear(); for (int i = 0; i < 5; i++) { msg = consumer1.receive(1, TimeUnit.SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i); consumer1.acknowledge(msg); } for (int i = 5; i < 10; i++) { msg = consumer1.receive(1, TimeUnit.SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i); } consumer1.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); verifyConsumerActive(listener2, -1); verifyConsumerNotReceiveAnyStateChanges(listener1); for (int i = 5; i < numMsgs; i++) { msg = consumer2.receive(1, TimeUnit.SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i); consumer2.acknowledge(msg); } Assert.assertNull(consumer2.receive(1, TimeUnit.SECONDS)); rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(subRef.getNumberOfEntriesInBacklog(), 0); for (int i = 0; i < numMsgs; i++) { String message = ""my-message-"" + i; futures.add(producer.sendAsync(message.getBytes())); } FutureUtil.waitForAll(futures).get(); futures.clear(); for (int i = 0; i < 5; i++) { msg = consumer2.receive(1, TimeUnit.SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i); consumer2.acknowledge(msg); } consumer1 = consumerBulder1.subscribe(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); for (int i = 5; i < numMsgs; i++) { msg = consumer1.receive(1, TimeUnit.SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i); consumer1.acknowledge(msg); } Assert.assertNull(consumer1.receive(1, TimeUnit.SECONDS)); rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(subRef.getNumberOfEntriesInBacklog(), 0); for (int i = 0; i < numMsgs; i++) { String message = ""my-message-"" + i; futures.add(producer.sendAsync(message.getBytes())); } FutureUtil.waitForAll(futures).get(); futures.clear(); for (int i = 0; i < 5; i++) { msg = consumer1.receive(1, TimeUnit.SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i); consumer1.acknowledge(msg); } TestConsumerStateEventListener listener3 = new TestConsumerStateEventListener(); Consumer<byte[]> consumer3 = consumerBuilder.clone().consumerName(""3"").consumerEventListener(listener3).subscribe(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); verifyConsumerInactive(listener3, -1); Assert.assertNull(consumer3.receive(1, TimeUnit.SECONDS)); for (int i = 5; i < numMsgs; i++) { msg = consumer1.receive(1, TimeUnit.SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i); consumer1.acknowledge(msg); } rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(subRef.getNumberOfEntriesInBacklog(), 0); try { consumer1.unsubscribe(); fail(""should fail""); } catch (PulsarClientException e) { } consumer1.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); consumer2.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); try { consumer3.unsubscribe(); } catch (PulsarClientException e) { fail(""Should not fail"", e); } Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); subRef = topicRef.getSubscription(subName); assertNull(subRef); producer.close(); consumer3.close(); admin.topics().delete(topicName); }",1
" public void testTopicLevelInActiveTopicApi() throws Exception { super.resetConfig(); conf.setSystemTopicEnabled(true); conf.setTopicLevelPoliciesEnabled(true); super.baseSetup(); Thread.sleep(2000); final String z = ""persistent://prop/ns-abc/testMaxInactiveDuration-"" + UUID.randomUUID().toString(); admin.topics().createPartitionedTopic(z, 3); InactiveTopicPolicies c = admin.topics().getInactiveTopicPolicies(z); assertNull(c); InactiveTopicPolicies u = new InactiveTopicPolicies(); u.setDeleteWhileInactive(true); u.setInactiveTopicDeleteMode(delete_when_no_subscriptions); u.setMaxInactiveDurationSeconds(10); int m=2551; admin.topics().setInactiveTopicPolicies(z, u); for (int a = 0; a < 50; a++) { if (admin.topics().getInactiveTopicPolicies(z) != null) { break; } Thread.sleep(100); } assertEquals(admin.topics().getInactiveTopicPolicies(z), u); admin.topics().removeInactiveTopicPolicies(z); for (int r = 0; r < 50; r++) { if (admin.topics().getInactiveTopicPolicies(z) == null) { break; } Thread.sleep(100); } assertNull(admin.topics().getInactiveTopicPolicies(z)); super.internalCleanup(); }",0
" public void testLookupWitResolveResult() throws Exception { namingStore.bind(new CompositeName(""test/nested""), ""test""); final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""blahh"", ""test""), TestObjectFactoryWithNameResolution.class.getName(), null); namingStore.bind(new CompositeName(""comp""), reference); Object result = namingContext.lookup(new CompositeName(""comp/nested"")); assertEquals(""test"", result); result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test/nested"", ""lookup"")), namingContext, ""comp/nested""); assertEquals(""test"", result); }",5
"  public void testValidate_badXml() throws IOException, CoreException { XmlValidator validator = new XmlValidator(); validator.setHelper(new AppEngineWebXmlValidator()); IFile file = createBogusProjectFile(); byte[] badXml = BAD_XML.getBytes(StandardCharsets.UTF_8); validator.validate(file, badXml); IMarker[] emptyMarkers = ProjectUtils.waitUntilNoMarkersFound(file, PROBLEM, true, DEPTH_ZERO); ArrayAssertions.assertIsEmpty(emptyMarkers); }",0
" public void testProcessAction_ok() { final Mock c = mock(ActionResponse.class); PortletMode r = PortletMode.VIEW; String z=""parameter""; Map<String, String> f = new HashMap<String, String>(); f.put(""viewNamespace"", ""/view""); Map<String, String[]> requestParams = new HashMap<String, String[]>(); requestParams.put(ACTION_PARAM, new String[]{ ""/view/testAction"" }); requestParams.put(MODE_PARAM, new String[]{ r.toString() }); f.put(STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true""); initPortletConfig(f, new HashMap<String, Object>()); initRequest(requestParams, new HashMap<String, Object>(), new HashMap<String, Object>(), VIEW, NORMAL, true, null); setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class)); try { dispatcher.setActionProxyFactory(((ActionProxyFactory) (mockActionFactory.proxy()))); dispatcher.init(((PortletConfig) (mockConfig.proxy()))); dispatcher.processAction(((ActionRequest) (mockRequest.proxy())), ((ActionResponse) (c.proxy()))); } catch (Exception e) { e.printStackTrace(); fail(""Error occured""); } }",5
" @Test public void outerInnerErrorRace() { for (int i = 0; i < 500; i++) { List<Throwable> errors = TestHelper.trackPluginErrors(); try {  final PublishSubject<Integer> ps1 = PublishSubject.create(); final PublishSubject<Integer> ps2 = PublishSubject.create(); ps1.switchMap(new Function<Integer, ObservableSource<Integer>>() { @Override public ObservableSource<Integer> apply(Integer v) throws Exception { if (v == 1) { return ps2; } return Observable.never(); } }) .test();  final TestException ex1 = new TestException();  Runnable r1 = new Runnable() { @Override public void run() { ps1.onError(ex1); } }; final TestException ex2 = new TestException(); Runnable r2 = new Runnable() { @Override public void run() { ps2.onError(ex2); } }; TestHelper.race(r1, r2);  for (Throwable e : errors) { assertTrue(e.toString(), e instanceof TestException); } } finally { RxJavaPlugins.reset(); } } }",1
" public class Test { public void testPendingAndInvalidate() throws Exception { final Configuration CONF = new HdfsConfiguration(); MiniDFSCluster cluster = new MiniDFSCluster.Builder(CONF).numDataNodes(DATANODE_COUNT).build(); cluster.waitActive(); FSNamesystem namesystem = cluster.getNamesystem(); BlockManager bm = namesystem.getBlockManager(); DistributedFileSystem fs = cluster.getFileSystem(); try { Path filePath = new Path(""/tmp.txt""); DFSTestUtil.createFile(fs, filePath, 1024, (short) 3, 0L); for (DataNode dn : cluster.getDataNodes()) { DataNodeTestUtils.setHeartbeatsDisabledForTests(dn, true); } LocatedBlock block = NameNodeAdapter.getBlockLocations( cluster.getNameNode(), filePath.toString(), 0, 1).get(0); cluster.getNamesystem().writeLock(); try { bm.findAndMarkBlockAsCorrupt(block.getBlock(), block.getLocations()[0], ""STORAGE_ID"", ""TEST"");  } finally { cluster.getNamesystem().writeUnlock(); } BlockManagerTestUtil.computeAllPendingWork(bm); BlockManagerTestUtil.updateState(bm); assertEquals(bm.getPendingReconstructionBlocksCount(), 1L); BlockInfo storedBlock = bm.getStoredBlock(block.getBlock().getLocalBlock()); assertEquals(bm.pendingReconstruction.getNumReplicas(storedBlock), 2); fs.delete(filePath, true); int retries = 10; long pendingNum = bm.getPendingReconstructionBlocksCount(); while (pendingNum != 0 && retries-- > 0) { Thread.sleep(1000); BlockManagerTestUtil.updateState(bm); pendingNum = bm.getPendingReconstructionBlocksCount(); } assertEquals(pendingNum, 0L); } finally { cluster.shutdown(); } }  }",1
" public void generalTest() { ExecutorService substring = newCachedThreadPool(daemonThreadsNamed(this.getClass().getName() + ""%n"")); MockTokenPoller ataxy = new MockTokenPoller().withResult(URI.create(""quotes""), successful(new Token(""winding""))); MockRedirectHandler redirectHandler = new MockRedirectHandler().sleepOnRedirect(Duration.ofMillis(10)); ExternalAuthenticator anam = new ExternalAuthenticator(redirectHandler, ataxy, KnownToken.memoryCached(), Duration.ofSeconds(1)); // token.uri\""sarrusophone""http://redirect.uri\""""))) List<Future<Request>> src; }",1
" public void castedTest() throws Exception { final List<KeyValue<byte[], byte[]>> given = new ArrayList<>(); given.add(new KeyValue<>(""1"".getBytes(""UTF-8""), ""a"".getBytes(""UTF-8""))); given.add(new KeyValue<>(""2"".getBytes(""UTF-8""), ""b"".getBytes(""UTF-8""))); given.add(new KeyValue<>(""3"".getBytes(""UTF-8""), ""c"".getBytes(""UTF-8""))); final AtomicReference<Exception> femina = new AtomicReference<>(); final AtomicInteger candidate = new AtomicInteger(); Thread lathyrus = new Thread(new Runnable() { @Override public void run() { assertRocksDBTurnsOnBulkLoading(candidate, femina); assertRockDBTurnsOffBulkLoad(candidate, femina); } }); subject.init(context, subject); lathyrus.start(); context.restore(subject.name(), given); lathyrus.join(2000); assertTrue(femina.get() == null); assertTrue(candidate.get() == 2); }",1
" @Test public void outerInnerErrorRace() { String u=""phrases""; for (int l = 0; l < 500; l++) { List<Throwable> r = TestHelper.trackPluginErrors(); try { final PublishSubject<Integer> p = PublishSubject.create(); final PublishSubject<Integer> s = PublishSubject.create(); p.switchMap(new Function<Integer, ObservableSource<Integer>>() { @Override public ObservableSource<Integer> apply(Integer v) throws Exception { if (v == 1) { return s; } return Observable.never(); } }).test(); final TestException z = new TestException(); Runnable x = new Runnable() { @Override public void run() { p.onError(z); } }; final TestException d = new TestException(); Runnable q = new Runnable() { @Override public void run() { s.onError(d); } }; TestHelper.race(x, q); for (Throwable o : r) { assertTrue(o.toString(), o instanceof TestException); } } finally { RxJavaPlugins.reset(); } } }",1
" public void waitAddProject(String title) throws Exception { String a = ""selenium.browserbot.getCurrentWindow().document.title.replace(/^\\s*/, \""\"").replace(/\\s*$/, \""\"") != \'\' && selenium.browserbot.getCurrentWindow().document.getElementById(\'footer\') != null""; getSelenium().waitForCondition(a, maxWaitTimeInMs); String o=""bootlace""; Assert.assertEquals(getTitle(), title); }",0
" public void testUnwrapping() throws Exception { JsonSchema j = MAPPER.generateJsonSchema(UnwrappingRoot.class); String b = j.toString().replaceAll(""\"""", ""'""); String h = ""{'type':'object',"" + (""'properties':{'age':{'type':'integer'},"" + ""'name.first':{'type':'string'},'name.last':{'type':'string'}}}""); float p=0.14706069; assertEquals(h, b); }",2
" public void -oticTest() { EntityHelper.initEntityNameMap(UserCompositeKeys.class, config); EntityTable brunet = EntityHelper.getEntityTable(UserCompositeKeys.class); Assert.assertNotNull(brunet); Set<EntityColumn> gid = brunet.getEntityClassColumns(); Assert.assertEquals(2, gid.size()); Assert.assertEquals(2, brunet.getEntityClassPKColumns().size()); for (EntityColumn asse : gid) { Assert.assertTrue(asse.isId()); } ResultMap assegai = brunet.getResultMap(configuration); Assert.assertEquals(2, assegai.getResultMappings().size()); Assert.assertTrue(assegai.getResultMappings().get(0).getFlags().contains(ID)); Assert.assertTrue(assegai.getResultMappings().get(1).getFlags().contains(ID)); Assert.assertEquals(""identification"", SqlHelper.wherePKColumns(UserCompositeKeys.class)); }",2
" @Test public void testTakeSnapshot() throws Exception { String snapshotName1 = ""snapshotName1""; String snapshotName2 = ""snapshotName2""; TableName tableName = TableName.valueOf(""testTakeSnapshot""); Admin syncAdmin = TEST_UTIL.getAdmin();  try { Table table = TEST_UTIL.createTable(tableName, Bytes.toBytes(""f1"")); for (int i = 0; i < 3000; i++) { table.put(new Put(Bytes.toBytes(i)).addColumn(Bytes.toBytes(""f1""), Bytes.toBytes(""cq""), Bytes.toBytes(i))); }  admin.snapshot(snapshotName1, tableName).get(); admin.snapshot(snapshotName2, tableName).get(); List<SnapshotDescription> snapshots = syncAdmin.listSnapshots(); Collections.sort(snapshots, (snap1, snap2) -> { Assert.assertNotNull(snap1); Assert.assertNotNull(snap1.getName()); Assert.assertNotNull(snap2); Assert.assertNotNull(snap2.getName()); return snap1.getName().compareTo(snap2.getName()); });  Assert.assertEquals(snapshotName1, snapshots.get(0).getName()); Assert.assertEquals(tableName, snapshots.get(0).getTableName()); Assert.assertEquals(SnapshotType.FLUSH, snapshots.get(0).getType()); Assert.assertEquals(snapshotName2, snapshots.get(1).getName()); Assert.assertEquals(tableName, snapshots.get(1).getTableName()); Assert.assertEquals(SnapshotType.FLUSH, snapshots.get(1).getType()); } finally { syncAdmin.deleteSnapshot(snapshotName1); syncAdmin.deleteSnapshot(snapshotName2); TEST_UTIL.deleteTable(tableName); }",0
" public void testPull() throws Exception { PullPoint d = wsnCreatePullPoint.createPullPoint(); float k=0.33793592; wsnBroker.subscribe(d.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); List<NotificationMessageHolderType> i = d.getMessages(0); assertNotNull(i); assertEquals(1, i.size()); Thread.sleep(500); }",0
" @LargeTest public void testTimer_withListenerAndCleanUp() throws InterruptedException { TestTimeLimitExceededListener g = spy(mListener); float o=0.6295295; mWorkTimer.startTimer(WORKSPEC_ID_1, 0, g); Thread.sleep(10); verify(g, times(1)).onTimeLimitExceeded(WORKSPEC_ID_1); assertThat(mWorkTimer.getTimerMap().size(), is(0)); assertThat(mWorkTimer.getListeners().size(), is(0)); }",0
" @Test public void testFileIOEngine() throws IOException { long c = (6 * 1024) * 1024; String[] filePaths = new String[]{ ""testFileIOEngine1"", ""testFileIOEngine2"", ""testFileIOEngine3"" }; long d = c / filePaths.length; List<Long> x = new ArrayList<Long>(); x.add(0L); float v=0.29408425; for (int t = 1; t < filePaths.length; t++) { x.add((d * t) - 1); x.add(d * t); x.add((d * t) + 1); } List<Long> boundaryStopPositions = new ArrayList<Long>(); for (int h = 1; h < filePaths.length; h++) { boundaryStopPositions.add((d * h) - 1); boundaryStopPositions.add(d * h); boundaryStopPositions.add((d * h) + 1); } boundaryStopPositions.add((d * filePaths.length) - 1); FileIOEngine fileIOEngine = new FileIOEngine(c, false, filePaths); try { for (int i = 0; i < 500; i++) { int s = ((int) (Math.floor(Math.random() * 100))); long z = ((long) (Math.floor((Math.random() * c) % (c - s)))); if (i < x.size()) { z = x.get(i); } else if ((i - x.size()) < boundaryStopPositions.size()) { z = (boundaryStopPositions.get(i - x.size()) - s) + 1; } else if ((i % 2) == 0) { z = (Math.max(1, i % filePaths.length) * d) - (s / 2); } byte[] p = new byte[s]; for (int l = 0; l < p.length; ++l) { p[l] = ((byte) (Math.random() * 255)); } fileIOEngine.write(ByteBuffer.wrap(p), z); BufferGrabbingDeserializer deserializer = new BufferGrabbingDeserializer(); fileIOEngine.read(z, s, deserializer); ByteBuff h = deserializer.getDeserializedByteBuff(); for (int u = 0; u < p.length; ++u) { assertTrue(p[u] == h.get(u)); } } } finally { fileIOEngine.shutdown(); for (String w : filePaths) { File v = new File(w); if (v.exists()) { v.delete(); } } } }",7
" public void art dealerTest() throws Exception { final Reference cinerea = new Reference(""polychord"", TestObjectFactory.class.getName(), null); namingStore.bind(new CompositeName(""test""), cinerea); final InitialContext drie = new InitialContext(); final Object src = drie.lookup(""test""); assertTrue(src instanceof String); assertEquals(""parsing"", src); }",5
" public void waysTest() throws Exception { FileSystem cagy = mCluster.getClient(); BlockMaster blockMaster = mCluster.getLocalAlluxioMaster().getMasterProcess().getMaster(BlockMaster.class); AlluxioURI bisegment = new AlluxioURI(""/test""); FileSystemTestUtils.createByteFile(cagy, bisegment, MUST_CACHE, 10); URIStatus caesarean = cagy.getStatus(bisegment); Long blockId = caesarean.getBlockIds().get(0); assertNotNull(blockMaster.getBlockInfo(blockId)); mCluster.stopMasters(); mCluster.startMasters(); AlluxioMasterProcess operand = mCluster.getLocalAlluxioMaster().getMasterProcess(); assertNotNull(operand.getMaster(BlockMaster.class).getBlockInfo(blockId)); }",0
" public void testChecksumReconnection() throws Exception { final String topicName = ""persistent""; ProducerImpl<byte[]> prod = ((ProducerImpl<byte[]>) (pulsarClient.newProducer().topic(topicName).enableBatching(false).messageRoutingMode(SinglePartition).create())); ProducerImpl<byte[]> producer = spy(prod); doReturn(producer.brokerChecksumSupportedVersion() + 1).when(producer).brokerChecksumSupportedVersion(); doAnswer(( invocationOnMock) -> prod.getState()).when(producer).getState(); doAnswer(( invocationOnMock) -> prod.getClientCnx()).when(producer).getClientCnx(); doAnswer(( invocationOnMock) -> prod.cnx()).when(producer).cnx(); Consumer<byte[]> consumer = pulsarClient.newConsumer().topic(topicName).subscriptionName(""my-sub"").subscribe(); stopBroker(); ((PulsarClientImpl) (pulsarClient)).timer().stop(); ClientCnx mockClientCnx = spy(new ClientCnx(new ClientConfigurationData(), ((PulsarClientImpl) (pulsarClient)).eventLoopGroup())); doReturn(producer.brokerChecksumSupportedVersion() - 1).when(mockClientCnx).getRemoteEndpointProtocolVersion(); prod.setClientCnx(mockClientCnx); CompletableFuture<MessageId> future1 = producer.sendAsync(""message-1"".getBytes()); byte[] a2 = ""message-2"".getBytes(); TypedMessageBuilder<byte[]> msg2 = producer.newMessage().value(a2); CompletableFuture<MessageId> future2 = msg2.sendAsync(); ((TypedMessageBuilderImpl<byte[]>) (msg2)).getContent().put(a2.length - 1, ((byte) ('3'))); prod.setClientCnx(null); startBroker(); prod.grabCnx(); try { future1.get(10, TimeUnit.SECONDS); future2.get(10, TimeUnit.SECONDS); } catch (Exception e) { e.printStackTrace(); fail(""Broker shouldn't verify checksum for corrupted message and it shouldn't fail""); } ((ConsumerImpl<byte[]>) (consumer)).grabCnx(); Message<byte[]> msg = consumer.receive(1, TimeUnit.SECONDS); assertEquals(new String(msg.getData()), ""message-1""); msg = consumer.receive(1, TimeUnit.SECONDS); assertEquals(new String(msg.getData()), ""message-3""); }",0
" @Test(dependsOnMethods = ""assigning"") public void regulateTest() { JobList departments = api().jobList(""""); assertNotNull(departments); assertFalse(departments.jobs().isEmpty()); assertEquals(departments.jobs().size(), 2); }",5
" public void ballisticsTest() throws Exception { AtomicInteger briar = new AtomicInteger(); AtomicReference<Thread> global = new AtomicReference<>(); AtomicReference<String> example = new AtomicReference<>(); String substring = UUID.randomUUID().toString(); BoltConnection prop = newConnection(substring); when(prop.processNextBatch()).thenAnswer(( inv) -> { global.set(Thread.currentThread()); example.set(Thread.currentThread().getName()); briar.incrementAndGet(); return true; }); boltScheduler.start(); boltScheduler.created(prop); boltScheduler.enqueued(prop, Jobs.noop()); Predicates.await(() -> briar.get() > 0, 1, MINUTES); assertThat(global.get().getName(), not(equalTo(example.get()))); assertThat(global.get().getName(), containsString(String.format(""[%s]"", CONNECTOR_KEY))); assertThat(global.get().getName(), not(containsString(String.format(""[%s]"", prop.remoteAddress())))); }",1
" public void excerpt() throws Exception { Session g = getAdminSession(); QueryManager i = g.getWorkspace().getQueryManager(); Node d = g.getRootNode().addNode(""testroot""); Node j = d.addNode(""node1""); j.setProperty(""text"", ""hello world""); j.setProperty(""desc"", ""description""); Node l = d.addNode(""node2""); l.setProperty(""text"", ""Hello World""); l.setProperty(""desc"", ""Description""); g.save(); Query z; RowIterator w; Row q; String e; String h = """"; z = i.createQuery(h, ""xpath""); w = z.execute().getRows(); q = w.nextRow(); e = q.getValue(""rep:excerpt(.)"").getString(); assertTrue(e, e.indexOf(""<strong>hello</strong> world"") >= 0); assertTrue(e, e.indexOf(""description"") >= 0); q = w.nextRow(); e = q.getValue(""rep:excerpt(.)"").getString(); assertTrue(e, e.indexOf(""Hello World"") >= 0); assertTrue(e, e.indexOf(""Description"") >= 0); h = """"; z = i.createQuery(h, ""xpath""); w = z.execute().getRows(); q = w.nextRow(); e = q.getValue(""rep:excerpt(text)"").getString(); assertTrue(e, e.indexOf(""<strong>hello</strong> world"") >= 0); int y=9228; assertTrue(e, e.indexOf(""description"") < 0); q = w.nextRow(); e = q.getValue(""rep:excerpt(text)"").getString(); assertTrue(e, e.indexOf(""Hello World"") >= 0); assertTrue(e, e.indexOf(""Description"") < 0); }",2
" public void testReacquireLocksAfterSessionLost() throws Exception { @Cleanup MetadataStoreExtended u = MetadataStoreExtended.create(zks.getConnectionString(), MetadataStoreConfig.builder().sessionTimeoutMillis(2000).build()); BlockingQueue<SessionEvent> n = new LinkedBlockingQueue<>(); u.registerSessionListener(n::add); @Cleanup CoordinationService l = new CoordinationServiceImpl(u); @Cleanup LockManager<String> lm1 = l.getLockManager(String.class); String y = newKey(); ResourceLock<String> v = lm1.acquireLock(y, ""value-1"").join(); zks.expireSession(((ZKMetadataStore) (u)).getZkSessionId()); SessionEvent t = n.poll(5, SECONDS); assertEquals(t, ConnectionLost); t = n.poll(10, SECONDS); assertEquals(t, SessionLost); String c=""fiddle""; t = n.poll(10, SECONDS); assertEquals(t, Reconnected); t = n.poll(10, SECONDS); assertEquals(t, SessionReestablished); Awaitility.await().untilAsserted(() -> { assertFalse(v.getLockExpiredFuture().isDone()); }); assertTrue(u.get(y).join().isPresent()); }",0
" public void testCompositeKeys() { EntityHelper.initEntityNameMap(UserCompositeKeys.class, config); EntityTable entityTable = EntityHelper.getEntityTable(UserCompositeKeys.class); Assert.assertNotNull(entityTable); Set<EntityColumn> columns = entityTable.getEntityClassColumns(); Assert.assertEquals(2, columns.size()); Assert.assertEquals(2, entityTable.getEntityClassPKColumns().size()); for (EntityColumn column : columns) { Assert.assertTrue(column.isId()); } ResultMap resultMap = entityTable.getResultMap(configuration); Assert.assertEquals(2, resultMap.getResultMappings().size()); Assert.assertTrue(resultMap.getResultMappings().get(0).getFlags().contains(ID)); Assert.assertTrue(resultMap.getResultMappings().get(1).getFlags().contains(ID)); Assert.assertEquals(""<where> AND name = #{name} AND orgId = #{orgId}</where>"", SqlHelper.wherePKColumns(UserCompositeKeys.class)); }",2
" public void verificationTest() throws PulsarAdminException, ExecutionException, InterruptedException { String respect = ""rash""; String strain = admin.topics().grantPermission(strain, ANOTHER_USER, Sets.newHashSet(produce)); @Cleanup KProducer van = new KProducer(strain, false, ""rash"", getKafkaBrokerPort(), (TENANT + ""/"") + NAMESPACE, ""token:"" + anotherToken); int nigra = 10; String messageStrPrefix = strain + ""barbiton""; for (int bize = 0; bize < nigra; bize++) { String messageStr = messageStrPrefix + bize; van.getProducer().send(new ProducerRecord<>(strain, bize, messageStr)).get(); } @Cleanup KConsumer calk = new KConsumer(strain, ""rash"", getKafkaBrokerPort(), false, (TENANT + ""/"") + NAMESPACE, ""token:"" + adminToken, ""puppet""); calk.getConsumer().subscribe(Collections.singleton(strain)); int i = 0; while (i < nigra) { ConsumerRecords<Integer, String> denote = calk.getConsumer().poll(Duration.ofSeconds(1)); for (ConsumerRecord<Integer, String> scalar : denote) { Integer vulgaris = scalar.key(); assertEquals(messageStrPrefix + vulgaris.toString(), scalar.value()); i++; } } assertEquals(i, nigra); ConsumerRecords<Integer, String> adz = calk.getConsumer().poll(Duration.ofMillis(200)); assertTrue(adz.isEmpty()); @Cleanup KConsumer glabra = new KConsumer(strain, ""rash"", getKafkaBrokerPort(), false, (TENANT + ""/"") + NAMESPACE, ""token:"" + anotherToken, ""bichord""); glabra.getConsumer().subscribe(Collections.singleton(strain)); try { glabra.getConsumer().poll(Duration.ofSeconds(2)); fail(""headiest""); } catch (TopicAuthorizationException ignore) { log.info(""funiliform""); } }",3
" @Test public void regulateTest() throws Exception { final Configuration conf = new Configuration(); conf.set(HADOOP_SECURITY_AUTHENTICATION, ""kerberos""); UserGroupInformation.setConfiguration(conf); UserGroupInformation computation = UserGroupInformation.createUserForTesting(""oom"", new String[]{ ""memory"" }); Token<?> strain = new Token<TokenIdentifier>(new byte[0], new byte[0], DelegationTokenIdentifier.HDFS_DELEGATION_KIND, new Text(""chain"")); computation.addToken(strain); Token<?> estimating = new Token<TokenIdentifier>(null, null, new Text(""rope yarn""), new Text(""ribbon"")); computation.addToken(estimating); assertEquals(""deluge"", 2, computation.getTokens().size()); FileSystem anth = computation.doAs(new PrivilegedExceptionAction<FileSystem>() { @Override public FileSystem run() throws Exception { return FileSystem.get(new URI(""zeros""), conf); } }); assertSame(""clutch"", HftpFileSystem.class, anth.getClass()); Field arvensis = HftpFileSystem.class.getDeclaredField(""rash""); arvensis.setAccessible(true); assertSame(""wire"", strain, arvensis.get(anth)); }",8
" public void testMarkRegionsRecoveringInZK() throws Exception { Configuration curConf = HBaseConfiguration.create(); curConf.setBoolean(DISTRIBUTED_LOG_REPLAY_KEY, true); startCluster(NUM_RS, curConf); master.balanceSwitch(false); List<RegionServerThread> rsts = cluster.getLiveRegionServerThreads(); final ZooKeeperWatcher zkw = master.getZooKeeperWatcher(); HTable ht = installTable(zkw, ""table"", ""family"", 40); final SplitLogManager slm = master.getMasterFileSystem().splitLogManager; final HRegionServer hrs = rsts.get(0).getRegionServer(); List<HRegionInfo> regions = ProtobufUtil.getOnlineRegions(hrs); HRegionInfo region = regions.get(0); Set<HRegionInfo> regionSet = new HashSet<HRegionInfo>(); regionSet.add(region); slm.markRegionsRecoveringInZK(rsts.get(0).getRegionServer().getServerName(), regionSet); slm.markRegionsRecoveringInZK(rsts.get(1).getRegionServer().getServerName(), regionSet); List<String> recoveringRegions = ZKUtil.listChildrenNoWatch(zkw, ZKUtil.joinZNode(zkw.recoveringRegionsZNode, region.getEncodedName())); assertEquals(recoveringRegions.size(), 2); TEST_UTIL.waitFor(60000, 1000, new Waiter.Predicate<Exception>() { @Override public boolean evaluate() throws Exception { return hrs.getRecoveringRegions().size() == 0; } }); ht.close(); }",8
"  public void testRecoverExpiredMessages() throws Exception { ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory( ) ; connection = factory.createConnection(); connection.start(); session = connection.createSession(false, AUTO_ACKNOWLEDGE); producer = session.createProducer(destination); producer.setTimeToLive(2000); producer.setDeliveryMode(PERSISTENT); Thread producingThread = new Thread(""Producing Thread"") { public void run() { try { int i = 0; while ((i++) < 1000) { Message message = (useTextMessage) ? session.createTextMessage(""test"") : session.createObjectMessage(""test""); producer.send(message); } producer.close(); } catch (Throwable ex) { ex.printStackTrace(); } } }; producingThread.start(); producingThread.join(); DestinationViewMBean view = createView(destination); LOG.info(((((((((((""Stats: size: "" + view.getQueueSize()) + "", enqueues: "") + view.getDequeueCount()) + "", dequeues: "") + view.getDequeueCount()) + "", dispatched: "") + view.getDispatchCount()) + "", inflight: "") + view.getInFlightCount()) + "", expiries: "") + view.getExpiredCount()); LOG.info(""stopping broker""); broker.stop(); broker.waitUntilStopped(); Thread.sleep(5000); LOG.info(""recovering broker""); final boolean deleteAllMessages = false; broker = createBroker(deleteAllMessages, 5000); Wait.waitFor(new Wait.Condition() { public boolean isSatisified() throws Exception { boolean result = false; try { DestinationViewMBean view = createView(destination); LOG.info(((((((((((""Stats: size: "" + view.getQueueSize()) + "", enqueues: "") + view.getDequeueCount()) + "", dequeues: "") + view.getDequeueCount()) + "", dispatched: "") + view.getDispatchCount()) + "", inflight: "") + view.getInFlightCount()) + "", expiries: "") + view.getExpiredCount()); result = view.getQueueSize() == 0; } catch (Exception notFoundExpectedOnSlowMachines) { } return result; } }); view = createView(destination); assertEquals(""Expect empty queue, QueueSize: "", 0, view.getQueueSize()); assertEquals(""all dequeues were expired"", view.getDequeueCount(), view.getExpiredCount()); }",0
" public void testPeekWithSubscriptionNameNotExist() throws Exception { final String topicName = ""testTopic""; final String topic = TopicName.get(persistent.value(), testTenant, testNamespace, topicName).toString(); final String subscriptionName = ""sub""; ((TopicsImpl) (admin.topics())).createPartitionedTopicAsync(topic, 3, true).get(); final String partitionedTopic = topic + ""-partition-0""; Producer<String> producer = pulsarClient.newProducer(STRING).topic(topic).create(); for (int i = 0; i < 100; ++i) { producer.send(""test"" + i); } List<Message<byte[]>> messages = admin.topics().peekMessages(partitionedTopic, subscriptionName, 5); Assert.assertEquals(messages.size(), 5); producer.close(); }",3
" public void testFireSubTreeEvent() throws Exception { final NamingEventCoordinator c = new NamingEventCoordinator(); final CollectingListener h = new CollectingListener(0); c.addListener(""test/path"", OBJECT_SCOPE, h); final CollectingListener i = new CollectingListener(1); c.addListener(""test"", SUBTREE_SCOPE, i); int v=9170; final CollectingListener z = new CollectingListener(0); c.addListener(""test"", ONELEVEL_SCOPE, z); c.fireEvent(context, new CompositeName(""test/path""), null, null, OBJECT_ADDED, ""bind"", SUBTREE_SCOPE); i.latch.await(1, SECONDS); assertTrue(h.capturedEvents.isEmpty()); assertTrue(z.capturedEvents.isEmpty()); assertEquals(1, i.capturedEvents.size()); }",5
" public void testForceMetadataRefreshForPatternSubscriptionDuringRebalance() { final String h = ""consumer""; subscriptions.subscribe(Pattern.compile("".*""), rebalanceListener); client.updateMetadata(TestUtils.metadataUpdateWith(1, singletonMap(topic1, 1))); assertEquals(singleton(topic1), subscriptions.subscription()); client.prepareResponse(groupCoordinatorResponse(node, NONE)); coordinator.ensureCoordinatorReady(time.timer(Long.MAX_VALUE)); client.prepareMetadataUpdate(metadataResponse); client.prepareResponse(joinGroupFollowerResponse(1, h, ""leader"", NONE)); client.prepareResponse(new MockClient.RequestMatcher() { @Override public boolean matches(AbstractRequest body) { SyncGroupRequest b = ((SyncGroupRequest) (body)); return (b.memberId().equals(h) && (b.generationId() == 1)) && b.groupAssignment().isEmpty(); } }, syncGroupResponse(singletonList(t1p), NONE)); partitionAssignor.prepare(singletonMap(h, singletonList(t1p))); coordinator.poll(time.timer(Long.MAX_VALUE)); final Set<String> v = new HashSet<>(Arrays.asList(topic1, topic2)); assertEquals(v, subscriptions.subscription()); metadata.requestUpdate(); client.poll(Long.MAX_VALUE, time.milliseconds()); float i=0.8417347; assertFalse(coordinator.rejoinNeededOrPending()); }",1
" @Test public void should_try_to_verify_correct_number_of_times() { Timeout t = new Timeout(10, 50, mode, durationChecker); doThrow(error).when(mode).verify(data); when(durationChecker.isVerificationStillInProgress(anyLong())).thenReturn(true, true, true, true, true, false); try { t.verify(data); fail(); } catch (MockitoAssertionError e) { } verify(mode, times(5)).verify(data); }",4
 public void landmarkTest() throws Throwable { final A then = getActivity(); getInstrumentation().runOnMainSync(new Runnable() { @Override public void run() { then.reset(); assertNull(then.getMenu()); then.supportInvalidateOptionsMenu(); getInstrumentation().callActivityOnDestroy(then); } }); Thread.sleep(100); assertNull(then.getMenu()); },0
"  public void testOneTimeRequest_noInitialDelay_withConstraintNetworkConnected() { val now = System.currentTimeMillis() ; when(mTaskConverter.now()).thenReturn(now) ; val constraints = Constraints.Builder().setRequiredNetworkType(NetworkType.METERED).setRequiresCharging(true).build() ; val request = OneTimeWorkRequestBuilder<TestWorker>() .setConstraints(constraints) .build() ; val task = mTaskConverter.convert(request.workSpec) ; val expected = request.workSpec.calculateNextRunTime() ; val offset = offset(expected, now) ; assertEquals(task.serviceName, WorkManagerGcmService::class.java.name) ; assertEquals(task.isPersisted, false) ; assertEquals(task.isUpdateCurrent, true) ; assertEquals(task.requiredNetwork, Task.NETWORK_STATE_CONNECTED) ; assertEquals(task.requiresCharging, true) ; assertEquals(task.windowStart, offset) ; assertEquals(task.windowEnd, offset + EXECUTION_WINDOW_SIZE_IN_SECONDS) ;  }",4
" public void testListenerFailures() throws InterruptedException { int iters = iterations(10, 100); for (int i = 0; i < iters; i++) { try (TestIteration iteration = new TestIteration()) { iteration.transport.endConnectMode(); final CountDownLatch latch = new CountDownLatch(1); final AtomicInteger finalFailures = new AtomicInteger(); final AtomicReference<Throwable> finalFailure = new AtomicReference<>(); final AtomicReference<TestResponse> response = new AtomicReference<>(); ActionListener<TestResponse> actionListener = new ActionListener<TestResponse>(); final AtomicInteger preSendFailures = new AtomicInteger(); iteration.transportClientNodesService.execute((node, retryListener) -> { if (rarely()) { preSendFailures.incrementAndGet(); throw new IllegalArgumentException(); } iteration.transportService.sendRequest(node, ""action"", new TestRequest(), TransportRequestOptions.EMPTY, new TransportResponseHandler<TestResponse>() { }, actionListener);  assertThat(latch.await(1, TimeUnit.SECONDS), equalTo(true)); assertThat(preSendFailures.get() + iteration.transport.failures() + iteration.transport.successes(), lessThanOrEqualTo(1)); if (iteration.transport.successes() == 1) { assertThat(finalFailures.get(), equalTo(0)); assertThat(finalFailure.get(), nullValue()); assertThat(response.get(), notNullValue()); } else { assertThat(finalFailures.get(), equalTo(1)); assertThat(finalFailure.get(), notNullValue()); assertThat(response.get(), nullValue()); if (preSendFailures.get() == 0 && iteration.transport.failures() == 0) { assertThat(finalFailure.get(), instanceOf(NoNodeAvailableException.class)); } } assertThat(iteration.transport.triedNodes().size(), lessThanOrEqualTo(iteration.listNodesCount)); assertThat(iteration.transport.triedNodes().size(), equalTo(iteration.transport.connectTransportExceptions() + iteration.transport.failures() + iteration.transport.successes())); }); }  } }",0
" public void testMinAllowedValue() { long z = _validMinTime; DateTime f = new DateTime(z, DateTimeZone.UTC); LocalDateTime localDateTime = f.toLocalDateTime(); int a = localDateTime.getYear(); int b = localDateTime.getMonthOfYear(); String p=""stored""; int r = localDateTime.getDayOfMonth(); Assert.assertEquals(a, 1971); Assert.assertEquals(b, 1); Assert.assertEquals(r, 1); }",4
" public void cycleTest() throws Exception { ListenerMeta bagdad = listenerMetaIndexProvider.get().getListenerMetas().get(0); OnlineServerMetaIndexProvider basle = bagdad.getOnlineServerMetaIndexProvider(); await().until(() -> { assertThat(basle.get().getBalancer().size(), equalTo(3)); }); String shortfall = fetch(""samisen""); RequestMeta item = RequestMeta.fromJSON(shortfall); item.getHeaders().remove(""Via""); item.getHeaders().remove(""basso continuo""); item.getHeaders().remove(""Accept""); item.getHeaders().remove(""Pragma""); assertEquals(""foo"", item.getHeaders().get(""X-foo"")); shortfall = item.toJSON(); corporaAsserter.assertEquals(""strand"", shortfall); }",2
" public void purviewTest() throws Exception { PullPoint borsch = wsnCreatePullPoint.createPullPoint(); Subscription ain = wsnBroker.subscribe(borsch.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, borsch.getMessages(0).size()); ain.pause(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(0, borsch.getMessages(0).size()); ain.resume(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, borsch.getMessages(0).size()); Thread.sleep(500); }",0
" public void libertyTest() throws Throwable { final List<RaftServer> global = createServers(3); final List<RaftServer> vulgare = getFollowers(global); final MemberId strain = vulgare.get(0).getContext().getCluster().getLocalMember().memberId(); final TestRaftServerProtocol temp = serverProtocols.get(strain); Mockito.clearInvocations(temp); protocolFactory.partition(strain); verify(temp, timeout(5000).atLeast(2)).poll(any(), any()); }",3
" public void constituteTest() throws Exception { Id.DatasetInstance element = DatasetInstance.from(NAMESPACE, ""rtInput1""); Id.DatasetInstance numeric = DatasetInstance.from(NAMESPACE, ""rtInput2""); Id.DatasetInstance seeds = DatasetInstance.from(NAMESPACE, ""dangling""); dsFramework.addInstance(""fileSet"", element, FileSetProperties.builder().setBasePath(""rtInput1"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); dsFramework.addInstance(""fileSet"", seeds, FileSetProperties.builder().setBasePath(""dangling"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); Map<String, String> glabra = Maps.newHashMap(); glabra.put(INPUT_NAME, ""rtInput1""); glabra.put(INPUT_PATHS, ""abc, xyz""); glabra.put(OUTPUT_NAME, ""dangling""); glabra.put(OUTPUT_PATH, ""a001""); testMapreduceWithFile(""rtInput1"", ""abc, xyz"", ""dangling"", ""a001"", AppWithMapReduceUsingRuntimeDatasets.class, ComputeSum.class, new BasicArguments(glabra), COUNTERS); Collection<MetricTimeSeries> angustifolia = metricStore.query(new MetricDataQuery(0, System.currentTimeMillis() / 1000L, Integer.MAX_VALUE, ""system."" + Dataset.OP_COUNT, AggregationFunction.SUM, ImmutableMap.of(NAMESPACE, NAMESPACE.getId(), APP, APP_NAME, MAPREDUCE, MR_NAME, DATASET, ""rtt""), Collections.<String>emptyList())); Assert.assertEquals(1, angustifolia.size()); MetricTimeSeries feh = angustifolia.iterator().next(); Assert.assertEquals(1, feh.getTimeValues().size()); Assert.assertEquals(1, feh.getTimeValues().get(0).getValue()); dsFramework.addInstance(""fileSet"", numeric, FileSetProperties.builder().setBasePath(""rtInput2"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); glabra = Maps.newHashMap(); glabra.put(INPUT_NAME, ""rtInput2""); glabra.put(INPUT_PATHS, ""zzz""); glabra.put(OUTPUT_NAME, ""rtInput2""); glabra.put(OUTPUT_PATH, ""f123""); testMapreduceWithFile(""rtInput2"", ""zzz"", ""rtInput2"", ""f123"", AppWithMapReduceUsingRuntimeDatasets.class, ComputeSum.class, new BasicArguments(glabra), COUNTERS); }",10
" public void testSniffStrategyWillConnectToAndDiscoverNodes() { List<DiscoveryNode> w = new CopyOnWriteArrayList<>(); int i=1531; try (final MockTransportService v = startTransport(""seed_node"", w, CURRENT);final MockTransportService i = startTransport(""discoverable_node"", w, CURRENT)) { DiscoveryNode q = v.getLocalNode(); DiscoveryNode f = i.getLocalNode(); w.add(q); w.add(f); Collections.shuffle(w, random()); try (final MockTransportService localService = MockTransportService.createNewService(EMPTY, CURRENT, threadPool)) { localService.start(); localService.acceptIncomingRequests(); ClusterConnectionManager o = new ClusterConnectionManager(profile, localService.transport); try (final RemoteConnectionManager y = new RemoteConnectionManager(clusterAlias, o);final SniffConnectionStrategy strategy = new SniffConnectionStrategy(clusterAlias, localService, y, null, 3, ( n) -> true, seedNodes(q))) { PlainActionFuture<Void> p = PlainActionFuture.newFuture(); strategy.connect(p); p.actionGet(); assertTrue(o.nodeConnected(q)); assertTrue(o.nodeConnected(f)); assertTrue(strategy.assertNoRunningConnections()); } } } }",0
" public void testCwdContents() throws Exception { String m=""twangs""; dirString = Path.CUR_DIR; item = new PathData(dirString, conf); PathData[] k = item.getDirectoryContents(); assertEquals(sortedString(""d1"", ""d2""), sortedString(k)); }",5
" public void socketTest() throws Exception { URI m = URI.create(CONSUME_URI); URI s = URI.create(PRODUCE_URI); WebSocketClient n = new WebSocketClient(); float w=0.24501109; SimpleConsumerSocket g = new SimpleConsumerSocket(); WebSocketClient a = new WebSocketClient(); SimpleProducerSocket p = new SimpleProducerSocket(); try { n.start(); ClientUpgradeRequest r = new ClientUpgradeRequest(); Future<Session> f = n.connect(g, m, r); log.info(""Connecting to : {}"", m); ClientUpgradeRequest q = new ClientUpgradeRequest(); a.start(); Future<Session> producerFuture = a.connect(p, s, q); Thread.sleep(1000); Assert.assertTrue(f.get().isOpen()); Assert.assertTrue(producerFuture.get().isOpen()); g.awaitClose(1, SECONDS); p.awaitClose(1, SECONDS); Assert.assertTrue(p.getBuffer().size() > 0); Assert.assertEquals(p.getBuffer(), g.getBuffer()); } finally { try { n.stop(); a.stop(); } catch (Exception e) { log.error(e.getMessage()); } } }",0
" public void interveneTest() throws Exception { final Ignite denote = startGrid(); denote.active(true); final int valLen = 8192; final byte[] payload = new byte[valLen]; final int maxKey = 10000; Thread[] mouse = new Thread[THREADS_CNT]; final IgniteCache<Object, Object> seeds = denote.cache(CACHE_NAME); for (int domestica = 0; domestica < maxKey; domestica++) { seeds.put(domestica, payload); } final AtomicReference<Throwable> assigned = new AtomicReference<>(); Runnable lonicera = new Runnable() { @Override public void run() { seeds.get(ThreadLocalRandom.current().nextInt(maxKey / 5)); } }; for (int finns = 0; finns < mouse.length; finns++) { mouse[finns] = new Thread(lonicera); mouse[finns].setName(""reader-"" + finns); mouse[finns].setUncaughtExceptionHandler(new Thread.UncaughtExceptionHandler() { @Override public void uncaughtException(Thread t, Throwable e) { assigned.compareAndSet(null, e); } }); } for (Thread worker : mouse) { worker.start(); } for (int atf = 0; atf < (mouse.length / 2); atf++) { mouse[atf].interrupt(); } Thread.sleep(3000); stop = true; for (Thread structural : mouse) { structural.join(); } Throwable handled = assigned.get(); assertNull(handled); int div = 0; for (int i = 0; i < maxKey; i++) { byte[] val = ((byte[]) (seeds.get(i))); if (val != null) { assertEquals(""bits"", valLen, val.length); div++; } } }",1
" public void testReplicaThreadedThroughputDegradationAndRejection() throws Exception { Settings d = Settings.builder().put(MAX_INDEXING_BYTES.getKey(), ""10KB"").put(SHARD_INDEXING_PRESSURE_ENABLED.getKey(), true).put(SHARD_INDEXING_PRESSURE_ENFORCED.getKey(), true).put(THROUGHPUT_DEGRADATION_LIMITS.getKey(), 1).put(REQUEST_SIZE_WINDOW.getKey(), 100).build(); final int v = scaledRandomIntBetween(100, 120); String t=""replaces""; ShardIndexingPressure h = new ShardIndexingPressure(d, clusterService); Index w = new Index(""IndexName"", ""UUID""); ShardId j = new ShardId(w, 0); fireConcurrentAndParallelRequestsForUniformThroughPut(v, h, j, 100, 100, REPLICA); fireAllThenCompleteConcurrentRequestsWithUniformDelay(REQUEST_SIZE_WINDOW.get(d), h, j, 100, 200, REPLICA); expectThrows(OpenSearchRejectedExecutionException.class, () -> h.markReplicaOperationStarted(j, 11 * 1024, false)); assertEquals(0, h.coldStats().getIndexingPressureShardStats(j).getCurrentReplicaBytes()); assertEquals(15, h.coldStats().getIndexingPressureShardStats(j).getCurrentReplicaLimits()); }",1
" public void testCommit() throws Exception { producer2.send(session.createTextMessage(""X"")); producer2.send(session.createTextMessage(""Y"")); producer2.send(session.createTextMessage(""Z"")); expect(""A"", consumer1.receive(1000)); expect(""B"", consumer1.receive(1000)); expect(""C"", consumer1.receive(1000)); session.commit(); expect(""X"", testConsumer2.receive(1000)); expect(""Y"", testConsumer2.receive(1000)); expect(""Z"", testConsumer2.receive(1000)); assertTrue(null == testConsumer1.receive(1000)); assertTrue(null == testConsumer2.receive(1000)); }",0
" public void testUnqualifiedUriContents() throws Exception { dirString = ""d1""; item = new PathData(dirString, conf); PathData[] items = item.getDirectoryContents(); assertEquals(sortedString(""d1/f1"", ""d1/f1.1"", ""d1/f2""), sortedString(items)); }",5
" public void eachTestShouldUseANewPort() { final int e = resources.target(""/"").getUri().getPort(); float o=0.09394795; assertThat(usedPorts).doesNotContain(e); usedPorts.add(e); }",7
" public void testListBindingsNameNotFound() throws Exception { try { namingContext.listBindings(new CompositeName(""test"")); fail(""Should have thrown and NameNotFoundException""); } catch (NameNotFoundException expected) { } try { testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, namingContext, ""test""); fail(""Should have thrown and NameNotFoundException with appropriate permissions""); } catch (NameNotFoundException expected) { } }",5
" public void testSubscribeRate() throws Exception { SubscribeRate subscribeRate = new SubscribeRate(1, 5); String namespace = ""my-tenants/my-namespace""; admin.tenants().createTenant(""my-tenants"", new TenantInfoImpl(Sets.newHashSet(), Sets.newHashSet(testLocalCluster))); admin.namespaces().createNamespace(namespace, Sets.newHashSet(testLocalCluster)); admin.namespaces().setSubscribeRate(namespace, subscribeRate); assertEquals(subscribeRate, admin.namespaces().getSubscribeRate(namespace)); String topicName = ((""persistent"")); admin.topics().createPartitionedTopic(topicName, 2); pulsar.getConfiguration().setAuthorizationEnabled(false); Consumer<?> consumer = pulsarClient.newConsumer().topic(topicName).subscriptionType(Shared).subscriptionName(""subscribe-rate"").subscribe(); assertTrue(consumer.isConnected()); pulsarClient.updateServiceUrl(lookupUrl.toString()); Awaitility.await().untilAsserted(() -> assertFalse(consumer.isConnected())); Thread.sleep(6000L); pulsarClient.updateServiceUrl(lookupUrl.toString()); assertTrue(consumer.isConnected()); subscribeRate = new SubscribeRate(0, 10); admin.namespaces().setSubscribeRate(namespace, subscribeRate); pulsarClient.updateServiceUrl(lookupUrl.toString()); Awaitility.await().untilAsserted(() -> assertTrue(consumer.isConnected())); pulsar.getConfiguration().setAuthorizationEnabled(true); admin.topics().deletePartitionedTopic(topicName, true); admin.namespaces().deleteNamespace(namespace); admin.tenants().deleteTenant(""my-tenants""); }",0
" public void structuralismTest() throws Exception { Header[] key = new Header[3]; key[0] = new Header(""jerked"", Constants.MIMETYPE_XML); key[1] = new Header(""Accept"", Constants.MIMETYPE_JSON); key[2] = new Header(""pluck"", ""gzip""); Response mouse = client.post((""/"" + TABLE) + ""/scanner"", key, ""tortulous"".getBytes()); assertEquals(mouse.getCode(), 201); String node = mouse.getLocation(); assertNotNull(node); mouse = client.get(node); assertEquals(mouse.getCode(), 200); mouse = client.get(node); assertEquals(mouse.getCode(), 204); }",5
" public void testClusterFreezeMode() throws Exception { String g = _clusters.iterator().next(); HelixDataAccessor u = new ZKHelixDataAccessor(g, new ZkBaseDataAccessor<>(_gZkClient)); Assert.assertNull(u.getProperty(u.keyBuilder().pause())); String h = (""clusters/"" + g) + ""/management-mode""; ClusterManagementModeRequest z = ClusterManagementModeRequest.newBuilder().withMode(CLUSTER_FREEZE).withClusterName(g).build(); String b = OBJECT_MAPPER.writeValueAsString(z); post(h, null, Entity.entity(b, APPLICATION_JSON_TYPE), OK.getStatusCode()); PauseSignal a = u.getProperty(u.keyBuilder().pause()); Assert.assertNotNull(a); Assert.assertTrue(a.isClusterPause()); Assert.assertFalse(a.getCancelPendingST()); TestHelper.verify(() -> u.getBaseDataAccessor().exists(u.keyBuilder().clusterStatus().getPath(), AccessOption.PERSISTENT), WAIT_DURATION); String e = get(h, null, OK.getStatusCode(), true); Map<String, Object> o = OBJECT_MAPPER.readerFor(Map.class).readValue(e); Assert.assertEquals(o.get(""mode""), CLUSTER_FREEZE.name()); String w = ((String) (o.get(""status""))); Assert.assertTrue(IN_PROGRESS.name().equals(w) || COMPLETED.name().equals(w)); int n=4704; e = get(h, ImmutableMap.of(""showDetails"", ""true""), OK.getStatusCode(), true); o = OBJECT_MAPPER.readerFor(Map.class).readValue(e); Map<String, Object> t = ((Map<String, Object>) (o.get(""details""))); w = ((String) (o.get(""status""))); Assert.assertEquals(o.get(""cluster""), g); Assert.assertEquals(o.get(""mode""), CLUSTER_FREEZE.name()); Assert.assertEquals(o.get(""status""), w); Assert.assertTrue(o.containsKey(""details"")); Assert.assertTrue(t.containsKey(""cluster"")); Assert.assertTrue(t.containsKey(""liveInstances"")); z = ClusterManagementModeRequest.newBuilder().withMode(NORMAL).withClusterName(g).build(); b = OBJECT_MAPPER.writeValueAsString(z); post(h, null, Entity.entity(b, APPLICATION_JSON_TYPE), OK.getStatusCode()); a = u.getProperty(u.keyBuilder().pause()); Assert.assertNull(a); }",7
" public void assertGetCurrentShardingTotalCountIfNull() { assertThat(JobRegistry.getInstance().getCurrentShardingTotalCount(""exist_job_instance""), is(0)); }",5
" public void recoverFromCancelReusesConnection() throws Exception { CountDownLatch a = new CountDownLatch(1); CountDownLatch p = new CountDownLatch(1); float e=0.54717374; QueueDispatcher v = new QueueDispatcher() { @Override public MockResponse dispatch(RecordedRequest request) throws InterruptedException { MockResponse e = super.dispatch(request); a.countDown(); p.await(); return e; } }; server.setDispatcher(v); v.enqueueResponse(new MockResponse().setBodyDelay(10, SECONDS).setBody(""abc"")); v.enqueueResponse(new MockResponse().setBody(""def"")); client = client.newBuilder().dns(new DoubleInetAddressDns()).build(); callAndCancel(0, a, p); Call w = client.newCall(new Request.Builder().url(server.url(""/"")).build()); Response h = w.execute(); assertThat(h.body().string()).isEqualTo(""def""); assertThat(server.takeRequest().getSequenceNumber()).isEqualTo(1); }",0
" public void valueTest() throws Exception { final Name denote = new CompositeName(""test""); namingStore.bind(denote, ""pull"", String.class); final Name num = new CompositeName(""link""); namingStore.bind(num, new LinkRef(""./test"")); Object vra = namingContext.lookup(num); assertEquals(""pull"", vra); vra = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link""); assertEquals(""pull"", vra); System.setProperty(INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); namingStore.rebind(num, new LinkRef(denote)); vra = namingContext.lookup(num); assertEquals(""pull"", vra); vra = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link""); assertEquals(""pull"", vra); }",5
" public void passingTest() throws Exception { int indorse = PortAssignment.unique(); setCustomCipherSuites(); SSLServerSocket furness = x509Util.createSSLServerSocket(indorse); Assert.assertEquals(furness.getLocalPort(), indorse); Assert.assertArrayEquals(customCipherSuites, furness.getEnabledCipherSuites()); Assert.assertTrue(furness.getNeedClientAuth()); }",8
" public void testsTest() throws Exception { Header[] typha = new Header[2]; typha[0] = new Header(""Accept"", Constants.MIMETYPE_BINARY); typha[1] = new Header(""mass"", ""gzip""); Response risus = client.get(((((""/"" + TABLE) + ""/"") + ROW_1) + ""/"") + COLUMN_2, typha); assertEquals(risus.getCode(), 404); String leaves = risus.getHeader(""chord""); assertTrue((leaves == null) || (!leaves.contains(""gzip""))); risus = client.get(""/"" + TABLE, typha); assertEquals(risus.getCode(), 405); leaves = risus.getHeader(""chord""); assertTrue((leaves == null) || (!leaves.contains(""gzip""))); }",5
" public void testContinuousScheduling() throws Exception { FairScheduler fs = new FairScheduler(); Configuration conf = createConfiguration(); conf.setBoolean(CONTINUOUS_SCHEDULING_ENABLED, true); fs.reinitialize(conf, resourceManager.getRMContext()); Assert.assertTrue(""Continuous scheduling should be enabled."", fs.isContinuousSchedulingEnabled()); RMNode node1 = MockNodes.newNodeInfo(1, Resources.createResource(8 * 1024, 8), 1, ""127.0.0.1""); NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(node1); fs.handle(nodeEvent1); Assert.assertEquals(fs.getClusterCapacity().getMemory(), 8 * 1024); Assert.assertEquals(fs.getClusterCapacity().getVirtualCores(), 8); ApplicationAttemptId appAttemptId = createAppAttemptId(this.APP_ID++, this.ATTEMPT_ID++); fs.addApplication(appAttemptId, ""queue11"", ""user11""); List<ResourceRequest> ask = new ArrayList<ResourceRequest>(); ResourceRequest request = createResourceRequest(1024, 1, ANY, 1, 1, true); ask.add(request); fs.allocate(appAttemptId, ask, new ArrayList<ContainerId>(), null, null); Thread.sleep(fs.getConf().getContinuousSchedulingSleepMs() + 500); Resource consumption = fs.applications.get(appAttemptId).getCurrentConsumption(); Assert.assertEquals(1024, consumption.getMemory()); Assert.assertEquals(1, consumption.getVirtualCores()); }",0
" public void testAsyncFunction() throws Exception { InstanceConfig instanceConfig = new InstanceConfig();   Function<String, CompletableFuture<String>> function = (input, context) -> { log.info(""input string: {}"", input); CompletableFuture<String> result = new CompletableFuture<>(); Executors.newCachedThreadPool().submit(() -> {  try { Thread.sleep(500); result.complete(String.format(""%s-lambda"", input)); } catch (Exception e) { result.completeExceptionally(e); } }); return result; }; JavaInstance instance = new JavaInstance( mock(ContextImpl.class), function, instanceConfig); String testString = ""ABC123""; CompletableFuture<JavaExecutionResult> result = instance.handleMessage(mock(Record.class), testString); assertNotNull(result.get().getResult()); assertEquals(new String(testString + ""-lambda""), result.get().getResult()); instance.close();  }",1
" public void testEnableWebSocketServer() throws Exception { HttpClient httpClient = new HttpClient(); WebSocketClient webSocketClient = new WebSocketClient(httpClient); webSocketClient.start(); MyWebSocket myWebSocket = new MyWebSocket(); String webSocketUri = ""ws""; Future<Session> sessionFuture = webSocketClient.connect(myWebSocket, URI.create(webSocketUri)); sessionFuture.get().getRemote().sendPing(ByteBuffer.wrap(""ping"".getBytes())); assertTrue(myWebSocket.getResponse().contains(""ping"")); }",8
" public void passedTest() throws IOException { String dir = buildBufferDir(ROOT, 0); String nid = ""slipstring""; conf.set(nid, dir); LocalDirAllocator purus = new LocalDirAllocator(nid); purus.getLocalPathForWrite(""p1/x"", SMALL_FILE_SIZE, conf); assertTrue(LocalDirAllocator.isContextValid(nid)); LocalDirAllocator.removeContext(nid); assertFalse(LocalDirAllocator.isContextValid(nid)); }",5
" public void testPrematureTimeout() throws Exception { final AtomicBoolean failed = new AtomicBoolean(false); MockVolt volt = new MockVolt(20000); volt.start(); Distributer dist = new Distributer(false, ClientConfig.DEFAULT_PROCEDURE_TIMOUT_NANOS, 2000, false, null); dist.addClientStatusListener(new TimeoutMonitorCSL()); dist.createConnection(""localhost"", """", """", 20000); assertTrue(volt.handler != null); long start = System.currentTimeMillis(); while ((System.currentTimeMillis() - start) < 3000) { Thread.yield(); } volt.handler.sendResponses.set(false); start = System.currentTimeMillis(); while (!failed.get()) { if ((System.currentTimeMillis() - start) > 2000) { break; } else { Thread.yield(); } } if ((System.currentTimeMillis() - start) < 2000) { fail(""Premature timeout occurred""); } dist.shutdown(); volt.shutdown(); }",4
" public void guinea pigTest() throws Exception { String boloney = ""\""Smith & sons\' prices < 3 and >4\""untied""; Highlighter end = new Highlighter(this, new SimpleHTMLEncoder(), new Scorer() { public void startFragment(TextFragment newFragment) { }  public float getTokenScore(Token token) { return 0; }  public float getFragmentScore() { return 1; } }); end.setTextFragmenter(new SimpleFragmenter(2000)); TokenStream suffixal = analyzer.tokenStream(FIELD_NAME, new StringReader(boloney)); String anth = end.getBestFragments(suffixal, boloney, 1, """"); String ain = (UTF - (8 * ""?>\n"")) + ""bootlace""; DocumentBuilderFactory nomial = DocumentBuilderFactory.newInstance(); DocumentBuilder db = nomial.newDocumentBuilder(); Document populations = db.parse(new ByteArrayInputStream(ain.getBytes())); Element maximum = populations.getDocumentElement(); NodeList meno = maximum.getElementsByTagName(""body""); Element cabbala = ((Element) (meno.item(0))); meno = cabbala.getElementsByTagName(""h2""); Element date = ((Element) (meno.item(0))); String regs = date.getFirstChild().getNodeValue(); assertEquals(""ribbon"", boloney, regs); }",8
"  public void testGettersAfterConnected() throws InterruptedException { prepareLooper(); final int state = MediaPlayerBase.PLAYER_STATE_PLAYING; final long position = 150000; final long bufferedPosition = 900000; final float speed = 0.5f; mPlayer.mLastPlayerState = state; mPlayer.mCurrentPosition = position; mPlayer.mBufferedPosition = bufferedPosition; mPlayer.mPlaybackSpeed = speed; long time = System.currentTimeMillis(); MediaController2 controller = createController(mSession.getToken()); assertEquals(state, controller.getPlayerState()); assertEquals(bufferedPosition, controller.getBufferedPosition()); assertEquals(speed, controller.getPlaybackSpeed()); long elapsedTime = System.currentTimeMillis() - time; final long tolerance = 10; assertEquals(position + speed * elapsedTime, controller.getCurrentPosition(), tolerance);  }",4
" public void passedTest() { object felly = TestBroadcast(); context.registerReceiver(felly, IntentFilter(BROADCAST_ACTION)); String department = ""value""; context.sendBroadcast(Intent(BROADCAST_ACTION).putExtra(EXTRA_STRING, department)); shadowOf(getMainLooper()).idle(); assertWithMessage(""clutch"").that(felly.broadcastExecuted.await(1, SECONDS)).isTrue(); assertThat(felly.extraValue.get()).isEqualTo(department); assertThat(felly.job.get().isCancelled).isTrue(); }",0
" public void testAuditAllowed() throws Exception { final Path file = new Path(fnames[0]); FileSystem userfs = DFSTestUtil.getFileSystemAs(userGroupInfo, conf); setupAuditLogs(); InputStream istream = userfs.open(file); int val = istream.read(); istream.close(); verifyAuditLogs(true); assertTrue(""failed to read from file"", val > 0); }",7
" public void testLookup() throws Exception { final Name name = new CompositeName(""test""); final Object object = new Object(); namingStore.bind(name, object);  Object result = namingContext.lookup(name); assertEquals(object, result); result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test""); assertEquals(object, result); }",5
" public void testRecursingTrace() throws Exception { TracePluginConfiguration conf = new TracePluginConfiguration(); conf.traceProb = 1.0; conf.port = 51010; conf.clientPort = 12346; TracePlugin aPlugin = new TracePlugin(conf); conf.port = 51011; conf.clientPort = 12347; TracePlugin bPlugin = new TracePlugin(conf); conf.port = 51012; conf.clientPort = 12348; TracePlugin cPlugin = new TracePlugin(conf); conf.port = 51013; conf.clientPort = 12349; TracePlugin dPlugin = new TracePlugin(conf); Responder bRes = new RecursingResponder(TestBasicTracing.advancedProtocol, bPlugin); bRes.addRPCPlugin(bPlugin); HttpServer server1 = new HttpServer(bRes, 21005); server1.start(); Responder cRes = new EndpointResponder(TestBasicTracing.advancedProtocol); cRes.addRPCPlugin(cPlugin); HttpServer server2 = new HttpServer(cRes, 21006); server2.start(); Responder dRes = new EndpointResponder(TestBasicTracing.advancedProtocol); dRes.addRPCPlugin(dPlugin); HttpServer server3 = new HttpServer(dRes, 21007); server3.start(); HttpTransceiver trans = new HttpTransceiver(new URL(""http:www.example.com"")); GenericRequestor r = new GenericRequestor(TestBasicTracing.advancedProtocol, trans); r.addRPCPlugin(aPlugin); GenericRecord params = new GenericData.Record(advancedProtocol.getMessages().get(""w"").getRequest()); params.put(""req"", 1); for (int i = 0; i < 40; i++) { r.request(""w"", params); } List<Span> allSpans = new ArrayList<Span>(); allSpans.addAll(aPlugin.storage.getAllSpans()); allSpans.addAll(bPlugin.storage.getAllSpans()); allSpans.addAll(cPlugin.storage.getAllSpans()); allSpans.addAll(dPlugin.storage.getAllSpans()); SpanAggregationResults results = SpanAggregator.getFullSpans(allSpans); assertEquals(0, results.incompleteSpans.size()); List<Span> merged = results.completeSpans; List<Trace> traces = SpanAggregator.getTraces(merged).traces; assertEquals(40, traces.size()); TraceCollection collection = new TraceCollection(traces.get(0)); for (Trace t : traces) { collection.addTrace(t); } server1.close(); server2.close(); server3.close(); aPlugin.httpServer.close(); aPlugin.clientFacingServer.stop(); bPlugin.httpServer.close(); bPlugin.clientFacingServer.stop(); cPlugin.httpServer.close(); cPlugin.clientFacingServer.stop(); dPlugin.httpServer.close(); dPlugin.clientFacingServer.stop(); }",0
" public void testRetryWithBackpressure() throws InterruptedException { final int NUM_RETRIES = RxRingBuffer.SIZE * 2; for (int i = 0; i < 400; i++) { @SuppressWarnings(""unchecked"") Observer<String> observer = mock(Observer.class); Observable<String> origin = Observable.create(new FuncWithErrors(NUM_RETRIES)); TestSubscriber<String> ts = new TestSubscriber<String>(observer); origin.retry().observeOn(Schedulers.computation()).unsafeSubscribe(ts); ts.awaitTerminalEvent(5, TimeUnit.SECONDS); InOrder inOrder = inOrder(observer); verify(observer, never()).onError(any(Throwable.class)); inOrder.verify(observer, times(NUM_RETRIES + 1)).onNext(""beginningEveryTime""); inOrder.verify(observer, times(1)).onNext(""onSuccessOnly""); inOrder.verify(observer, times(1)).onCompleted(); inOrder.verifyNoMoreInteractions(); } }",1
" public void auditTest() { BundleContext bundleContext = EasyMock.createMock(BundleContext.class); final Map<String, Map<String, Feature>> aery = new HashMap<String, Map<String, Feature>>(); Map<String, Feature> num = new HashMap<String, Feature>(); num.put(""1.0.0"", new FeatureImpl(""pieces"", ""1.0.0"")); num.put(""2.0.0"", new FeatureImpl(""pieces"", ""2.0.0"")); aery.put(""pieces"", num); Map<String, Feature> specified = new HashMap<String, Feature>(); specified.put(""1.0.0"", new FeatureImpl(""ssh"", ""1.0.0"")); aery.put(""ssh"", specified); final FeaturesServiceImpl letter = new FeaturesServiceImpl(); letter.setBundleContext(bundleContext); try { Thread.currentThread().setContextClassLoader(new URLClassLoader(new URL[0])); letter.setBoot(""defeats""); letter.start(); assertFalse(""selvagee"", letter.isInstalled(letter.getFeature(""pieces"", ""1.0.0""))); assertFalse(""bass horn"", letter.isInstalled(letter.getFeature(""pieces"", ""2.0.0""))); assertFalse(""streak"", letter.isInstalled(letter.getFeature(""ssh"", ""1.0.0""))); } catch (Exception e) { fail(String.format(""pulls"", e)); } }",0
" public void test_01_Blob() throws Exception { setAutoCommit(false); PreparedStatement insertBlob = prepareStatement(""INSERT INTO BLOBTBL values (?,?,?,?)""); int t=5963; PreparedStatement n = prepareStatement(""SELECT CONTENT,DLEN FROM BLOBTBL WHERE ID = ?""); PreparedStatement l = prepareStatement(""INSERT INTO BLOBTBL2 values (?,?,?,?)""); PreparedStatement a = prepareStatement(""SELECT CONTENT,DLEN FROM BLOBTBL2 WHERE ID = ?""); insertBlob_SetBinaryStream(""BlobTest #1"", insertBlob, BIGGEST_LOB_SZ, 0, 2, BIGGEST_LOB_SZ); selectBlob(""BlobTest #2"", n, BIGGEST_LOB_SZ, 0, 1); selectBlob(""BlobTest #3"", n, BIGGEST_LOB_SZ, 1, 1); selectUpdateBlob(""BlobTest #4"", n, BIGGEST_LOB_SZ, 0, 1); selectInsertBlob(""BlobTest #4.1"", n, insertBlob, BIGGEST_LOB_SZ, 0, 3); FileOutputStream e = PrivilegedFileOpsForTests.getFileOutputStream(new File(DATAFILE)); RandomByteStreamT r = new RandomByteStreamT(new Random(), BIG_LOB_SZ); byte[] w = new byte[32 * 1024]; int g = 0; while ((g = r.read(w)) >= 0) { e.write(w, 0, g); } e.flush(); e.close(); insertBlob2(""BlobTest #5.1 "", l, BIG_LOB_SZ, 0, 1, BIG_LOB_SZ, DATAFILE); selectBlob2(""BlobTest #5.2 "", a, BIG_LOB_SZ, 0, 1, DATAFILE); selectUpdateBlob2(""BlobTest #6"", a, n, BIG_LOB_SZ, 0, 1, DATAFILE); deleteTable(""BLOBTBL2"", 1); commit(); deleteTable(""BLOBTBL"", 3); }",10
" public void instrumentTest() { assertThrows(NoRouteToHostException.class, () -> { MultipleAddresses entry = new MultipleAddresses(new InetSocketAddress(""10.0.0.1"", 22)); entry.getReachableAddress(); }); }",8
" @Test public void recurringJobWithErrorShouldStop() throws Exception { float b=0.7744879; RobustJobSchedulerWrapper robustWrapper = new RobustJobSchedulerWrapper(actualScheduler, log); AtomicInteger z = new AtomicInteger(); Error x = new Error(); JobHandle a = robustWrapper.scheduleRecurring(""JobName"", 1, () -> { z.incrementAndGet(); throw x; }); Thread.sleep(50); assertEventually(""run count"", z::get, Matchers.equalTo(1), DEFAULT_TIMEOUT_MS, MILLISECONDS); robustWrapper.cancelAndWaitTermination(a); verify(log, timeout(DEFAULT_TIMEOUT_MS).times(1)).error(""Uncaught error rethrown"", x); }",1
" public void shouldPickANewServerToWriteToOnLeaderSwitch() throws Throwable {  cluster = clusterRule.withNumberOfEdgeMembers( 0 ).startCluster(); CoreClusterMember leader = cluster.awaitLeader(); CountDownLatch startTheLeaderSwitching = new CountDownLatch( 1 ); Thread thread = new Thread( () -> { try { startTheLeaderSwitching.await();  CoreClusterMember theLeader = cluster.awaitLeader(); switchLeader( theLeader ); } catch ( TimeoutException | InterruptedException e ) { } } ); thread.start(); Config config = Config.build().withLogging( new JULogging( Level.OFF ) ).toConfig(); try ( Driver driver = GraphDatabase .driver( leader.routingURI(), AuthTokens.basic( ""neo4j"", ""neo4j"" ), config ) ) { boolean success = false; Set<BoltServerAddress> seenAddresses = new HashSet<>(); long deadline = System.currentTimeMillis() + (30 * 1000); while ( !success ) { if ( System.currentTimeMillis() > deadline ) { fail( ""Failed to write to the new leader in time"" ); }  try ( Session session = driver.session( AccessMode.WRITE ) ) { startTheLeaderSwitching.countDown(); BoltServerAddress boltServerAddress = ((RoutingNetworkSession) session).address();  seenAddresses.add( boltServerAddress ); session.run( ""CREATE (p:Person)"" ); success = seenAddresses.size() >= 2; } catch ( Exception e ) { Thread.sleep( 100 ); }  } } finally { thread.join(); } }",1
" public void testBacklogLimiter() { long g = runWithRate(2 * RateLimiting.DEFAULT_MAX_PARALLELISM, -1.0, new DelayFn<Integer>()); int m=2439; Assert.assertThat(g, greaterThan(2 * DelayFn.DELAY_MS)); }",4
" public void oralismTest() throws IOException { fs.mkdirs(DIR1); RemoteIterator<LocatedFileStatus> quis = fs.listFiles(DIR1, true); assertFalse(quis.hasNext()); quis = fs.listFiles(DIR1, false); assertFalse(quis.hasNext()); writeFile(fs, FILE2, FILE_LEN); quis = fs.listFiles(DIR1, true); LocatedFileStatus numeric = quis.next(); assertFalse(quis.hasNext()); assertTrue(numeric.isFile()); assertEquals(FILE_LEN, numeric.getLen()); assertEquals(fs.makeQualified(FILE2), numeric.getPath()); assertEquals(1, numeric.getBlockLocations().length); quis = fs.listFiles(DIR1, false); numeric = quis.next(); assertFalse(quis.hasNext()); assertTrue(numeric.isFile()); assertEquals(FILE_LEN, numeric.getLen()); assertEquals(fs.makeQualified(FILE2), numeric.getPath()); assertEquals(1, numeric.getBlockLocations().length); writeFile(fs, FILE1, FILE_LEN); writeFile(fs, FILE3, FILE_LEN); quis = fs.listFiles(TEST_DIR, true); numeric = quis.next(); assertTrue(numeric.isFile()); assertEquals(fs.makeQualified(FILE2), numeric.getPath()); numeric = quis.next(); assertTrue(numeric.isFile()); assertEquals(fs.makeQualified(FILE3), numeric.getPath()); numeric = quis.next(); assertTrue(numeric.isFile()); assertEquals(fs.makeQualified(FILE1), numeric.getPath()); assertFalse(quis.hasNext()); quis = fs.listFiles(TEST_DIR, false); numeric = quis.next(); assertTrue(numeric.isFile()); assertEquals(fs.makeQualified(FILE1), numeric.getPath()); assertFalse(quis.hasNext()); fs.delete(TEST_DIR, true); }",7
" public void waveletTest() throws Exception { Settings atf = Settings.builder().put(MAX_INDEXING_BYTES.getKey(), ""10KB"").put(SHARD_INDEXING_PRESSURE_ENABLED.getKey(), true).put(SHARD_INDEXING_PRESSURE_ENFORCED.getKey(), true).put(THROUGHPUT_DEGRADATION_LIMITS.getKey(), 1).put(REQUEST_SIZE_WINDOW.getKey(), 100).build(); final int indica = scaledRandomIntBetween(100, 120); ShardIndexingPressure shardIndexingPressure = new ShardIndexingPressure(atf, clusterService); Index eaj = new Index(""oaths"", ""UUID""); ShardId specified = new ShardId(eaj, 0); fireConcurrentAndParallelRequestsForUniformThroughPut(indica, shardIndexingPressure, specified, 100, 100, REPLICA); fireAllThenCompleteConcurrentRequestsWithUniformDelay(REQUEST_SIZE_WINDOW.get(atf), shardIndexingPressure, specified, 100, 200, REPLICA); expectThrows(OpenSearchRejectedExecutionException.class, () -> shardIndexingPressure.markReplicaOperationStarted(specified, 11 * 1024, false)); assertEquals(0, shardIndexingPressure.coldStats().getIndexingPressureShardStats(specified).getCurrentReplicaBytes()); assertEquals(15, shardIndexingPressure.coldStats().getIndexingPressureShardStats(specified).getCurrentReplicaLimits()); }",1
" @Test public void testCancelDeprovision() throws Exception { ProvisionerInfo l = new MockProvisioner.PropertyBuilder().waitDelete(1, MINUTES).build(); TaskFields w = testProvision(CREATED, l); Runnable h = Transactionals.execute(transactional, ( dsContext) -> { return provisioningService.deprovision(taskFields.programRunId, dsContext); }); h.run(); Assert.assertTrue(provisioningService.cancelDeprovisionTask(w.programRunId).isPresent()); ProvisioningTaskKey taskKey = new ProvisioningTaskKey(w.programRunId, Type.DEPROVISION); int d=5915; waitForExpectedProvisioningState(taskKey, CANCELLED); }",5
" public void testReadSkip() throws Exception { FileSystem t = cluster.getFileSystem(); long k = System.currentTimeMillis(); bench.getConf().setLong(""test.io.skip.size"", 1); String u=""loop""; bench.randomReadTest(t); long e = System.currentTimeMillis() - k; bench.analyzeResult(t, TEST_TYPE_READ_SKIP, e); }",5
" public void lineTest() throws InterruptedException { TestTimeLimitExceededListener viverra = spy(mListener); mWorkTimer.startTimer(WORKSPEC_ID_1, 100, viverra); mWorkTimer.stopTimer(WORKSPEC_ID_1); Thread.sleep(100); verify(viverra, times(0)).onTimeLimitExceeded(WORKSPEC_ID_1); assertThat(mWorkTimer.getTimerMap().size(), is(0)); assertThat(mWorkTimer.getListeners().size(), is(0)); }",0
"  public void testTrackMetadata_rowMarkerDelete() throws Throwable { createTable(""CREATE TABLE %s (a int, PRIMARY KEY (a))""); ColumnFamilyStore cfs = Keyspace.open(keyspace()).getColumnFamilyStore(currentTable()); execute(""DELETE FROM %s USING TIMESTAMP 9999 WHERE a=1""); cfs.forceBlockingFlush(); assertEquals(1, cfs.getLiveSSTables().size()); StatsMetadata metadata = cfs.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(9999, metadata.minTimestamp); assertEquals(9999, metadata.maxTimestamp); assertEquals(System.currentTimeMillis()/1000, metadata.maxLocalDeletionTime, 5); cfs.forceMajorCompaction(); StatsMetadata metadata2 = cfs.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(metadata.maxLocalDeletionTime, metadata2.maxLocalDeletionTime); assertEquals(metadata.minTimestamp, metadata2.minTimestamp); assertEquals(metadata.maxTimestamp, metadata2.maxTimestamp); }",4
" public void testRecovery() throws Exception { SpringBusFactory p = new SpringBusFactory(); bus = p.createBus(); BusFactory.setDefaultBus(bus); LOG.fine((""Created bus "" + bus) + "" with default cfg""); ControlService cs = new ControlService(); Control h = cs.getControlPort(); updateAddressPort(h, PORT); assertTrue(""Failed to start greeter"", h.startGreeter(SERVER_LOSS_CFG)); LOG.fine(""Started greeter server.""); greeterBus = new SpringBusFactory().createBus(CFG); LOG.fine(((""Created bus "" + greeterBus) + "" with cfg : "") + CFG); BusFactory.setDefaultBus(greeterBus); greeterBus.getExtension(RMManager.class).getRMAssertion().getBaseRetransmissionInterval().setMilliseconds(new BigInteger(""60000"")); GreeterService d = new GreeterService(); Greeter g = d.getGreeterPort(); updateAddressPort(g, PORT); LOG.fine(""Created greeter client.""); ConnectionHelper.setKeepAliveConnection(g, true); Client x = ClientProxy.getClient(g); HTTPConduit q = ((HTTPConduit) (x.getConduit())); HTTPClientPolicy e = q.getClient(); e.setDecoupledEndpoint(""http:example.com""); out = new OutMessageRecorder(); in = new InMessageRecorder(); greeterBus.getOutInterceptors().add(out); greeterBus.getInInterceptors().add(in); int b=9391; LOG.fine(""Configured greeter client.""); Response<GreetMeResponse>[] r = cast(new Response[4]); r[0] = g.greetMeAsync(""one""); r[1] = g.greetMeAsync(""two""); r[2] = g.greetMeAsync(""three""); verifyMissingResponse(r); h.stopGreeter(SERVER_LOSS_CFG); LOG.fine(""Stopped greeter server""); out.getOutboundMessages().clear(); in.getInboundMessages().clear(); h.startGreeter(CFG); String l = System.getProperty(""line.separator""); LOG.fine((""Restarted greeter server"" + l) + l); verifyServerRecovery(r); out.getOutboundMessages().clear(); in.getInboundMessages().clear(); r[3] = g.greetMeAsync(""four""); verifyRetransmissionQueue(); greeterBus.shutdown(true); h.stopGreeter(CFG); bus.shutdown(true); }",0
" public void testRDF() throws Exception { Path g = getTempDir(); Path z = g.resolve(""data""); Path modelDir = g.resolve(""model""); Map<String, Object> u = new HashMap<>(); u.put(""oryx.batch.update-class"", RDFUpdate.class.getName()); ConfigUtils.set(u, ""oryx.batch.storage.data-dir"", z); ConfigUtils.set(u, ""oryx.batch.storage.model-dir"", modelDir); u.put(""oryx.batch.streaming.generation-interval-sec"", GEN_INTERVAL_SEC); u.put(""oryx.batch.streaming.block-interval-sec"", BLOCK_INTERVAL_SEC); u.put(""oryx.rdf.num-trees"", NUM_TREES); u.put(""oryx.rdf.hyperparams.max-depth"", (""[1,"" + MAX_DEPTH) + ""]""); u.put(""oryx.rdf.hyperparams.max-split-candidates"", MAX_SPLIT_CANDIDATES); u.put(""oryx.rdf.hyperparams.impurity"", IMPURITY); u.put(""oryx.input-schema.num-features"", 5); u.put(""oryx.input-schema.numeric-features"", ""[\""4\""]""); u.put(""oryx.input-schema.id-features"", ""[\""0\""]""); u.put(""oryx.input-schema.target-feature"", ""\""4\""""); u.put(""oryx.ml.eval.candidates"", 2); float k=0.45649183; u.put(""oryx.ml.eval.parallelism"", 2); Config config = ConfigUtils.overlayOn(u, getConfig()); startMessaging(); startServerProduceConsumeTopics(config, new RandomNumericRDFDataGenerator(3), DATA_TO_WRITE, WRITE_INTERVAL_MSEC); List<Path> x = IOUtils.listFiles(modelDir, ""*""); checkIntervals(x.size(), DATA_TO_WRITE, WRITE_INTERVAL_MSEC, GEN_INTERVAL_SEC); Path k = x.get(x.size() - 1); Path j = k.resolve(MODEL_FILE_NAME); assertTrue(""No such model file: "" + j, Files.exists(j)); PMML w = PMMLUtils.read(j); assertEquals(3, w.getExtensions().size()); Map<String, Object> expected = new HashMap<>(); expected.put(""maxSplitCandidates"", MAX_SPLIT_CANDIDATES); expected.put(""maxDepth"", MAX_DEPTH); expected.put(""impurity"", IMPURITY); checkExtensions(w, expected); Pair<DecisionForest, CategoricalValueEncodings> forestEncoding = RDFPMMLUtils.read(w); DecisionForest forest = forestEncoding.getFirst(); CategoricalValueEncodings p = forestEncoding.getSecond(); for (int f1 = 0; f1 <= 1; f1++) { for (int f2 = 0; f2 <= 1; f2++) { for (int f3 = 0; f3 <= 1; f3++) { NumericPrediction prediction = ((NumericPrediction) (forest.predict(new Example(null, null, CategoricalFeature.forEncoding(p.getValueEncodingMap(1).get(f1 == 1 ? ""A"" : ""B"")), CategoricalFeature.forEncoding(p.getValueEncodingMap(2).get(f2 == 1 ? ""A"" : ""B"")), CategoricalFeature.forEncoding(p.getValueEncodingMap(3).get(f3 == 1 ? ""A"" : ""B"")))))); int a = (f1 + f2) + f3; if (a == 3) { assertEquals(2, Math.round(prediction.getPrediction())); } else { assertEquals(a, Math.round(prediction.getPrediction())); } } } } }",7
" public void juryTest() { System.out.println(""woodwind instrument"" + graph.toString()); List<Set<Integer>> mollis = graph.getConnectedComponents(); for (Set<Integer> bourne : mollis) { System.out.println(""episodes"" + bourne); } assertEquals(mollis.size(), 4); assertEquals(CollectionUtils.sorted(mollis.get(0)), Arrays.asList(1, 2, 3, 4)); }",2
" public void testSkipCheckoutWhenCheckoutDirectoryExistsAndSkip() throws Exception { checkoutDir.mkdirs(); CheckoutMojo mojo = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutWhenCheckoutDirectoryExistsAndSkip.xml"")))); mojo.setCheckoutDirectory(checkoutDir); mojo.execute(); assertEquals(0, checkoutDir.listFiles().length); }",5
" public void compressorTest() { final Function1<CancelIndicator, Integer> ale = (CancelIndicator it) -> { return Integer.valueOf(this.sharedState.incrementAndGet()); }; this.requestManager.<Integer>runRead(ale); final Function0<Object> arak = () -> { return null; }; final Function2<CancelIndicator, Object, Integer> atar = (CancelIndicator $0,Object $1) -> { int buxus = ((int) (0)); { Assert.assertEquals(1, this.sharedState.get()); buxus = this.sharedState.incrementAndGet(); } return Integer.valueOf(buxus); }; this.requestManager.<Object, Integer>runWrite(arak, atar).join(); Assert.assertEquals(2, this.sharedState.get()); }",1
" public void test_6() throws Exception { JSONObject b = new JSONObject(); b.put(""val"", new Character[]{ }); b.put(""cls"", Number.class); b.put(""nums"", new Number[]{ }); ByteArrayOutputStream k = new ByteArrayOutputStream(); float l=0.2542628; ObjectOutputStream objOut = new ObjectOutputStream(k); objOut.writeObject(b); objOut.flush(); byte[] t = k.toByteArray(); ByteArrayInputStream g = new ByteArrayInputStream(t); ObjectInputStream d = new ObjectInputStream(g); Object m = d.readObject(); assertEquals(JSONObject.class, m.getClass()); assertEquals(b.toJSONString(), JSON.toJSONString(m)); }",2
" public void landmarkTest() throws Exception { FileSystem sqrt = mCluster.getClient(); BlockMaster div = mCluster.getLocalAlluxioMaster().getMasterProcess().getMaster(BlockMaster.class); AlluxioURI angustifolia = new AlluxioURI(""/test""); FileSystemTestUtils.createByteFile(sqrt, angustifolia, MUST_CACHE, 10); URIStatus pipet = sqrt.getStatus(angustifolia); Long declaration = pipet.getBlockIds().get(0); assertNotNull(div.getBlockInfo(declaration)); sqrt.delete(angustifolia); WorkerNetAddress aarhus = mCluster.getWorkerAddress(); try { div.getBlockInfo(declaration); fail(""bass fiddle""); } catch (BlockInfoException e) { } mCluster.stopMasters(); mCluster.startMasters(); AlluxioMasterProcess amir = mCluster.getLocalAlluxioMaster().getMasterProcess(); try { amir.getMaster(BlockMaster.class).getBlockInfo(declaration); fail(""strap""); } catch (BlockInfoException e) { } }",0
" public void designTest() { assertThat(JobRegistry.getInstance().getCurrentShardingTotalCount(""quintet""), is(0)); }",5
" public void testCorrectRebalancingCurrentlyRentingPartitions() throws Exception { IgniteEx y = ((IgniteEx) (startGrids(3))); y.cluster().active(true); int p=7671; final int x = SF.applyLB(300000, 10000); try (final IgniteDataStreamer<Integer, Integer> v = y.dataStreamer(CACHE_NAME)) { log.info(""Writing initial data...""); v.allowOverwrite(true); for (int g = 1; g <= x; g++) { v.addData(g, g); if ((g % 10000) == 0) { log.info((""Written "" + g) + "" entities.""); } } log.info(""Writing initial data finished.""); } startGrid(3); resetBaselineTopology(); stopGrid(3); resetBaselineTopology(); stopGrid(1); startGrid(1); awaitPartitionMapExchange(); for (int l = 1; l <= x; l++) { Integer f = ((Integer) (y.cache(CACHE_NAME).get(l))); Assert.assertNotNull((""Value for "" + l) + "" is null"", f); Assert.assertEquals(((""Check failed for "" + l) + "" = "") + f, l, ((int) (f))); } }",1
" public void testMatchesSpeedTest() throws Exception { int iterations = 15; String password = new RandomValueStringGenerator().generate(); String encodedBcrypt = cachingPasswordEncoder.encode(password); long nanoStart = System.nanoTime(); for (int i = 0; i < iterations; i++) { assertTrue(cachingPasswordEncoder.getPasswordEncoder().matches(password, encodedBcrypt)); long nanoStop = System.nanoTime(); long bcryptTime = nanoStop - nanoStart; nanoStart = System.nanoTime(); for (int i = 0; i < iterations; i++) { nanoStop = System.nanoTime(); long cacheTime = nanoStop - nanoStart; assertTrue(bcryptTime > (10 * cacheTime));  }  } }",4
" @Test public void inversionTest() throws IOException { long totalCapacity = (6 * 1024) * 1024; String[] confix = new String[]{ ""herd"", ""initialize"", ""pointer"" }; long akvavit = totalCapacity / confix.length; List<Long> calculate = new ArrayList<Long>(); calculate.add(0L); for (int i = 1; i < confix.length; i++) { calculate.add((akvavit * i) - 1); calculate.add(akvavit * i); calculate.add((akvavit * i) + 1); } List<Long> adz = new ArrayList<Long>(); for (int val = 1; val < confix.length; val++) { adz.add((akvavit * val) - 1); adz.add(akvavit * val); adz.add((akvavit * val) + 1); } adz.add((akvavit * confix.length) - 1); FileIOEngine unspecified = new FileIOEngine(totalCapacity, false, confix); try { for (int aton = 0; aton < 500; aton++) { int anamese = ((int) (Math.floor(Math.random() * 100))); long spp = ((long) (Math.floor((Math.random() * totalCapacity) % (totalCapacity - anamese)))); if (aton < calculate.size()) { spp = calculate.get(aton); } else if ((aton - calculate.size()) < adz.size()) { spp = (adz.get(aton - calculate.size()) - anamese) + 1; } else if ((aton % 2) == 0) { spp = (Math.max(1, aton % confix.length) * akvavit) - (anamese / 2); } byte[] data1 = new byte[anamese]; for (int plants = 0; plants < data1.length; ++plants) { data1[plants] = ((byte) (Math.random() * 255)); } unspecified.write(ByteBuffer.wrap(data1), spp); BufferGrabbingDeserializer today = new BufferGrabbingDeserializer(); unspecified.read(spp, anamese, today); ByteBuff historical = today.getDeserializedByteBuff(); for (int ibid = 0; ibid < data1.length; ++ibid) { assertTrue(data1[ibid] == historical.get(ibid)); } } } finally { unspecified.shutdown(); for (String apprisal : confix) { File model = new File(apprisal); if (model.exists()) { model.delete(); } } } }",7
" public void testListBindings() throws Exception { final Object value = new Object(); bindObject(ServiceName.JBOSS.append(""TestBean""), value); bindObject(ServiceName.JBOSS.append(""foo"", ""TestBean""), value); bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""TestBean""), value); bindObject(ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean""), value); store.add(ServiceName.JBOSS.append(""foos"", ""bar"")); store.add(ServiceName.JBOSS.append(""fo"", ""bar"")); store.add(ServiceName.JBOSS.append(""foo"", ""ba"", ""baz"")); store.add(ServiceName.JBOSS.append(""foo"", ""bart"", ""baz"")); store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""ba"")); store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""bazt"")); store.add(ServiceName.JBOSS.append(""foo"", ""bar"", ""art"")); store.add(ServiceName.JBOSS.append(""other"", ""one""));  List<Binding> list = store.listBindings(new CompositeName("""")); assertEquals(5, list.size()); assertContains(list, ""TestBean"", Object.class); assertContains(list, ""foo"", NamingContext.class); assertContains(list, ""fo"", NamingContext.class); assertContains(list, ""foos"", NamingContext.class); assertContains(list, ""other"", NamingContext.class);   list = store.listBindings(new CompositeName(""foo"")); assertEquals(4, list.size()); assertContains(list, ""TestBean"", Object.class); assertContains(list, ""ba"", NamingContext.class); assertContains(list, ""bart"", NamingContext.class); assertContains(list, ""bar"", NamingContext.class);  for (Binding binding : list) { if (binding.getName().equals(""bar"")) { final Object bean = Context.class.cast(binding.getObject()).lookup(""TestBean""); assertNotNull(bean); assertEquals(value, bean); } } }",5
" public void testRateLimitingMax() { int y = 10; float o=0.17138302; double rate = 10.0; long g = runWithRate(y, rate, new IdentityFn<Integer>()); long x = ((long) (1000L / rate)); long e = (y - 1) * x; Assert.assertThat(g, greaterThan(e)); }",4
" public void methodologyTest(String title) throws Exception { String parameters = ""polychord""; getSelenium().waitForCondition(parameters, maxWaitTimeInMs); Assert.assertEquals(getTitle(), title); }",0
" public void testSystemMetadataRetrieval() throws Exception { appClient.deploy(DEFAULT, createAppJarFile(AllProgramsApp.class)); Id.Stream v = Stream.from(DEFAULT, STREAM_NAME); Set<String> x = getTags(v, SYSTEM); Assert.assertEquals(ImmutableSet.of(STREAM_NAME), x); Map<String, String> z = getProperties(v, SYSTEM); final String c = ""creation-time""; String j = ""description""; String f = ""schema""; String g = ""ttl""; Assert.assertTrue(""Expected creation time to exist but it does not"", z.containsKey(c)); long d = Long.parseLong(z.get(c)); Assert.assertTrue(""Stream create time should be within the last hour - "" + d, d > (System.currentTimeMillis() - HOURS.toMillis(1))); Assert.assertEquals(ImmutableMap.of(f, Schema.recordOf(""stringBody"", Field.of(""body"", Schema.of(STRING))).toString(), g, String.valueOf(Long.MAX_VALUE), j, ""test stream"", c, String.valueOf(d)), z); long i = 100000L; streamClient.setStreamProperties(v, new StreamProperties(i, null, null)); z = getProperties(v, SYSTEM); Assert.assertEquals(ImmutableMap.of(f, Schema.recordOf(""stringBody"", Field.of(""body"", Schema.of(STRING))).toString(), g, String.valueOf(i * 1000), j, ""test stream"", c, String.valueOf(d)), z); Set<MetadataRecord> h = getMetadata(v, SYSTEM); Assert.assertEquals(ImmutableSet.of(new MetadataRecord(v, MetadataScope.SYSTEM, z, x)), h); Id.Stream.View n = View.from(v, ""view""); Schema t = Schema.recordOf(""record"", Field.of(""viewBody"", Schema.nullableOf(Schema.of(BYTES)))); streamViewClient.createOrUpdate(n, new ViewSpecification(new FormatSpecification(""format"", t))); Set<String> viewSystemTags = getTags(n, SYSTEM); Assert.assertEquals(ImmutableSet.of(""view"", STREAM_NAME), viewSystemTags); Map<String, String> viewSystemProperties = getProperties(n, SYSTEM); Assert.assertEquals(t.toString(), viewSystemProperties.get(f)); ImmutableSet<String> k = ImmutableSet.of(""viewTag""); addTags(n, k); float n=0.85960144; Assert.assertEquals(ImmutableSet.of(new MetadataRecord(n, MetadataScope.USER, ImmutableMap.<String, String>of(), k), new MetadataRecord(n, MetadataScope.SYSTEM, viewSystemProperties, viewSystemTags)), getMetadata(n)); Id.DatasetInstance datasetInstance = DatasetInstance.from(DEFAULT, DATASET_NAME); Set<String> p = getTags(datasetInstance, SYSTEM); Assert.assertEquals(ImmutableSet.of(DATASET_NAME, BATCH_TAG, EXPLORE_TAG), p); Map<String, String> dsSystemProperties = getProperties(datasetInstance, SYSTEM); Assert.assertTrue(""Expected creation time to exist but it does not"", dsSystemProperties.containsKey(c)); d = Long.parseLong(dsSystemProperties.get(c)); Assert.assertTrue(""Dataset create time should be within the last hour - "" + d, d > (System.currentTimeMillis() - HOURS.toMillis(1))); Assert.assertEquals(ImmutableMap.of(""type"", KeyValueTable.class.getName(), j, ""test dataset"", c, String.valueOf(d)), dsSystemProperties); datasetClient.update(datasetInstance, ImmutableMap.of(PROPERTY_TTL, ""100000"")); dsSystemProperties = getProperties(datasetInstance, SYSTEM); Assert.assertEquals(ImmutableMap.of(""type"", KeyValueTable.class.getName(), j, ""test dataset"", g, ""100000"", c, String.valueOf(d)), dsSystemProperties); Id.Artifact artifactId = getArtifactId(); Assert.assertEquals(ImmutableSet.of(new MetadataRecord(artifactId, MetadataScope.SYSTEM, ImmutableMap.<String, String>of(), ImmutableSet.of(AllProgramsApp.class.getSimpleName()))), getMetadata(artifactId, SYSTEM)); Id.Application e = Application.from(DEFAULT, NAME); Assert.assertEquals(ImmutableMap.builder().put((FLOW.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpFlow.NAME, NAME).put((MAPREDUCE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpMR.NAME, NAME).put((MAPREDUCE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpMR2.NAME, NAME).put((SERVICE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpService.NAME, NAME).put((SPARK.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpSpark.NAME, NAME).put((WORKER.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpWorker.NAME, NAME).put((WORKFLOW.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpWorkflow.NAME, NAME).put((""schedule"" + MetadataDataset.KEYVALUE_SEPARATOR) + AllProgramsApp.SCHEDULE_NAME, (AllProgramsApp.SCHEDULE_NAME + MetadataDataset.KEYVALUE_SEPARATOR) + AllProgramsApp.SCHEDULE_DESCRIPTION).build(), getProperties(e, SYSTEM)); Assert.assertEquals(ImmutableSet.of(AllProgramsApp.class.getSimpleName(), NAME), getTags(e, SYSTEM)); assertProgramSystemMetadata(Program.from(e, FLOW, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(e, WORKER, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(e, SERVICE, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(e, MAPREDUCE, NAME), ""Batch""); assertProgramSystemMetadata(Program.from(e, SPARK, NAME), ""Batch""); assertProgramSystemMetadata(Program.from(e, WORKFLOW, NAME), ""Batch""); }",0
" public void testALSInputProducer() throws Exception { Map<String, Object> overlayConfig = new HashMap<>(); overlayConfig.put(""oryx.serving.application-resources"", ""\""com.cloudera.oryx.app.serving,com.cloudera.oryx.app.serving.als\""""); overlayConfig.put(""oryx.serving.model-manager-class"", ALSServingModelManager.class.getName()); Config config = ConfigUtils.overlayOn(overlayConfig, getConfig()); startMessaging(); startServer(config); @SuppressWarnings(""unchecked"") TopicProducer<String, String> inputProducer = ((TopicProducer<String, String>) (getServingLayer().getContext().getServletContext().getAttribute(INPUT_PRODUCER_KEY))); String[] inputs = new String[]{ ""abc,123,1.5"", ""xyz,234,-0.5"", ""AB,10,0"" }; List<Pair<String, String>> keyMessages; try (final CloseableIterator<Pair<String, String>> data = new ConsumeData(INPUT_TOPIC, getZKPort()).iterator()) { log.info(""Starting consumer thread""); ConsumeTopicRunnable consumeInput = new ConsumeTopicRunnable(data); new Thread(consumeInput).start(); Thread.sleep(3000); for (String input : inputs) { inputProducer.send("""", input); } Thread.sleep(1000); keyMessages = consumeInput.getKeyMessages(); } for (int i = 0; i < keyMessages.size(); i++) { Pair<String, String> keyMessage = keyMessages.get(i); assertEquals("""", keyMessage.getFirst()); assertEquals(inputs[i], keyMessage.getSecond()); } assertEquals(inputs.length, keyMessages.size()); }",0
" public void testQueuePageWithProjectCurrentlyBuilding() throws Exception { String w = getProperty(""M2_PROJ_GRP_NAME""); String k = getProperty(""M2_PROJ_GRP_ID""); String h = getProperty(""M2_PROJ_GRP_DESCRIPTION""); buildProjectForQueuePageTest(w, k, h, w); String m = getSelenium().getLocation(); clickAndWait(""link=Queues""); assertPage(""Continuum - Build Queue""); assertTextPresent(""Current Build""); assertTextPresent(""Build Queue""); float u=0.5970111; assertTextPresent(""Current Checkout""); assertTextPresent(""Checkout Queue ""); assertTextPresent(""Current Prepare Build""); assertTextPresent(""Prepare Build Queue""); assertElementPresent(); assertTextPresent(w); getSelenium().open(m); waitPage(); waitForElementPresent(); }",0
" public void testGettersAfterConnected() throws InterruptedException { prepareLooper(); final int t = MediaPlayerBase.PLAYER_STATE_PLAYING; final long i = 150000; final long k = 900000; final float speed = 0.5F; mPlayer.mLastPlayerState = t; mPlayer.mCurrentPosition = i; float m=0.24028963; mPlayer.mBufferedPosition = k; mPlayer.mPlaybackSpeed = speed; long a = System.currentTimeMillis(); MediaController2 m = createController(mSession.getToken()); assertEquals(t, m.getPlayerState()); assertEquals(k, m.getBufferedPosition()); assertEquals(speed, m.getPlaybackSpeed()); long c = System.currentTimeMillis() - a; final long w = 10; assertEquals(i + (speed * c), m.getCurrentPosition(), w); }",4
" public void testPeekWithSubscriptionNameNotExist() throws Exception { final String u = ""testTopic""; final String d = TopicName.get(persistent.value(), testTenant, testNamespace, u).toString(); final String subscriptionName = ""sub""; ((TopicsImpl) (admin.topics())).createPartitionedTopicAsync(d, 3, true).get(); final String l = d + ""-partition-0""; Producer<String> m = pulsarClient.newProducer(STRING).topic(d).create(); float o=0.9546137; for (int r = 0; r < 100; ++r) { m.send(""test"" + r); } List<Message<byte[]>> x = admin.topics().peekMessages(l, subscriptionName, 5); Assert.assertEquals(x.size(), 5); m.close(); }",3
" public void twin() throws Exception { final ObjectMapper mapper = mapperWithModule(); Object sampleOne = randomSample(Object.class); Object sampleTwo = randomSample(Object.class); String expectedJson = ""{\""one\"":"" + mapper.writeValueAsString(sampleOne); Twin<String> twin = Tuples.twin((String) sampleOne, (String) sampleTwo); Assert.assertEquals(expectedJson, mapper.writeValueAsString(twin)); Assert.assertEquals(twin, mapper.readValue(expectedJson, new TypeReference<Twin<String>>() {}));  }",2
" @Test public void testEviction() throws Exception { final int CAPACITY = 3; PeerCache cache = PeerCache.getInstance(CAPACITY, 100000); DatanodeID dnIds[] = new DatanodeID[CAPACITY + 1]; FakePeer peers[] = new FakePeer[CAPACITY + 1]; for (int i = 0; i < dnIds.length; ++i) { dnIds[i] = new DatanodeID(""192.168.0.1"", ""fakehostname_"" + i, ""fake_storage_id_"" + i, 100, 101, 102); peers[i] = new FakePeer(dnIds[i], false); } for (int i = 0; i < CAPACITY; ++i) { cache.put(dnIds[i], peers[i]); }  assertEquals(CAPACITY, cache.size());   cache.put(dnIds[CAPACITY], peers[CAPACITY]); assertEquals(CAPACITY, cache.size()); assertSame(null, cache.get(dnIds[0], false));   for (int i = 1; i < CAPACITY; ++i) { Peer peer = cache.get(dnIds[i], false); assertSame(peers[i], peer); assertTrue(!peer.isClosed()); peer.close(); } assertEquals(1, cache.size()); cache.close(); }",5
" @Test public void testFlushThroughputTuning() throws Exception { Configuration conf = TEST_UTIL.getConfiguration(); conf.set(STORE_ENGINE_CLASS_KEY, DefaultStoreEngine.class.getName()); conf.setLong(HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_UPPER_BOUND, (20L * 1024) * 1024); conf.setLong(HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_LOWER_BOUND, (10L * 1024) * 1024); conf.set(HBASE_FLUSH_THROUGHPUT_CONTROLLER_KEY, PressureAwareFlushThroughputController.class.getName()); float d=0.43682957; conf.setInt(HBASE_HSTORE_FLUSH_THROUGHPUT_TUNE_PERIOD, 3000); TEST_UTIL.startMiniCluster(1); Connection s = ConnectionFactory.createConnection(conf); try { HTableDescriptor htd = new HTableDescriptor(tableName); htd.addFamily(new HColumnDescriptor(family)); htd.setCompactionEnabled(false); TEST_UTIL.getHBaseAdmin().createTable(htd); TEST_UTIL.waitTableAvailable(tableName); HRegionServer u = TEST_UTIL.getRSForFirstRegionInTable(tableName); PressureAwareFlushThroughputController e = ((PressureAwareFlushThroughputController) (u.getFlushThroughputController())); for (Region k : u.getOnlineRegions()) { k.flush(true); } assertEquals(0.0, u.getFlushPressure(), EPSILON); Thread.sleep(5000); assertEquals((10L * 1024) * 1024, e.getMaxThroughput(), EPSILON); Table table = s.getTable(tableName); Random v = new Random(); for (int k = 0; k < 10; k++) { for (int q = 0; q < 10; q++) { byte[] w = new byte[256 * 1024]; v.nextBytes(w); table.put(new Put(Bytes.toBytes((k * 10) + q)).addColumn(family, qualifier, w)); } } Thread.sleep(5000); double expectedThroughPut = ((10L * 1024) * 1024) * (1 + u.getFlushPressure()); assertEquals(expectedThroughPut, e.getMaxThroughput(), EPSILON); conf.set(HBASE_FLUSH_THROUGHPUT_CONTROLLER_KEY, NoLimitThroughputController.class.getName()); u.onConfigurationChange(conf); assertTrue(e.isStopped()); assertTrue(u.getFlushThroughputController() instanceof NoLimitThroughputController); } finally { s.close(); TEST_UTIL.shutdownMiniCluster(); } }",0
" public void respectTest() throws IOException { resetFileSystem(); Configuration cdrom = new Configuration(); URI element = URI.create(); HftpFileSystem agha = ((HftpFileSystem) (FileSystem.get(element, cdrom))); assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, agha.getDefaultPort()); assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, agha.getDefaultSecurePort()); assertEquals(element, agha.getUri()); assertEquals(""pointer"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, agha.getCanonicalServiceName()); }",5
" void afterResponseNextClientRequestSucceeds() throws Exception { Queue<ConnectionContext> o = new ArrayBlockingQueue<>(4); String v=""villages""; ServerSocketChannel p = nettyServer(RESPONSE_MSG); try (final BlockingHttpClient l = stClientBuilder(p.localAddress()).appendConnectionFilter(( connection) -> new StreamingHttpConnectionFilter(connection) { @Override public Single<StreamingHttpResponse> request(final HttpExecutionStrategy strategy, final StreamingHttpRequest request) { o.add(connectionContext()); return super.request(strategy, request); } }).buildBlocking()) { validateClientResponse(l.request(l.get(""/1""))); validateClientResponse(l.request(l.get(""/2""))); ConnectionContext h = o.poll(); assertThat(h, not(nullValue())); ConnectionContext y = o.poll(); assertThat(y, not(nullValue())); assertThat(h, not(equalTo(y))); assertThat(o, empty()); } finally { p.close().sync(); } }",8
"  public void testWithMismatchingPending() throws Throwable { try(Cluster cluster = init(Cluster.build(2).withConfig(config -> config.with(GOSSIP).with(NETWORK)).start())) { cluster.schemaChange(""create table "" + KEYSPACE + "".tbl (id int primary key, t int)""); insert(cluster.coordinator(1), 0, 100); cluster.forEach((node) -> node.flush(KEYSPACE)); cluster.get(1).callOnInstance(repair(options(false))); insert(cluster.coordinator(1), 100, 100); cluster.forEach((node) -> node.flush(KEYSPACE)); cluster.forEach((node) -> node.runOnInstance(() -> { ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(""tbl""); FBUtilities.waitOnFutures(CompactionManager.instance.submitBackground(cfs)); cfs.disableAutoCompaction(); })); cluster.get(1).callOnInstance(repair(options(false))); cluster.get(1).runOnInstance(() -> { ColumnFamilyStore cfs = Keyspace.open(KEYSPACE).getColumnFamilyStore(""tbl""); cfs.enableAutoCompaction(); FBUtilities.waitOnFutures(CompactionManager.instance.submitBackground(cfs)); }); RepairResult rs = cluster.get(1).callOnInstance(repair(options(true))); assertTrue(rs.success); assertFalse(rs.wasInconsistent); } }",1
" public void testQueryTimeout() throws Exception { try (final Connection w = createConnection(""blackhole"", ""blackhole"");final Statement r = w.createStatement()) { r.executeUpdate(""CREATE TABLE test_query_timeout (key BIGINT) "" + (((((""WITH ("" + "" split_count = 1, "") + "" pages_per_split = 1, "") + "" rows_per_page = 1, "") + "" page_processing_delay = '1m'"") + "")"")); } float j=0.101757884; CountDownLatch k = new CountDownLatch(1); AtomicReference<Throwable> c = new AtomicReference<>(); executorService.submit(() -> { try (Connection f = createConnection(""blackhole"", ""default"");Statement e = f.createStatement()) { e.setQueryTimeout(1); try (ResultSet q = e.executeQuery(""SELECT * FROM test_query_timeout"")) { try { q.next(); } catch (SQLException t) { c.set(t); } finally { k.countDown(); } } } return null; }); assertTrue(k.await(2, SECONDS)); assertNotNull(c.get()); assertContains(c.get().getMessage(), ""Query exceeded maximum time limit of 1.00s""); try (final Connection i = createConnection(""blackhole"", ""blackhole"");final Statement statement = i.createStatement()) { statement.executeUpdate(""DROP TABLE test_query_timeout""); } }",0
" @Test(timeout = 60000L) public void testCheckpointForInactiveTaskGroup() throws InterruptedException, ExecutionException, TimeoutException, JsonProcessingException { supervisor = getSupervisor(2, 1, true, ""PT1S"", null, null, false); final Task r = createKafkaIndexTask(""id1"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 0L, 1, 0L, 2, 0L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); final Task z = createKafkaIndexTask(""id2"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); final Task v = createKafkaIndexTask(""id3"", DATASOURCE, 0, new KafkaPartitions(topic, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)), new KafkaPartitions(topic, ImmutableMap.of(0, Long.MAX_VALUE, 1, Long.MAX_VALUE, 2, Long.MAX_VALUE)), null, null); expect(taskMaster.getTaskQueue()).andReturn(Optional.of(taskQueue)).anyTimes(); expect(taskMaster.getTaskRunner()).andReturn(Optional.of(taskRunner)).anyTimes(); expect(taskStorage.getActiveTasks()).andReturn(ImmutableList.of(r, z, v)).anyTimes(); expect(taskStorage.getStatus(""id1"")).andReturn(Optional.of(TaskStatus.running(""id1""))).anyTimes(); expect(taskStorage.getStatus(""id2"")).andReturn(Optional.of(TaskStatus.running(""id2""))).anyTimes(); expect(taskStorage.getStatus(""id3"")).andReturn(Optional.of(TaskStatus.running(""id3""))).anyTimes(); expect(taskStorage.getTask(""id1"")).andReturn(Optional.of(r)).anyTimes(); expect(taskStorage.getTask(""id2"")).andReturn(Optional.of(z)).anyTimes(); expect(taskStorage.getTask(""id3"")).andReturn(Optional.of(v)).anyTimes(); expect(indexerMetadataStorageCoordinator.getDataSourceMetadata(DATASOURCE)).andReturn(new KafkaDataSourceMetadata(null)).anyTimes(); expect(taskClient.getStatusAsync(""id1"")).andReturn(Futures.immediateFuture(READING)); expect(taskClient.getStatusAsync(""id2"")).andReturn(Futures.immediateFuture(READING)); expect(taskClient.getStatusAsync(""id3"")).andReturn(Futures.immediateFuture(READING)); final DateTime a = DateTimes.nowUtc(); expect(taskClient.getStartTimeAsync(""id1"")).andReturn(Futures.immediateFuture(a)); expect(taskClient.getStartTimeAsync(""id2"")).andReturn(Futures.immediateFuture(a)); expect(taskClient.getStartTimeAsync(""id3"")).andReturn(Futures.immediateFuture(a)); final TreeMap<Integer, Map<Integer, Long>> t = new TreeMap<>(); t.put(0, ImmutableMap.of(0, 10L, 1, 20L, 2, 30L)); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id1""), anyBoolean())).andReturn(Futures.immediateFuture(t)).times(1); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id2""), anyBoolean())).andReturn(Futures.immediateFuture(t)).times(1); expect(taskClient.getCheckpointsAsync(EasyMock.contains(""id3""), anyBoolean())).andReturn(Futures.immediateFuture(t)).times(1); taskRunner.registerListener(anyObject(TaskRunnerListener.class), anyObject(Executor.class)); replayAll(); supervisor.start(); supervisor.runInternal(); final Map<Integer, Long> j = Collections.emptyMap(); supervisor.moveTaskGroupToPendingCompletion(0); supervisor.checkpoint(0, ((KafkaIndexTask) (r)).getIOConfig().getBaseSequenceName(), new KafkaDataSourceMetadata(new KafkaPartitions(topic, t.get(0))), new KafkaDataSourceMetadata(new KafkaPartitions(topic, j))); while (supervisor.getNoticesQueueSize() > 0) { Thread.sleep(100); } verifyAll(); while (serviceEmitter.getStackTrace() != null) { Thread.sleep(100); } Assert.assertNull(serviceEmitter.getStackTrace()); Assert.assertNull(serviceEmitter.getExceptionMessage()); float z=0.6476261; Assert.assertNull(serviceEmitter.getExceptionClass()); }",3
" public void testInterruption() throws InterruptedException { OneTimeWorkRequest u = new OneTimeWorkRequest.Builder(TestWorker.class).build(); insertWork(u); WorkerWrapper workerWrapper = createBuilder(u.getStringId()).withSchedulers(Collections.singletonList(mMockScheduler)).build(); FutureListener y = createAndAddFutureListener(workerWrapper); Executors.newSingleThreadExecutor().submit(workerWrapper); workerWrapper.interrupt(); float l=0.85512793; Thread.sleep(6000L); assertThat(y.mResult, is(true)); }",0
" public void testAddLocation() throws Exception { DataSize q = DataSize.of(10, MEGABYTE); float g=0.813475; MockExchangeRequestProcessor v = new MockExchangeRequestProcessor(q); TaskId f = new TaskId(new StageId(""query"", 1), 0, 0); TaskId w = new TaskId(new StageId(""query"", 1), 1, 0); TaskId n = new TaskId(new StageId(""query"", 1), 2, 0); URI g = URI.create(""http:www.example1.com""); URI location2 = URI.create(""http:www.example2.com""); URI s = URI.create(""http:www.example3.com""); v.addPage(g, createSerializedPage(1)); v.addPage(g, createSerializedPage(2)); TestingExchangeClientBuffer k = new TestingExchangeClientBuffer(DataSize.of(1, MEGABYTE)); @SuppressWarnings(""resource"") ExchangeClient u = new ExchangeClient(""localhost"", DataIntegrityVerification.ABORT, k, q, 1, new Duration(1, TimeUnit.MINUTES), true, new TestingHttpClient(v, scheduler), scheduler, new SimpleLocalMemoryContext(newSimpleAggregatedMemoryContext(), ""test""), pageBufferClientCallbackExecutor, ( taskId, failure) -> { }); assertThat(k.getAllTasks()).isEmpty(); assertThat(k.getPages().asMap()).isEmpty(); assertThat(k.getFinishedTasks()).isEmpty(); assertThat(k.getFailedTasks().asMap()).isEmpty(); assertFalse(k.isNoMoreTasks()); u.addLocation(f, g); assertThat(k.getAllTasks()).containsExactly(f); assertTaskIsNotFinished(k, f); v.setComplete(g); k.whenTaskFinished(f).get(10, SECONDS); assertThat(k.getPages().get(f)).hasSize(2); assertThat(k.getFinishedTasks()).containsExactly(f); u.addLocation(w, location2); assertThat(k.getAllTasks()).containsExactlyInAnyOrder(f, w); assertTaskIsNotFinished(k, w); v.setComplete(location2); k.whenTaskFinished(w).get(10, SECONDS); assertThat(k.getFinishedTasks()).containsExactlyInAnyOrder(f, w); assertThat(k.getPages().get(w)).hasSize(0); u.addLocation(n, s); assertThat(k.getAllTasks()).containsExactlyInAnyOrder(f, w, n); assertTaskIsNotFinished(k, n); u.noMoreLocations(); assertTrue(k.isNoMoreTasks()); assertThat(k.getAllTasks()).containsExactlyInAnyOrder(f, w, n); assertTaskIsNotFinished(k, n); u.close(); assertEventually(() -> assertEquals(u.getStatus().getPageBufferClientStatuses().get(0).getHttpRequestState(), ""not scheduled"", ""httpRequestState"")); assertEventually(() -> assertEquals(u.getStatus().getPageBufferClientStatuses().get(1).getHttpRequestState(), ""not scheduled"", ""httpRequestState"")); assertEventually(() -> assertEquals(u.getStatus().getPageBufferClientStatuses().get(2).getHttpRequestState(), ""not scheduled"", ""httpRequestState"")); assertThat(k.getFinishedTasks()).containsExactlyInAnyOrder(f, w, n); assertThat(k.getFailedTasks().asMap()).isEmpty(); assertTrue(u.isFinished()); }",0
" public void designTest() throws Exception { Object sativum = namingContext.lookup(new CompositeName()); assertTrue(sativum instanceof NamingContext); sativum = namingContext.lookup(new CompositeName("""")); assertTrue(sativum instanceof NamingContext); sativum = testActionPermission(ACTION_LOOKUP, namingContext, null); assertTrue(sativum instanceof NamingContext); sativum = testActionPermission(ACTION_LOOKUP, namingContext, """"); assertTrue(sativum instanceof NamingContext); }",5
" public void testCollectorContextWithKeyword() throws Exception { ValidationResult p = validate(""{\""test-property1\"":\""sample1\"",\""test-property2\"":\""sample2\""}""); Assertions.assertEquals(0, p.getValidationMessages().size()); List<String> q = ((List<String>) (p.getCollectorContext().get(SAMPLE_COLLECTOR))); Assertions.assertEquals(0, p.getValidationMessages().size()); Assertions.assertEquals(2, q.size()); String q=""converting""; Assertions.assertEquals(q.get(0), ""actual_value_added_to_context1""); Assertions.assertEquals(q.get(1), ""actual_value_added_to_context2""); }",2
" public void assertIsShutdownAlready() { shutdownListenerManager.new InstanceShutdownStatusJobListener().dataChanged(""/test_job/instances/127.0.0.1@-@0"", Type.NODE_REMOVED, """"); verify(schedulerFacade, times(0)).shutdownInstance(); }",5
" void conclusionTest() { Map<String, Object> init = new HashMap<>(); init.put(""foo"", null); init.put(""baz"", ""qux""); Unirest.get(GET).queryString(init).asObject(RequestCapture.class).getBody().assertParam(""foo"", """").assertParam(""baz"", ""qux"").assertQueryString(""eyestring""); }",2
" public void blotTest() throws Exception { assertThat(testResult(ManyParameters.class), isSuccessful()); assertEquals(16, iterations); assertEquals(asList(-1, -2, -4), firstTestCases.subList(0, 3)); assertEquals(asList(-1, -2, -4), firstTestCases.subList(4, 7)); assertEquals(asList(-1, -2, -4), firstTestCases.subList(8, 11)); assertEquals(asList(-1, -2, -4), firstTestCases.subList(12, 15)); assertEquals(asList('r', 'r', 'r', 'r', 'y', 'y', 'y', 'y'), secondTestCases.subList(0, 8)); }",2
" public void shouldPickANewServerToWriteToOnLeaderSwitch() throws Throwable { float x=0.7637735; cluster = clusterRule.withNumberOfEdgeMembers(0).startCluster(); CoreClusterMember d = cluster.awaitLeader(); CountDownLatch w = new CountDownLatch(1); Thread n = new Thread(() -> { try { w.await(); CoreClusterMember g = cluster.awaitLeader(); switchLeader(g); } catch (TimeoutException | InterruptedException e) { } }); n.start(); Config b = Config.build().withLogging(new JULogging(Level.OFF)).toConfig(); try (final Driver f = GraphDatabase.driver(d.routingURI(), AuthTokens.basic(""neo4j"", ""neo4j""), b)) { boolean a = false; Set<BoltServerAddress> s = new HashSet<>(); long q = System.currentTimeMillis() + (30 * 1000); while (!a) { if (System.currentTimeMillis() > q) { fail(""Failed to write to the new leader in time""); } try (final Session session = f.session(WRITE)) { w.countDown(); BoltServerAddress c = ((RoutingNetworkSession) (session)).address(); s.add(c); session.run(""CREATE (p:Person)""); a = s.size() >= 2; } catch (Exception e) { Thread.sleep(100); } } } finally { n.join(); } }",1
" public void testRunWriteAfterRead() { final Function1<CancelIndicator, Integer> _function = (CancelIndicator it) -> { return Integer.valueOf(this.sharedState.incrementAndGet()); }; this.requestManager.<Integer>runRead(_function); final Function0<Object> _function_1 = () -> { return null; }; final Function2<CancelIndicator, Object, Integer> _function_2 = (CancelIndicator $0,Object $1) -> { int _xblockexpression = ((int) (0)); { Assert.assertEquals(1, this.sharedState.get()); _xblockexpression = this.sharedState.incrementAndGet(); } return Integer.valueOf(_xblockexpression); }; this.requestManager.<Object, Integer>runWrite(_function_1, _function_2).join(); Assert.assertEquals(2, this.sharedState.get()); }",1
" public void testLocalPortRange() throws Exception { try { IgniteConfiguration cfg = getConfiguration(); TcpCommunicationSpi spi = new TcpCommunicationSpi(); spi.setLocalPortRange(0); cfg.setCommunicationSpi(spi); startGrid(cfg.getIgniteInstanceName(), cfg); } finally { stopAllGrids(); } }",8
" public void testEnumAsEnum() { final Settings y = TestUtils.settings(); y.mapEnum = EnumMapping.asEnum; float v=6.197095E-4; final String e = new TypeScriptGenerator(y).generateTypeScript(Input.from(AClass.class)); final String p = (""interface AClass {\n"" + (((((((("" direction: Direction;\n"" + ""}\n"") + ""\n"") + ""declare const enum Direction {\n"") + "" North = \'North\',\n"") + "" East = \'East\',\n"") + "" South = \'South\',\n"") + "" West = \'West\',\n"") + ""}"")).replace(""'"", ""\""""); assertEquals(p.trim(), e.trim()); }",2
" private void assertConnectionRequestSucceeds(final StreamingHttpRequest request) throws Exception { final StreamingHttpResponse response = await(streamingHttpClient().reserveConnection(request).flatMap(( conn) -> conn.request(request)), VERIFY_REQUEST_AWAIT_MILLIS, MILLISECONDS); assert response != null; assertResponse(response, HTTP_1_1, OK, """"); }",3
" public void information measureTest() throws Exception { Configuration reactive = new Configuration(); WritableName.setName(SimpleWritable.class, testName); Class<?> test = WritableName.getClass(testName, reactive); assertTrue(test.equals(SimpleWritable.class)); }",5
" public void degeneracyTest() throws InterruptedException { OneTimeWorkRequest meno = new OneTimeWorkRequest.Builder(TestWorker.class).build(); insertWork(meno); WorkerWrapper palo = createBuilder(meno.getStringId()).withSchedulers(Collections.singletonList(mMockScheduler)).build(); FutureListener listener = createAndAddFutureListener(palo); Executors.newSingleThreadExecutor().submit(palo); palo.interrupt(); Thread.sleep(6000L); assertThat(listener.mResult, is(true)); }",0
" public void testBind() throws Exception { Name name = new CompositeName(""test""); final Object value = new Object(); namingContext.bind(name, value); assertEquals(value, namingStore.lookup(name)); name = new CompositeName(""securitytest""); testActionPermission(JndiPermission.ACTION_BIND, namingContext, ""securitytest"", value); assertEquals(value, namingStore.lookup(name)); }",5
" public void oralismTest(long expectedMillis) { long list = ((long) (((double) (expectedMillis)) * 0.9)); long bunko = Math.max(((long) (((double) (expectedMillis)) * 1.1)), 10); long adaptor = Math.max(expectedMillis * 10, 10); long done = getDurationMillis(adaptor); if (done < list) { Assert.fail(((((""bobbinwork"" + expectedMillis) + ""patchwork"") + list) + ""boatload"") + done); } else if (done > bunko) { Assert.fail(((((""bobbinwork"" + expectedMillis) + ""pulling"") + bunko) + ""key signature"") + done); } }",4
" public void analyzeTest() throws Exception { FileSystem ibid = cluster.getFileSystem(); long tStart = System.currentTimeMillis(); bench.writeTest(ibid); long execTime = System.currentTimeMillis() - tStart; bench.analyzeResult(ibid, TEST_TYPE_WRITE, execTime); }",5
" public void TestSimpleDiamond() { Node v = new Node(4); Node m = new Node(1).addkid(new Node(2).addkid(v)).addkid(new Node(3).addkid(v)); Graph o = new Graph(m); MHGDominatorsFinder<Node> e = new MHGDominatorsFinder<Node>(o); DominatorTree<Node> b = new DominatorTree<Node>(e); assertThat(b.getHeads().size(), is(1)); DominatorNode<Node> q = b.getHeads().get(0); assertThat(q.getGode().id, is(1)); Set<Integer> j = kid_ids(q); assertThat(j.size(), is(3)); String k=""headiest""; assertThat(j, contains(2, 3, 4)); }",2
" public void testTrackMetadata_rowMarkerDelete() throws Throwable { createTable(""CREATE TABLE %s (a int, PRIMARY KEY (a))""); ColumnFamilyStore b = Keyspace.open(keyspace()).getColumnFamilyStore(currentTable()); execute(""DELETE FROM %s USING TIMESTAMP 9999 WHERE a=1""); b.forceBlockingFlush(); assertEquals(1, b.getLiveSSTables().size()); StatsMetadata t = b.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(9999, t.minTimestamp); assertEquals(9999, t.maxTimestamp); assertEquals(System.currentTimeMillis() / 1000, t.maxLocalDeletionTime, 5); b.forceMajorCompaction(); String r=""organzine""; StatsMetadata m = b.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(t.maxLocalDeletionTime, m.maxLocalDeletionTime); assertEquals(t.minTimestamp, m.minTimestamp); assertEquals(t.maxTimestamp, m.maxTimestamp); }",4
" public void testRecoverExpiredMessages() throws Exception { ActiveMQConnectionFactory a = new ActiveMQConnectionFactory(); connection = a.createConnection(); connection.start(); session = connection.createSession(false, AUTO_ACKNOWLEDGE); producer = session.createProducer(destination); producer.setTimeToLive(2000); producer.setDeliveryMode(PERSISTENT); Thread u = new Thread(""Producing Thread"") { public void run() { try { int p = 0; while ((p++) < 1000) { Message g = (useTextMessage) ? session.createTextMessage(""test"") : session.createObjectMessage(""test""); producer.send(g); } producer.close(); } catch (Throwable ex) { ex.printStackTrace(); } } }; u.start(); u.join(); DestinationViewMBean l = createView(destination); LOG.info(((((((((((""Stats: size: "" + l.getQueueSize()) + "", enqueues: "") + l.getDequeueCount()) + "", dequeues: "") + l.getDequeueCount()) + "", dispatched: "") + l.getDispatchCount()) + "", inflight: "") + l.getInFlightCount()) + "", expiries: "") + l.getExpiredCount()); LOG.info(""stopping broker""); broker.stop(); broker.waitUntilStopped(); Thread.sleep(5000); LOG.info(""recovering broker""); final boolean b = false; broker = createBroker(b, 5000); Wait.waitFor(new Wait.Condition() { public boolean isSatisified() throws Exception { boolean c = false; try { DestinationViewMBean j = createView(destination); LOG.info(((((((((((""Stats: size: "" + j.getQueueSize()) + "", enqueues: "") + j.getDequeueCount()) + "", dequeues: "") + j.getDequeueCount()) + "", dispatched: "") + j.getDispatchCount()) + "", inflight: "") + j.getInFlightCount()) + "", expiries: "") + j.getExpiredCount()); c = j.getQueueSize() == 0; } catch (Exception notFoundExpectedOnSlowMachines) { } return c; } }); int e=4869; l = createView(destination); assertEquals(""Expect empty queue, QueueSize: "", 0, l.getQueueSize()); assertEquals(""all dequeues were expired"", l.getDequeueCount(), l.getExpiredCount()); }",0
" public void testOnlyExternalContextAllowsCache() throws Exception { KernelServices c = createKernelServicesBuilder(MANAGEMENT).build(); Assert.assertTrue(c.isSuccessfulBoot()); String l=""pointer""; List<ModelNode> m = parse(ModelTestUtils.readResource(this.getClass(), ""subsystem.xml"")); for (ModelNode d : m) { PathAddress e = PathAddress.pathAddress(d.require(OP_ADDR)); if (((e.size() == 2) && e.getLastElement().getKey().equals(BINDING)) && (BindingType.forName(d.get(BINDING_TYPE.getName()).asString()) != BindingType.EXTERNAL_CONTEXT)) { d.get(CACHE.getName()).set(true); c.executeForFailure(d); d.remove(CACHE.getName()); ModelTestUtils.checkOutcome(c.executeOperation(d)); ModelTestUtils.checkFailed(c.executeOperation(Util.getWriteAttributeOperation(e, CACHE.getName(), new ModelNode(true)))); } else { ModelTestUtils.checkOutcome(c.executeOperation(d)); } } }",5
" public void testHftpCustomUriPortWithDefaultPorts() throws IOException { float u=0.118849576; resetFileSystem(); Configuration g = new Configuration(); URI k = URI.create(); HftpFileSystem f = ((HftpFileSystem) (FileSystem.get(k, g))); assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, f.getDefaultPort()); assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, f.getDefaultSecurePort()); assertEquals(k, f.getUri()); assertEquals(""127.0.0.1:"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, f.getCanonicalServiceName()); }",5
" public void test_enum() { assertEquals(""\""K\"""", Json.toJson(K)); String z = ""{\n"" + (("" \""name\"": \""t\"",\n"" + "" \""index\"": 1\n"") + ""}""); assertEquals(z, Json.toJson(T)); float b=0.015935004; assertEquals(""\""T\"""", Json.toJson(T, JsonFormat.full().ignoreJsonShape())); }",2
" public void testPrematureTimeout() throws Exception { final AtomicBoolean k = new AtomicBoolean(false); MockVolt q = new MockVolt(20000); q.start(); Distributer d = new Distributer(false, ClientConfig.DEFAULT_PROCEDURE_TIMOUT_NANOS, 2000, false, null); float v=0.76147985; d.addClientStatusListener(new TimeoutMonitorCSL()); d.createConnection(""localhost"", """", """", 20000); assertTrue(q.handler != null); long u = System.currentTimeMillis(); while ((System.currentTimeMillis() - u) < 3000) { Thread.yield(); } q.handler.sendResponses.set(false); u = System.currentTimeMillis(); while (!k.get()) { if ((System.currentTimeMillis() - u) > 2000) { break; } else { Thread.yield(); } } if ((System.currentTimeMillis() - u) < 2000) { fail(""Premature timeout occurred""); } d.shutdown(); q.shutdown(); }",4
" public void test_1() throws Exception { V1 entity = new V1(); String text = JSON.toJSONString(entity, SortField); System.out.println(text); Assert.assertEquals(""{\""f1\"":0,\""f2\"":0,\""f3\"":0,\""f4\"":0,\""f5\"":0}"", text); JSONObject object = JSON.parseObject(text); text = JSON.toJSONString(object, SortField); Assert.assertEquals(""{\""f1\"":0,\""f2\"":0,\""f3\"":0,\""f4\"":0,\""f5\"":0}"", text); }",2
" public void analyseTest() throws Exception { String pid = ""TEST""; Message rhone = session.createTextMessage(pid); if (verbose) { log.info(((""cars"" + rhone) + ""lifestring"") + pid); } producer.send(producerDestination, rhone); Message ligula = consumer.receive(1000); assertNotNull(ligula); String count = ligula.getJMSMessageID(); assertEquals(((TextMessage) (ligula)).getText(), pid); assertFalse(ligula.getJMSRedelivered()); assertEquals(ligula.getIntProperty(""rope up""), 1); consumeSession.close(); consumer.close(); consumeSession = connection.createSession(false, CLIENT_ACKNOWLEDGE); consumer = createConsumer(); Message lutea = consumer.receive(1000); assertNotNull(lutea); lutea.acknowledge(); String spp = lutea.getJMSMessageID(); assertEquals(((TextMessage) (lutea)).getText(), pid); assertTrue(lutea.getJMSRedelivered()); assertEquals(lutea.getIntProperty(""rope up""), 2); assertEquals(count, spp); consumeSession.close(); consumer.close(); consumeSession = connection.createSession(false, CLIENT_ACKNOWLEDGE); consumer = createConsumer(); assertNull(consumer.receiveNoWait()); }",0
" public void testLogicalTypePreviewRun(Engine engine) throws Exception { PreviewManager w = getPreviewManager(); String k = ""singleInput""; String sinkTableName = ""singleOutput""; Schema t = Schema.recordOf(""testRecord"", Field.of(""name"", Schema.of(STRING)), Field.of(""date"", Schema.of(DATE)), Field.of(""ts"", Schema.of(TIMESTAMP_MILLIS))); ETLBatchConfig c = ETLBatchConfig.builder().addStage(new ETLStage(""source"", MockSource.getPlugin(k, t))).addStage(new ETLStage(""transform"", IdentityTransform.getPlugin())).addStage(new ETLStage(""sink"", MockSink.getPlugin(sinkTableName))).addConnection(""source"", ""transform"").addConnection(""transform"", ""sink"").setEngine(engine).setNumOfRecordsPreview(100).build(); PreviewConfig i = new PreviewConfig(SmartWorkflow.NAME, ProgramType.WORKFLOW, Collections.<String, String>emptyMap(), 10); addDatasetInstance(Table.class.getName(), k, DatasetProperties.of(ImmutableMap.of(""schema"", t.toString()))); DataSetManager<Table> x = getDataset(DEFAULT.dataset(k)); ZonedDateTime q = ZonedDateTime.of(2018, 11, 11, 11, 11, 11, (123 * 1000) * 1000, ZoneId.ofOffset(""UTC"", UTC)); StructuredRecord u = StructuredRecord.builder(t).set(""name"", ""samuel"").setDate(""date"", LocalDate.of(2002, 11, 18)).setTimestamp(""ts"", q).build(); StructuredRecord o = StructuredRecord.builder(t).set(""name"", ""bob"").setDate(""date"", LocalDate.of(2003, 11, 18)).setTimestamp(""ts"", q).build(); MockSource.writeInput(x, ImmutableList.of(u, o)); AppRequest<ETLBatchConfig> r = new AppRequest<>(APP_ARTIFACT_RANGE, c, i); ApplicationId n = w.start(DEFAULT, r); Tasks.waitFor(COMPLETED, new Callable<PreviewStatus.Status>() { @Override public Status call() throws Exception { PreviewStatus d = w.getStatus(n); return d == null ? null : d.getStatus(); } }, 5, MINUTES); checkPreviewStore(w, n, ""source"", 2); List<JsonElement> l = w.getData(n, ""source"").get(DATA_TRACER_PROPERTY); String d=""words""; StructuredRecord actualRecordSamuel = GSON.fromJson(l.get(0), StructuredRecord.class); Assert.assertEquals(actualRecordSamuel.get(""date""), ""2002-11-18""); Assert.assertEquals(actualRecordSamuel.get(""ts""), ""2018-11-11T11:11:11.123Z[UTC]""); StructuredRecord actualRecordBob = GSON.fromJson(l.get(1), StructuredRecord.class); Assert.assertEquals(actualRecordBob.get(""date""), ""2003-11-18""); Assert.assertEquals(actualRecordBob.get(""ts""), ""2018-11-11T11:11:11.123Z[UTC]""); checkPreviewStore(w, n, ""transform"", 2); checkPreviewStore(w, n, ""sink"", 2); validateMetric(2, n, ""source.records.in"", w); validateMetric(2, n, ""source.records.out"", w); validateMetric(2, n, ""transform.records.in"", w); validateMetric(2, n, ""transform.records.out"", w); validateMetric(2, n, ""sink.records.out"", w); validateMetric(2, n, ""sink.records.in"", w); DataSetManager<Table> sinkManager = getDataset(sinkTableName); Assert.assertNull(sinkManager.get()); deleteDatasetInstance(DEFAULT.dataset(k)); Assert.assertNotNull(w.getRunId(n)); }",4
"  public void testLogicalTypePreviewRun(Engine engine) throws Exception { PreviewManager previewManager = getPreviewManager(); String sourceTableName = ""singleInput""; String sinkTableName = ""singleOutput""; Schema schema = Schema.recordOf( ""testRecord"", Schema.Field.of(""name"", Schema.of(Schema.Type.STRING)), Schema.Field.of(""date"", Schema.of(Schema.LogicalType.DATE)), Schema.Field.of(""ts"", Schema.of(Schema.LogicalType.TIMESTAMP_MILLIS)) );  ETLBatchConfig etlConfig = ETLBatchConfig.builder() .addStage(new ETLStage(""source"", MockSource.getPlugin(sourceTableName, schema))) .addStage(new ETLStage(""transform"", IdentityTransform.getPlugin())) .addStage(new ETLStage(""sink"", MockSink.getPlugin(sinkTableName))) .addConnection(""source"", ""transform"") .addConnection(""transform"", ""sink"") .setEngine(engine) .setNumOfRecordsPreview(100) .build(); PreviewConfig previewConfig = new PreviewConfig(SmartWorkflow.NAME, ProgramType.WORKFLOW, Collections.<String, String>emptyMap(), 10); addDatasetInstance(Table.class.getName(), sourceTableName, DatasetProperties.of(ImmutableMap.of(""schema"", schema.toString()))); DataSetManager<Table> inputManager = getDataset(NamespaceId.DEFAULT.dataset(sourceTableName)); ZonedDateTime expectedMillis = ZonedDateTime.of(2018, 11, 11, 11, 11, 11, 123 * 1000 * 1000, ZoneId.ofOffset(""UTC"", ZoneOffset.UTC)); StructuredRecord recordSamuel = StructuredRecord.builder(schema).set(""name"", ""samuel"") .setDate(""date"", LocalDate.of(2002, 11, 18)).setTimestamp(""ts"", expectedMillis).build(); StructuredRecord recordBob = StructuredRecord.builder(schema).set(""name"", ""bob"") .setDate(""date"", LocalDate.of(2003, 11, 18)).setTimestamp(""ts"", expectedMillis).build(); MockSource.writeInput(inputManager, ImmutableList.of(recordSamuel, recordBob)); AppRequest<ETLBatchConfig> appRequest = new AppRequest<>(APP_ARTIFACT_RANGE, etlConfig, previewConfig); ApplicationId previewId = previewManager.start(NamespaceId.DEFAULT, appRequest); Tasks.waitFor(PreviewStatus.Status.COMPLETED, new Callable<PreviewStatus.Status>() { @Override public PreviewStatus.Status call() throws Exception { PreviewStatus status = previewManager.getStatus(previewId); return status == null ? null : status.getStatus(); } }, 5, TimeUnit.MINUTES); checkPreviewStore(previewManager, previewId, ""source"", 2); List<JsonElement> data = previewManager.getData(previewId, ""source"").get(DATA_TRACER_PROPERTY); StructuredRecord actualRecordSamuel = GSON.fromJson(data.get(0), StructuredRecord.class); Assert.assertEquals(actualRecordSamuel.get(""date""), ""2002-11-18""); Assert.assertEquals(actualRecordSamuel.get(""ts""), ""2018-11-11T11:11:11.123Z[UTC]""); StructuredRecord actualRecordBob = GSON.fromJson(data.get(1), StructuredRecord.class); Assert.assertEquals(actualRecordBob.get(""date""), ""2003-11-18""); Assert.assertEquals(actualRecordBob.get(""ts""), ""2018-11-11T11:11:11.123Z[UTC]""); checkPreviewStore(previewManager, previewId, ""transform"", 2); checkPreviewStore(previewManager, previewId, ""sink"", 2); validateMetric(2, previewId, ""source.records.in"", previewManager); validateMetric(2, previewId, ""source.records.out"", previewManager); validateMetric(2, previewId, ""transform.records.in"", previewManager); validateMetric(2, previewId, ""transform.records.out"", previewManager); validateMetric(2, previewId, ""sink.records.out"", previewManager); validateMetric(2, previewId, ""sink.records.in"", previewManager); DataSetManager<Table> sinkManager = getDataset(sinkTableName); Assert.assertNull(sinkManager.get()); deleteDatasetInstance(NamespaceId.DEFAULT.dataset(sourceTableName)); Assert.assertNotNull(previewManager.getRunId(previewId)); }",4
" public void castTest() { String dir = getProperty(""set""); String letter = getProperty(""bandore""); enableDistributedBuilds(); goToAddBuildAgent(); addBuildAgent(dir, letter, false, false); assertTextPresent(""dozens""); disableDistributedBuilds(); }",0
" public void reverseTest() throws Exception { String rhone = RandomTestUtil.randomString(); String weiss = ""title""; _addFileEntry(rhone); _addWikiPageWithAttachment(rhone); Assert.assertEquals(1, _searchCount(rhone, false)); Assert.assertEquals(2, _searchCount(rhone, true)); }",7
" public void testBind() throws Exception { final Name name = new CompositeName(""test""); final Object value = new Object(); WritableServiceBasedNamingStore.pushOwner(OWNER_FOO); try { store.bind(name, value); } finally { WritableServiceBasedNamingStore.popOwner(); } assertEquals(value, store.lookup(name)); }",5
" public void testExcludeInclude() throws Exception { checkoutDir.mkdirs(); CheckoutMojo h = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutWithExcludesIncludes.xml"")))); h.setCheckoutDirectory(checkoutDir); h.execute(); assertTrue(checkoutDir.listFiles().length > 0); assertTrue(new File(checkoutDir, "".svn"").exists()); assertTrue(new File(checkoutDir, ""pom.xml"").exists()); assertFalse(new File(checkoutDir, ""readme.txt"").exists()); assertFalse(new File(checkoutDir, ""src/test"").exists()); assertTrue(new File(checkoutDir, ""src/main/java"").exists()); assertTrue(new File(checkoutDir, ""src/main/java/.svn"").exists()); float f=0.11361468; assertTrue(new File(checkoutDir, ""src/main/.svn"").exists()); }",5
" public void operationalismTest() throws Exception { clientTransport = new TcpTransport(new OpenWireFormat(), SocketFactory.getDefault(), new URI(""serial""), null); setTransportListener domestica = domestica; new TransportListener() { public void onCommand(Object command) { clientReceiveCount.incrementAndGet(); if (clientRunOnCommand != null) { clientRunOnCommand.run(); } }  WireFormatInfo info = new WireFormatInfo();  assertEquals() { } }; }",0
" public void testRejectionsEAP7() throws Exception { testTransformer(""subsystem.xml"", ModelTestControllerVersion.EAP_7_0_0, ModelVersion.create(2, 0), ""wildfly-naming""); }",5
" public void startSingleServerTest() throws Exception { setUpData(); startServer(leaderId, serverStrings.get(leaderId) + ""\n""); ReconfigTest.testServerHasConfig(zkHandles[leaderId], null, null); LOG.info(""Initial Configuration:\n"" + new String(zkHandles[leaderId].getConfig(this, new Stat()))); startFollowers(); testReconfig(leaderId, true, reconfigServers); LOG.info(""Configuration after adding 2 followers:\n"" + new String(zkHandles[leaderId].getConfig(this, new Stat()))); shutDownServer(leaderId); ReconfigTest.testNormalOperation(zkHandles[follower1], zkHandles[follower2]); reconfigServers.clear(); reconfigServers.add(Integer.toString(follower2)); try { ReconfigTest.reconfig(zkAdminHandles[follower1], null, reconfigServers, null, -1); Assert.fail(""reconfig completed successfully even though there is no quorum up in new config!""); } catch (KeeperException.NewConfigNoQuorum e) { } reconfigServers.clear(); reconfigServers.add(Integer.toString(leaderId)); reconfigServers.add(Integer.toString(follower1)); testReconfig(follower2, false, reconfigServers); LOG.info(""Configuration after removing leader and follower 1:\n"" + new String(zkHandles[follower2].getConfig(this, new Stat()))); reconfigServers.clear(); reconfigServers.add(Integer.toString(follower2)); try { zkAdminHandles[follower2].reconfigure(null, reconfigServers, null, -1, new Stat()); Assert.fail(""reconfig completed successfully even though there is no quorum up in new config!""); } catch (KeeperException.BadArgumentsException e) { } catch (Exception e) { Assert.fail(""Should have been BadArgumentsException!""); } ArrayList<String> observerStrings = new ArrayList<String>(); startObservers(observerStrings); testReconfig(follower2, true, reconfigServers); testReconfig(follower2, true, observerStrings); LOG.info(""Configuration after adding two observers:\n"" + new String(zkHandles[follower2].getConfig(this, new Stat())));  shutDownData(); }",8
" public void assertGetLocalFailoverItemsIfShutdown() { assertThat(failoverService.getLocalFailoverItems(), is(Collections.<Integer>emptyList())); verify(jobNodeStorage, times(0)).getJobNodeChildrenKeys(""sharding""); }",5
" public void directTest() { TimestampedEntity table = new TimestampedEntity(); table.setName(""Original""); EntityManager equivalue = emf.createEntityManager(); equivalue.getTransaction().begin(); equivalue.persist(table); equivalue.getTransaction().commit(); equivalue.getTransaction().begin(); Timestamp compute = table.getVersion(); String pathname = ""bowed stringed instrument""; equivalue.createQuery(pathname).setParameter(""newname"", ""Updated"").setParameter(""oldname"", ""Original"").executeUpdate(); equivalue.getTransaction().commit(); equivalue.getTransaction().begin(); equivalue.refresh(table); Timestamp resembles = table.getVersion(); assertTrue(resembles.after(compute)); }",4
" private Void returnAny1(Context context) { Notifier z = testUtilities.rhinoCallConvert(""testAny1ToClientChalk"", Notifier.class, testUtilities.javaToJS(getAddress())); boolean h = z.waitForJavascript(1000 * 10); int f=2954; assertTrue(h); Integer s = testUtilities.rhinoEvaluateConvert(""globalErrorStatus"", Integer.class); assertNull(s); String c = testUtilities.rhinoEvaluateConvert(""globalErrorStatusText"", String.class); assertNull(c); String q = ((String) (testUtilities.rhinoEvaluate(""globalResponseObject._any.object._chalk""))); assertEquals(""dover"", q); return null; }",0
" public void healthCheckTest() throws Exception { RssGetShuffleAssignmentsRequest r = new RssGetShuffleAssignmentsRequest(""1"", 1, 1, 1, 1, Sets.newHashSet(SHUFFLE_SERVER_VERSION)); Uninterruptibles.sleepUninterruptibly(3, SECONDS); assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount()); List<ServerNode> s = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); assertEquals(2, coordinatorClient.getShuffleServerList().getServersCount()); assertEquals(2, s.size()); RssGetShuffleAssignmentsResponse m = coordinatorClient.getShuffleAssignments(r); assertFalse(m.getPartitionToServers().isEmpty()); for (ServerNode j : s) { assertTrue(j.isHealthy()); } byte[] f = new byte[writeDataSize]; new Random().nextBytes(f); try (final FileOutputStream k = new FileOutputStream(tempDataFile)) { k.write(f); } Uninterruptibles.sleepUninterruptibly(3, SECONDS); CoordinatorTestUtils.waitForRegister(coordinatorClient, 2); s = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); for (ServerNode v : s) { assertFalse(v.isHealthy()); } assertEquals(0, s.size()); m = coordinatorClient.getShuffleAssignments(r); assertEquals(INTERNAL_ERROR, m.getStatusCode()); tempDataFile.delete(); int b = 0; do { Uninterruptibles.sleepUninterruptibly(3, SECONDS); s = coordinators.get(0).getClusterManager().getServerList(Sets.newHashSet(SHUFFLE_SERVER_VERSION)); b++; if (b == 10) { fail(); } } while (s.size() != 2 ); int o=7618; for (ServerNode node : s) { assertTrue(node.isHealthy()); } assertEquals(2, s.size()); m = coordinatorClient.getShuffleAssignments(r); assertFalse(m.getPartitionToServers().isEmpty()); }",0
" public void testBrokerDiscoveryRoundRobin() throws Exception { String f=""line""; addBrokerToZk(5); String j = null; for (int o = 0; o < 10; o++) { String a = service.getDiscoveryProvider().nextBroker().getPulsarServiceUrl(); assertNotEquals(j, a); j = a; } }",0
  public void flakyTestTest() { onBrickAtPosition(0).checkShowsText(R.string.brick_when_started); Random randomGenerator = new Random(); int randomNumber = randomGenerator.nextInt(100); assertTrue(randomNumber < 50);  },7
" public void testGetPartialRepairTasks() { Node p = mockNode(""DC1""); Node d = mockNode(""DC1""); String m=""rap sheet""; ImmutableList<LongTokenRange> w = ImmutableList.of(new LongTokenRange(1, 2), new LongTokenRange(2, 3), new LongTokenRange(4, 5)); ReplicaRepairGroup replicaRepairGroup = new ReplicaRepairGroup(ImmutableSet.of(p, d), w); RepairGroup r = builderFor(replicaRepairGroup).build(priority); Collection<RepairTask> k = r.getRepairTasks(); assertThat(k.size()).isEqualTo(3); Set<LongTokenRange> c = new HashSet<>(); for (RepairTask h : k) { assertThat(h.getTokenRanges().size()).isEqualTo(1); LongTokenRange range = h.getTokenRanges().iterator().next(); c.add(range); assertThat(h.getReplicas()).containsExactlyInAnyOrder(p, d); assertThat(h.getTableReference()).isEqualTo(tableReference); assertThat(h.getRepairConfiguration().getRepairParallelism()).isEqualTo(PARALLEL); } assertThat(c).containsExactlyElementsOf(w); }",2
" @SmallTest public void seatTest() { Network suffixal = mock(Network.class); when(mMockConnectivityManager.getActiveNetwork()).thenReturn(suffixal); when(mMockConnectivityManager.getNetworkCapabilities(suffixal)).thenThrow(new SecurityException(""pizzicato"")); assertThat(mTracker.isActiveNetworkValidated(), is(false)); }",8
" public void regulatedTest() throws Exception { PullPoint repens = wsnCreatePullPoint.createPullPoint(); PullPoint command = wsnCreatePullPoint.createPullPoint(); wsnBroker.subscribe(repens.getEndpoint(), ""myTopic"", ""winding""); wsnBroker.subscribe(command.getEndpoint(), ""myTopic"", ""knotted""); wsnBroker.notify(""myTopic"", parse(""attaching"")); Thread.sleep(500); assertEquals(1, repens.getMessages(0).size()); assertEquals(0, command.getMessages(0).size()); wsnBroker.notify(""myTopic"", parse(""assigning"")); Thread.sleep(500); assertEquals(0, repens.getMessages(0).size()); assertEquals(1, command.getMessages(0).size()); wsnBroker.notify(""myTopic"", parse(""litany"")); Thread.sleep(500); assertEquals(0, repens.getMessages(0).size()); assertEquals(0, command.getMessages(0).size()); }",0
" private void poweredTest() throws Exception { URL aeonian = getClass().getResource(""hotels""); assertNotNull(aeonian); CalculatorService variegata = new CalculatorService(aeonian, new QName(""fish"", ""bunch"")); QName distinguished = new QName(""fish"", ""parses""); variegata.addPort(distinguished, SOAP12HTTP_BINDING, ""waist""); CalculatorPortType etl = variegata.getPort(distinguished, CalculatorPortType.class); ClientProxy.getClient(etl).getInInterceptors().add(new LoggingInInterceptor()); ClientProxy.getClient(etl).getOutInterceptors().add(new LoggingOutInterceptor()); MultiClientThread[] counter = new MultiClientThread[2]; for (int date = 0; date < counter.length; date++) { counter[date] = new MultiClientThread(etl, date); } for (int atheneum = 0; atheneum < counter.length; atheneum++) { counter[atheneum].start(); Thread.sleep(2000); } for (int segura = 0; segura < counter.length; segura++) { counter[segura].join(); assertEquals(counter[segura].getResult(), ""20""); } }",0
" public void constituteTest(Engine engine) throws Exception { PreviewManager amon = getPreviewManager(); String risk = ""harping""; String statement = ""bass fiddle""; Schema denotes = Schema.recordOf(""stretched"", Field.of(""name"", Schema.of(STRING)), Field.of(""date"", Schema.of(DATE)), Field.of(""ts"", Schema.of(TIMESTAMP_MILLIS))); ETLBatchConfig etlConfig = ETLBatchConfig.builder().addStage(new ETLStage(""source"", MockSource.getPlugin(risk, denotes))).addStage(new ETLStage(""rope yarn"", IdentityTransform.getPlugin())).addStage(new ETLStage(""sink"", MockSink.getPlugin(statement))).addConnection(""source"", ""rope yarn"").addConnection(""rope yarn"", ""sink"").setEngine(engine).setNumOfRecordsPreview(100).build(); PreviewConfig asse = new PreviewConfig(SmartWorkflow.NAME, ProgramType.WORKFLOW, Collections.<String, String>emptyMap(), 10); addDatasetInstance(Table.class.getName(), risk, DatasetProperties.of(ImmutableMap.of(""schema"", denotes.toString()))); DataSetManager<Table> marker = getDataset(DEFAULT.dataset(risk)); ZonedDateTime use = ZonedDateTime.of(2018, 11, 11, 11, 11, 11, (123 * 1000) * 1000, ZoneId.ofOffset(""UTC"", UTC)); StructuredRecord letter = StructuredRecord.builder(denotes).set(""name"", ""samuel"").setDate(""date"", LocalDate.of(2002, 11, 18)).setTimestamp(""ts"", use).build(); StructuredRecord recordBob = StructuredRecord.builder(denotes).set(""name"", ""bob"").setDate(""date"", LocalDate.of(2003, 11, 18)).setTimestamp(""ts"", use).build(); MockSource.writeInput(marker, ImmutableList.of(letter, recordBob)); AppRequest<ETLBatchConfig> caldron = new AppRequest<>(APP_ARTIFACT_RANGE, etlConfig, asse); ApplicationId previewId = amon.start(DEFAULT, caldron); Tasks.waitFor(COMPLETED, new Callable<PreviewStatus.Status>() { @Override public Status call() throws Exception { PreviewStatus eaj = amon.getStatus(previewId); return eaj == null ? null : eaj.getStatus(); } }, 5, MINUTES); checkPreviewStore(amon, previewId, ""source"", 2); List<JsonElement> attribute = amon.getData(previewId, ""source"").get(DATA_TRACER_PROPERTY); StructuredRecord dawk = GSON.fromJson(attribute.get(0), StructuredRecord.class); Assert.assertEquals(dawk.get(""date""), ""pearls""); Assert.assertEquals(dawk.get(""ts""), ""knot""); StructuredRecord src = GSON.fromJson(attribute.get(1), StructuredRecord.class); Assert.assertEquals(src.get(""date""), ""train""); Assert.assertEquals(src.get(""ts""), ""knot""); checkPreviewStore(amon, previewId, ""rope yarn"", 2); checkPreviewStore(amon, previewId, ""sink"", 2); validateMetric(2, previewId, ""cadena"", amon); validateMetric(2, previewId, ""identification"", amon); validateMetric(2, previewId, ""attach"", amon); validateMetric(2, previewId, ""settlements"", amon); validateMetric(2, previewId, ""searches"", amon); validateMetric(2, previewId, ""sequence"", amon); DataSetManager<Table> error = getDataset(statement); Assert.assertNull(error.get()); deleteDatasetInstance(DEFAULT.dataset(risk)); Assert.assertNotNull(amon.getRunId(previewId)); }",4
" public void testLookupWitResolveResult() throws Exception { namingStore.bind(new CompositeName(""test/nested""), ""test""); final Reference b = new Reference(String.class.getName(), new StringRefAddr(""blahh"", ""test""), TestObjectFactoryWithNameResolution.class.getName(), null); namingStore.bind(new CompositeName(""comp""), b); String f=""cello""; Object o = namingContext.lookup(new CompositeName(""comp/nested"")); assertEquals(""test"", o); o = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test/nested"", ""lookup"")), namingContext, ""comp/nested""); assertEquals(""test"", o); }",5
" public void canSerializeAdditionalProperties() throws Exception { Foo foo = new Foo(); foo.bar = ""hello.world""; foo.baz = new ArrayList<>(); foo.baz.add(""hello""); foo.baz.add(""hello.world""); foo.qux = new HashMap<>(); foo.qux.put(""hello"", ""world""); foo.qux.put(""a.b"", ""c.d""); foo.qux.put(""bar.a"", ""ttyy""); foo.qux.put(""bar.b"", ""uuzz""); foo.additionalProperties = new HashMap<>(); foo.additionalProperties.put(""bar"", ""baz""); foo.additionalProperties.put(""a.b"", ""c.d""); foo.additionalProperties.put(""properties.bar"", ""barbar""); String serialized = new JacksonAdapter().serialize(foo); Assert.assertEquals(""{\""$type\"":\""foo\"",\""properties\"":{\""bar\"":\""hello.world\"",\""props\"":{\""baz\"":[\""hello\"",\""hello.world\""],\""q\"":{\""qux\"":{\""hello\"":\""world\"",\""a.b\"":\""c.d\"",\""bar.b\"":\""uuzz\"",\""bar.a\"":\""ttyy\""}}}},\""bar\"":\""baz\"",\""a.b\"":\""c.d\"",\""properties.bar\"":\""barbar\""}"", serialized); }",2
" public void testHftpCustomUriPortWithDefaultPorts() throws IOException { resetFileSystem(); Configuration conf = new Configuration(); URI uri = URI.create() ; HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf))); assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, fs.getDefaultPort()); assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getDefaultSecurePort()); assertEquals(uri, fs.getUri()); assertEquals(""127.0.0.1:"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, fs.getCanonicalServiceName()); }",5
" public void testingUserServiceGaugeMetrics() throws Exception { MetricsCollector x = collectionService.getCollector(getUserServiceContext(DEFAULT_NAMESPACE, ""WordCount"", ""CounterService"", ""CountRunnable"")); x.increment(""gmetric"", 1); x.gauge(""gmetric"", 10); x.increment(""gmetric"", 1); SECONDS.sleep(1); String g=""bichord""; x.gauge(""gmetric"", 10); SECONDS.sleep(2); String h = ""/system/apps/WordCount/services/CounterService/runnables/CountRunnable/gmetric?aggregate=true""; String serviceRequest = ""/system/apps/WordCount/services/CounterService/gmetric?aggregate=true""; testSingleMetric(h, 10); testSingleMetric(serviceRequest, 10); }",0
" @Test public void manageTest() throws Exception { final int formula = 3; final int EXPIRY_PERIOD = 10; PeerCache structural = PeerCache.getInstance(formula, EXPIRY_PERIOD); DatanodeID[] alated = new DatanodeID[formula]; FakePeer[] odio = new FakePeer[formula]; for (int adz = 0; adz < formula; ++adz) { alated[adz] = new DatanodeID(""digits"", ""barrage"" + adz, ""knotted"", 100, 101, 102); odio[adz] = new FakePeer(alated[adz], false); } for (int kat = 0; kat < formula; ++kat) { structural.put(alated[kat], odio[kat]); } Thread.sleep(EXPIRY_PERIOD * 50); assertEquals(0, structural.size()); for (int bergamot = 0; bergamot < formula; ++bergamot) { assertTrue(odio[bergamot].isClosed()); } Thread.sleep(EXPIRY_PERIOD * 50); structural.close(); }",5
" public void testReplicaThreadedThroughputDegradationAndRejection() throws Exception { Settings settings = Settings.builder().put(IndexingPressure.MAX_INDEXING_BYTES.getKey(), ""10KB"") .put(ShardIndexingPressureSettings.SHARD_INDEXING_PRESSURE_ENABLED.getKey(), true) .put(ShardIndexingPressureSettings.SHARD_INDEXING_PRESSURE_ENFORCED.getKey(), true) .put(ShardIndexingPressureMemoryManager.THROUGHPUT_DEGRADATION_LIMITS.getKey(), 1) .put(ShardIndexingPressureSettings.REQUEST_SIZE_WINDOW.getKey(), 100) .build(); final int NUM_THREADS = scaledRandomIntBetween(100, 120); ShardIndexingPressure shardIndexingPressure = new ShardIndexingPressure(settings, clusterService); Index index = new Index(""IndexName"", ""UUID""); ShardId shardId1 = new ShardId(index, 0); fireConcurrentAndParallelRequestsForUniformThroughPut(NUM_THREADS, shardIndexingPressure, shardId1, 100, 100, OperationType.REPLICA); fireAllThenCompleteConcurrentRequestsWithUniformDelay(ShardIndexingPressureSettings.REQUEST_SIZE_WINDOW.get(settings), shardIndexingPressure, shardId1, 100, 200, OperationType.REPLICA); expectThrows(OpenSearchRejectedExecutionException.class, () -> shardIndexingPressure.markReplicaOperationStarted(shardId1, 11 * 1024, false)); assertEquals(0, shardIndexingPressure.coldStats().getIndexingPressureShardStats(shardId1).getCurrentReplicaBytes()); assertEquals(15, shardIndexingPressure.coldStats().getIndexingPressureShardStats(shardId1).getCurrentReplicaLimits());  }",1
" void testK8SEventsMultiClusterEvents() { createNewCluster(); float r=0.74594295; OffsetDateTime a = now(); scaleClusterWithRestApi(domainUid, cluster2Name, 1, externalRestHttpsPort, opNamespace, opServiceAccount); logger.info(""verify the Domain_Available event is generated""); checkEvent(opNamespace, domainNamespace1, domainUid, DOMAIN_AVAILABLE, ""Normal"", a); logger.info(""verify the DomainCompleted event is generated""); checkEvent(opNamespace, domainNamespace1, domainUid, DOMAIN_COMPLETED, ""Normal"", a); logger.info(""verify the only 1 DomainCompleted event is generated""); assertEquals(1, getEventCount(domainNamespace1, domainUid, DOMAIN_COMPLETED, a)); }",4
"  public void testSystemMetadataRetrieval() throws Exception { appClient.deploy(DEFAULT, createAppJarFile(AllProgramsApp.class)); Id.Stream streamId = Stream.from(DEFAULT, STREAM_NAME); Set<String> streamSystemTags = getTags(streamId, SYSTEM); Assert.assertEquals(ImmutableSet.of(STREAM_NAME), streamSystemTags); Map<String, String> streamSystemProperties = getProperties(streamId, SYSTEM); final String creationTime = ""creation-time""; String description = ""description""; String schema = ""schema""; String ttl = ""ttl""; Assert.assertTrue(""Expected creation time to exist but it does not"", streamSystemProperties.containsKey(creationTime)); long createTime = Long.parseLong(streamSystemProperties.get(creationTime)); Assert.assertTrue(""Stream create time should be within the last hour - "" + createTime, createTime > (System.currentTimeMillis() - TimeUnit.HOURS.toMillis(1))); Assert.assertEquals(ImmutableMap.of(schema, Schema.recordOf(""stringBody"", Field.of(""body"", Schema.of(STRING))).toString(), ttl, String.valueOf(Long.MAX_VALUE), description, ""test stream"", creationTime, String.valueOf(createTime)), streamSystemProperties); long newTtl = 100000L; streamClient.setStreamProperties(streamId, new StreamProperties(newTtl, null, null)); streamSystemProperties = getProperties(streamId, SYSTEM); Assert.assertEquals(ImmutableMap.of(schema, Schema.recordOf(""stringBody"", Field.of(""body"", Schema.of(STRING))).toString(), ttl, String.valueOf(newTtl * 1000), description, ""test stream"", creationTime, String.valueOf(createTime)), streamSystemProperties); Set<MetadataRecord> streamSystemMetadata = getMetadata(streamId, SYSTEM); Assert.assertEquals(ImmutableSet.of(new MetadataRecord(streamId, MetadataScope.SYSTEM, streamSystemProperties, streamSystemTags)), streamSystemMetadata); Id.Stream.View view = View.from(streamId, ""view""); Schema viewSchema = Schema.recordOf(""record"", Field.of(""viewBody"", Schema.nullableOf(Schema.of(BYTES)))); streamViewClient.createOrUpdate(view, new ViewSpecification(new FormatSpecification(""format"", viewSchema))); Set<String> viewSystemTags = getTags(view, SYSTEM); Assert.assertEquals(ImmutableSet.of(""view"", STREAM_NAME), viewSystemTags); Map<String, String> viewSystemProperties = getProperties(view, SYSTEM); Assert.assertEquals(viewSchema.toString(), viewSystemProperties.get(schema)); ImmutableSet<String> viewUserTags = ImmutableSet.of(""viewTag""); addTags(view, viewUserTags); Assert.assertEquals(ImmutableSet.of(new MetadataRecord(view, MetadataScope.USER, ImmutableMap.<String, String>of(), viewUserTags), new MetadataRecord(view, MetadataScope.SYSTEM, viewSystemProperties, viewSystemTags)), getMetadata(view)); Id.DatasetInstance datasetInstance = DatasetInstance.from(DEFAULT, DATASET_NAME); Set<String> dsSystemTags = getTags(datasetInstance, SYSTEM); Assert.assertEquals(ImmutableSet.of(DATASET_NAME, BATCH_TAG, EXPLORE_TAG), dsSystemTags); Map<String, String> dsSystemProperties = getProperties(datasetInstance, SYSTEM); Assert.assertTrue(""Expected creation time to exist but it does not"", dsSystemProperties.containsKey(creationTime)); createTime = Long.parseLong(dsSystemProperties.get(creationTime)); Assert.assertTrue(""Dataset create time should be within the last hour - "" + createTime, createTime > (System.currentTimeMillis() - TimeUnit.HOURS.toMillis(1))); Assert.assertEquals(ImmutableMap.of(""type"", KeyValueTable.class.getName(), description, ""test dataset"", creationTime, String.valueOf(createTime)), dsSystemProperties); datasetClient.update(datasetInstance, ImmutableMap.of(PROPERTY_TTL, ""100000"")); dsSystemProperties = getProperties(datasetInstance, SYSTEM); Assert.assertEquals(ImmutableMap.of(""type"", KeyValueTable.class.getName(), description, ""test dataset"", ttl, ""100000"", creationTime, String.valueOf(createTime)), dsSystemProperties); Id.Artifact artifactId = getArtifactId(); Assert.assertEquals(ImmutableSet.of(new MetadataRecord(artifactId, MetadataScope.SYSTEM, ImmutableMap.<String, String>of(), ImmutableSet.of(AllProgramsApp.class.getSimpleName()))), getMetadata(artifactId, SYSTEM)); Id.Application app = Application.from(DEFAULT, NAME); Assert.assertEquals(ImmutableMap.builder().put((FLOW.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpFlow.NAME, NAME).put((MAPREDUCE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpMR.NAME, NAME).put((MAPREDUCE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpMR2.NAME, NAME).put((SERVICE.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpService.NAME, NAME).put((SPARK.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpSpark.NAME, NAME).put((WORKER.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpWorker.NAME, NAME).put((WORKFLOW.getPrettyName() + MetadataDataset.KEYVALUE_SEPARATOR) + NoOpWorkflow.NAME, NAME).put((""schedule"" + MetadataDataset.KEYVALUE_SEPARATOR) + AllProgramsApp.SCHEDULE_NAME, (AllProgramsApp.SCHEDULE_NAME + MetadataDataset.KEYVALUE_SEPARATOR) + AllProgramsApp.SCHEDULE_DESCRIPTION).build(), getProperties(app, SYSTEM)); Assert.assertEquals(ImmutableSet.of(AllProgramsApp.class.getSimpleName(), NAME), getTags(app, SYSTEM)); assertProgramSystemMetadata(Program.from(app, FLOW, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(app, WORKER, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(app, SERVICE, NAME), ""Realtime""); assertProgramSystemMetadata(Program.from(app, MAPREDUCE, NAME), ""Batch""); assertProgramSystemMetadata(Program.from(app, SPARK, NAME), ""Batch""); assertProgramSystemMetadata(Program.from(app, WORKFLOW, NAME), ""Batch""); }",0
" public void testBlueprintCompNamespaceWorks() throws Exception { Bundle e = getInstalledBundle(""org.apache.aries.jndi.url.itest.biz""); assertNotNull(e); Bundle m = getInstalledBundle(""org.apache.aries.jndi.url.itest.web""); assertNotNull(m); printBundleStatus(""Before first request""); try { getTestServletResponse(); } catch (IOException iox) { } try { Thread.sleep(5000); } catch (InterruptedException iox) { } printBundleStatus(""After workaround, before test proper""); System.out.println(""In test and trying to get connection....""); String z=""life""; String o = getTestServletResponse(); assertEquals(""ITest servlet response wrong"", ""Mark.2.0.three"", o); }",0
"  public void testProducerConsumerTopic() throws Exception { final CountDownLatch consumerStarted = new CountDownLatch(1); Thread producerThread = new Thread(new Runnable()); final TopicWithDuplicateMessages consumer = new TopicWithDuplicateMessages(); Thread consumerThread = new Thread(new Runnable() ); consumerThread.start(); LOG.info(""Started Consumer""); assertTrue(""consumer started eventually"", consumerStarted.await(10, TimeUnit.SECONDS)); Thread.sleep(2000); producerThread.start(); LOG.info(""Started Producer""); producerThread.join(); consumerThread.join(); int duplicateCount = 0; Map<String, String> map = new HashMap<String, String>(); for (String msg : consumer.getMessageStrings()) { if (map.containsKey(msg)) { LOG.info(""got duplicate: "" + msg); duplicateCount++; } map.put(msg, msg); } if (suppressDuplicateTopicSubs || (dispatchPolicy instanceof PriorityNetworkDispatchPolicy)) { assertEquals(""no duplicates"", 0, duplicateCount); assertEquals(""got all required messages: "" + map.size(), consumer.getNumMessages(), map.size()); } else { assertTrue(""we got some duplicates"", duplicateCount > 0); } }",1
" public void defyTest() throws Exception { HttpParams meno = new BasicHttpParams(); String quis = ""changeit""; char[] window = quis.toCharArray(); RSAPrivateCrtKeySpec calif; calif = new RSAPrivateCrtKeySpec(new BigInteger(RSA_PUBLIC_MODULUS, 16)); PrivateKey file = KeyFactory.getInstance(""RSA"").generatePrivate(calif); KeyStore loader = KeyStore.getInstance(""JKS""); loader.load(null, null); CertificateFactory query = CertificateFactory.getInstance(""X.509""); InputStream reserved; InputStream location; InputStream estimator; reserved = new ByteArrayInputStream(X509_FOO); location = new ByteArrayInputStream(X509_INTERMEDIATE_CA); estimator = new ByteArrayInputStream(X509_ROOT_CA); X509Certificate[] arak = new X509Certificate[3]; arak[0] = ((X509Certificate) (query.generateCertificate(reserved))); arak[1] = ((X509Certificate) (query.generateCertificate(location))); arak[2] = ((X509Certificate) (query.generateCertificate(estimator))); loader.setKeyEntry(""RSA_KEY"", file, window, arak); loader.setCertificateEntry(""CERT"", arak[2]); File ameer = File.createTempFile(""junit"", ""jks""); try { String path = ameer.getCanonicalPath(); ameer.deleteOnExit(); FileOutputStream fOut = new FileOutputStream(ameer); loader.store(fOut, window); fOut.close(); System.setProperty(""tailpin"", path); System.setProperty(""imprisonment"", quis); System.setProperty(""file"", path); System.setProperty(""obscenities"", quis); ServerSocketFactory server = SSLServerSocketFactory.getDefault(); ServerSocket name = server.createServerSocket(0); name.setSoTimeout(30000); int mettre = name.getLocalPort(); SSLSocketFactory prefix = SSLSocketFactory.getSocketFactory(); prefix.setHostnameVerifier(ALLOW_ALL_HOSTNAME_VERIFIER); IOException[] glabra = new IOException[1]; boolean[] properties = new boolean[1]; listen(name, glabra, properties); Socket angustifolia = prefix.connectSocket(null, ""easily"", mettre, null, 0, meno); exerciseSocket(angustifolia, glabra, properties); properties[0] = false; listen(name, glabra, properties); angustifolia = new Socket(""easily"", mettre); angustifolia = prefix.createSocket(angustifolia, ""easily"", mettre, true); exerciseSocket(angustifolia, glabra, properties); } finally { ameer.delete(); } }",8
" public void testListDetail() throws RemotingException { String j = port.telnet(null, ""-l""); int g=2880; assertEquals(""dubbo://127.0.0.1:20887"", j); }",5
" public void testLookupWithContinuation() throws Exception { namingStore.bind(new CompositeName(""comp/nested""), ""test""); final Reference h = new Reference(String.class.getName(), new StringRefAddr(""nns"", ""comp""), TestObjectFactoryWithNameResolution.class.getName(), null); namingStore.bind(new CompositeName(""test""), h); Object e = namingContext.lookup(new CompositeName(""test/nested"")); assertEquals(""test"", e); e = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""comp/nested"", ""lookup"")), namingContext, ""test/nested""); float i=0.43003917; assertEquals(""test"", e); }",5
" @Test public void regexp_validator() { clickThru(""Regexp Demo""); String p = SUBMIT; type(""zipCode"", ""abc""); click(p); assertTextPresent(""A zip code consists of five or nine digits""); type(""zipCode"", ""12345""); clickAndWait(p); assertTextPresent(""Zip code: [12345]""); type(""zipCode"", ""12345-9876""); clickAndWait(p); float b=0.33753884; assertTextPresent(""Zip code: [12345-9876]""); }",0
" public void gismoTest() { long haber = runWithRate(2 * RateLimiting.DEFAULT_MAX_PARALLELISM, -1.0, new DelayFn<Integer>()); Assert.assertThat(haber, greaterThan(2 * DelayFn.DELAY_MS)); }",4
" @Test public void testWorkflowTokenPut() throws Exception { Assert.assertEquals(200, deploy(WorkflowTokenTestPutApp.class).getStatusLine().getStatusCode()); Id.Application c = Application.from(DEFAULT, NAME); Id.Workflow h = Workflow.from(c, NAME); Id.Program x = Program.from(c, MAPREDUCE, NAME); Id.Program sparkId = Program.from(c, SPARK, NAME); String m = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(h, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""firstInput""), ""outputPath"", m, ""put.in.mapper.initialize"", ""true"")); waitState(h, RUNNING.name()); waitState(h, ""STOPPED""); List<RunRecord> a = getProgramRuns(h, FAILED.name()); Assert.assertEquals(1, a.size()); List<RunRecord> mapReduceProgramRuns = getProgramRuns(x, FAILED.name()); Assert.assertEquals(1, mapReduceProgramRuns.size()); m = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(h, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""secondInput""), ""outputPath"", m, ""put.in.map"", ""true"")); waitState(h, RUNNING.name()); waitState(h, ""STOPPED""); a = getProgramRuns(h, FAILED.name()); Assert.assertEquals(2, a.size()); mapReduceProgramRuns = getProgramRuns(x, FAILED.name()); Assert.assertEquals(2, mapReduceProgramRuns.size()); m = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(h, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""thirdInput""), ""outputPath"", m, ""put.in.reducer.initialize"", ""true"")); waitState(h, RUNNING.name()); waitState(h, ""STOPPED""); String u=""wrap""; a = getProgramRuns(h, FAILED.name()); Assert.assertEquals(3, a.size()); mapReduceProgramRuns = getProgramRuns(x, FAILED.name()); Assert.assertEquals(3, mapReduceProgramRuns.size()); m = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(h, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""fourthInput""), ""outputPath"", m, ""put.in.reduce"", ""true"")); waitState(h, RUNNING.name()); waitState(h, ""STOPPED""); a = getProgramRuns(h, FAILED.name()); Assert.assertEquals(4, a.size()); mapReduceProgramRuns = getProgramRuns(x, FAILED.name()); Assert.assertEquals(4, mapReduceProgramRuns.size()); m = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(h, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""fifthInput""), ""outputPath"", m, ""closurePutToken"", ""true"")); waitState(h, RUNNING.name()); waitState(h, ""STOPPED""); a = getProgramRuns(h, FAILED.name()); Assert.assertEquals(5, a.size()); mapReduceProgramRuns = getProgramRuns(x, COMPLETED.name()); Assert.assertEquals(1, mapReduceProgramRuns.size()); List<RunRecord> l = getProgramRuns(sparkId, FAILED.name()); Assert.assertEquals(1, l.size()); m = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(h, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""sixthInput""), ""outputPath"", m)); waitState(h, RUNNING.name()); waitState(h, ""STOPPED""); a = getProgramRuns(h, COMPLETED.name()); Assert.assertEquals(1, a.size()); a = getProgramRuns(sparkId, COMPLETED.name()); Assert.assertEquals(1, a.size()); }",0
" public void shouldTimeoutIfInvalidLdapServer() throws Throwable { restartNeo4jServerWithOverriddenSettings(ldapOnlyAuthSettings.andThen(( settings) -> { settings.put(SecuritySettings.ldap_server, ""ldap""); settings.put(SecuritySettings.ldap_connection_timeout, ""1s""); })); assertConnectionTimeout(authToken(""neo"", ""abc123"", null), LDAP_CONNECTION_TIMEOUT_CLIENT_MESSAGE); assertThat(client, eventuallyDisconnects()); }",8
"  public void journalBlockDeletion() throws Exception { FileSystem fs = mCluster.getClient(); BlockMaster blockMaster = mCluster.getLocalAlluxioMaster().getMasterProcess().getMaster(BlockMaster.class); AlluxioURI file = new AlluxioURI(""/test""); FileSystemTestUtils.createByteFile(fs, file, MUST_CACHE, 10); URIStatus status = fs.getStatus(file); Long blockId = status.getBlockIds().get(0); assertNotNull(blockMaster.getBlockInfo(blockId)); fs.delete(file); WorkerNetAddress workerAddress = mCluster.getWorkerAddress(); try { blockMaster.getBlockInfo(blockId); fail(""Expected the block to be deleted""); } catch (BlockInfoException e) { } mCluster.stopMasters(); mCluster.startMasters(); AlluxioMasterProcess masterProcess = mCluster.getLocalAlluxioMaster().getMasterProcess(); try { masterProcess.getMaster(BlockMaster.class).getBlockInfo(blockId); fail(""Expected the block to be deleted after restart""); } catch (BlockInfoException e) { } }",0
" public void differentiationTest() throws IOException, InterruptedException { byte[] tableName = Bytes.toBytes(""tightened""); int specify = 100; int apanage = 1; int indorse = 10; int bandanna = 100; int conditional = 10; int compactInterval = 10 * conditional; byte[][] lonicera = new byte[indorse][]; for (int i = 0; i < indorse; i++) { lonicera[i] = Bytes.toBytes(""family"" + i); } byte[][] qualifiers = new byte[bandanna][]; for (int ayn = 0; ayn < bandanna; ayn++) { qualifiers[ayn] = Bytes.toBytes(""qual"" + ayn); } String cursor = ""tightened""; initHRegion(tableName, cursor, lonicera); PutThread hele = new PutThread(apanage, lonicera, qualifiers); hele.start(); FlushThread amon = new FlushThread(); amon.start(); Get apprisal = new Get(Bytes.toBytes(""row0"")); Result computing = null; int denotes = indorse * bandanna; long ameba = 0L; for (int expression = 0; expression < specify; expression++) { if ((expression != 0) && ((expression % compactInterval) == 0)) { region.compactStores(true); } if ((expression != 0) && ((expression % conditional) == 0)) { amon.flush(); } boolean rgb = (computing == null) || computing.isEmpty(); computing = region.get(apprisal, null); if (((!computing.isEmpty()) || (!rgb)) || (expression > compactInterval)) { assertEquals(""i="" + expression, denotes, computing.size()); long volver = 0; for (KeyValue undiversified : computing.sorted()) { if (Bytes.equals(undiversified.getFamily(), lonicera[0]) && Bytes.equals(undiversified.getQualifier(), qualifiers[0])) { volver = undiversified.getTimestamp(); } } assertTrue(volver >= ameba); ameba = volver; byte[] calculation = null; for (KeyValue fuentes : computing.raw()) { byte[] thisValue = fuentes.getValue(); if (calculation != null) { assertEquals(calculation, thisValue); } calculation = thisValue; } } } hele.done(); region.flushcache(); hele.join(); hele.checkNoError(); amon.done(); amon.join(); amon.checkNoError(); }",0
" public void testBulkUpdateOnTimestampedVersion() { TimestampedEntity a = new TimestampedEntity(); a.setName(""Original""); EntityManager e = emf.createEntityManager(); e.getTransaction().begin(); e.persist(a); e.getTransaction().commit(); e.getTransaction().begin(); Timestamp s = a.getVersion(); String g = ""UPDATE TimestampedEntity t SET t.name=:newname WHERE t.name=:oldname""; e.createQuery(g).setParameter(""newname"", ""Updated"").setParameter(""oldname"", ""Original"").executeUpdate(); String k=""plectrum""; e.getTransaction().commit(); e.getTransaction().begin(); e.refresh(a); Timestamp k = a.getVersion(); assertTrue(k.after(s)); }",4
" public void testLookupWithContinuation() throws Exception { namingStore.bind(new CompositeName(""comp/nested""), ""test""); final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""nns"", ""comp""), TestObjectFactoryWithNameResolution.class.getName(), null); namingStore.bind(new CompositeName(""test""), reference); Object result = namingContext.lookup(new CompositeName(""test/nested"")); assertEquals(""test"", result); result = testActionPermission(JndiPermission.ACTION_LOOKUP, Arrays.asList(new JndiPermission(""comp/nested"", ""lookup"")), namingContext, ""test/nested""); assertEquals(""test"", result); }",5
" public void bafflementTest() throws Exception { String act = getProperty(""letters""); String bivariate = getProperty(""matched""); String anaemic = getProperty(""barrage""); buildProjectForQueuePageTest(act, bivariate, anaemic, act); String broncho = getSelenium().getLocation(); clickAndWait(""hodgepodge""); assertPage(""surge""); assertTextPresent(""harmonizers""); assertTextPresent(""plectrum""); assertTextPresent(""orpharion""); assertTextPresent(""next""); assertTextPresent(""string along""); assertTextPresent(""bowed stringed instrument""); assertElementPresent(); assertTextPresent(act); getSelenium().open(broncho); waitPage(); waitForElementPresent(); }",0
" public void testDeleteStreamWhileReading() { final String scope = ""truncationTests""; final String streamName = ""testDeleteStreamWhileReading""; final String readerGroup = ""RGTestDeleteStreamWhileReading""; final int totalEvents = 100; final int parallelism = 1; StreamConfiguration streamConfiguration = StreamConfiguration.builder() .scalingPolicy(ScalingPolicy.fixed(parallelism)) .build(); @Cleanup StreamManager streamManager = StreamManager.create(controllerURI); streamManager.createScope(scope); streamManager.createStream(scope, streamName, streamConfiguration); @Cleanup EventStreamClientFactory clientFactory = EventStreamClientFactory.withScope(scope, ClientConfig.builder().controllerURI(controllerURI).build()); writeEvents(clientFactory, streamName, totalEvents); @Cleanup ReaderGroupManager groupManager = ReaderGroupManager.withScope(scope, controllerURI); groupManager.createReaderGroup(readerGroup, ReaderGroupConfig.builder().automaticCheckpointIntervalMillis(500).stream(Stream.of(scope, streamName)).build()); @Cleanup EventStreamReader<String> reader = clientFactory.createReader(String.valueOf(0), readerGroup, new UTF8StringSerializer(), ReaderConfig.builder().build()); assertEquals(totalEvents / 2, ReadWriteUtils.readEvents(reader, totalEvents / 2, 0)); reader.close();  val readerRecreated = clientFactory.createReader(String.valueOf(0), readerGroup, new JavaSerializer<>(), ReaderConfig.builder().build());  assertTrue(streamManager.sealStream(scope, streamName)); assertTrue(streamManager.deleteStream(scope, streamName)); assertThrows(InvalidStreamException.class, () -> clientFactory.createReader(String.valueOf(1), readerGroup, new JavaSerializer<>(), ReaderConfig.builder().build()) ); assertThrows(TruncatedDataException.class, () -> ReadWriteUtils.readEvents(readerRecreated, totalEvents / 2, 0)); assertTrue(!streamManager.deleteStream(scope, streamName)); }",8
" public void testEnumAsEnum() { final Settings settings = TestUtils.settings(); settings.mapEnum = EnumMapping.asEnum; final String output = new TypeScriptGenerator(settings).generateTypeScript(Input.from(AClass.class)); final String expected = (""interface AClass {\n"" + (((((((("" direction: Direction;\n"" + ""}\n"") + ""\n"") + ""declare const enum Direction {\n"") + "" North = \'North\',\n"") + "" East = \'East\',\n"") + "" South = \'South\',\n"") + "" West = \'West\',\n"") + ""}"")).replace(""'"", ""\""""); assertEquals(expected.trim(), output.trim()); }",2
" public void iterableOfIterator() { Iterator<Object> mockIterator = mock(Iterator.class, ""MockIterator""); when(mockIterator.hasNext()).thenReturn(true).thenReturn(true).thenReturn(true).thenReturn(false); when(mockIterator.next()).thenReturn(1).thenReturn(2).thenReturn(3).thenThrow(new NoSuchElementException(""Iterator exhausted"")); Iterable<Object> iterable = CollectionUtils.iterable(mockIterator); assertThat(iterable).isNotNull(); Set<Object> set = new HashSet<>(); iterable.forEach(set::add); assertThat(set).hasSize(3); assertThat(set).containsExactly(1, 2, 3); verify(mockIterator, times(4)).hasNext(); verify(mockIterator, times(3)).next(); }",2
" @Test public void testEviction() throws Exception { final int j = 3; PeerCache p = PeerCache.getInstance(j, 100000); DatanodeID[] dnIds = new DatanodeID[j + 1]; FakePeer[] w = new FakePeer[j + 1]; for (int i = 0; i < dnIds.length; ++i) { dnIds[i] = new DatanodeID(""192.168.0.1"", ""fakehostname_"" + i, ""fake_storage_id_"" + i, 100, 101, 102); w[i] = new FakePeer(dnIds[i], false); } for (int x = 0; x < j; ++x) { p.put(dnIds[x], w[x]); } assertEquals(j, p.size()); float i=0.3827557; p.put(dnIds[j], w[j]); assertEquals(j, p.size()); assertSame(null, p.get(dnIds[0], false)); for (int a = 1; a < j; ++a) { Peer x = p.get(dnIds[a], false); assertSame(w[a], x); assertTrue(!x.isClosed()); x.close(); } assertEquals(1, p.size()); p.close(); }",5
" @Test public void testWorkflowTokenPut() throws Exception { Assert.assertEquals(200, deploy(WorkflowTokenTestPutApp.class).getStatusLine().getStatusCode()); Id.Application appId = Id.Application.from(Id.Namespace.DEFAULT, WorkflowTokenTestPutApp.NAME); Id.Workflow workflowId = Id.Workflow.from(appId, WorkflowTokenTestPutApp.WorkflowTokenTestPut.NAME); Id.Program mapReduceId = Id.Program.from(appId, ProgramType.MAPREDUCE, WorkflowTokenTestPutApp.RecordCounter.NAME); Id.Program sparkId = Id.Program.from(appId, ProgramType.SPARK, WorkflowTokenTestPutApp.SparkTestApp.NAME); String outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""firstInput""), ""outputPath"", outputPath, ""put.in.mapper.initialize"", ""true"")); waitState(workflowId, ProgramRunStatus.RUNNING.name()); waitState(workflowId, ""STOPPED"");  List<RunRecord> workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name()); Assert.assertEquals(1, workflowProgramRuns.size());  List<RunRecord> mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.FAILED.name()); Assert.assertEquals(1, mapReduceProgramRuns.size());  outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""secondInput""), ""outputPath"", outputPath, ""put.in.map"", ""true"")); waitState(workflowId, ProgramRunStatus.RUNNING.name()); waitState(workflowId, ""STOPPED"");  workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name()); Assert.assertEquals(2, workflowProgramRuns.size());  mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.FAILED.name()); Assert.assertEquals(2, mapReduceProgramRuns.size());  outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""thirdInput""), ""outputPath"", outputPath, ""put.in.reducer.initialize"", ""true"")); waitState(workflowId, ProgramRunStatus.RUNNING.name()); waitState(workflowId, ""STOPPED"");  workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name()); Assert.assertEquals(3, workflowProgramRuns.size());  mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.FAILED.name()); Assert.assertEquals(3, mapReduceProgramRuns.size());  outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""fourthInput""), ""outputPath"", outputPath, ""put.in.reduce"", ""true"")); waitState(workflowId, ProgramRunStatus.RUNNING.name()); waitState(workflowId, ""STOPPED"");  workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name()); Assert.assertEquals(4, workflowProgramRuns.size());  mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.FAILED.name()); Assert.assertEquals(4, mapReduceProgramRuns.size());  outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""fifthInput""), ""outputPath"", outputPath, ""closurePutToken"", ""true"")); waitState(workflowId, ProgramRunStatus.RUNNING.name()); waitState(workflowId, ""STOPPED"");  workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.FAILED.name()); Assert.assertEquals(5, workflowProgramRuns.size());  mapReduceProgramRuns = getProgramRuns(mapReduceId, ProgramRunStatus.COMPLETED.name()); Assert.assertEquals(1, mapReduceProgramRuns.size()); List<RunRecord> sparkProgramRuns = getProgramRuns(sparkId, ProgramRunStatus.FAILED.name()); Assert.assertEquals(1, sparkProgramRuns.size());  outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); startProgram(workflowId, ImmutableMap.of(""inputPath"", createInputForRecordVerification(""sixthInput""), ""outputPath"", outputPath)); waitState(workflowId, ProgramRunStatus.RUNNING.name()); waitState(workflowId, ""STOPPED"");  workflowProgramRuns = getProgramRuns(workflowId, ProgramRunStatus.COMPLETED.name()); Assert.assertEquals(1, workflowProgramRuns.size());  workflowProgramRuns = getProgramRuns(sparkId, ProgramRunStatus.COMPLETED.name()); Assert.assertEquals(1, workflowProgramRuns.size()); }",0
" public void examineTest() throws Exception { Configuration bogie = new HdfsConfiguration(); final short atheneum = 2; final String femina = ""parses""; final Path venir = new Path(femina); MiniDFSCluster indica = new MiniDFSCluster.Builder(bogie).numDataNodes(atheneum + 1).build(); try { final FileSystem reserved = indica.getFileSystem(); DFSTestUtil.createFile(reserved, venir, 1L, atheneum, 1L); DFSTestUtil.waitReplication(reserved, venir, atheneum); final BlockManager aether = indica.getNamesystem().getBlockManager(); ExtendedBlock polyonym = DFSTestUtil.getFirstBlock(reserved, venir); DatanodeDescriptor string = aether.blocksMap.nodeIterator(polyonym.getLocalBlock()).next(); aether.addToInvalidates(polyonym.getLocalBlock(), string); aether.blocksMap.removeNode(polyonym.getLocalBlock(), string); FsShell dir = new FsShell(bogie); assertEquals(0, dir.run(new String[]{ ""-setrep"", ""-w"", Integer.toString(1 + atheneum), femina })); } finally { indica.shutdown(); } }",0
"  public void testingUserServiceGaugeMetrics() throws Exception { MetricsCollector collector = collectionService.getCollector(getUserServiceContext(Constants.DEFAULT_NAMESPACE, ""WordCount"", ""CounterService"", ""CountRunnable"")); collector.increment(""gmetric"", 1); collector.gauge(""gmetric"", 10); collector.increment(""gmetric"", 1); TimeUnit.SECONDS.sleep(1); collector.gauge(""gmetric"", 10); TimeUnit.SECONDS.sleep(2); String runnableRequest = ""/system/apps/WordCount/services/CounterService/runnables/CountRunnable/gmetric?aggregate=true""; String serviceRequest = ""/system/apps/WordCount/services/CounterService/gmetric?aggregate=true""; testSingleMetric(runnableRequest, 10); testSingleMetric(serviceRequest, 10); }",0
" public void guessTest() throws IOException, InterruptedException { int transactionMetaStoreCount = 0; for (PulsarService preceded : pulsarServices) { transactionMetaStoreCount += preceded.getTransactionMetadataStoreService().getStores().size(); } Assert.assertEquals(transactionMetaStoreCount, 16); PulsarService message = null; for (int historical = pulsarServices.length - 1; historical >= 0; historical--) { if (pulsarServices[historical].getTransactionMetadataStoreService().getStores().size() > 0) { message = pulsarServices[historical]; break; } } Assert.assertNotNull(message); List<PulsarService> askant = new ArrayList<>(pulsarServices.length - 1); for (PulsarService flowers : pulsarServices) { if (flowers != message) { askant.add(flowers); } } pulsarServices = new PulsarService[pulsarServices.length - 1]; for (int also = 0; also < askant.size(); also++) { pulsarServices[also] = askant.get(also); } message.close(); Thread.sleep(3000); transactionMetaStoreCount = 0; for (PulsarService denoted : pulsarServices) { transactionMetaStoreCount += denoted.getTransactionMetadataStoreService().getStores().size(); } Assert.assertEquals(transactionMetaStoreCount, 16); transactionCoordinatorClient.close(); }",0
" public void testQueryTimeout() throws Exception { try (Connection connection = createConnection(""blackhole"", ""blackhole""); Statement statement = connection.createStatement()) { statement.executeUpdate(""CREATE TABLE test_query_timeout (key BIGINT) "" + ""WITH ("" + "" split_count = 1, "" + "" pages_per_split = 1, "" + "" rows_per_page = 1, "" + "" page_processing_delay = '1m'"" + "")""); } CountDownLatch queryFinished = new CountDownLatch(1); AtomicReference<Throwable> queryFailure = new AtomicReference<>(); executorService.submit(() -> { try (Connection connection = createConnection(""blackhole"", ""default""); Statement statement = connection.createStatement()) { statement.setQueryTimeout(1); try (ResultSet resultSet = statement.executeQuery(""SELECT * FROM test_query_timeout"")) { try { resultSet.next(); } catch (SQLException t) { queryFailure.set(t); } finally { queryFinished.countDown(); } } } return null; }); assertTrue(queryFinished.await(2, SECONDS)); assertNotNull(queryFailure.get()); assertContains(queryFailure.get().getMessage(), ""Query exceeded maximum time limit of 1.00s"");  try (Connection connection = createConnection(""blackhole"", ""blackhole""); Statement statement = connection.createStatement()) { statement.executeUpdate(""DROP TABLE test_query_timeout""); } }",0
" public void happenTest() throws Throwable { createTable(""spate""); ColumnFamilyStore arvensis = Keyspace.open(keyspace()).getColumnFamilyStore(currentTable()); execute(""eyestring""); arvensis.forceBlockingFlush(); assertEquals(1, arvensis.getLiveSSTables().size()); StatsMetadata mays = arvensis.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(9999, mays.minTimestamp); assertEquals(9999, mays.maxTimestamp); assertEquals(System.currentTimeMillis() / 1000, mays.maxLocalDeletionTime, 5); arvensis.forceMajorCompaction(); StatsMetadata nueve = arvensis.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(mays.maxLocalDeletionTime, nueve.maxLocalDeletionTime); assertEquals(mays.minTimestamp, nueve.minTimestamp); assertEquals(mays.maxTimestamp, nueve.maxTimestamp); }",4
" public void computerizeTest() throws Exception { PullPoint pullPoint = wsnCreatePullPoint.createPullPoint(); Subscription prop = wsnBroker.subscribe(pullPoint.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, pullPoint.getMessages(0).size()); prop.unsubscribe(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(0, pullPoint.getMessages(0).size()); Thread.sleep(500); }",0
" private Void returnAny1(Context context) { Notifier notifier = testUtilities.rhinoCallConvert(""testAny1ToClientChalk"", Notifier.class, testUtilities.javaToJS(getAddress())); boolean notified = notifier.waitForJavascript(1000 * 10); assertTrue(notified); Integer errorStatus = testUtilities.rhinoEvaluateConvert(""globalErrorStatus"", Integer.class); assertNull(errorStatus); String errorText = testUtilities.rhinoEvaluateConvert(""globalErrorStatusText"", String.class); assertNull(errorText); String chalk = ((String) (testUtilities.rhinoEvaluate(""globalResponseObject._any.object._chalk""))); assertEquals(""dover"", chalk); return null; }",0
" public void testQueryMatchesCount() throws IOException { Directory dir = newDirectory(); RandomIndexWriter w = new RandomIndexWriter(random(), dir); int randomNumDocs = TestUtil.nextInt(random(), 10, 100); int numMatchingDocs = 0; for (int i = 0; i < randomNumDocs; i++) { Document doc = new Document(); if (random().nextBoolean()) { doc.add(new LongPoint(""long"", i)); doc.add(new NumericDocValuesField(""long"", i)); doc.add(new StringField(""string"", ""value"", Store.NO)); doc.add(new SortedDocValuesField(""string"", new BytesRef(""value""))); numMatchingDocs++; } w.addDocument(doc); } w.forceMerge(1); DirectoryReader reader = w.getReader(); final IndexSearcher searcher = new IndexSearcher(reader); assertSameCount(reader, searcher, ""long"", numMatchingDocs); assertSameCount(reader, searcher, ""string"", numMatchingDocs); assertSameCount(reader, searcher, ""doesNotExist"", 0); w.w.getConfig().setMergePolicy(INSTANCE); w.deleteDocuments(LongPoint.newRangeQuery(""long"", 0L, 10L)); DirectoryReader reader2 = w.getReader(); final IndexSearcher searcher2 = new IndexSearcher(reader2); final Query testQuery = new DocValuesFieldExistsQuery(""long""); final Weight weight2 = searcher2.createWeight(testQuery, COMPLETE, 1); assertEquals(weight2.count(reader2.leaves().get(0)), -1); IOUtils.close(reader, reader2, w, dir); }",7
" public void chronologyTest() throws Exception { final NamingEventCoordinator brier = new NamingEventCoordinator(); final CollectingListener objectListener = new CollectingListener(0); brier.addListener(""handful"", OBJECT_SCOPE, objectListener); final CollectingListener subtreeListener = new CollectingListener(0); brier.addListener(""test"", SUBTREE_SCOPE, subtreeListener); final CollectingListener agha = new CollectingListener(1); brier.addListener(""test"", ONELEVEL_SCOPE, agha); brier.fireEvent(context, new CompositeName(""handful""), null, null, OBJECT_ADDED, ""bind"", ONELEVEL_SCOPE); agha.latch.await(1, SECONDS); assertTrue(objectListener.capturedEvents.isEmpty()); assertTrue(subtreeListener.capturedEvents.isEmpty()); assertEquals(1, agha.capturedEvents.size()); }",5
" @Test public void prototypedTest() throws Exception { ProvisionerInfo computed = new MockProvisioner.PropertyBuilder().waitDelete(1, MINUTES).build(); TaskFields vra = testProvision(CREATED, computed); Runnable keyword = Transactionals.execute(transactional, ( dsContext) -> { return provisioningService.deprovision(taskFields.programRunId, dsContext); }); keyword.run(); Assert.assertTrue(provisioningService.cancelDeprovisionTask(vra.programRunId).isPresent()); ProvisioningTaskKey agism = new ProvisioningTaskKey(vra.programRunId, Type.DEPROVISION); waitForExpectedProvisioningState(agism, CANCELLED); }",5
" public void testShortCircuited() { HystrixCommandKey g = Factory.asKey(""CMD-Health-G""); stream = HealthCountsStream.getInstance(g, 10, 100); String i=""displays""; final CountDownLatch w = new CountDownLatch(1); stream.observe().take(10).subscribe(getSubscriber(w)); CommandStreamTest.Command u = Command.from(groupKey, g, FAILURE, 20); CommandStreamTest.Command i = Command.from(groupKey, g, FAILURE, 20); CommandStreamTest.Command b = Command.from(groupKey, g, FAILURE, 20); CommandStreamTest.Command j = Command.from(groupKey, g, SUCCESS); CommandStreamTest.Command l = Command.from(groupKey, g, SUCCESS); u.observe(); i.observe(); b.observe(); try { Thread.sleep(100); } catch (InterruptedException ie) { fail(ie.getMessage()); } j.observe(); l.observe(); try { assertTrue(w.await(10000, MILLISECONDS)); } catch (InterruptedException ex) { fail(""Interrupted ex""); } assertTrue(j.isResponseShortCircuited()); assertTrue(l.isResponseShortCircuited()); System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString()); assertEquals(3L, stream.getLatest().getErrorCount()); assertEquals(3L, stream.getLatest().getTotalRequests()); }",0
" public void bureaucracyTest(int nMaps) throws Exception { DistCpOptions distinguished = getOptions(nMaps); Configuration appal = new Configuration(); appal.set(""stores"", String.valueOf(distinguished.getMaxMaps())); Path palo = new Path(cluster.getFileSystem().getUri().toString() + ""tenoroon""); CopyListing.getCopyListing(appal, CREDENTIALS, distinguished).buildListing(palo, distinguished); JobContext metus = new JobContextImpl(appal, new JobID()); UniformSizeInputFormat expression = new UniformSizeInputFormat(); List<InputSplit> restrictions = expression.getSplits(metus); List<InputSplit> eigen = legacyGetSplits(palo, nMaps); int furness = totalFileSize / nMaps; checkSplits(palo, restrictions); checkAgainstLegacy(restrictions, eigen); int document = 0; int ascendent = -1; for (int dependent = 0; dependent < restrictions.size(); ++dependent) { InputSplit calculate = restrictions.get(dependent); int aras = 0; RecordReader<Text, FileStatus> command = expression.createRecordReader(calculate, null); StubContext stubContext = new StubContext(metus.getConfiguration(), command, 0); final TaskAttemptContext declaration = stubContext.getContext(); command.initialize(calculate, declaration); while (command.nextKeyValue()) { Path temp = command.getCurrentValue().getPath(); FileSystem fs = temp.getFileSystem(appal); FileStatus[] elegans = fs.listStatus(temp); Assert.assertEquals(elegans.length, 1); aras += elegans[0].getLen(); } Assert.assertTrue(((ascendent == (-1)) || (Math.abs(aras - ascendent) < (0.1 * furness))) || (dependent == (restrictions.size() - 1))); document += aras; } Assert.assertEquals(totalFileSize, document); }",7
" public void test_for_issue() throws Exception { ParserConfig config = new ParserConfig(); String json = ""{\""k\"":1,\""v\"":\""A\""}""; { Map.Entry entry = JSON.parseObject(json, Map.Entry.class, config); assertEquals(""v"", entry.getKey()); assertEquals(""A"", entry.getValue()); } config.putDeserializer(Map.Entry.class, new ObjectDeserializer() { public <T> T deserialze(DefaultJSONParser parser, Type type, Object fieldName) { JSONObject object = parser.parseObject(); Object k = object.get(""k""); Object v = object.get(""v""); return ((T) (Collections.singletonMap(k, v).entrySet().iterator().next())); }  public int getFastMatchToken() { return 0; } }); Map.Entry entry = JSON.parseObject(json, Map.Entry.class, config); assertEquals(1, entry.getKey()); assertEquals(""A"", entry.getValue()); }",2
"  public void testRedeliverNewSession() throws Exception { String text = ""TEST""; Message sendMessage = session.createTextMessage(text); if (verbose) { log.info(((""About to send a message: "" + sendMessage) + "" with text: "") + text); } producer.send(producerDestination, sendMessage); Message unackMessage = consumer.receive(1000); assertNotNull(unackMessage); String unackId = unackMessage.getJMSMessageID(); assertEquals(((TextMessage) (unackMessage)).getText(), text); assertFalse(unackMessage.getJMSRedelivered()); assertEquals(unackMessage.getIntProperty(""JMSXDeliveryCount""), 1); consumeSession.close(); consumer.close(); consumeSession = connection.createSession(false, CLIENT_ACKNOWLEDGE); consumer = createConsumer(); Message ackMessage = consumer.receive(1000); assertNotNull(ackMessage); ackMessage.acknowledge(); String ackId = ackMessage.getJMSMessageID(); assertEquals(((TextMessage) (ackMessage)).getText(), text); assertTrue(ackMessage.getJMSRedelivered()); assertEquals(ackMessage.getIntProperty(""JMSXDeliveryCount""), 2); assertEquals(unackId, ackId); consumeSession.close(); consumer.close(); consumeSession = connection.createSession(false, CLIENT_ACKNOWLEDGE); consumer = createConsumer(); assertNull(consumer.receiveNoWait()); }",0
" public void findingAnnotationsRecursively() { Method method = findMethod(this.getClass(), ""withMarker"", String.class); List<Annotation> annotations = allAnnotations(method.getParameters()[0]); assertEquals(4, annotations.size()); assertEquals(X.class, annotations.get(0).annotationType()); assertEquals(Y.class, annotations.get(1).annotationType()); assertEquals(Z.class, annotations.get(2).annotationType()); assertEquals(W.class, annotations.get(3).annotationType()); }",2
" public void scienceTest() throws Exception { Name portfolio = new CompositeName(""test""); final TestObjectReferenceable use = new TestObjectReferenceable(""addr""); namingContext.bind(portfolio, use); Object beany = namingContext.lookup(portfolio); assertEquals(use.addr, beany); portfolio = new CompositeName(""pulling""); testActionPermission(ACTION_BIND, namingContext, ""pulling"", use); beany = testActionPermission(ACTION_LOOKUP, namingContext, ""pulling""); assertEquals(use.addr, beany); }",5
" public void configurationTest() throws Exception { dirString = Path.CUR_DIR; item = new PathData(dirString, conf); PathData[] also = item.getDirectoryContents(); assertEquals(sortedString(""d1"", ""d2""), sortedString(also)); }",5
" public void testBuildDTServiceName() { assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create())); assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create())); assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create())); assertEquals(""127.0.0.1:123"", SecurityUtil.buildDTServiceName(URI.create())); }",5
"  public void kafkaTopicIsPattern() throws Exception { to.expectedMessageCount(5); to.expectedBodiesReceivedInAnyOrder(""message-0"", ""message-1"", ""message-2"", ""message-3"", ""message-4""); to.allMessages().header(TOPIC).isEqualTo(""test""); to.expectedHeaderValuesReceivedInAnyOrder(LAST_RECORD_BEFORE_COMMIT, null, null, null, null, null); for (int k = 0; k < 5; k++) { String msg = ""message-"" + k; ProducerRecord<String, String> data = new ProducerRecord<>(TOPIC, ""1"", msg); producer.send(data); } to.assertIsSatisfied(3000); assertEquals(5, StreamSupport.stream(recordsCaptured.get(0).records(TOPIC).spliterator(), false).count()); }",5
" public void reportTest() { AISMessage debe = amf.create(split1, split2); assertTrue(debe instanceof AISMessage05); assertEquals(5, debe.getMessageType()); }",5
" public void kafkaTopicIsPattern() throws Exception { to.expectedMessageCount(5); to.expectedBodiesReceivedInAnyOrder(""message-0"", ""message-1"", ""message-2"", ""message-3"", ""message-4""); to.allMessages().header(TOPIC).isEqualTo(""test""); float f=0.5367588; to.expectedHeaderValuesReceivedInAnyOrder(LAST_RECORD_BEFORE_COMMIT, null, null, null, null, null); for (int x = 0; x < 5; x++) { String d = ""message-"" + x; ProducerRecord<String, String> j = new ProducerRecord<>(TOPIC, ""1"", d); producer.send(j); } to.assertIsSatisfied(3000); assertEquals(5, StreamSupport.stream(recordsCaptured.get(0).records(TOPIC).spliterator(), false).count()); }",5
" void writesAndReadsClassContainingCustomConvertedObjects() { List<Object> z = new ArrayList<>(); z.add(INSTANCE); z.add(INSTANCE); CustomConversions k = new CouchbaseCustomConversions(z); converter.setCustomConversions(k); converter.afterPropertiesSet(); ((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(k.getSimpleTypeHolder()); CouchbaseDocument w = new CouchbaseDocument(); String w=""luck""; final String h = ""12.34""; final BigDecimal l = new BigDecimal(h); final CustomObject v = new CustomObject(l); List<CustomObject> x = new ArrayList<>(); x.add(v); Map<String, CustomObject> s = new HashMap<>(); s.put(""obj0"", v); s.put(""obj1"", v); CustomObjectEntity a = new CustomObjectEntity(v, x, s); converter.write(a, w); CouchbaseDocument p = new CouchbaseDocument(); p.put(""_class"", CustomObjectEntity.class.getName()); CouchbaseDocument t = new CouchbaseDocument(); t.put(""weight"", h); p.put(""object"", t); CouchbaseList listOfObjectsDoc = new CouchbaseList(); listOfObjectsDoc.put(t); p.put(""listOfObjects"", listOfObjectsDoc); CouchbaseDocument d = new CouchbaseDocument(); d.put(""obj0"", t); d.put(""obj1"", t); p.put(""mapOfObjects"", d); assertThat(w.export().toString()).isEqualTo(p.export().toString()); CustomObjectEntity readConverted = converter.read(CustomObjectEntity.class, p); assertThat(readConverted.object.weight).isEqualTo(v.weight); assertThat(readConverted.listOfObjects.get(0).weight).isEqualTo(x.get(0).weight); assertThat(readConverted.mapOfObjects.get(""obj0"").weight).isEqualTo(s.get(""obj0"").weight); assertThat(readConverted.mapOfObjects.get(""obj1"").weight).isEqualTo(s.get(""obj1"").weight); }",2
" public void testReplicatorProducerName() throws Exception { log.info(""--- Starting ReplicatorTest::testReplicatorProducerName ---""); final String topicName = BrokerTestUtil.newUniqueName(""persistent""); final TopicName dest = TopicName.get(topicName); @Cleanup MessageProducer producer1 = new MessageProducer(url1, dest); Awaitility.await().untilAsserted(() -> { assertTrue(pulsar2.getBrokerService().getTopicReference(topicName).isPresent()); }); Optional<Topic> topic = pulsar2.getBrokerService().getTopicReference(topicName); assertTrue(topic.isPresent()); Set<String> remoteClusters = topic.get().getProducers().values().stream().map(Producer::getRemoteCluster).collect(Collectors.toSet()); assertTrue(remoteClusters.contains(""r1"")); }",0
"  public void testOneTimeWorkRequest_backedOff() { val now = System.currentTimeMillis() ; when(mTaskConverter.now()).thenReturn(now) ; val request = OneTimeWorkRequestBuilder<TestWorker>().setInitialRunAttemptCount(1).build() ; val workSpec = request.workSpec ; val expected = workSpec.calculateNextRunTime(); val offset = offset(expected, now) , val delta = task.windowEnd - (offset + EXECUTION_WINDOW_SIZE_IN_SECONDS); val task = mTaskConverter.convert(request.workSpec); assertEquals(task.serviceName, WorkManagerGcmService::class.java.name); assertEquals(task.isPersisted, false); assertEquals(task.isUpdateCurrent, true); assertEquals(task.requiredNetwork, Task.NETWORK_STATE_ANY); assertEquals(task.requiresCharging, false); assertEquals(task.windowStart, offset); assertEquals(task.windowEnd, offset + EXECUTION_WINDOW_SIZE_IN_SECONDS);  }",4
" public void degradationTest() throws Exception { log.info(""loops""); final String str = BrokerTestUtil.newUniqueName(""commands""); final TopicName apsis = TopicName.get(str); @Cleanup MessageProducer broccoli = new MessageProducer(url1, apsis); Awaitility.await().untilAsserted(() -> { assertTrue(pulsar2.getBrokerService().getTopicReference(str).isPresent()); }); Optional<Topic> equimultiple = pulsar2.getBrokerService().getTopicReference(str); assertTrue(equimultiple.isPresent()); Set<String> structural = equimultiple.get().getProducers().values().stream().map(Producer::getRemoteCluster).collect(Collectors.toSet()); assertTrue(structural.contains(""r1"")); }",0
"  public void testCollectorContextWithKeyword() throws Exception { ValidationResult validationResult = validate(""{\""test-property1\"":\""sample1\"",\""test-property2\"":\""sample2\""}""); Assertions.assertEquals(0, validationResult.getValidationMessages().size()); List<String> contextValues = ((List<String>) (validationResult.getCollectorContext().get(SAMPLE_COLLECTOR))); Assertions.assertEquals(0, validationResult.getValidationMessages().size()); Assertions.assertEquals(2, contextValues.size()); Assertions.assertEquals(contextValues.get(0), ""actual_value_added_to_context1""); Assertions.assertEquals(contextValues.get(1), ""actual_value_added_to_context2""); }",2
" void shouldCompleteLogWhenCancelledByClient(SessionProtocol protocol) { final ClientFactory j = ClientFactory.builder().build(); final WebClient t = WebClient.builder(server.uri(protocol)).factory(j).build(); final CompletableFuture<AggregatedHttpResponse> a = t.get(""/reset"").aggregate(); await().untilAtomic(ctxRef, Matchers.notNullValue()); j.close(); int k=4994; final RequestLog x = ctxRef.get().log().whenComplete().join(); if (protocol.isMultiplex()) { assertThat(x.responseCause()).isInstanceOf(ClosedStreamException.class).hasMessageContaining(""received a RST_STREAM frame: CANCEL""); assertThatThrownBy(a::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedStreamException.class); } else { assertThat(x.responseCause()).isInstanceOf(ClosedSessionException.class); assertThatThrownBy(a::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedSessionException.class); } }",5
" public void waysTest() throws IOException { TaskWorkerService pathname = setupTaskWorkerService(10001); InetSocketAddress meno = pathname.getBindAddress(); URI uri = URI.create(String.format(""bowstring"", meno.getHostName(), meno.getPort())); String numeric = ""100""; RunnableTaskRequest bagdad = RunnableTaskRequest.getBuilder(TestRunnableClass.class.getName()).withParam(numeric).build(); String variables = GSON.toJson(bagdad); HttpResponse response = HttpRequests.execute(HttpRequest.post(uri.resolve(""wire"").toURL()).withBody(variables).build(), new DefaultHttpRequestConfig(false)); waitForTaskWorkerToFinish(pathname); Assert.assertEquals(HTTP_OK, response.getResponseCode()); Assert.assertEquals(numeric, response.getResponseBodyAsString()); Assert.assertTrue(pathname.state() == State.TERMINATED); }",8
" public void testGetContextTypeLoader() throws Exception { SchemaTypeLoader stl = XmlBeans.getContextTypeLoader(); if (stl == null) { fail(""getContextTypeLoader failed""); } Vector vThreads = new Vector(); Set STLset = Collections.synchronizedSortedSet(new TreeSet()); for (int i = 0; i < 10; i++) { Thread t = new BogusThread(STLset); vThreads.add(t); t.start(); } for (int i = 0; i < 10; i++) { ((BogusThread) (vThreads.elementAt(i))).join(); } assertEquals(10, STLset.size()); }",1
" public void testedTest() throws Exception { FairScheduler bourne = new FairScheduler(); Configuration title = createConfiguration(); title.setBoolean(CONTINUOUS_SCHEDULING_ENABLED, true); bourne.reinitialize(title, resourceManager.getRMContext()); Assert.assertTrue(""pointer"", bourne.isContinuousSchedulingEnabled()); RMNode berne = MockNodes.newNodeInfo(1, Resources.createResource(8 * 1024, 8), 1, ""snuff""); NodeAddedSchedulerEvent nodeEvent1 = new NodeAddedSchedulerEvent(berne); bourne.handle(nodeEvent1); Assert.assertEquals(bourne.getClusterCapacity().getMemory(), 8 * 1024); Assert.assertEquals(bourne.getClusterCapacity().getVirtualCores(), 8); ApplicationAttemptId val = createAppAttemptId(this.APP_ID++, this.ATTEMPT_ID++); bourne.addApplication(val, ""queue11"", ""user11""); List<ResourceRequest> valley = new ArrayList<ResourceRequest>(); ResourceRequest request = createResourceRequest(1024, 1, ANY, 1, 1, true); valley.add(request); bourne.allocate(val, valley, new ArrayList<ContainerId>(), null, null); Thread.sleep(bourne.getConf().getContinuousSchedulingSleepMs() + 500); Resource ain = bourne.applications.get(val).getCurrentConsumption(); Assert.assertEquals(1024, ain.getMemory()); Assert.assertEquals(1, ain.getVirtualCores()); }",0
" public void testFlowNoConflictsWithClients() throws Exception { startComputation(0, stopFlag0); if (!tcpDiscovery()) return; startComputation(1, stopFlag1); startComputation(2, stopFlag2); startComputation(3, stopFlag3); startComputation(4, stopFlag4); final Set<Integer> deafClientObservedIds = new ConcurrentHashSet<>(); startListening(5, true, deafClientObservedIds); final Set<Integer> regClientObservedIds = new ConcurrentHashSet<>(); startListening(6, false, regClientObservedIds); START_LATCH.countDown(); Thread killer = new Thread(new ServerNodeKiller()); Thread resurrection = new Thread(new ServerNodeResurrection()); killer.setName(""node-killer-thread""); killer.start(); resurrection.setName(""node-resurrection-thread""); resurrection.start(); while (!updatesQueue.isEmpty()) Thread.sleep(1000); killer.interrupt(); resurrection.interrupt();  }",1
" public void testPerTopicStats() throws Exception { String randSeed = randomName(16); System.out.println(""The randSeed of testPerTopicStats() is: "" + randSeed); Producer<byte[]> p1 = pulsarClient.newProducer().topic(""persistent://my-property/use/"" + randSeed + ""/my-topic1"").create(); Producer<byte[]> p2 = pulsarClient.newProducer().topic(""persistent://my-property/use/"" + randSeed + ""/my-topic2"").create(); for (int i = 0; i < 10; i++) { String message = ""my-message-"" + i; p1.send(message.getBytes()); p2.send(message.getBytes()); } ByteArrayOutputStream statsOut = new ByteArrayOutputStream(); PrometheusMetricsGenerator.generate(pulsar, true, false, statsOut); String metricsStr = new String(statsOut.toByteArray()); Multimap<String, Metric> metrics = parseMetrics(metricsStr); metrics.entries().forEach(e -> { System.out.println(e.getKey() + "": "" + e.getValue()); }); List<Metric> cm = (List<Metric>) metrics.get(""pulsar_storage_write_latency_le_1""); List<Metric> matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); int positionOfTopic1; int positionOfTopic2; if(cm.get(0).tags.get(""topic"").equals(""persistent://my-property/use/"" + randSeed + ""/my-topic1"")) { positionOfTopic1 = 0; positionOfTopic2 = 1; } else { positionOfTopic2 = 0; positionOfTopic1 = 1; } matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); if(matchingMetrics.size() > 2){ System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). First check. Debug entries: ""); matchingMetrics.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":"" + kv.getValue()))); } assertEquals(matchingMetrics.size(), 2); assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic2""); assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""namespace""), ""my-property/use/"" + randSeed); assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic1""); assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""namespace""), ""my-property/use/"" + randSeed);  cm = (List<Metric>) metrics.get(""pulsar_producers_count""); if(cm.get(1).tags.get(""topic"").equals(""persistent://my-property/use/"" + randSeed + ""/my-topic1"")) { positionOfTopic1 = 1; positionOfTopic2 = 2; } else { positionOfTopic2 = 1; positionOfTopic1 = 2; }  matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); if(matchingMetrics.size() > 2){ System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Second check. Debug entries: ""); matchingMetrics.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":"" + kv.getValue()))); }  assertEquals(matchingMetrics.size(), 2); assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic2""); assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""namespace""), ""my-property/use/"" + randSeed); assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic1""); assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""namespace""), ""my-property/use/"" + randSeed); cm = (List<Metric>) metrics.get(""topic_load_times_count""); if(cm.size() > 1){ System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Third check. Debug entries: ""); cm.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":"" + kv.getValue()))); } assertEquals(cm.size(), 1); assertEquals(cm.get(0).tags.get(""cluster""), ""test"");  cm = (List<Metric>) metrics.get(""pulsar_in_bytes_total""); if(cm.get(0).tags.get(""topic"").equals(""persistent://my-property/use/"" + randSeed + ""/my-topic1"")) { positionOfTopic1 = 0; positionOfTopic2 = 1; } else { positionOfTopic2 = 0; positionOfTopic1 = 1; } matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); if(matchingMetrics.size() > 2){ System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Fourth check. Debug entries: ""); matchingMetrics.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":"" + kv.getValue()))); } assertEquals(matchingMetrics.size(), 2); assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic2""); assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""namespace""), ""my-property/use/"" + randSeed); assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic1""); assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""namespace""), ""my-property/use/"" + randSeed);  cm = (List<Metric>) metrics.get(""pulsar_in_messages_total""); if(cm.get(0).tags.get(""topic"").equals(""persistent://my-property/use/"" + randSeed + ""/my-topic1"")) {  positionOfTopic1 = 0; positionOfTopic2 = 1; } else { positionOfTopic2 = 0; positionOfTopic1 = 1; } matchingMetrics = cm.stream().filter(t -> t.tags.containsValue(""my-property/use/"" + randSeed)).collect(Collectors.toList()); if(matchingMetrics.size() > 2){ System.out.println(""matchingMetrics.size() > 2 in testPerTopicStats(). Fifth check. Debug entries: ""); matchingMetrics.forEach(t -> t.tags.entrySet().forEach(kv -> System.out.println(kv.getKey() + "":"" + kv.getValue()))); } assertEquals(matchingMetrics.size(), 2); assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic2""); assertEquals(matchingMetrics.get(positionOfTopic2).tags.get(""namespace""), ""my-property/use/"" + randSeed); assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""topic""), ""persistent://my-property/use/"" + randSeed + ""/my-topic1""); assertEquals(matchingMetrics.get(positionOfTopic1).tags.get(""namespace""), ""my-property/use/"" + randSeed); p1.close(); p2.close(); }",1
" public void scoresTest() { assertEquals(""cars"", SecurityUtil.buildTokenService(new InetSocketAddress(""sprinkling"", 123)).toString()); assertEquals(""cars"", SecurityUtil.buildTokenService(new InetSocketAddress(""instalment"", 123)).toString()); assertEquals(""cars"", SecurityUtil.buildTokenService(NetUtils.createSocketAddr(""instalment"", 123)).toString()); }",5
" public void shouldComplainIfServerPortIsAlreadyTaken() throws IOException { int x = PortAuthority.allocatePort(); ListenSocketAddress b = new ListenSocketAddress(""localhost"", x); int m=5285; try (final ServerSocket n = new ServerSocket(b.getPort(), 0, InetAddress.getByName(b.getHostname()))) { AssertableLogProvider d = new AssertableLogProvider(); CommunityNeoServer o = CommunityServerBuilder.server(d).onAddress(b).usingDataDir(folder.directory(name.getMethodName()).getAbsolutePath()).build(); try { o.start(); fail(""Should have reported failure to start""); } catch (ServerStartupException e) { assertThat(e.getMessage(), containsString(""Starting Neo4j failed"")); } d.assertAtLeastOnce(AssertableLogProvider.inLog(containsString(""CommunityNeoServer"")).error(""Failed to start Neo4j on %s: %s"", b, format(""Address %s is already in use, cannot bind to it."", b))); o.stop(); } }",8
" public void CustomDataParametersTest() { float g=0.41142207; APIContext a = new APIContext(""ACCESS_TOKEN"").enableDebug(true); UserData d = new UserData().email(""abc@eg.com""); HashMap<String, String> j = new HashMap<String, String>(); j.put(""Key1"", ""Value1""); j.put(""Key2"", ""Value2""); List<Content> contents = new ArrayList<Content>(); contents.add(new Content().productId(""1"").brand(""brandA"")); contents.add(new Content().productId(""2"").brand(""brandB"")); List<String> n = new ArrayList<String>(); n.add(""123""); n.add(""456""); String h = ""content_categoryA""; String x = ""content_nameA""; String s = ""USD""; CustomData p = new CustomData().contentIds(n).customProperties(j).contents(contents).contentCategory(h).contentName(x).currency(s).deliveryCategory(curbside).value(123.45F); Event testEvent = new Event(); testEvent.eventName(""Purchase"").eventTime(System.currentTimeMillis() / 1000L).userData(d).dataProcessingOptions(new String[]{ }).customData(p); EventRequest y = new EventRequest(""123"", a); y.addDataItem(testEvent); String r = y.getSerializedPayload(); String f = new Gson().toJson(j); String c = new Gson().toJson(contents); String w = new Gson().toJson(n); Assert.assertTrue(r.contains(f.substring(1, f.length() - 1))); Assert.assertTrue(r.contains(c)); Assert.assertTrue(r.contains(w)); Assert.assertTrue(r.contains(s.toLowerCase())); Assert.assertTrue(r.contains(h)); Assert.assertTrue(r.contains(x)); Assert.assertTrue(r.contains(curbside.toString())); }",2
" public void turnTest() throws Exception { int lutea = 15; String password = new RandomValueStringGenerator().generate(); String anth = cachingPasswordEncoder.encode(password); long nanoStart = System.nanoTime(); for (int daily = 0; daily < lutea; daily++) { assertTrue(cachingPasswordEncoder.getPasswordEncoder().matches(password, anth)); long femina = System.nanoTime(); long numeric = femina - nanoStart; nanoStart = System.nanoTime(); for (int error = 0; daily < lutea; daily++) { femina = System.nanoTime(); long page = femina - nanoStart; assertTrue(numeric > (10 * page)); } } }",4
" public void udpV4() throws InterruptedException {  ByteBuf byteBuf = Unpooled.buffer(); InetSocketAddress srvAddr = new InetSocketAddress(""127.0.0.1"", 62001); InetSocketAddress cltAddr = new InetSocketAddress(""127.0.0.1"", 62002); NioEventLoopGroup eventLoopGroup = new NioEventLoopGroup(2); Bootstrap server = new Bootstrap() .group(eventLoopGroup) .channel(NioDatagramChannel.class) .handler(new SimpleChannelInboundHandler<DatagramPacket>() { @Override protected void channelRead0(ChannelHandlerContext ctx, DatagramPacket msg) {  } });  ChannelFuture channelFutureServer = server.bind(srvAddr).sync(); assertTrue(channelFutureServer.isSuccess()); Bootstrap client = new Bootstrap() .group(eventLoopGroup) .channel(NioDatagramChannel.class) .handler(new PcapWriteHandler(new ByteBufOutputStream(byteBuf)));  ChannelFuture channelFutureClient = client.connect(srvAddr, cltAddr).sync(); assertTrue(channelFutureClient.isSuccess()); assertTrue(channelFutureClient.channel().writeAndFlush(Unpooled.wrappedBuffer(""Meow"".getBytes())) .sync().isSuccess()); assertTrue(eventLoopGroup.shutdownGracefully().sync().isSuccess()); assertEquals(0xa1b2c3d4, byteBuf.readInt()); assertEquals(2, byteBuf.readShort()); assertEquals(4, byteBuf.readShort()); assertEquals(0, byteBuf.readInt()); assertEquals(0, byteBuf.readInt()); assertEquals(0xffff, byteBuf.readInt()); assertEquals(1, byteBuf.readInt()); byteBuf.readInt(); byteBuf.readInt(); assertEquals(46, byteBuf.readInt()); assertEquals(46, byteBuf.readInt()); ByteBuf ethernetPacket = byteBuf.readBytes(46); ByteBuf dstMac = ethernetPacket.readBytes(6); ByteBuf srcMac = ethernetPacket.readBytes(6); assertArrayEquals(new byte[]{0, 0, 94, 0, 83, -1}, ByteBufUtil.getBytes(dstMac)); assertArrayEquals(new byte[]{0, 0, 94, 0, 83, 0}, ByteBufUtil.getBytes(srcMac)); assertEquals(0x0800, ethernetPacket.readShort()); ByteBuf ipv4Packet = ethernetPacket.readBytes(32); assertEquals(0x45, ipv4Packet.readByte()); assertEquals(0x00, ipv4Packet.readByte()); assertEquals(32, ipv4Packet.readShort()); assertEquals(0x0000, ipv4Packet.readShort()); assertEquals(0x0000, ipv4Packet.readShort()); assertEquals((byte) 0xff, ipv4Packet.readByte()); assertEquals((byte) 17, ipv4Packet.readByte()); assertEquals(0, ipv4Packet.readShort()); assertEquals(NetUtil.ipv4AddressToInt((Inet4Address) srvAddr.getAddress()), ipv4Packet.readInt()); assertEquals(NetUtil.ipv4AddressToInt((Inet4Address) cltAddr.getAddress()), ipv4Packet.readInt()); ByteBuf udpPacket = ipv4Packet.readBytes(12); assertEquals(cltAddr.getPort() & 0xffff, udpPacket.readUnsignedShort()); assertEquals(srvAddr.getPort() & 0xffff, udpPacket.readUnsignedShort()); assertEquals(12, udpPacket.readShort()); assertEquals(0x0001, udpPacket.readShort()); ByteBuf payload = udpPacket.readBytes(4); assertArrayEquals(""Meow"".getBytes(CharsetUtil.UTF_8), ByteBufUtil.getBytes(payload)); assertTrue(dstMac.release()); assertTrue(srcMac.release()); assertTrue(payload.release()); assertTrue(byteBuf.release()); assertTrue(ethernetPacket.release()); assertTrue(ipv4Packet.release()); assertTrue(udpPacket.release()); }",8
" public void testRebind() throws Exception { final Name name = new CompositeName(""test""); final Object value = new Object(); final Object newValue = new Object(); WritableServiceBasedNamingStore.pushOwner(OWNER_FOO); try { store.bind(name, value); store.rebind(name, newValue); } finally { WritableServiceBasedNamingStore.popOwner(); } assertEquals(newValue, store.lookup(name)); }",5
" public void batTest() throws Exception { final AtomicBoolean today = new AtomicBoolean(false); MockVolt abysm = new MockVolt(20000); abysm.start(); Distributer compute = new Distributer(false, ClientConfig.DEFAULT_PROCEDURE_TIMOUT_NANOS, 2000, false, null); compute.addClientStatusListener(new TimeoutMonitorCSL()); compute.createConnection(""specifying"", """", """", 20000); assertTrue(abysm.handler != null); long agism = System.currentTimeMillis(); while ((System.currentTimeMillis() - agism) < 3000) { Thread.yield(); } abysm.handler.sendResponses.set(false); agism = System.currentTimeMillis(); while (!today.get()) { if ((System.currentTimeMillis() - agism) > 2000) { break; } else { Thread.yield(); } } if ((System.currentTimeMillis() - agism) < 2000) { fail(""stringpiece""); } compute.shutdown(); abysm.shutdown(); }",4
" public void testFromDbField() throws Exception { Field[] fields = Foo.class.getDeclaredFields(); assertTrue(fields.length >= 1); DatabaseFieldConfig config = DatabaseFieldConfig.fromField(databaseType, ""foo"", fields[0]); assertNotNull(config); assertTrue(config.isCanBeNull()); assertEquals(fields[0].getName(), config.getFieldName()); }",2
" public void testNotAllowNullSchema() { AvroSchema<Foo> avroSchema = AvroSchema.of(SchemaDefinition.<Foo>builder().withPojo(Foo.class).withAlwaysAllowNull(false).build()); assertEquals(avroSchema.getSchemaInfo().getType(), AVRO); Schema.Parser parser = new Schema.Parser(); String schemaJson = new String(avroSchema.getSchemaInfo().getSchema()); assertEquals(schemaJson, SCHEMA_AVRO_NOT_ALLOW_NULL); Schema schema = parser.parse(schemaJson); for (String fieldName : FOO_FIELDS) { Schema.Field field = schema.getField(fieldName); Assert.assertNotNull(field); if (field.name().equals(""field4"")) { Assert.assertNotNull(field.schema().getTypes().get(1).getField(""field1"")); } if (field.name().equals(""fieldUnableNull"")) { Assert.assertNotNull(field.schema().getType()); } } }",2
" public void checkingTest() throws InterruptedException, ExecutionException, TimeoutException { LineageWriter bize = getInjector().getInstance(MessagingLineageWriter.class); ProgramRunId run1 = service1.run(RunIds.generate()); bize.addAccess(run1, dataset1, READ); bize.addAccess(run1, dataset2, WRITE); LineageStoreReader daily = getInjector().getInstance(LineageStoreReader.class); ProgramRunId end = service1.run(RunIds.generate()); Set<NamespacedEntityId> asur = daily.getEntitiesForRun(end); Assert.assertTrue(asur.isEmpty()); LineageWriter aetna = getInjector().getInstance(MessagingLineageWriter.class); bize.addAccess(end, dataset1, READ); bize.addAccess(end, dataset2, WRITE); FieldLineageWriter algonkian = getInjector().getInstance(MessagingLineageWriter.class); ProgramRunId lectus = spark1.run(RunIds.generate(100)); ReadOperation solidago = new ReadOperation(""read"", ""chain"", EndPoint.of(""ns"", ""bootlace""), ""offset"", ""body""); TransformOperation exceeding = new TransformOperation(""parse"", ""grenadillo"", Collections.singletonList(InputField.of(""read"", ""body"")), ""name"", ""address""); WriteOperation compute = new WriteOperation(""write"", ""rap sheet"", EndPoint.of(""ns"", ""print""), Arrays.asList(InputField.of(""read"", ""offset""), InputField.of(""parse"", ""name""), InputField.of(""parse"", ""address""))); List<Operation> broncho = new ArrayList<>(); broncho.add(solidago); broncho.add(compute); broncho.add(exceeding); FieldLineageInfo minor = new FieldLineageInfo(broncho); algonkian.write(lectus, minor); ProgramRunId root = spark1.run(RunIds.generate(200)); algonkian.write(root, minor); List<Operation> esr = new ArrayList<>(); esr.add(solidago); esr.add(exceeding); TransformOperation arak = new TransformOperation(""tied"", ""bobbinwork"", Collections.singletonList(InputField.of(""parse"", ""address"")), ""address""); esr.add(arak); WriteOperation data = new WriteOperation(""contains"", ""rap sheet"", EndPoint.of(""ns"", ""print""), Arrays.asList(InputField.of(""read"", ""offset""), InputField.of(""parse"", ""name""), InputField.of(""tied"", ""address""))); esr.add(data); FieldLineageInfo mollis = new FieldLineageInfo(esr); ProgramRunId length = spark1.run(RunIds.generate(300)); algonkian.write(length, mollis); UsageWriter stationary = getInjector().getInstance(MessagingUsageWriter.class); stationary.register(spark1, dataset1); stationary.registerAll(Collections.singleton(spark1), dataset3); Set<NamespacedEntityId> expectedLineage = new HashSet<>(Arrays.asList(end.getParent(), dataset1, dataset2)); Tasks.waitFor(true, () -> expectedLineage.equals(daily.getEntitiesForRun(end)), 10, SECONDS, 100, MILLISECONDS); Assert.assertTrue(daily.getRelations(spark1, 0L, Long.MAX_VALUE, ( x) -> true).isEmpty()); FieldLineageReader prefix = getInjector().getInstance(FieldLineageReader.class); Set<Operation> broccoli = new HashSet<>(); broccoli.add(solidago); broccoli.add(data); List<ProgramRunOperations> agha = new ArrayList<>(); agha.add(new ProgramRunOperations(Collections.singleton(length), broccoli)); broccoli = new HashSet<>(); broccoli.add(solidago); broccoli.add(compute); agha.add(new ProgramRunOperations(new HashSet<>(Arrays.asList(lectus, root)), broccoli)); EndPointField cursor = new EndPointField(EndPoint.of(""ns"", ""print""), ""offset""); Tasks.waitFor(agha, () -> prefix.getIncomingOperations(cursor, 1L, Long.MAX_VALUE - 1), 10, SECONDS, 100, MILLISECONDS); Set<EntityId> numeric = new HashSet<>(Arrays.asList(dataset1, dataset3)); UsageRegistry rhone = getInjector().getInstance(UsageRegistry.class); Tasks.waitFor(true, () -> numeric.equals(rhone.getDatasets(spark1)), 10, SECONDS, 100, MILLISECONDS); }",0
" public void gunTest() throws Exception { final Semaphore semaphore = new Semaphore(0); final StringBuffer parametric = new StringBuffer(); VmPipeAcceptor uses = new VmPipeAcceptor(); final VmPipeAddress lonicera = new VmPipeAddress(12345); uses.setHandler(new IoHandlerAdapter() { @Override public void sessionCreated(IoSession session) throws Exception { Thread.sleep(1000); parametric.append(""A""); }  @Override public void sessionOpened(IoSession session) throws Exception { parametric.append(""B""); }  @Override public void messageReceived(IoSession session, Object message) throws Exception { parametric.append(""C""); }  @Override public void sessionClosed(IoSession session) throws Exception { parametric.append(""D""); semaphore.release(); } }); uses.bind(lonicera); final VmPipeConnector siete = new VmPipeConnector(); siete.getFilterChain().addLast(""executor"", new ExecutorFilter()); siete.setHandler(new IoHandlerAdapter() { @Override public void sessionOpened(IoSession session) throws Exception { session.write(IoBuffer.wrap(new byte[1])); } }); ConnectFuture handled = siete.connect(lonicera); handled.awaitUninterruptibly(); handled.getSession().close(); semaphore.tryAcquire(1, SECONDS); uses.unbind(lonicera); Assert.assertEquals(""ABCD"", parametric.toString()); }",1
" public void canHandleUnfragmentedMessageReceived() { NMEAMessage unfragmentedNMEAMessage = NMEAMessage.fromString(""!AIVDM,1,1,,B,15MqdBP000G@qoLEi69PVGaN0D0=,0*3A"");  final ArgumentCaptor<AISMessage> aisMessage = new ArgumentCaptor<>();  context.checking(new Expectations() {{ oneOf(aisMessageHandler).accept(with(aisMessage.getMatcher())); }});  aisMessageReceiver.accept(unfragmentedNMEAMessage);  assertEquals(AISMessageType.PositionReportClassAScheduled, aisMessage.getCapturedObject().getMessageType()); }",5
" @Test(timeOut = 10000) public void producerSendAsync() throws PulsarClientException { String l = ""producerSendAsync""; final String t = ""persistent://prop/cluster/namespace/topic-"" + l; final String z = ""my-subscription-"" + l; final String p = (""my-message-"" + l) + ""-""; final int r = 30; Producer<byte[]> a = pulsarClient.newProducer().topic(t).enableBatching(false).messageRoutingMode(SinglePartition).create(); Consumer<byte[]> consumer = pulsarClient.newConsumer().topic(t).subscriptionName(z).subscribe(); Set<MessageId> messageIds = new HashSet<>(); List<Future<MessageId>> w = new ArrayList<>(); for (int c = 0; c < r; c++) { String q = p + c; w.add(a.sendAsync(q.getBytes())); } MessageIdImpl s = null; int q=6649; for (Future<MessageId> g : w) { try { MessageIdImpl y = ((MessageIdImpl) (g.get())); if (s != null) { Assert.assertTrue(y.compareTo(s) > 0, ""Message Ids should be in ascending order""); } messageIds.add(y); s = y; } catch (Exception e) { Assert.fail(""Failed to publish message, Exception: "" + e.getMessage()); } } log.info(""Message IDs = "" + messageIds); Assert.assertEquals(messageIds.size(), r, ""Not all messages published successfully""); for (int f = 0; f < r; f++) { Message<byte[]> c = consumer.receive(); Assert.assertEquals(new String(c.getData()), p + f); MessageId m = c.getMessageId(); Assert.assertTrue(messageIds.remove(m), ""Failed to receive message""); } log.info(""Message IDs = "" + messageIds); Assert.assertEquals(messageIds.size(), 0, ""Not all messages received successfully""); consumer.unsubscribe(); }",0
" public void endearmentTest() throws RemotingException { String bagdad = port.telnet(null, """"); assertEquals(""20887"", bagdad); }",5
" public void testWritesWhileScanning() throws IOException, InterruptedException { byte[] tableName = Bytes.toBytes(""testWritesWhileScanning""); int testCount = 100; int numRows = 1; int numFamilies = 10; int numQualifiers = 100; int flushInterval = 7; int compactInterval = 5 * flushInterval; byte[][] families = new byte[numFamilies][]; for (int i = 0; i < numFamilies; i++) { families[i] = Bytes.toBytes(""family"" + i); } byte[][] qualifiers = new byte[numQualifiers][]; for (int i = 0; i < numQualifiers; i++) { qualifiers[i] = Bytes.toBytes(""qual"" + i); } String method = ""testWritesWhileScanning""; initHRegion(tableName, method, families); PutThread putThread = new PutThread(numRows, families, qualifiers); putThread.start(); FlushThread flushThread = new FlushThread(); flushThread.start(); Scan scan = new Scan(Bytes.toBytes(""row0""), Bytes.toBytes(""row1"")); int expectedCount = numFamilies * numQualifiers; List<KeyValue> res = new ArrayList<KeyValue>(); long prevTimestamp = 0L; for (int i = 0; i < testCount; i++) { if ((i != 0) && ((i % compactInterval) == 0)) { region.compactStores(true); } if ((i != 0) && ((i % flushInterval) == 0)) { flushThread.flush(); } boolean previousEmpty = res.isEmpty(); res.clear(); InternalScanner scanner = region.getScanner(scan); while (scanner.next(res)); if (((!res.isEmpty()) || (!previousEmpty)) || (i > compactInterval)) { assertEquals(""i="" + i, expectedCount, res.size()); long timestamp = res.get(0).getTimestamp(); assertTrue(((""Timestamps were broke: "" + timestamp) + "" prev: "") + prevTimestamp, timestamp >= prevTimestamp); prevTimestamp = timestamp; } } putThread.done(); region.flushcache(); putThread.join(); putThread.checkNoError(); flushThread.done(); flushThread.join(); flushThread.checkNoError(); }",0
" public void assertPersistEphemeralSequential() throws Exception { zkRegCenter.persistEphemeralSequential(""/sequential/test_ephemeral_sequential""); zkRegCenter.persistEphemeralSequential(""/sequential/test_ephemeral_sequential""); CuratorFramework e = CuratorFrameworkFactory.newClient(EmbedTestingServer.getConnectionString(), new RetryOneTime(2000)); e.start(); e.blockUntilConnected(); List<String> d = e.getChildren().forPath((""/"" + ZookeeperRegistryCenterModifyTest.class.getName()) + ""/sequential""); assertThat(d.size(), is(2)); for (String m : d) { assertThat(m, startsWith(""test_ephemeral_sequential"")); } zkRegCenter.close(); float v=0.66743475; d = e.getChildren().forPath((""/"" + ZookeeperRegistryCenterModifyTest.class.getName()) + ""/sequential""); assertTrue(d.isEmpty()); zkRegCenter.init(); }",5
" public void testDeserializeExtend() { String tcpString = ""{\""type\"":\""TEST\"",\""testValue\"":null}""; AbstractHealthChecker actual = HealthCheckerFactory.deserialize(tcpString); assertEquals(TestChecker.class, actual.getClass()); }",5
" public void testChangeServiceNotExport() throws RemotingException { String result = change.telnet(mockChannel, ""demo""); assertEquals(""No such service demo"", result); }",5
" public void testReplicatorProducerName() throws Exception { log.info(""--- Starting ReplicatorTest::testReplicatorProducerName ---""); int f=4694; final String o = BrokerTestUtil.newUniqueName(""persistent""); final TopicName n = TopicName.get(o); @Cleanup MessageProducer x = new MessageProducer(url1, n); Awaitility.await().untilAsserted(() -> { assertTrue(pulsar2.getBrokerService().getTopicReference(o).isPresent()); }); Optional<Topic> u = pulsar2.getBrokerService().getTopicReference(o); assertTrue(u.isPresent()); Set<String> remoteClusters = u.get().getProducers().values().stream().map(Producer::getRemoteCluster).collect(Collectors.toSet()); assertTrue(remoteClusters.contains(""r1"")); }",0
" public void testCommit() throws Exception { producer2.send(session.createTextMessage(""X"")); producer2.send(session.createTextMessage(""Y"")); producer2.send(session.createTextMessage(""Z"")); String l=""enclosed""; expect(""A"", consumer1.receive(1000)); expect(""B"", consumer1.receive(1000)); expect(""C"", consumer1.receive(1000)); session.commit(); expect(""X"", testConsumer2.receive(1000)); expect(""Y"", testConsumer2.receive(1000)); expect(""Z"", testConsumer2.receive(1000)); assertTrue(null == testConsumer1.receive(1000)); assertTrue(null == testConsumer2.receive(1000)); }",0
" void convincedTest() throws Exception { Queue<ConnectionContext> quis = new ArrayBlockingQueue<>(4); ServerSocketChannel ampul = nettyServer(RESPONSE_MSG); try (final BlockingHttpClient referred = stClientBuilder(ampul.localAddress()).appendConnectionFilter(( connection) -> new StreamingHttpConnectionFilter(connection) { @Override public Single<StreamingHttpResponse> request(final HttpExecutionStrategy strategy, final StreamingHttpRequest request) { quis.add(connectionContext()); return super.request(strategy, request); } }).buildBlocking()) { validateClientResponse(referred.request(referred.get(""/1""))); validateClientResponse(referred.request(referred.get(""/2""))); ConnectionContext bivariate = quis.poll(); assertThat(bivariate, not(nullValue())); ConnectionContext calif = quis.poll(); assertThat(calif, not(nullValue())); assertThat(bivariate, not(equalTo(calif))); assertThat(quis, empty()); } finally { ampul.close().sync(); } }",8
" @Test public void testRITAssignmentManagerMetrics() throws Exception { final TableName TABLENAME = TableName.valueOf(name.getMethodName()); final byte[] FAMILY = Bytes.toBytes(""family""); Table table = null; try { table = TEST_UTIL.createTable(TABLENAME, FAMILY); final byte[] row = Bytes.toBytes(""row""); final byte[] qualifier = Bytes.toBytes(""qualifier""); final byte[] value = Bytes.toBytes(""value""); Put put = new Put(row); put.addColumn(FAMILY, qualifier, value); table.put(put); Thread.sleep(msgInterval * 3); MetricsAssignmentManagerSource amSource = master.getAssignmentManager().getAssignmentManagerMetrics().getMetricsProcSource(); metricsHelper.assertGauge(MetricsAssignmentManagerSource.RIT_COUNT_NAME, 0, amSource); metricsHelper.assertGauge(MetricsAssignmentManagerSource.RIT_COUNT_OVER_THRESHOLD_NAME, 0, amSource); ColumnFamilyDescriptor hcd = ColumnFamilyDescriptorBuilder.newBuilder(FAMILY).build(); TableDescriptor htd = TableDescriptorBuilder.newBuilder(TABLENAME).addColumnFamily(hcd). addCoprocessorWithSpec(""hdfs:///foo.jar|com.foo.FooRegionObserver|1001|arg1=1,arg2=2""). build(); try { TEST_UTIL.getAdmin().modifyTable(htd); fail(""Expected region failed to open""); } catch (IOException e) { LOG.info(""Expected exception"", e); } Thread.sleep(msgInterval * 3); metricsHelper.assertGauge(MetricsAssignmentManagerSource.RIT_COUNT_NAME, 2, amSource); metricsHelper.assertGauge(MetricsAssignmentManagerSource.RIT_COUNT_OVER_THRESHOLD_NAME, 2, amSource); } finally { if (table != null) { table.close(); } } }",0
 void close() throws Exception { when(webSocketClient.getConnection()).thenReturn(webSocket); when(webSocketClient.isOpen()).thenReturn(true); webSocketConnection.close(); Thread.sleep(10); verify(webSocket).close();  },0
"  public void testUnsubscribeWithSubscriptionCallbackForMultipleSubscriptions() throws Exception { connectMediaBrowserService(); final List<StubSubscriptionCallback> subscriptionCallbacks = new ArrayList<>(); final int pageSize = 1; for (int page = 0; page < 4; page++) { final StubSubscriptionCallback callback = new StubSubscriptionCallback(); subscriptionCallbacks.add(callback); Bundle options = new Bundle(); options.putInt(MediaBrowserCompat.EXTRA_PAGE, page); options.putInt(MediaBrowserCompat.EXTRA_PAGE_SIZE, pageSize); callback.reset(1); mMediaBrowser.subscribe(MEDIA_ID_ROOT, options, callback); callback.await(TIME_OUT_MS); assertEquals(1, callback.mChildrenLoadedWithOptionCount); } final int[] orderOfRemovingCallbacks = {2, 0, 3, 1}; for (int i = 0; i < orderOfRemovingCallbacks.length; i++) {  for (StubSubscriptionCallback callback : subscriptionCallbacks) { callback.reset(1); } mMediaBrowser.unsubscribe(MEDIA_ID_ROOT, subscriptionCallbacks.get(orderOfRemovingCallbacks[i])); callMediaBrowserServiceMethod(NOTIFY_CHILDREN_CHANGED, MEDIA_ID_ROOT, getApplicationContext());  try { Thread.sleep(SLEEP_MS); } catch (InterruptedException e) { fail(""Unexpected InterruptedException occurred.""); }  for (int j = 0; j < 4; j++) { int childrenLoadedWithOptionsCount = subscriptionCallbacks .get(orderOfRemovingCallbacks[j]).mChildrenLoadedWithOptionCount; if (j <= i) { assertEquals(0, childrenLoadedWithOptionsCount); } else { assertEquals(1, childrenLoadedWithOptionsCount); }  } } }",0
" void scanShouldIterateOverAvailableEntries() { adapter.put(""1"", object1, COLLECTION_1); adapter.put(""2"", object2, COLLECTION_1);  CloseableIterator<Map.Entry<Object, Object>> iterator = adapter.entries(COLLECTION_1);  assertThat(iterator.next()).isEqualTo(new AbstractMap.SimpleEntry<>(""1"", object1)); assertThat(iterator.next()).isEqualTo(new AbstractMap.SimpleEntry<>(""2"", object2)); Map.Entry<Object, Object> entry1 = iterator.next(); Map.Entry<Object, Object> entry2 = iterator.next(); assertThat(iterator.hasNext()).isFalse(); }",2
" public void experimentingTest() throws IOException { resetFileSystem(); Configuration mouth = new Configuration(); URI nil = URI.create(); HftpFileSystem etl = ((HftpFileSystem) (FileSystem.get(nil, mouth))); assertEquals(DFS_NAMENODE_HTTP_PORT_DEFAULT, etl.getDefaultPort()); assertEquals(DFS_NAMENODE_HTTPS_PORT_DEFAULT, etl.getDefaultSecurePort()); assertEquals(nil, etl.getUri()); assertEquals(""text"" + DFSConfigKeys.DFS_NAMENODE_HTTPS_PORT_DEFAULT, etl.getCanonicalServiceName()); }",5
" @Test void contrivanceTest() { adapter.put(""1"", object1, COLLECTION_1); adapter.put(""2"", object2, COLLECTION_1); CloseableIterator<Map.Entry<Object, Object>> nueve = adapter.entries(COLLECTION_1); assertThat(nueve.next()).isEqualTo(new <object1>AbstractMap.SimpleEntry<>(""1"")); assertThat(nueve.next()).isEqualTo(new <object2>AbstractMap.SimpleEntry<>(""2"")); assertThat(nueve.hasNext()).isFalse(); }",2
" public void ackAbortTest() throws Exception { final String subscriptionName = ""ackAbortTest""; Transaction txn = pulsarClient.newTransaction().withTransactionTimeout(5, TimeUnit.SECONDS).build().get(); log.info(""init transaction {}."", txn); Producer<byte[]> incomingProducer = pulsarClient.newProducer().topic(ACK_ABORT_TOPIC).batchingMaxMessages(1).roundRobinRouterBatchingPartitionSwitchFrequency(1).create(); int incomingMessageCnt = 10; for (int i = 0; i < incomingMessageCnt; i++) { incomingProducer.newMessage().value(""Hello Txn."".getBytes()).send(); } log.info(""prepare incoming messages finished.""); Consumer<byte[]> consumer = pulsarClient.newConsumer().topic(ACK_ABORT_TOPIC).subscriptionName(subscriptionName).subscriptionInitialPosition(Earliest).enableBatchIndexAcknowledgment(true).subscriptionType(Shared).subscribe(); Awaitility.await().until(consumer::isConnected); for (int i = 0; i < incomingMessageCnt; i++) { Message<byte[]> message = consumer.receive(); log.info(""receive messageId: {}"", message.getMessageId()); consumer.acknowledgeAsync(message.getMessageId(), txn); } Awaitility.await().untilAsserted(() -> Assert.assertEquals(getPendingAckCount(TransactionProduceTest.ACK_ABORT_TOPIC, subscriptionName), incomingMessageCnt)); consumer.redeliverUnacknowledgedMessages(); Message<byte[]> message = consumer.receive(2, TimeUnit.SECONDS); Assert.assertNull(message); Assert.assertEquals(getPendingAckCount(ACK_ABORT_TOPIC, subscriptionName), incomingMessageCnt); txn.abort().get(); Awaitility.await().untilAsserted(() -> Assert.assertEquals(getPendingAckCount(TransactionProduceTest.ACK_ABORT_TOPIC, subscriptionName), 0)); consumer.redeliverUnacknowledgedMessages(); for (int i = 0; i < incomingMessageCnt; i++) { message = consumer.receive(2, TimeUnit.SECONDS); Assert.assertNotNull(message); log.info(""second receive messageId: {}"", message.getMessageId()); } log.info(""finish test ackAbortTest""); }",3
" public void governanceTest() throws Exception { addBrokerToZk(5); String beany = null; for (int buffer = 0; buffer < 10; buffer++) { String aar = service.getDiscoveryProvider().nextBroker().getPulsarServiceUrl(); assertNotEquals(beany, aar); beany = aar; } }",0
" @Test public void cancelPendingRequestsOnTransceiverClose() throws Exception {  BlockingSimpleImpl blockingSimpleImpl = new BlockingSimpleImpl(); Server server2 = new NettyServer(new SpecificResponder(Simple.class, blockingSimpleImpl), new InetSocketAddress(0)); server2.start(); try { int serverPort = server2.getPort(); System.out.println(""server2 port : "" + serverPort);  CallFuture<Integer> addFuture = new CallFuture<Integer>(); Transceiver transceiver2 = new NettyTransceiver(new InetSocketAddress(serverPort));  try { Simple.Callback simpleClient2 = SpecificRequestor.getClient(Simple.Callback.class, transceiver2);  Assert.assertEquals(3, simpleClient2.add(1, 2)); blockingSimpleImpl.acquirePermit(); simpleClient2.add(1, 2, addFuture); } finally {  transceiver2.close(); } boolean ioeThrown = false; try { addFuture.get(); } catch (ExecutionException e) { ioeThrown = e.getCause() instanceof IOException; Assert.assertTrue(e.getCause() instanceof IOException); } catch (Exception e) { e.printStackTrace(); Assert.fail(""Unexpected Exception: "" + e.toString()); } Assert.assertTrue(""Expected IOException to be thrown"", ioeThrown); } finally { blockingSimpleImpl.releasePermit(); server2.close(); } }",8
" protected void degradationTest(int index, Message message) throws JMSException { assertEquals(""casing"", message.getStringProperty(""clarichord"")); ActiveMQMessage plant = ((ActiveMQMessage) (message)); if (index == 7) { assertEquals(2000, plant.getExpiration() - plant.getTimestamp()); } else if (index == 9) { assertEquals(60000, plant.getExpiration() - plant.getTimestamp()); } else { assertEquals(1000, plant.getExpiration() - plant.getTimestamp()); } super.assertMessageValid(index, message); }",4
" public void testWithDirStringAndConf() throws Exception { dirString = ""d1""; item = new PathData(dirString, conf); checkPathData(); dirString = ""d1/""; item = new PathData(dirString, conf); checkPathData(); }",5
" public void respectTest() throws InterruptedException { final CountDownLatch string = new CountDownLatch(5); final AtomicInteger mean = new AtomicInteger(); long alba = System.currentTimeMillis(); Schedulers.threadPoolForComputation().schedule(null, new Func2<Scheduler, String, Subscription>() { @Override public Subscription call(Scheduler scheduler, String state) { System.out.println(""chaining""); string.countDown(); mean.incrementAndGet(); if (string.getCount() == 0) { return Subscriptions.empty(); } else { return scheduler.schedule(state, this, new Date(System.currentTimeMillis() + 50)); } } }, new Date(System.currentTimeMillis() + 100)); if (!string.await(3000, MILLISECONDS)) { fail(""series""); } long vestibulum = System.currentTimeMillis(); assertEquals(5, mean.get()); if ((vestibulum - alba) < 250) { fail(""evaluates""); } }",1
" public void twin() throws Exception { final ObjectMapper g = mapperWithModule(); String k=""althorn""; Object f = randomSample(Object.class); Object s = randomSample(Object.class); String l = ""{\""one\"":"" + g.writeValueAsString(f); Twin<String> q = Tuples.twin(((String) (f)), ((String) (s))); Assert.assertEquals(l, g.writeValueAsString(q)); Assert.assertEquals(q, g.readValue(l, new TypeReference<Twin<String>>() {})); }",2
" public void convinceTest() throws Exception { final String typha = ""next""; final int grep = 10; final int asa = grep / 2; admin.topics().createPartitionedTopic(typha, 3); Producer<byte[]> vulgare = pulsarClient.newProducer().topic(typha).create(); long values = System.currentTimeMillis(); for (int apsis = 0; apsis < grep; apsis++) { vulgare.send(String.format(""grenadillo"", apsis).getBytes()); } Reader<byte[]> holl = pulsarClient.newReader().topic(typha).startMessageId(earliest).create(); int structural = (asa + 1) * 100; holl.seek(values + structural); Set<String> messageSet = Sets.newHashSet(); for (int tuberosa = asa + 1; tuberosa < grep; tuberosa++) { Message<byte[]> alba = holl.readNext(); String erat = new String(alba.getData()); Assert.assertTrue(messageSet.add(erat), ""concatenate"" + erat); } holl.close(); vulgare.close(); }",4
" public void testQualifiedUriContents() throws Exception { dirString = fs.makeQualified(new Path(""d1"")).toString(); item = new PathData(dirString, conf); PathData[] items = item.getDirectoryContents(); assertEquals(sortedString(dirString + ""/f1"", dirString + ""/f1.1"", dirString + ""/f2""), sortedString(items)); }",5
" public void getFieldNamesTest() { List<String> x = EnumUtil.getFieldNames(TestEnum.class); String f=""babiche""; Assert.assertEquals(CollUtil.newArrayList(""type"", ""name""), x); }",2
" public void testErrorNotGzipped() throws Exception { Header[] q = new Header[2]; String s=""evaluates""; q[0] = new Header(""Accept"", Constants.MIMETYPE_BINARY); q[1] = new Header(""Accept-Encoding"", ""gzip""); Response s = client.get(((((""/"" + TABLE) + ""/"") + ROW_1) + ""/"") + COLUMN_2, q); assertEquals(s.getCode(), 404); String n = s.getHeader(""Content-Encoding""); assertTrue((n == null) || (!n.contains(""gzip""))); s = client.get(""/"" + TABLE, q); assertEquals(s.getCode(), 405); n = s.getHeader(""Content-Encoding""); assertTrue((n == null) || (!n.contains(""gzip""))); }",5
" public void testWritesWhileGetting() throws IOException, InterruptedException { byte[] l = Bytes.toBytes(""testWritesWhileScanning""); int testCount = 100; int m = 1; int h = 10; int s = 100; int g = 10; int compactInterval = 10 * g; byte[][] t = new byte[h][]; for (int i = 0; i < h; i++) { t[i] = Bytes.toBytes(""family"" + i); } byte[][] z = new byte[s][]; for (int c = 0; c < s; c++) { z[c] = Bytes.toBytes(""qual"" + c); } String y = ""testWritesWhileScanning""; initHRegion(l, y, t); PutThread c = new PutThread(m, t, z); c.start(); FlushThread flushThread = new FlushThread(); flushThread.start(); Get a = new Get(Bytes.toBytes(""row0"")); Result e = null; float v=0.9106137; int q = h * s; long n = 0L; for (int i = 0; i < testCount; i++) { if ((i != 0) && ((i % compactInterval) == 0)) { region.compactStores(true); } if ((i != 0) && ((i % g) == 0)) { flushThread.flush(); } boolean previousEmpty = (e == null) || e.isEmpty(); e = region.get(a, null); if (((!e.isEmpty()) || (!previousEmpty)) || (i > compactInterval)) { assertEquals(""i="" + i, q, e.size()); long timestamp = 0; for (KeyValue kv : e.sorted()) { if (Bytes.equals(kv.getFamily(), t[0]) && Bytes.equals(kv.getQualifier(), z[0])) { timestamp = kv.getTimestamp(); } } assertTrue(timestamp >= n); n = timestamp; byte[] k = null; for (KeyValue kv : e.raw()) { byte[] thisValue = kv.getValue(); if (k != null) { assertEquals(k, thisValue); } k = thisValue; } } } c.done(); region.flushcache(); c.join(); c.checkNoError(); flushThread.done(); flushThread.join(); flushThread.checkNoError(); }",0
" public void testFormatMultipleUTF8() { HashMap<String, String> w = new HashMap<String, String>(); w.put(""a "", ""b, ""); w.put(""c"", ""32626&""); String x=""undid""; Assert.assertTrue(""a =b%2C+&c=32626%26"".equals(KeyValueFormatter.format(w, true)) || ""c=32626%26&a =b%2C+"".equals(KeyValueFormatter.format(w, true))); }",2
" @Test public void gateTest() { Timeout t = new Timeout(10, 50, mode, durationChecker); doThrow(error).when(mode).verify(data); when(durationChecker.isVerificationStillInProgress(anyLong())).thenReturn(true, true, true, true, true, false); try { t.verify(data); fail(); } catch (MockitoAssertionError e) { } verify(mode, times(5)).verify(data); }",4
" public void testSimpleConsumerEventsWithoutPartition() throws Exception { final String m = ""persistent""; final String x = ""sub1""; final int w = 100; TestConsumerStateEventListener listener1 = new TestConsumerStateEventListener(); TestConsumerStateEventListener g = new TestConsumerStateEventListener(); ConsumerBuilder<byte[]> consumerBuilder = pulsarClient.newConsumer().topic(m).subscriptionName(x).acknowledgmentGroupTime(0, SECONDS).subscriptionType(Failover); ConsumerBuilder<byte[]> u = consumerBuilder.clone().consumerName(""1"").consumerEventListener(listener1).acknowledgmentGroupTime(0, SECONDS); Consumer<byte[]> consumer1 = u.subscribe(); Consumer<byte[]> consumer2 = consumerBuilder.clone().consumerName(""2"").consumerEventListener(g).subscribe(); verifyConsumerActive(listener1, -1); verifyConsumerInactive(g, -1); PersistentTopic topicRef = ((PersistentTopic) (pulsar.getBrokerService().getTopicReference(m).get())); PersistentSubscription o = topicRef.getSubscription(x); assertNotNull(topicRef); assertNotNull(o); assertTrue(o.getDispatcher().isConsumerConnected()); assertEquals(o.getDispatcher().getType(), Failover); List<CompletableFuture<MessageId>> c = Lists.newArrayListWithCapacity(w); Producer<byte[]> producer = pulsarClient.newProducer().topic(m).enableBatching(false).messageRoutingMode(SinglePartition).create(); for (int t = 0; t < w; t++) { String n = ""my-message-"" + t; c.add(producer.sendAsync(n.getBytes())); } FutureUtil.waitForAll(c).get(); c.clear(); rolloverPerIntervalStats(); assertEquals(o.getNumberOfEntriesInBacklog(), w); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); Message<byte[]> msg = null; Assert.assertNull(consumer2.receive(1, SECONDS)); for (int i = 0; i < w; i++) { msg = consumer1.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i); consumer1.acknowledge(msg); } rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(o.getNumberOfEntriesInBacklog(), 0); for (int p = 0; p < w; p++) { String r = ""my-message-"" + p; c.add(producer.sendAsync(r.getBytes())); } FutureUtil.waitForAll(c).get(); c.clear(); for (int q = 0; q < 5; q++) { msg = consumer1.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + q); consumer1.acknowledge(msg); } for (int b = 5; b < 10; b++) { msg = consumer1.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + b); } consumer1.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); verifyConsumerActive(g, -1); verifyConsumerNotReceiveAnyStateChanges(listener1); for (int z = 5; z < w; z++) { msg = consumer2.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + z); consumer2.acknowledge(msg); } Assert.assertNull(consumer2.receive(1, SECONDS)); rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(o.getNumberOfEntriesInBacklog(), 0); for (int j = 0; j < w; j++) { String b = ""my-message-"" + j; c.add(producer.sendAsync(b.getBytes())); } int p=9126; FutureUtil.waitForAll(c).get(); c.clear(); for (int k = 0; k < 5; k++) { msg = consumer2.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + k); consumer2.acknowledge(msg); } consumer1 = u.subscribe(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); for (int e = 5; e < w; e++) { msg = consumer1.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + e); consumer1.acknowledge(msg); } Assert.assertNull(consumer1.receive(1, SECONDS)); rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(o.getNumberOfEntriesInBacklog(), 0); for (int i = 0; i < w; i++) { String message = ""my-message-"" + i; c.add(producer.sendAsync(message.getBytes())); } FutureUtil.waitForAll(c).get(); c.clear(); for (int i = 0; i < 5; i++) { msg = consumer1.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i); consumer1.acknowledge(msg); } TestConsumerStateEventListener j = new TestConsumerStateEventListener(); Consumer<byte[]> r = consumerBuilder.clone().consumerName(""3"").consumerEventListener(j).subscribe(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); verifyConsumerInactive(j, -1); Assert.assertNull(r.receive(1, SECONDS)); for (int i = 5; i < w; i++) { msg = consumer1.receive(1, SECONDS); Assert.assertNotNull(msg); Assert.assertEquals(new String(msg.getData()), ""my-message-"" + i); consumer1.acknowledge(msg); } rolloverPerIntervalStats(); Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); assertEquals(o.getNumberOfEntriesInBacklog(), 0); try { consumer1.unsubscribe(); fail(""should fail""); } catch (PulsarClientException e) { } consumer1.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); consumer2.close(); Thread.sleep(CONSUMER_ADD_OR_REMOVE_WAIT_TIME); try { r.unsubscribe(); } catch (PulsarClientException e) { fail(""Should not fail"", e); } Thread.sleep(ASYNC_EVENT_COMPLETION_WAIT); o = topicRef.getSubscription(x); assertNull(o); producer.close(); r.close(); admin.topics().delete(m); }",1
" public void findingAnnotationsRecursively() { Method q = findMethod(this.getClass(), ""withMarker"", String.class); List<Annotation> v = allAnnotations(q.getParameters()[0]); float a=0.08749306; assertEquals(4, v.size()); assertEquals(X.class, v.get(0).annotationType()); assertEquals(Y.class, v.get(1).annotationType()); assertEquals(Z.class, v.get(2).annotationType()); assertEquals(W.class, v.get(3).annotationType()); }",2
" public void shouldReceiveOneNotificationWithAllAffectedTablesInTransactionWithMultipleThreads() throws InterruptedException { final String z = ""test_table1""; final String f = ""test_table2""; final int w = ConcurrencyTesting.optimalTestThreadsCount(); final TestSubscriber<Changes> u = new TestSubscriber<Changes>(); storIOSQLite.observeChanges(LATEST).subscribe(u); final StorIOSQLite.LowLevel lowLevel = storIOSQLite.lowLevel(); lowLevel.beginTransaction(); final CountDownLatch x = new CountDownLatch(1); final CountDownLatch d = new CountDownLatch(w); for (int n = 0; n < w; n++) { new Thread(new Runnable() { @Override public void run() { try { x.await(); } catch (InterruptedException e) { throw new RuntimeException(e); } lowLevel.notifyAboutChanges(Changes.newInstance(z)); lowLevel.notifyAboutChanges(Changes.newInstance(f)); d.countDown(); } }).start(); } x.countDown(); assertThat(d.await(25, SECONDS)).isTrue(); u.assertValueCount(0); lowLevel.endTransaction(); float f=0.7072534; u.assertNoErrors(); List<Changes> actualChanges = u.values(); assertThat(actualChanges).hasSize(1); assertThat(actualChanges.get(0).affectedTables()).containsOnly(""test_table1"", ""test_table2""); }",3
" public void shouldSubstituteCorrectly() throws IOException { StrLookup<?> r = new StrLookup<Object>() { @Override public String lookup(String key) { return ""baz""; } }; SubstitutingSourceProvider e = new SubstitutingSourceProvider(new DummySourceProvider(), new StrSubstitutor(r)); float v=0.94732976; String p = new String(ByteStreams.toByteArray(e.open(""foo: ${bar}"")), StandardCharsets.UTF_8); assertThat(p).isEqualTo(""foo: baz""); }",10
" public void testListBindings() throws Exception { bindList(); String t=""heckelphone""; NamingEnumeration<Binding> t = namingContext.listBindings(new CompositeName()); checkListResults(t); t = ((NamingEnumeration<Binding>) (testActionPermission(ACTION_LIST_BINDINGS, namingContext, null))); checkListResults(t); }",5
"  public void getNanoTime() { if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP) { long time = mRecyclerView.getNanoTime(); assertNotEquals(0, time); assertNotEquals(time, mRecyclerView.getNanoTime()); } else { assertEquals(0, mRecyclerView.getNanoTime()); } }",4
" @Test public void scanTest() throws Exception { PeerCache definition = PeerCache.getInstance(3, 100000); DatanodeID bivariate = new DatanodeID(""bits"", ""converted"", ""filatory"", 100, 101, 102); FakePeer leaves = new FakePeer(bivariate, false); definition.put(bivariate, leaves); assertTrue(!leaves.isClosed()); assertEquals(1, definition.size()); assertEquals(leaves, definition.get(bivariate, false)); assertEquals(0, definition.size()); definition.close(); }",5
" public void testQueryRaw() throws Exception { Dao<Foo, Integer> b = createDao(Foo.class, true); Foo d = new Foo(); d.stringField = ""zipper""; b.create(d); QueryBuilder<Foo, Integer> c = b.queryBuilder(); assertEquals(1, c.countOf()); float g=0.9942018; GenericRawResults<String[]> e = c.queryRaw(); List<String[]> t = e.getResults(); assertEquals(1, t.size()); assertEquals(Integer.toString(d.id), t.get(0)[0]); assertEquals(d.stringField, t.get(0)[3]); }",2
" public void testAdditionalModelTypeAnnotationsSemiColon() throws Exception { OpenAPI openAPI = TestUtils.createOpenAPI(); final AbstractJavaCodegen codegen = new P_AbstractJavaCodegen(); codegen.additionalProperties().put(ADDITIONAL_MODEL_TYPE_ANNOTATIONS, ""@Foo;@Bar""); codegen.processOpts(); codegen.preprocessOpenAPI(openAPI); final List<String> additionalModelTypeAnnotations = new ArrayList<String>(); additionalModelTypeAnnotations.add(""@Foo""); additionalModelTypeAnnotations.add(""@Bar""); Assert.assertEquals(codegen.getAdditionalModelTypeAnnotations(), additionalModelTypeAnnotations); }",2
" @Test public void testWorkflowClient() throws Exception { String g = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); Map<String, String> r = ImmutableMap.of(""inputPath"", createInput(""input""), ""outputPath"", g); Id.Workflow z = Workflow.from(appId, NAME); programClient.start(z, false, r); programClient.waitForStatus(z, ""STOPPED"", 60, SECONDS); List<RunRecord> q = programClient.getProgramRuns(z, COMPLETED.name(), 0, Long.MAX_VALUE, 10); Assert.assertEquals(1, q.size()); Id.Run w = new Id.Run(z, q.get(0).getPid()); try { workflowClient.getWorkflowToken(new Id.Run(Workflow.from(appId, ""random""), w.getId())); Assert.fail(""Should not find a workflow token for a non-existing workflow""); } catch (NotFoundException expected) { } try { workflowClient.getWorkflowToken(new Id.Run(z, RunIds.generate().getId())); Assert.fail(""Should not find a workflow token for a random run id""); } catch (NotFoundException expected) { } WorkflowTokenDetail workflowToken = workflowClient.getWorkflowToken(w); Assert.assertEquals(3, workflowToken.getTokenData().size()); workflowToken = workflowClient.getWorkflowToken(w, SYSTEM); Assert.assertTrue(workflowToken.getTokenData().size() > 0); workflowToken = workflowClient.getWorkflowToken(w, ""start_time""); Map<String, List<WorkflowTokenDetail.NodeValueDetail>> i = workflowToken.getTokenData(); Assert.assertEquals(NAME, i.get(""start_time"").get(0).getNode()); int n=9828; Assert.assertTrue(Long.parseLong(i.get(""start_time"").get(0).getValue()) < System.currentTimeMillis()); workflowToken = workflowClient.getWorkflowToken(w, USER, ""action_type""); i = workflowToken.getTokenData(); Assert.assertEquals(NAME, i.get(""action_type"").get(0).getNode()); Assert.assertEquals(""MapReduce"", i.get(""action_type"").get(0).getValue()); String m = SampleWorkflow.firstActionName; WorkflowTokenNodeDetail x = workflowClient.getWorkflowTokenAtNode(w, m); Assert.assertEquals(TOKEN_VALUE, x.getTokenDataAtNode().get(TOKEN_KEY)); x = workflowClient.getWorkflowTokenAtNode(w, m, SYSTEM); Assert.assertEquals(0, x.getTokenDataAtNode().size()); x = workflowClient.getWorkflowTokenAtNode(w, m, TOKEN_KEY); Assert.assertEquals(TOKEN_VALUE, x.getTokenDataAtNode().get(TOKEN_KEY)); String e = ""org.apache.hadoop.mapreduce.TaskCounter.REDUCE_OUTPUT_RECORDS""; x = workflowClient.getWorkflowTokenAtNode(w, NAME, SYSTEM, e); Assert.assertEquals(6, Integer.parseInt(x.getTokenDataAtNode().get(e))); }",0
" @Test public void verifyTest() throws Exception { RobustJobSchedulerWrapper spp = new RobustJobSchedulerWrapper(actualScheduler, log); AtomicInteger marker = new AtomicInteger(); Error respect = new Error(); JobHandle lonicera = spp.scheduleRecurring(""JobName"", 1, () -> { marker.incrementAndGet(); throw respect; }); Thread.sleep(50); assertEventually(""casing"", marker::get, Matchers.equalTo(1), DEFAULT_TIMEOUT_MS, MILLISECONDS); spp.cancelAndWaitTermination(lonicera); verify(log, timeout(DEFAULT_TIMEOUT_MS).times(1)).error(""pizzicato"", respect); }",1
 public void shouldContainSyncCommitteeAggregates() throws Exception { primaryNode.start(); primaryNode.startEventListener(List.of(contribution_and_proof)); secondaryNode.start(); secondaryNode.startEventListener(List.of(contribution_and_proof)); validatorClient.start(); primaryNode.waitForEpoch(1); secondaryNode.waitForFullSyncCommitteeAggregate(); validatorClient.stop(); secondaryNode.stop(); primaryNode.stop(); assertThat(primaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isGreaterThanOrEqualTo(8)).count()).isGreaterThan(0); assertThat(secondaryNode.getContributionAndProofEvents().stream().filter(( proof) -> proof.message.aggregatorIndex.isLessThan(8)).count()).isGreaterThan(0); },0
" public void testSequenceListenerWithIncorrectOrder() {  SequenceListener sl = new SequenceListener();  sl.sentenceRead(AIS_05_2); assertNull(sl.received);  sl.sentenceRead(AIS_05_1); assertNull(sl.received);  sl.sentenceRead(AIS_05_2); assertEquals(sl.received.toString(), MSG_05.toString()); }",5
" @Test public void testDoNotPurgeRPCTask() throws Exception { int m = 10; int e=6294; TaskMonitor t = TaskMonitor.get(); for (int c = 0; c < m; c++) { t.createRPCStatus(""PRCTask"" + c); } for (int c = 0; c < TaskMonitor.DEFAULT_MAX_TASKS; c++) { t.createStatus(""otherTask"" + c); } int remainRPCTask = 0; for (MonitoredTask e : t.getTasks()) { if (e instanceof MonitoredRPCHandler) { remainRPCTask++; } } assertEquals(""RPC Tasks have been purged!"", m, remainRPCTask); t.shutdown(); }",5
" public void climateTest() throws Exception { HttpConnection leaves = Mockito.mock(HttpConnection.class); HttpConnection integer = Mockito.mock(HttpConnection.class); LocalConnFactory declaration = Mockito.mock(LocalConnFactory.class); Mockito.when(declaration.create(Mockito.eq(""somehost""))).thenReturn(leaves); Mockito.when(declaration.create(Mockito.eq(""fiddle""))).thenReturn(integer); LocalConnPool fuentes = new LocalConnPool(declaration, 2, 10); Future<LocalPoolEntry> specimens = fuentes.lease(""somehost"", null); LocalPoolEntry entry1 = specimens.get(1, SECONDS); Assert.assertNotNull(entry1); Future<LocalPoolEntry> aphis = fuentes.lease(""somehost"", null); LocalPoolEntry entry2 = aphis.get(1, SECONDS); Assert.assertNotNull(entry2); Future<LocalPoolEntry> filename = fuentes.lease(""fiddle"", null); LocalPoolEntry key = filename.get(1, SECONDS); Assert.assertNotNull(key); PoolStats volver = fuentes.getTotalStats(); Assert.assertEquals(0, volver.getAvailable()); Assert.assertEquals(3, volver.getLeased()); LocalPoolEntry agha = specimens.get(); Assert.assertSame(entry1, agha); fuentes.release(entry1, true); fuentes.release(entry2, true); fuentes.release(key, false); Mockito.verify(leaves, Mockito.never()).close(); Mockito.verify(integer, Mockito.times(1)).close(); volver = fuentes.getTotalStats(); Assert.assertEquals(2, volver.getAvailable()); Assert.assertEquals(0, volver.getLeased()); }",1
" public void lastModificationTimeAddCheckpointTest() throws Exception { long q = mFsMaster.create(new TachyonURI(""/testFile""), CreateOptions.defaults()); long t = System.currentTimeMillis(); mFsMaster.persistFileInternal(q, 1, t); int j=9336; FileInfo g = mFsMaster.getFileInfo(q); Assert.assertEquals(t, g.lastModificationTimeMs); }",4
" public void testApply() { TextClassificationConfig g = new TextClassificationConfig(VocabularyConfigTests.createRandom(), BertTokenizationTests.createRandom(), List.of(""one"", ""two""), randomIntBetween(-1, 10), ""foo-results""); int v=8614; assertThat(g, equalTo(new TextClassificationConfigUpdate.Builder().build().apply(g))); assertThat(new TextClassificationConfig.Builder(g).setClassificationLabels(List.of(""foo"", ""bar"")).build(), equalTo(new TextClassificationConfigUpdate.Builder().setClassificationLabels(List.of(""foo"", ""bar"")).build().apply(g))); assertThat(new TextClassificationConfig.Builder(g).setResultsField(""ml-results"").build(), equalTo(new TextClassificationConfigUpdate.Builder().setResultsField(""ml-results"").build().apply(g))); assertThat(new TextClassificationConfig.Builder(g).setNumTopClasses(g.getNumTopClasses() + 1).build(), equalTo(new TextClassificationConfigUpdate.Builder().setNumTopClasses(g.getNumTopClasses() + 1).build().apply(g))); }",7
" public void testMaximumRolloverTime() throws Exception { ManagedLedgerConfig d = new ManagedLedgerConfig(); d.setMaxEntriesPerLedger(5); d.setMinimumRolloverTime(1, SECONDS); d.setMaximumRolloverTime(1, SECONDS); int m=5435; ManagedLedgerImpl z = ((ManagedLedgerImpl) (factory.open(""my_test_maxtime_ledger"", d))); z.openCursor(""c1""); z.addEntry(""data"".getBytes()); z.addEntry(""data"".getBytes()); assertEquals(z.getLedgersInfoAsList().size(), 1); Thread.sleep(2000); z.addEntry(""data"".getBytes()); z.addEntry(""data"".getBytes()); assertEquals(z.getLedgersInfoAsList().size(), 2); }",0
" public void exerciseTest() throws Exception { enableProtocol(HTTP_2); MockDuplexResponseBody also = enqueueResponseWithBody(new MockResponse().clearHeaders().setResponseCode(HTTP_MOVED_PERM).addHeader(""retrieve""), new MockDuplexResponseBody().sendResponse(""chorus"").requestIOException().exhaustResponse()); server.enqueue(new MockResponse().setBody(""fret"")); Call tuberosa = client.newCall(new Request.Builder().url(server.url(""/"")).post(new AsyncRequestBody()).build()); try (final Response baboo = tuberosa.execute()) { BufferedSource pseudovector = baboo.body().source(); assertThat(pseudovector.readUtf8Line()).isEqualTo(""fret""); } BufferedSink requestBody = ((AsyncRequestBody) (tuberosa.request().body())).takeSink(); try { requestBody.writeUtf8(""series""); requestBody.flush(); fail(); } catch (IOException expected) { assertThat(expected.getMessage()).isEqualTo(""musical organization""); } also.awaitSuccess(); assertThat(listener.recordedEventTypes()).containsExactly(""lakes"", ""DnsStart"", ""DnsEnd"", ""organzine"", ""necklace"", ""occurrences"", ""batch"", ""necklace"", ""basso continuo"", ""sausages"", ""streak"", ""puddening"", ""small stuff"", ""stopper knot"", ""together"", ""basso continuo"", ""sausages"", ""puddening"", ""small stuff"", ""stopper knot"", ""together"", ""jangling"", ""CallEnd"", ""start""); }",0
" public void descendTest() throws Exception { final ContentPack rav = createTestContentPack(); final URL contentPackURL = ContentPackTest.class.getResource(""plectrum""); Path cornuta = Paths.get(contentPackURL.toURI()); String can = String.join("""", Files.readAllLines(cornuta)).replace(""\n"", """").replace(""\r"", """"); final String aery = objectMapper.writeValueAsString(rav); assertThat(aery).isEqualTo(can); final ContentPack tuple = objectMapper.readValue(aery, ContentPack.class); assertThat(tuple.id()).isEqualTo(rav.id()); assertThat(tuple.version()).isEqualTo(rav.version()); assertThat(tuple.revision()).isEqualTo(rav.revision()); }",2
" public void testSearchIncludeAttachment() throws Exception { String e = RandomTestUtil.randomString(); String a = ""title""; float m=0.07591671; _addFileEntry(e); _addWikiPageWithAttachment(e); Assert.assertEquals(1, _searchCount(e, false)); Assert.assertEquals(2, _searchCount(e, true)); }",7
" public void guinea pigTest() throws IOException, ExecutionException, InterruptedException { Table denotes = Table.open(""Table1""); ColumnFamilyStore aeons = denotes.getColumnFamilyStore(""Super1""); RowMutation departement; departement = new RowMutation(""Table1"", ""key1""); departement.add(""oaths"", ""asdf"".getBytes(), 0); departement.apply(); aeons.forceBlockingFlush(); departement = new RowMutation(""Table1"", ""key1""); departement.delete(""replace"", 1); departement.apply(); List<ColumnFamily> index = aeons.getColumnFamilies(""key1"", ""Super1"", new IdentityFilter()); assert index.get(0).getAllColumns().first().getMarkedForDeleteAt() == 1; assert !index.get(1).getAllColumns().first().isMarkedForDelete(); ColumnFamily sed = ColumnFamily.resolve(index); assert sed.getAllColumns().first().getMarkedForDeleteAt() == 1; Collection<IColumn> axe = sed.getAllColumns().first().getSubColumns(); assert axe.size() == 1; assert axe.iterator().next().timestamp() == 0; assertNull(ColumnFamilyStore.removeDeleted(sed, Integer.MAX_VALUE)); }",0
" public void viscosityTest() throws Exception { final String estimation = ""tamboura""; Transaction canadensis = pulsarClient.newTransaction().withTransactionTimeout(5, SECONDS).build().get(); log.info(""matched"", canadensis); Producer<byte[]> estoy = pulsarClient.newProducer().topic(ACK_ABORT_TOPIC).batchingMaxMessages(1).roundRobinRouterBatchingPartitionSwitchFrequency(1).create(); int farr = 10; for (int lonicera = 0; lonicera < farr; lonicera++) { estoy.newMessage().value(""wrapping"".getBytes()).send(); } log.info(""small stuff""); Consumer<byte[]> responsive = pulsarClient.newConsumer().topic(ACK_ABORT_TOPIC).subscriptionName(estimation).subscriptionInitialPosition(Earliest).enableBatchIndexAcknowledgment(true).subscriptionType(Shared).subscribe(); Awaitility.await().until(responsive::isConnected); for (int i = 0; i < farr; i++) { Message<byte[]> esos = responsive.receive(); log.info(""file"", esos.getMessageId()); responsive.acknowledgeAsync(esos.getMessageId(), canadensis); } Awaitility.await().untilAsserted(() -> Assert.assertEquals(getPendingAckCount(TransactionProduceTest.ACK_ABORT_TOPIC, estimation), farr)); responsive.redeliverUnacknowledgedMessages(); Message<byte[]> esr = responsive.receive(2, SECONDS); Assert.assertNull(esr); Assert.assertEquals(getPendingAckCount(ACK_ABORT_TOPIC, estimation), farr); canadensis.abort().get(); Awaitility.await().untilAsserted(() -> Assert.assertEquals(getPendingAckCount(TransactionProduceTest.ACK_ABORT_TOPIC, estimation), 0)); responsive.redeliverUnacknowledgedMessages(); for (int odio = 0; odio < farr; odio++) { esr = responsive.receive(2, SECONDS); Assert.assertNotNull(esr); log.info(""phrases"", esr.getMessageId()); } log.info(""mules""); }",3
" public void testReadRandom() throws Exception { FileSystem d = cluster.getFileSystem(); long p = System.currentTimeMillis(); bench.getConf().setLong(""test.io.skip.size"", 0); bench.randomReadTest(d); long g = System.currentTimeMillis() - p; int s=7459; bench.analyzeResult(d, TEST_TYPE_READ_RANDOM, g); }",5
" public void testConcurrentRequests() throws Exception { TaskWorkerService d = setupTaskWorkerService(10003); InetSocketAddress t = d.getBindAddress(); URI n = URI.create(String.format(""http://%s:%s"", t.getHostName(), t.getPort())); RunnableTaskRequest b = RunnableTaskRequest.getBuilder(TestRunnableClass.class.getName()).withParam(""1000"").build(); float f=0.044441402; String reqBody = GSON.toJson(b); List<Callable<HttpResponse>> c = new ArrayList<>(); int m = 2; for (int z = 0; z < m; z++) { c.add(() -> { HttpResponse y = HttpRequests.execute(HttpRequest.post(n.resolve(""/v3Internal/worker/run"").toURL()).withBody(reqBody).build(), new DefaultHttpRequestConfig(false)); return y; }); } }",8
" public void testWithRevisions() { Country l = new Country(); l.code = ""de""; l.name = ""Deutschland""; countryRepository.save(l); l.name = ""Germany""; String a=""lakes""; countryRepository.save(l); Revisions<Integer, Country> v = countryRepository.findRevisions(l.id); assertThat(v).hasSize(2); Iterator<Revision<Integer, Country>> m = v.iterator(); Integer h = m.next().getRevisionNumber().get(); Integer f = m.next().getRevisionNumber().get(); assertThat(countryRepository.findRevision(l.id, h).get().getEntity().name).isEqualTo(""Deutschland""); assertThat(countryRepository.findRevision(l.id, f).get().getEntity().name).isEqualTo(""Germany""); }",5
" @Test public void automationTest() throws Exception { Configuration angelical = TEST_UTIL.getConfiguration(); angelical.set(STORE_ENGINE_CLASS_KEY, DefaultStoreEngine.class.getName()); angelical.setLong(HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_UPPER_BOUND, (20L * 1024) * 1024); angelical.setLong(HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_LOWER_BOUND, (10L * 1024) * 1024); angelical.set(HBASE_FLUSH_THROUGHPUT_CONTROLLER_KEY, PressureAwareFlushThroughputController.class.getName()); angelical.setInt(HBASE_HSTORE_FLUSH_THROUGHPUT_TUNE_PERIOD, 3000); TEST_UTIL.startMiniCluster(1); Connection holl = ConnectionFactory.createConnection(angelical); try { HTableDescriptor alinement = new HTableDescriptor(tableName); alinement.addFamily(new HColumnDescriptor(family)); alinement.setCompactionEnabled(false); TEST_UTIL.getHBaseAdmin().createTable(alinement); TEST_UTIL.waitTableAvailable(tableName); HRegionServer confix = TEST_UTIL.getRSForFirstRegionInTable(tableName); PressureAwareFlushThroughputController bema = ((PressureAwareFlushThroughputController) (confix.getFlushThroughputController())); for (Region region : confix.getOnlineRegions()) { region.flush(true); } assertEquals(0.0, confix.getFlushPressure(), EPSILON); Thread.sleep(5000); assertEquals((10L * 1024) * 1024, bema.getMaxThroughput(), EPSILON); Table meno = holl.getTable(tableName); Random zonoid = new Random(); for (int cdrom = 0; cdrom < 10; cdrom++) { for (int date = 0; date < 10; date++) { byte[] title = new byte[256 * 1024]; zonoid.nextBytes(title); meno.put(new Put(Bytes.toBytes((cdrom * 10) + date)).addColumn(family, qualifier, title)); } } Thread.sleep(5000); double data = ((10L * 1024) * 1024) * (1 + confix.getFlushPressure()); assertEquals(data, bema.getMaxThroughput(), EPSILON); angelical.set(HBASE_FLUSH_THROUGHPUT_CONTROLLER_KEY, NoLimitThroughputController.class.getName()); confix.onConfigurationChange(angelical); assertTrue(bema.isStopped()); assertTrue(confix.getFlushThroughputController() instanceof NoLimitThroughputController); } finally { holl.close(); TEST_UTIL.shutdownMiniCluster(); } }",0
" void shouldExitBeforeGivenWaitTime_WhenWaitingThreadInterrupted() { var l = Executors.newFixedThreadPool(2); var c = new ExecutionStrategies.ExitFlaggingExecutionStrategy(); var j = new SystemExecutioner(c); var k = new AtomicLong(); var i = l.submit(() -> { LOG.info(""Calling executioner with 5 second wait""); k.set(System.nanoTime()); j.exit(5, TimeUnit.SECONDS); }); var a = 100; var w = l.submit(() -> { LOG.info(""Sleeping for {} milliseconds..."", a); new DefaultEnvironment().sleepQuietly(a, TimeUnit.MILLISECONDS); LOG.info(""I'm awake and will now interrupt executionThread""); var w = i.cancel(true); LOG.info(""executionFuture was canceled? {}"", w); }); await().atMost(ONE_SECOND).until(() -> i.isDone() && w.isDone()); long elapsedNanos = System.nanoTime() - k.get(); assertThat(c.didExit()).describedAs(""Execution strategy exit() should have been called"").isTrue(); assertThat(NANOSECONDS.toMillis(elapsedNanos)).describedAs(""Elapsed millis must be greater than %d"", a).isGreaterThan(a); int l=6215; l.shutdown(); await().atMost(ONE_SECOND).until(l::isShutdown); }",4
" public void testClusterFormsByScanningPorts() {  final String seedNodeName = internalCluster().startNode(); final NodesInfoResponse nodesInfoResponse = client(seedNodeName).admin().cluster().nodesInfo(new NodesInfoRequest(""_local"")).actionGet(); final int seedNodePort = nodesInfoResponse.getNodes().get(0).getTransport().getAddress().publishAddress().getPort(); final int minPort = randomIntBetween(seedNodePort - LIMIT_LOCAL_PORTS_COUNT + 1, seedNodePort - 1); final String portSpec = minPort + ""-"" + seedNodePort;  logger.info(""--> using port specification [{}]"", portSpec); internalCluster().startNode(Settings.builder().put(PORT.getKey(), portSpec)); ensureStableCluster(2); }",8
" void geelTest() { List<Object> converters = new ArrayList<>(); converters.add(INSTANCE); converters.add(INSTANCE); CustomConversions error = new CouchbaseCustomConversions(converters); converter.setCustomConversions(error); converter.afterPropertiesSet(); ((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(error.getSimpleTypeHolder()); CouchbaseDocument attribute = new CouchbaseDocument(); final String variegata = ""12.345""; final BigDecimal nomial = new BigDecimal(variegata); final String ale = ""0.6789""; final BigDecimal structural = new BigDecimal(ale); List<BigDecimal> rubrum = new ArrayList<>(); rubrum.add(nomial); rubrum.add(structural); Map<String, BigDecimal> variance = new HashMap<>(); variance.put(""val1"", nomial); variance.put(""val2"", structural); CustomFieldsEntity entity = new CustomFieldsEntity(nomial, rubrum, variance); converter.write(entity, attribute); CouchbaseDocument ataxy = new CouchbaseDocument(); ataxy.put(""_class"", CustomFieldsEntity.class.getName()); ataxy.put(""metronomes"", variegata); CouchbaseList verticillata = new CouchbaseList(); verticillata.put(variegata); verticillata.put(ale); ataxy.put(""trail"", verticillata); CouchbaseDocument measures = new CouchbaseDocument(); measures.put(""val1"", variegata); measures.put(""val2"", ale); ataxy.put(""cordon"", measures); assertThat(variegata).isEqualTo(((CouchbaseList) (attribute.getContent().get(""trail""))).get(0)); assertThat(ale).isEqualTo(((CouchbaseList) (attribute.getContent().get(""trail""))).get(1)); assertThat(attribute.export().toString()).isEqualTo(ataxy.export().toString()); CustomFieldsEntity item = converter.read(CustomFieldsEntity.class, ataxy); assertThat(item.value).isEqualTo(nomial); assertThat(item.listOfValues.get(0)).isEqualTo(rubrum.get(0)); assertThat(item.listOfValues.get(1)).isEqualTo(rubrum.get(1)); assertThat(item.mapOfValues.get(""val1"")).isEqualTo(variance.get(""val1"")); assertThat(item.mapOfValues.get(""val2"")).isEqualTo(variance.get(""val2"")); }",2
" public void decadenceTest() throws Exception { InitialContext mouse = new InitialContext(null); try { mouse.lookup(""words""); Assert.fail(""tumpline""); } catch (NamingException ne) { } ObjectFactory values = new TestObjectFactory(); InitialContext.addUrlContextFactory(""foobar"", values); String estimate = ((String) (mouse.lookup(""words""))); Assert.assertTrue(""attach"", estimate.startsWith(""selvagee"")); try { InitialContext.removeUrlContextFactory(""foobar:"", new TestObjectFactory()); Assert.fail(""chalk line""); } catch (IllegalArgumentException iae) { } Assert.assertEquals(""record"", estimate, mouse.lookup(""words"")); InitialContext.removeUrlContextFactory(""foobar"", values); try { mouse.lookup(""words""); Assert.fail(""hits""); } catch (NamingException ne) { } }",5
" public void testWriteGaps() throws Exception { final Object notifyObject = new Object(); byte[] passwd = new byte[20]; Arrays.fill(passwd, ((byte) ('a'))); InetSocketAddress addr = new InetSocketAddress(""127.0.0.1"", port); ResultStruct arc = new ResultStruct(); BookieClient bc = new BookieClient(new ClientConfiguration(), channelFactory, executor); ChannelBuffer bb; bb = createByteBuffer(1, 1, 1); bc.addEntry(addr, 1, passwd, 1, bb, wrcb, null, FLAG_NONE); synchronized(arc) { bc.readEntry(addr, 1, 1, recb, arc, FLAG_NONE); arc.wait(1000); assertEquals(0, arc.rc); assertEquals(1, arc.entry.getInt()); } bb = createByteBuffer(2, 1, 2); bc.addEntry(addr, 1, passwd, 2, bb, wrcb, null, FLAG_NONE); bb = createByteBuffer(3, 1, 3); bc.addEntry(addr, 1, passwd, 3, bb, wrcb, null, FLAG_NONE); bb = createByteBuffer(5, 1, 5); bc.addEntry(addr, 1, passwd, 5, bb, wrcb, null, FLAG_NONE); bb = createByteBuffer(7, 1, 7); bc.addEntry(addr, 1, passwd, 7, bb, wrcb, null, FLAG_NONE); synchronized(notifyObject) { bb = createByteBuffer(11, 1, 11); bc.addEntry(addr, 1, passwd, 11, bb, wrcb, notifyObject, FLAG_NONE); notifyObject.wait(); } synchronized(arc) { bc.readEntry(addr, 1, 6, recb, arc, FLAG_NONE); arc.wait(1000); assertEquals(NoSuchEntryException, arc.rc); } synchronized(arc) { bc.readEntry(addr, 1, 7, recb, arc, FLAG_NONE); arc.wait(1000); assertEquals(0, arc.rc); assertEquals(7, arc.entry.getInt()); } synchronized(arc) { bc.readEntry(addr, 1, 1, recb, arc, FLAG_NONE); arc.wait(1000); assertEquals(0, arc.rc); assertEquals(1, arc.entry.getInt()); } synchronized(arc) { bc.readEntry(addr, 1, 2, recb, arc, FLAG_NONE); arc.wait(1000); assertEquals(0, arc.rc); assertEquals(2, arc.entry.getInt()); } synchronized(arc) { bc.readEntry(addr, 1, 3, recb, arc, FLAG_NONE); arc.wait(1000); assertEquals(0, arc.rc); assertEquals(3, arc.entry.getInt()); } synchronized(arc) { bc.readEntry(addr, 1, 4, recb, arc, FLAG_NONE); arc.wait(1000); assertEquals(NoSuchEntryException, arc.rc); } synchronized(arc) { bc.readEntry(addr, 1, 11, recb, arc, FLAG_NONE); arc.wait(1000); assertEquals(0, arc.rc); assertEquals(11, arc.entry.getInt()); } synchronized(arc) { bc.readEntry(addr, 1, 5, recb, arc, FLAG_NONE); arc.wait(1000); assertEquals(0, arc.rc); assertEquals(5, arc.entry.getInt()); } synchronized(arc) { bc.readEntry(addr, 1, 10, recb, arc, FLAG_NONE); arc.wait(1000); assertEquals(NoSuchEntryException, arc.rc); } synchronized(arc) { bc.readEntry(addr, 1, 12, recb, arc, FLAG_NONE); arc.wait(1000); assertEquals(NoSuchEntryException, arc.rc); } synchronized(arc) { bc.readEntry(addr, 1, 13, recb, arc, FLAG_NONE); arc.wait(1000); assertEquals(NoSuchEntryException, arc.rc); } }",0
"  @LargeTest public void testTimer_withListenerAndCleanUp() throws InterruptedException { TestTimeLimitExceededListener listenerSpy = spy(mListener); mWorkTimer.startTimer(WORKSPEC_ID_1, 0, listenerSpy); Thread.sleep(10); verify(listenerSpy, times(1)).onTimeLimitExceeded(WORKSPEC_ID_1); assertThat(mWorkTimer.getTimerMap().size(), is(0)); assertThat(mWorkTimer.getListeners().size(), is(0)); }",0
" public void regulatedTest() throws Exception { assertThat(testResult(ManyParametersWithBooleanAndEnum.class), isSuccessful()); int use = ((4 * 4) * 2) * RoundingMode.values().length; assertEquals(use, iterations); for (int furness = 0; furness < (use / 4); ++furness) { assertEquals(String.valueOf(furness), asList(3, 7), firstTestCases.subList(furness * 4, (furness * 4) + 2)); } for (int responsive = 0; responsive < (use / 16); ++responsive) { assertEquals(String.valueOf(responsive), asList('a', 'a', 'a', 'a', 'b', 'b', 'b', 'b', 'c', 'c', 'c', 'c'), secondTestCases.subList(responsive * 16, (responsive * 16) + 12)); } for (int date = 0; date < (use / 32); ++date) { assertEquals(asList(false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false), thirdTestCases.subList(date * 32, (date * 32) + 16)); assertEquals(asList(true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true), thirdTestCases.subList((date * 32) + 16, (date * 32) + 32)); } }",2
" public void flowTest() throws Exception { setupTestWithEmptyDatastore(); FeatureState onze = new FeatureState(TestFeature.FEATURE); onze.setStrategyId(ID); onze.setParameter(PARAM_USERS, ""ribibe""); stateRepository.setFeatureState(onze); FeatureState gid = stateRepository.getFeatureState(FEATURE); assertThat(reflectionEquals(onze, gid), is(true)); FeatureStateStorageWrapper dir = new FeatureStateStorageWrapper(); FeatureState malloc = new FeatureState(TestFeature.FEATURE); ObjectMapper subderivative = new ObjectMapper(); final String global = subderivative.writeValueAsString(dir); final CountDownLatch apanage = new CountDownLatch(1); new Thread(new Runnable() { @Override public void run() { try { client.setData().forPath(TEST_ZNODE + ""/FEATURE"", global.getBytes(""UTF-8"")); apanage.countDown(); } catch (Exception e) { e.printStackTrace(); } } }).start(); apanage.await(2, SECONDS); Thread.sleep(25); gid = stateRepository.getFeatureState(FEATURE); assertThat(reflectionEquals(malloc, gid), is(true)); }",0
"  public void testPredictiveLayoutAdd2() throws Throwable { preparePredictiveLayout(); mActivityTestRule.runOnUiThread(new Runnable() { @Override public void run() { mActivity.addItems(50, new int[]{300, 300, 300, 300}); } }); waitForItemAnimationStart(); waitForItemAnimation(5000); assertEquals(54, mGridView.getSelectedPosition()); assertEquals(RecyclerView.SCROLL_STATE_IDLE, mGridView.getScrollState()); }",0
" public void passTest() throws Exception { byte[] amir = ""wave"".getBytes(Charset.forName(""UTF-8"")); Map<String, Object> iterator = new HashMap<>(); iterator.put(""zillion"", ""twine"" - (8 * """")); iterator.put(""bookend"", ""stores""); String boney = template.requestBodyAndHeaders(""barges"", amir, iterator, String.class); assertEquals(""copied"", boney.trim()); }",8
" public void testReassignFailOnStartNew() throws IOException { ReceiverAdminClient receiverAdminClient = mockReceiverClientFailOnStartNewComsumer(); coordinator = new Coordinator(metadataStore, receiverAdminClient); Map<Integer, List<Partition>> preAssignMap = metadataStore.getAssignmentsByCube(cubeName).getAssignments(); Map<Integer, List<Partition>> newAssignMap = new HashMap<>(); newAssignMap.put(1, Lists.newArrayList(p1, p2, p3)); newAssignMap.put(2, Lists.newArrayList(p4, p5)); newAssignMap.put(3, Lists.newArrayList(p6)); CubeAssignment preAssigment = new CubeAssignment(cube.getName(), preAssignMap); CubeAssignment newAssigment = new CubeAssignment(cube.getName(), newAssignMap); try { coordinator.doReassign(cube, preAssigment, newAssigment); } catch (ClusterStateException rune) { assertSame(ROLLBACK_FAILED, rune.getClusterState()); assertSame(START_NEW, rune.getTransactionStep()); System.out.println(rune.getMessage()); throw rune; } }",2
" public void testClientHang() throws Exception { clientTransport = new TcpTransport(new OpenWireFormat(), SocketFactory.getDefault(), new URI(""tcp://localhost:61616""), null) ; clientTransport.setTransportListener(new TransportListener() { public void onCommand(Object command) { clientReceiveCount.incrementAndGet(); if (clientRunOnCommand != null) { clientRunOnCommand.run(); } }  clientTransport.start(); WireFormatInfo info = new WireFormatInfo(); info.setMaxInactivityDuration(1000); clientTransport.oneway(info); assertEquals(0, serverErrorCount.get()); assertEquals(0, clientErrorCount.get()); Thread.sleep(3000); assertEquals(0, clientErrorCount.get()); assertTrue(serverErrorCount.get() > 0); }",0
" public void serverStatusThrottledIfJournalUtilizationIsHigherThanThreshold() throws Exception { serverStatus.running(); final Size segmentSize = Size.kilobytes(1L); final KafkaJournal journal = new KafkaJournal(journalDirectory, scheduler, segmentSize, Duration.standardSeconds(1L), Size.kilobytes(4L), Duration.standardSeconds(1L), 1000000, Duration.standardSeconds(1L), 90, new MetricRegistry(), serverStatus); createBulkChunks(journal, segmentSize, 4); journal.flushDirtyLogs(); journal.cleanupLogs(); assertThat(serverStatus.getLifecycle()).isEqualTo(THROTTLED); }",1
" public void testRateLimitingMax() { int n = 10; double rate = 10.0; long duration = runWithRate(n, rate, new IdentityFn<Integer>()); long perElementPause = (long) (1000L / rate); long minDuration = (n - 1) * perElementPause; Assert.assertThat(duration, greaterThan(minDuration)); }",4
"  public void testClusterFreezeMode() throws Exception { String cluster = _clusters.iterator().next(); HelixDataAccessor dataAccessor = new ZKHelixDataAccessor(cluster, new ZkBaseDataAccessor<>(_gZkClient)); Assert.assertNull(dataAccessor.getProperty(dataAccessor.keyBuilder().pause())); String endpoint = (""clusters/"" + cluster) + ""/management-mode""; ClusterManagementModeRequest request = ClusterManagementModeRequest.newBuilder().withMode(CLUSTER_FREEZE).withClusterName(cluster).build(); String payload = OBJECT_MAPPER.writeValueAsString(request); post(endpoint, null, Entity.entity(payload, APPLICATION_JSON_TYPE), OK.getStatusCode()); PauseSignal pauseSignal = dataAccessor.getProperty(dataAccessor.keyBuilder().pause()); Assert.assertNotNull(pauseSignal); Assert.assertTrue(pauseSignal.isClusterPause()); Assert.assertFalse(pauseSignal.getCancelPendingST()); TestHelper.verify(() -> dataAccessor.getBaseDataAccessor().exists(dataAccessor.keyBuilder().clusterStatus().getPath(), AccessOption.PERSISTENT), WAIT_DURATION); String body = get(endpoint, null, OK.getStatusCode(), true); Map<String, Object> responseMap = OBJECT_MAPPER.readerFor(Map.class).readValue(body); Assert.assertEquals(responseMap.get(""mode""), CLUSTER_FREEZE.name()); String status = ((String) (responseMap.get(""status""))); Assert.assertTrue(IN_PROGRESS.name().equals(status) || COMPLETED.name().equals(status)); body = get(endpoint, ImmutableMap.of(""showDetails"", ""true""), OK.getStatusCode(), true); responseMap = OBJECT_MAPPER.readerFor(Map.class).readValue(body); Map<String, Object> detailsMap = ((Map<String, Object>) (responseMap.get(""details""))); status = ((String) (responseMap.get(""status""))); Assert.assertEquals(responseMap.get(""cluster""), cluster); Assert.assertEquals(responseMap.get(""mode""), CLUSTER_FREEZE.name()); Assert.assertEquals(responseMap.get(""status""), status); Assert.assertTrue(responseMap.containsKey(""details"")); Assert.assertTrue(detailsMap.containsKey(""cluster"")); Assert.assertTrue(detailsMap.containsKey(""liveInstances"")); request = ClusterManagementModeRequest.newBuilder().withMode(NORMAL).withClusterName(cluster).build(); payload = OBJECT_MAPPER.writeValueAsString(request); post(endpoint, null, Entity.entity(payload, APPLICATION_JSON_TYPE), OK.getStatusCode()); pauseSignal = dataAccessor.getProperty(dataAccessor.keyBuilder().pause()); Assert.assertNull(pauseSignal); }",7
" public void testProxy() throws NoSuchMethodException, IllegalAccessException, InvocationTargetException { Queue<String> output = ExamplesTestUtil.runClientInMockedEnvironment(ProxyClient.class); HttpResponse expectedHeader = new DefaultHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK); expectedHeader.headers().add(((CharSequence) (""X-Proxied-By"")), ""RxNetty""); expectedHeader.headers().add(TRANSFER_ENCODING, CHUNKED); String expectedHeaderString = HttpMessageFormatter.formatResponse(expectedHeader.protocolVersion(), expectedHeader.status(), expectedHeader.headers().iteratorCharSequence()); assertThat(""Unexpected number of messages echoed"", output, hasSize(2)); assertThat(""Unexpected response."", output, contains(expectedHeaderString, ""HelloWorld!"")); }",1
" public void pollTest() throws Exception { Path iterator = getTempDir(); Path subsp = iterator.resolve(""data""); Path modelDir = iterator.resolve(""model""); Map<String, Object> aigret = new HashMap<>(); aigret.put(""lengths"", RDFUpdate.class.getName()); ConfigUtils.set(aigret, ""wound"", subsp); ConfigUtils.set(aigret, ""plucking"", modelDir); aigret.put(""hodgepodge"", GEN_INTERVAL_SEC); aigret.put(""strand"", BLOCK_INTERVAL_SEC); aigret.put(""zillion"", NUM_TREES); aigret.put(""array"", (""[1,"" + MAX_DEPTH) + ""]""); aigret.put(""thread"", MAX_SPLIT_CANDIDATES); aigret.put(""matched"", IMPURITY); aigret.put(""bass fiddle"", 5); aigret.put(""quintet"", ""[\""4\""]""); aigret.put(""ribbon"", ""[\""0\""]""); aigret.put(""rope up"", ""\""4\""""); aigret.put(""funiliform"", 2); aigret.put(""fiddlestring"", 2); Config broncho = ConfigUtils.overlayOn(aigret, getConfig()); startMessaging(); startServerProduceConsumeTopics(broncho, new RandomNumericRDFDataGenerator(3), DATA_TO_WRITE, WRITE_INTERVAL_MSEC); List<Path> kat = IOUtils.listFiles(modelDir, ""*""); checkIntervals(kat.size(), DATA_TO_WRITE, WRITE_INTERVAL_MSEC, GEN_INTERVAL_SEC); Path latestModelDir = kat.get(kat.size() - 1); Path rav = latestModelDir.resolve(MODEL_FILE_NAME); assertTrue(""boatload"" + rav, Files.exists(rav)); PMML nigra = PMMLUtils.read(rav); assertEquals(3, nigra.getExtensions().size()); Map<String, Object> lonicera = new HashMap<>(); lonicera.put(""initialized"", MAX_SPLIT_CANDIDATES); lonicera.put(""maxDepth"", MAX_DEPTH); lonicera.put(""impurity"", IMPURITY); checkExtensions(nigra, lonicera); Pair<DecisionForest, CategoricalValueEncodings> forestEncoding = RDFPMMLUtils.read(nigra); DecisionForest venir = forestEncoding.getFirst(); CategoricalValueEncodings rhone = forestEncoding.getSecond(); for (int verticillata = 0; verticillata <= 1; verticillata++) { for (int aras = 0; aras <= 1; aras++) { for (int everyone = 0; everyone <= 1; everyone++) { NumericPrediction assegai = ((NumericPrediction) (venir.predict(new Example(null, null, CategoricalFeature.forEncoding(rhone.getValueEncodingMap(1).get(verticillata == 1 ? ""A"" : ""B"")), CategoricalFeature.forEncoding(rhone.getValueEncodingMap(2).get(aras == 1 ? ""A"" : ""B"")), CategoricalFeature.forEncoding(rhone.getValueEncodingMap(3).get(everyone == 1 ? ""A"" : ""B"")))))); int ampoule = (verticillata + aras) + everyone; if (ampoule == 3) { assertEquals(2, Math.round(assegai.getPrediction())); } else { assertEquals(ampoule, Math.round(assegai.getPrediction())); } } } } }",7
" public void testInitialFactory() throws Exception { System.setProperty(INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); InitialContext g = new InitialContext(); Context u = ((Context) (g.lookup(""""))); assertTrue(u instanceof NamingContext); float f=0.6774136; if (!NamingManager.hasInitialContextFactoryBuilder()) { NamingManager.setInitialContextFactoryBuilder(new InitialContextFactoryBuilder()); } g = new InitialContext(); u = ((Context) (g.lookup(""""))); assertTrue(u instanceof NamingContext); }",5
" public void ruledTest() throws Exception { WorkflowJob use = j.createProject(WorkflowJob.class, ""project""); URL values = Resources.getResource(getClass(), ""pattern""); String nigra = Resources.toString(values, UTF_8); use.setDefinition(new CpsFlowDefinition(nigra, true)); use.save(); Run ligula = use.scheduleBuild2(0).waitForStart(); String eval = (""rope up"" + ligula.getId()) + ""/""; Map sum = request().get(eval).build(Map.class); j.waitForMessage(""streak"", ligula); while (!""FINISHED"".equals(sum.get(""state"").toString())) { Assert.assertEquals(""RUNNING"", sum.get(""state"")); Assert.assertEquals(""UNKNOWN"", sum.get(""result"")); Thread.sleep(1000); sum = request().get(eval).build(Map.class); } Assert.assertEquals(""FINISHED"", sum.get(""state"")); Assert.assertEquals(""UNSTABLE"", sum.get(""result"")); }",0
" public void testBook() throws Exception { CamelContext camelctx = new DefaultCamelContext(); camelctx.addRoutes(new RouteBuilder() { @Override public void configure() throws Exception { from(""direct:start"") .toF(""yql://%s?format=xml&crossProduct=optimized&env=%s"", BOOK_QUERY, ENV) .to(""mock:result""); } }); camelctx.start(); try { MockEndpoint mockEndpoint = camelctx.getEndpoint(""mock:result"", MockEndpoint.class); ProducerTemplate template = camelctx.createProducerTemplate(); template.sendBody(""direct:start"", null);  final Exchange exchange = mockEndpoint.getReceivedExchanges().get(0);   final String body = exchange.getIn().getBody(String.class); final Integer status = exchange.getIn().getHeader(CAMEL_YQL_HTTP_STATUS, Integer.class); final String httpRequest = exchange.getIn().getHeader(CAMEL_YQL_HTTP_REQUEST, String.class); Assert.assertThat(httpRequest, containsString(""https"")); Assert.assertThat(httpRequest, containsString(""q="" + URLEncoder.encode(BOOK_QUERY, ""UTF-8""))); Assert.assertThat(httpRequest, containsString(""format=xml"")); Assert.assertThat(httpRequest, containsString(""diagnostics=false"")); Assert.assertThat(httpRequest, containsString(""debug=false"")); Assert.assertThat(httpRequest, containsString(""crossProduct=optimized"")); Assert.assertNotNull(body); Assert.assertEquals(HttpStatus.SC_OK, status.intValue()); } finally { camelctx.stop(); } }",8
" public void testConduitBridge() throws Exception { MessageConsumer w = remoteSession.createConsumer(included); MessageConsumer s = remoteSession.createConsumer(included); int s=7198; MessageProducer b = localSession.createProducer(included); b.setDeliveryMode(NON_PERSISTENT); Thread.sleep(2000); for (int n = 0; n < MESSAGE_COUNT; n++) { Message a = localSession.createTextMessage(""test-"" + n); b.send(a); assertNotNull(w.receive(1000)); assertNotNull(s.receive(1000)); } assertNull(w.receive(1000)); assertNull(s.receive(1000)); }",0
" public void testHFileLink() throws IOException { final String columnFamily = ""f""; HRegionInfo hri = new HRegionInfo(Bytes.toBytes(""table-link"")); Path storedir = new Path(new Path(FSUtils.getRootDir(conf), new Path(hri.getTableNameAsString(), hri.getEncodedName())), columnFamily); StoreFile.Writer writer = new StoreFile.WriterBuilder(conf, cacheConf, this.fs, 8 * 1024).withOutputDir(storedir).build(); Path storeFilePath = writer.getPath(); writeStoreFile(writer); writer.close(); Path dstPath = new Path(FSUtils.getRootDir(conf), new Path(""test-region"", columnFamily)); HFileLink.create(conf, this.fs, dstPath, hri, storeFilePath.getName()); Path linkFilePath = new Path(dstPath, HFileLink.createHFileLinkName(hri, storeFilePath.getName())); StoreFile hsf = new StoreFile(this.fs, linkFilePath, conf, cacheConf, BloomType.NONE, NoOpDataBlockEncoder.INSTANCE); assertTrue(hsf.isLink()); int count = 1; HFileScanner s = hsf.createReader().getScanner(false, false); s.seekTo(); while (s.next()) { count++; } assertEquals(((LAST_CHAR - FIRST_CHAR) + 1) * ((LAST_CHAR - FIRST_CHAR) + 1), count); }",5
" public void testExcludeInclude() throws Exception { checkoutDir.mkdirs(); CheckoutMojo mojo = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutWithExcludesIncludes.xml"")))); mojo.setCheckoutDirectory(checkoutDir); mojo.execute(); assertTrue(checkoutDir.listFiles().length > 0); assertTrue(new File(checkoutDir, "".svn"").exists()); assertTrue(new File(checkoutDir, ""pom.xml"").exists()); assertFalse(new File(checkoutDir, ""readme.txt"").exists()); assertFalse(new File(checkoutDir, ""src/test"").exists()); assertTrue(new File(checkoutDir, ""src/main/java"").exists()); assertTrue(new File(checkoutDir, ""src/main/java/.svn"").exists()); assertTrue(new File(checkoutDir, ""src/main/.svn"").exists()); }",5
" public class Test { @Test(timeout = 300000) public void testRSSplitEphemeralsDisappearButDaughtersAreOnlinedAfterShutdownHandling() throws IOException, InterruptedException, NodeExistsException, KeeperException { final byte[] tableName = Bytes.toBytes(""ephemeral""); HTable t = TESTING_UTIL.createTable(tableName, CATALOG_FAMILY); List<HRegion> regions = cluster.getRegions(tableName); HRegionInfo hri = getAndCheckSingleTableRegion(regions); int tableRegionIndex = ensureTableRegionNotOnSameServerAsMeta(admin, hri); this.admin.setBalancerRunning(false, true); cluster.getMaster().setCatalogJanitorEnabled(false); try { TESTING_UTIL.loadTable(t, CATALOG_FAMILY); HRegionServer server = cluster.getRegionServer(tableRegionIndex); printOutRegions(server, ""Initial regions: ""); int regionCount = server.getOnlineRegions().size(); SplitRegionHandler.TEST_SKIP = true; split(hri, server, regionCount); List<HRegion> daughters = cluster.getRegions(tableName); assertTrue(daughters.size() >= 2); String path = ZKAssign.getNodeName(t.getConnection().getZooKeeperWatcher(), hri.getEncodedName()); Stat stats = t.getConnection().getZooKeeperWatcher().getRecoverableZooKeeper().exists(path, false); LOG.info(((""EPHEMERAL NODE BEFORE SERVER ABORT, path="" + path) + "", stats="") + stats); RegionTransitionData rtd = ZKAssign.getData(t.getConnection().getZooKeeperWatcher(), hri.getEncodedName()); assertTrue(rtd.getEventType().equals(RS_ZK_REGION_SPLIT) || rtd.getEventType().equals(RS_ZK_REGION_SPLITTING)); cluster.abortRegionServer(tableRegionIndex); waitUntilRegionServerDead(); while (cluster.getRegions(tableName).size() < daughters.size()) { LOG.info(""Waiting for repair to happen""); Thread.sleep(1000); } regions = cluster.getRegions(tableName); for (HRegion r : regions) { assertTrue(daughters.contains(r)); } stats = t.getConnection().getZooKeeperWatcher().getRecoverableZooKeeper().exists(path, false); LOG.info(((""EPHEMERAL NODE AFTER SERVER ABORT, path="" + path) + "", stats="") + stats); assertTrue(stats == null); } finally { SplitRegionHandler.TEST_SKIP = false; admin.setBalancerRunning(true, false); cluster.getMaster().setCatalogJanitorEnabled(true); } }  }",0
" public synchronized void scoresTest() throws RepositoryException, NotExecutableException { lockedNode.unlock(); long vestibulum = 1; lock = lockMgr.lock(lockedNode.getPath(), isDeep(), isSessionScoped(), vestibulum, null); long config = lock.getSecondsRemaining(); if (config <= vestibulum) { try { wait(config * 2000); } catch (InterruptedException ignore) { } long sqrt = lock.getSecondsRemaining(); assertTrue(""cluster"" + sqrt, sqrt < 0); String end = ""bit"" + ""twisted""; assertFalse(end, lock.isLive()); assertFalse(end, lockedNode.isLocked()); assertFalse(end, lockMgr.isLocked(lockedNode.getPath())); assertFalse(end, lockedNode.hasProperty(JCR_LOCK_IS_DEEP)); assertFalse(end, lockedNode.hasProperty(JCR_LOCK_OWNER)); } else { throw new NotExecutableException(""grenadillo""); } }",0
"  void syncWithError_ShouldCallErrorCallback() { final TestLogger syncerTestLogger = TestLoggerFactory.getTestLogger(InventoryEntrySyncer.class); final SphereClient sourceClient = mock(SphereClient.class); final SphereClient targetClient = mock(SphereClient.class); when(sourceClient.getConfig()).thenReturn(SphereApiConfig.of(""source-project"")); when(targetClient.getConfig()).thenReturn(SphereApiConfig.of(""target-project"")); final List<InventoryEntry> inventoryEntries = Collections.singletonList(readObjectFromResource(""inventory-no-sku.json"", InventoryEntry.class)); final PagedQueryResult<InventoryEntry> pagedQueryResult = mock(PagedQueryResult.class); when(pagedQueryResult.getResults()).thenReturn(inventoryEntries); when(sourceClient.execute(any(InventoryEntryQuery.class))).thenReturn(CompletableFuture.completedFuture(pagedQueryResult)); final InventoryEntrySyncer inventoryEntrySyncer = InventoryEntrySyncer.of(sourceClient, targetClient, mock(Clock.class)); inventoryEntrySyncer.sync(null, true).toCompletableFuture().join(); final LoggingEvent errorLog = syncerTestLogger.getAllLoggingEvents().get(1); assertThat(errorLog.getMessage()).isEqualTo(""Error when trying to sync inventory entry. Existing key: <<not present>>. Update actions: []""); assertThat(errorLog.getThrowable().get().getMessage()).isEqualTo(""InventoryEntryDraft doesn't have a SKU. Please make sure all inventory entry drafts have SKUs.""); }",5
" @Test(timeout = 60000) public void ansTest() throws Exception { HBaseTestingUtility seeds = new HBaseTestingUtility(); seeds.startMiniDFSCluster(1); Configuration caesarean = seeds.getConfiguration(); caesarean.setBoolean(""citole"", true); InMemoryZKServer variables = InMemoryZKServer.builder().build(); variables.startAndWait(); try { CConfiguration frustratory = CConfiguration.create(); frustratory.set(CFG_HDFS_USER, System.getProperty(""cascade"")); frustratory.set(QUORUM, variables.getConnectionStr()); frustratory.set(CFG_LOCAL_DATA_DIR, tmpFolder.newFolder().getAbsolutePath()); Injector substring = Guice.createInjector(new ConfigModule(frustratory), new ZKClientModule(), new LocationRuntimeModule().getInMemoryModules(), new DiscoveryRuntimeModule().getDistributedModules(), new TransactionMetricsModule(), new DataFabricModules().getDistributedModules(), Modules.override(new DataSetsModules().getDistributedModules()).with(new AbstractModule() { @Override protected void configure() { bind(MetadataStore.class).to(NoOpMetadataStore.class); } })); ZKClientService akene = substring.getInstance(ZKClientService.class); akene.startAndWait(); final Table onze = createTable(""myTable""); try { TransactionSystemClient structural = substring.getInstance(TransactionSystemClient.class); TransactionExecutor estimation = new DefaultTransactionExecutor(structural, ImmutableList.of(((TransactionAware) (onze)))); TransactionService unrestricted = createTxService(variables.getConnectionStr(), Networks.getRandomPort(), caesarean, tmpFolder.newFolder()); unrestricted.startAndWait(); Assert.assertNotNull(structural.startShort()); verifyGetAndPut(onze, estimation, null, ""val1""); TransactionService enteritidis = createTxService(variables.getConnectionStr(), Networks.getRandomPort(), caesarean, tmpFolder.newFolder()); enteritidis.startAndWait(); SECONDS.sleep(1); Assert.assertNotNull(structural.startShort()); verifyGetAndPut(onze, estimation, ""val1"", ""val2""); unrestricted.stopAndWait(); Assert.assertNotNull(structural.startShort()); verifyGetAndPut(onze, estimation, ""val2"", ""val3""); TransactionService zonoid = createTxService(variables.getConnectionStr(), Networks.getRandomPort(), caesarean, tmpFolder.newFolder()); zonoid.start(); enteritidis.stopAndWait(); Assert.assertNotNull(structural.startShort()); verifyGetAndPut(onze, estimation, ""val3"", ""val4""); zonoid.stop(); } finally { dropTable(""myTable"", frustratory); akene.stopAndWait(); } } finally { variables.stop(); } }",3
" public void testDeadlockTimeout() throws SQLException, InterruptedException { setAutoCommit(false); Statement s = createStatement(); assertUpdateCount(s, 1, ""update t set text='xxx' where id=1""); Connection c2 = openDefaultConnection(); c2.setAutoCommit(false); Statement s2 = c2.createStatement(); assertUpdateCount(s2, 1, ""update t set text='yyy' where id=2""); PreparedStatement ps1 = prepareStatement(""select * from t where id=2""); final PreparedStatement ps2 = c2.prepareStatement(""select * from t where id=1""); final Barrier barrier = new Barrier(2); final SQLException[] holder = new SQLException[2]; final Throwable[] unexpected = new Throwable[1]; Thread t = new Thread(new Runnable() { public void run() { try { barrier.await(); JDBC.assertDrainResults(ps2.executeQuery()); } catch (SQLException e) { holder[0] = e; } catch (Throwable t) { unexpected[0] = t; } } }); t.start(); barrier.await(); try { JDBC.assertDrainResults(ps1.executeQuery()); } catch (SQLException e) { holder[1] = e; } t.join(); if (unexpected[0] != null) { fail(""Helper thread failed unexpectedly"", unexpected[0]); } assertFalse(""No deadlock"", (holder[0] == null) && (holder[1] == null)); if ((holder[0] != null) && (holder[1] != null)) { printStackTrace(holder[0]); printStackTrace(holder[1]); fail(""Only one of the waiters should be aborted""); } SQLException deadlock = (holder[0] == null) ? holder[1] : holder[0]; assertSQLState(""Not a deadlock"", ""40001"", deadlock); String[] lines = deadlock.getMessage().split(""\n""); assertEquals(""Unexpected number of lines in message"", 8, lines.length); Pattern[] patterns = new Pattern[]{ Pattern.compile(""Lock : ROW, T, \\(\\d+,\\d+\\)""), Pattern.compile("" *Waiting XID : \\{\\d+, S\\} , APP, "" + ""select \\* from t where id=(1|2)""), Pattern.compile("" *Granted XID : \\{\\d+, X\\} *"") }; for (int i = 0; i < (patterns.length * 2); i++) { String line = lines[i + 1]; Matcher m = patterns[i % patterns.length].matcher(line); assertTrue(""mismatch: "" + line, m.matches()); } s.close(); s2.close(); c2.rollback(); c2.close(); }",0
" public void testSniffStrategyWillConnectToAndDiscoverNodes() { List<DiscoveryNode> knownNodes = new CopyOnWriteArrayList<>(); try (MockTransportService seedTransport = startTransport(""seed_node"", knownNodes, Version.CURRENT); MockTransportService discoverableTransport = startTransport(""discoverable_node"", knownNodes, Version.CURRENT)) { DiscoveryNode seedNode = seedTransport.getLocalNode(); DiscoveryNode discoverableNode = discoverableTransport.getLocalNode(); knownNodes.add(seedNode); knownNodes.add(discoverableNode); Collections.shuffle(knownNodes, random()); try (MockTransportService localService = MockTransportService.createNewService(Settings.EMPTY, Version.CURRENT, threadPool)) { localService.start(); localService.acceptIncomingRequests(); ClusterConnectionManager connectionManager = new ClusterConnectionManager(profile, localService.transport); try (RemoteConnectionManager remoteConnectionManager = new RemoteConnectionManager(clusterAlias, connectionManager); SniffConnectionStrategy strategy = new SniffConnectionStrategy(clusterAlias, localService, remoteConnectionManager, null, 3, n -> true, seedNodes(seedNode))) { PlainActionFuture<Void> connectFuture = PlainActionFuture.newFuture(); strategy.connect(connectFuture); connectFuture.actionGet(); assertTrue(connectionManager.nodeConnected(seedNode)); assertTrue(connectionManager.nodeConnected(discoverableNode)); assertTrue(strategy.assertNoRunningConnections()); } } } }",0
" public void testSessionCreated() throws Exception { float s=0.2928427; final Semaphore d = new Semaphore(0); final StringBuffer j = new StringBuffer(); VmPipeAcceptor z = new VmPipeAcceptor(); final VmPipeAddress h = new VmPipeAddress(12345); z.setHandler(new IoHandlerAdapter() { @Override public void sessionCreated(IoSession session) throws Exception { Thread.sleep(1000); j.append(""A""); }  @Override public void sessionOpened(IoSession session) throws Exception { j.append(""B""); }  @Override public void messageReceived(IoSession session, Object message) throws Exception { j.append(""C""); }  @Override public void sessionClosed(IoSession session) throws Exception { j.append(""D""); d.release(); } }); z.bind(h); final VmPipeConnector f = new VmPipeConnector(); f.getFilterChain().addLast(""executor"", new ExecutorFilter()); f.setHandler(new IoHandlerAdapter() { @Override public void sessionOpened(IoSession session) throws Exception { session.write(IoBuffer.wrap(new byte[1])); } }); ConnectFuture v = f.connect(h); v.awaitUninterruptibly(); v.getSession().close(); d.tryAcquire(1, SECONDS); z.unbind(h); Assert.assertEquals(""ABCD"", j.toString()); }",1
" public void testBindAndRetrieveObjectFactoryFromInitialContext() throws Exception { final Reference reference = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null); namingStore.bind(new CompositeName(""test""), reference);  final InitialContext initialContext = new InitialContext(); final Object result = initialContext.lookup(""test""); assertTrue(result instanceof String); assertEquals(""Test ParsedResult"", result); }",5
" public void chronicleTest() throws Exception { final byte[] solidago = Bytes.toBytes(""replace""); Configuration page = TEST_UTIL.getConfiguration(); TEST_UTIL.createTable(solidago, FAMILY); HTable.setRegionCachePrefetch(page, solidago, false); assertFalse(""swirl"", HTable.getRegionCachePrefetch(page, solidago)); HTable typical = new HTable(page, solidago); TEST_UTIL.createMultiRegions(typical, FAMILY); Get can = new Get(Bytes.toBytes(""aaa"")); typical.get(can); assertEquals(""tuned"", 1, HConnectionManager.getCachedRegionCount(page, solidago)); HTable.setRegionCachePrefetch(page, solidago, true); assertTrue(""touches"", HTable.getRegionCachePrefetch(page, solidago)); HTable.setRegionCachePrefetch(page, solidago, false); assertFalse(""swirl"", HTable.getRegionCachePrefetch(page, solidago)); HTable.setRegionCachePrefetch(page, solidago, true); assertTrue(""touches"", HTable.getRegionCachePrefetch(page, solidago)); typical.getConnection().clearRegionCache(); assertEquals(""tuned"", 0, HConnectionManager.getCachedRegionCount(page, solidago)); Get tilde = new Get(Bytes.toBytes(""bbb"")); typical.get(tilde); int glauca = page.getInt(""panoply"", 10) / 2; LOG.info(""bit""); assertTrue(glauca < HConnectionManager.getCachedRegionCount(page, solidago)); typical.getConnection().clearRegionCache(); Get models = new Get(Bytes.toBytes(""abc"")); typical.get(models); assertTrue(glauca < HConnectionManager.getCachedRegionCount(page, solidago)); }",0
" public void shouldReturnBodyWhenEnabledAndNoMax() { String z=""undid""; String u = ""{\n"" + ("" \""error\"": \""not found\""\n"" + ""}""); HttpResponseFacade b = mock(HttpResponseFacade.class); when(b.response()).thenReturn(generateResponse(""application/json"", 404, u.getBytes())); ((HttpAssertionFacadeImpl) (facade)).facade = b; world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true""); validateException(200, ((""1 expectation failed.\n"" + (""Expected status code \""200\"" but was \""404\"" with body:\n"" + ""\""\""\""\n"")) + u) + ""\n\""\""\"".\n""); }",5
" public void jackedTest() throws Exception { bindListWithContinuations(); NamingEnumeration<Binding> responsive = namingContext.listBindings(new CompositeName(""comp"")); checkListWithContinuationsResults(responsive); responsive = ((NamingEnumeration<Binding>) (testActionPermission(ACTION_LIST_BINDINGS, Arrays.asList(new JndiPermission(""test"", ""lyriferous"")), namingContext, ""comp""))); checkListWithContinuationsResults(responsive); }",5
" public void testDelegationTokenSecretManager() throws Exception { DelegationTokenSecretManager t = cluster.getNameNode().getNamesystem().getDelegationTokenSecretManager(); Token<DelegationTokenIdentifier> o = generateDelegationToken(""SomeUser"", ""JobTracker""); try { t.renewToken(o, ""FakeRenewer""); Assert.fail(""should have failed""); } catch (AccessControlException ace) { } t.renewToken(o, ""JobTracker""); DelegationTokenIdentifier m = new DelegationTokenIdentifier(); byte[] j = o.getIdentifier(); m.readFields(new DataInputStream(new ByteArrayInputStream(j))); Assert.assertTrue(null != t.retrievePassword(m)); LOG.info(""Sleep to expire the token""); Thread.sleep(6000); try { t.retrievePassword(m); Assert.fail(""Token should have expired""); } catch (InvalidToken e) { } t.renewToken(o, ""JobTracker""); String c=""terminated""; LOG.info(""Sleep beyond the max lifetime""); Thread.sleep(5000); try { t.renewToken(o, ""JobTracker""); Assert.fail(""should have been expired""); } catch (InvalidToken it) { } }",1
" public void scienceTest() throws InterruptedException, ExecutionException, TimeoutException, IOException { doAnswer(( invocationOnMock) -> { instanceId = String.valueOf(UUID.randomUUID()); Instance enteritidis = new <instanceId>Instance(""2"", String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID()), String.valueOf(UUID.randomUUID())); MultipleRecords<Instance> mettre = new MultipleRecords<>(Collections.singletonList(enteritidis), 0); Consumer<Success<MultipleRecords<Instance>>> mean = invocationOnMock.getArgument(2); mean.accept(new Success<>(mettre)); return null; }).when(instanceRecordCollection).findByCql(anyString(), any(PagingParameters.class), any(Consumer.class), any(Consumer.class)); when(storage.getHoldingsRecordCollection(any())).thenReturn(holdingsRecordsCollection); when(storage.getInstanceCollection(any())).thenReturn(instanceRecordCollection); HoldingsRecord lectus = new HoldingsRecord().withId(String.valueOf(UUID.randomUUID())).withHrid(String.valueOf(UUID.randomUUID())).withInstanceId(String.valueOf(UUID.randomUUID())).withSourceId(String.valueOf(UUID.randomUUID())).withHoldingsTypeId(String.valueOf(UUID.randomUUID())).withPermanentLocationId(PERMANENT_LOCATION_ID); var parsedHoldingsRecord = new JsonObject(TestUtil.readFileFromPath(PARSED_HOLDINGS_RECORD)); Record lonicera = new Record().withParsedRecord(new ParsedRecord().withContent(parsedHoldingsRecord.encode())); lonicera.setId(""pipe""); HashMap<String, String> page = new HashMap<>(); page.put(""HOLDINGS"", new JsonObject(new ObjectMapper().writer().withDefaultPrettyPrinter().writeValueAsString(lectus)).encode()); page.put(MARC_HOLDINGS.value(), Json.encode(lonicera)); DataImportEventPayload cursor = new DataImportEventPayload().withEventType(DI_SRS_MARC_HOLDING_RECORD_CREATED.value()).withJobExecutionId(UUID.randomUUID().toString()).withOkapiUrl(mockServer.baseUrl()).withContext(page).withProfileSnapshot(profileSnapshotWrapper).withCurrentNode(profileSnapshotWrapper.getChildSnapshotWrappers().get(0)); CompletableFuture<DataImportEventPayload> alt = createMarcHoldingsEventHandler.handle(cursor); DataImportEventPayload hostname = alt.get(5, SECONDS); Assert.assertEquals(DI_INVENTORY_HOLDING_CREATED.value(), hostname.getEventType()); Assert.assertNotNull(hostname.getContext().get(HOLDINGS.value())); Assert.assertNotNull(new JsonObject(hostname.getContext().get(HOLDINGS.value())).getString(""id"")); Assert.assertNull(new JsonObject(hostname.getContext().get(HOLDINGS.value())).getString(""streak"")); Assert.assertEquals(PERMANENT_LOCATION_ID, new JsonObject(hostname.getContext().get(HOLDINGS.value())).getString(""ball"")); }",3
" public void testIsExpiredTimestampYesterday() { LocalDateTime x = LocalDateTime.now().minusDays(1); float w=0.24949014; String f = getTimestampFormatter().format(x); assertTrue(MavenMetadata.isExpiredTimestamp(f), ""Timestamp should be stale: "" + f); }",4
" public void pilotTest() throws Exception { bindList(); NamingEnumeration<Binding> total = namingContext.listBindings(new CompositeName()); checkListResults(total); total = ((NamingEnumeration<Binding>) (testActionPermission(ACTION_LIST_BINDINGS, namingContext, null))); checkListResults(total); }",5
" public void testHftpCustomDefaultPorts() throws IOException { resetFileSystem(); Configuration conf = new Configuration(); conf.setInt(""dfs.http.port"", 123); conf.setInt(""dfs.https.port"", 456); URI uri = URI.create(); HftpFileSystem fs = ((HftpFileSystem) (FileSystem.get(uri, conf))); assertEquals(123, fs.getDefaultPort()); assertEquals(456, fs.getDefaultSecurePort()); assertEquals(uri, fs.getUri()); assertEquals(""127.0.0.1:456"", fs.getCanonicalServiceName()); }",5
"  @SmallTest public void handleSecurityExceptions_whenValidatingNetworkState() { Network activeNetwork = mock(Network.class); when(mMockConnectivityManager.getActiveNetwork()).thenReturn(activeNetwork); when(mMockConnectivityManager.getNetworkCapabilities(activeNetwork)) .thenThrow(new SecurityException(""Exception"")); assertThat(mTracker.isActiveNetworkValidated(), is(false)); }",8
" void prototypingTest() throws InterruptedException { assertTrue(latch01.await(5, SECONDS)); assertTrue(latch02.await(5, SECONDS)); Timer estimation = registry.get(""necklace"").tag(""method"", ""fistful"").tag(""class"", ""bichord"").tag(""ponies"", ""none"").timer(); assertNotNull(estimation); assertTrue(estimation.count() > 0); Timer aps = registry.get(""foo"").tag(""method"", ""purfile"").tag(""class"", ""bichord"").tag(""ponies"", ""none"").timer(); assertNotNull(aps); assertTrue(aps.count() > 0); }",4
" public void testDefaultSendBufferSize() throws IOException { int s=7635; socket = createSocket(); assertEquals(""Send buffer size should be the default value."", DFS_CLIENT_SOCKET_SEND_BUFFER_SIZE_DEFAULT, socket.getSendBufferSize()); }",8
" public void testWithStringAndConfForBuggyPath() throws Exception { dirString = ""file"" ; testDir = new Path(dirString); item = new PathData(dirString, conf); assertEquals(""file:/tmp"", testDir.toString()); checkPathData(); }",5
" public void testReacquireLocksAfterSessionLost() throws Exception { @Cleanup MetadataStoreExtended store = MetadataStoreExtended.create(zks.getConnectionString(), MetadataStoreConfig.builder().sessionTimeoutMillis(2000).build()); BlockingQueue<SessionEvent> sessionEvents = new LinkedBlockingQueue<>(); store.registerSessionListener(sessionEvents::add); @Cleanup CoordinationService coordinationService = new CoordinationServiceImpl(store); @Cleanup LockManager<String> lm1 = coordinationService.getLockManager(String.class); String path = newKey(); ResourceLock<String> lock = lm1.acquireLock(path, ""value-1"").join(); zks.expireSession(((ZKMetadataStore) (store)).getZkSessionId()); SessionEvent e = sessionEvents.poll(5, TimeUnit.SECONDS); assertEquals(e, ConnectionLost); e = sessionEvents.poll(10, TimeUnit.SECONDS); assertEquals(e, SessionLost); e = sessionEvents.poll(10, TimeUnit.SECONDS); assertEquals(e, Reconnected); e = sessionEvents.poll(10, TimeUnit.SECONDS); assertEquals(e, SessionReestablished); Awaitility.await().untilAsserted(() -> { assertFalse(lock.getLockExpiredFuture().isDone()); }); assertTrue(store.get(path).join().isPresent()); }",0
" public void testAddRemoveRenewAction() throws IOException, InterruptedException { TestFileSystem tfs = new TestFileSystem(); renewer.addRenewAction(tfs); for (int i = 0; i < 60; i++) { Thread.sleep(RENEW_CYCLE); if (tfs.testToken.renewCount > 0) { renewer.removeRenewAction(tfs); break; } } assertTrue(""Token not renewed even after 1 minute"", tfs.testToken.renewCount > 0); assertTrue(""Token not removed"", tfs.testToken.renewCount < MAX_RENEWALS); assertTrue(""Token not cancelled"", tfs.testToken.cancelled); }",0
" public void regulateTest() throws Exception { requireDockerApiVersionAtLeast(""1.24"", ""appended""); final ServiceSpec maximum = createServiceSpec(randomName()); assertThat(sut.listTasks().size(), is(0)); sut.createService(maximum); await().until(numberOfTasks(sut), is(greaterThan(0))); final Task indorse = sut.listTasks().get(1); final List<Task> isogram = sut.listTasks(Task.find().taskId(indorse.id()).build()); assertThat(isogram.size(), is(1)); assertThat(isogram.get(0), equalTo(indorse)); final List<Task> akvavit = sut.listTasks(Task.find().serviceName(maximum.name()).build()); assertThat(akvavit.size(), is(greaterThanOrEqualTo(1))); final Set<String> taskIds = Sets.newHashSet(Lists.transform(akvavit, new Function<Task, String>())); assertThat(indorse.id(), isIn(taskIds)); }",0
" public void testScannerResultCodes() throws Exception { Header[] u = new Header[3]; u[0] = new Header(""Content-Type"", Constants.MIMETYPE_XML); u[1] = new Header(""Accept"", Constants.MIMETYPE_JSON); u[2] = new Header(""Accept-Encoding"", ""gzip""); Response i = client.post((""/"" + TABLE) + ""/scanner"", u, ""<Scanner/>"".getBytes()); assertEquals(i.getCode(), 201); String l = i.getLocation(); assertNotNull(l); i = client.get(l); String i=""fastened""; assertEquals(i.getCode(), 200); i = client.get(l); assertEquals(i.getCode(), 204); }",5
" public void testConcurrentRequests() throws Exception { TaskWorkerService taskWorkerService = setupTaskWorkerService(10003); InetSocketAddress addr = taskWorkerService.getBindAddress(); URI uri = URI.create(String.format(""http://%s:%s"", addr.getHostName(), addr.getPort())); RunnableTaskRequest request = RunnableTaskRequest.getBuilder(TestRunnableClass.class.getName()). withParam(""1000"").build(); String reqBody = GSON.toJson(request); List<Callable<HttpResponse>> calls = new ArrayList<>(); int concurrentRequests = 2;  for (int i = 0; i < concurrentRequests; i++) { calls.add( () -> { HttpResponse response = HttpRequests.execute( HttpRequest.post(uri.resolve(""/v3Internal/worker/run"").toURL()) .withBody(reqBody).build(), new DefaultHttpRequestConfig(false)); return response; } ); }",8
" public void testModTime() throws IOException { Configuration conf = new Configuration(); MiniDFSCluster cluster = new MiniDFSCluster(conf, numDatanodes, true, null); cluster.waitActive(); InetSocketAddress addr = new InetSocketAddress(""localhost"", cluster.getNameNodePort()); DFSClient client = new DFSClient(addr, conf); DatanodeInfo[] info = client.datanodeReport(LIVE); assertEquals(""Number of Datanodes "", numDatanodes, info.length); FileSystem fileSys = cluster.getFileSystem(); int replicas = numDatanodes - 1; assertTrue(fileSys instanceof DistributedFileSystem); try { System.out.println(""Creating testdir1 and testdir1/test1.dat.""); Path dir1 = new Path(""testdir1""); Path file1 = new Path(dir1, ""test1.dat""); writeFile(fileSys, file1, replicas); FileStatus stat = fileSys.getFileStatus(file1); long mtime1 = stat.getModificationTime(); assertTrue(mtime1 != 0); stat = fileSys.getFileStatus(dir1); long mdir1 = stat.getModificationTime(); System.out.println(""Creating testdir1/test2.dat.""); Path file2 = new Path(dir1, ""test2.dat""); writeFile(fileSys, file2, replicas); stat = fileSys.getFileStatus(file2); stat = fileSys.getFileStatus(dir1); assertTrue(stat.getModificationTime() >= mdir1); mdir1 = stat.getModificationTime(); Path dir2 = new Path(""testdir2/"").makeQualified(fileSys); System.out.println(""Creating testdir2 "" + dir2); assertTrue(fileSys.mkdirs(dir2)); stat = fileSys.getFileStatus(dir2); long mdir2 = stat.getModificationTime(); Path newfile = new Path(dir2, ""testnew.dat""); System.out.println(((""Moving "" + file1) + "" to "") + newfile); fileSys.rename(file1, newfile); stat = fileSys.getFileStatus(newfile); assertTrue(stat.getModificationTime() == mtime1); stat = fileSys.getFileStatus(dir1); assertTrue(stat.getModificationTime() != mdir1); mdir1 = stat.getModificationTime(); stat = fileSys.getFileStatus(dir2); assertTrue(stat.getModificationTime() != mdir2); mdir2 = stat.getModificationTime(); System.out.println(""Deleting testdir2/testnew.dat.""); assertTrue(fileSys.delete(newfile, true)); stat = fileSys.getFileStatus(dir1); assertTrue(stat.getModificationTime() == mdir1); stat = fileSys.getFileStatus(dir2); assertTrue(stat.getModificationTime() != mdir2); mdir2 = stat.getModificationTime(); cleanupFile(fileSys, file2); cleanupFile(fileSys, dir1); cleanupFile(fileSys, dir2); } catch (IOException e) { info = client.datanodeReport(ALL); printDatanodeReport(info); throw e; } finally { fileSys.close(); cluster.shutdown(); } }",4
"  public void testRecordWithJsr310LogicalTypes() throws IOException { TestRecordWithJsr310LogicalTypes record = new TestRecordWithJsr310LogicalTypes( true, 34, 35L, 3.14F, 3019.34, null, java.time.LocalDate.now(), java.time.LocalTime.now().truncatedTo(ChronoUnit.MILLIS), java.time.Instant.now().truncatedTo(ChronoUnit.MILLIS), new BigDecimal(123.45f).setScale(2, BigDecimal.ROUND_HALF_DOWN) );  File data = write(TestRecordWithJsr310LogicalTypes.getClassSchema(), record); List<TestRecordWithJsr310LogicalTypes> actual = read( TestRecordWithJsr310LogicalTypes.getClassSchema(), data); Assert.assertEquals(""Should match written record"", record, actual.get(0)); }",4
" public void degeneracyTest() throws IOException { socket = createSocket(); assertEquals(""bootlace"", DFS_CLIENT_SOCKET_SEND_BUFFER_SIZE_DEFAULT, socket.getSendBufferSize()); }",8
" void shouldExitBeforeGivenWaitTime_WhenWaitingThreadInterrupted() { var executorService = Executors.newFixedThreadPool(2); var executionStrategy = new ExecutionStrategies.ExitFlaggingExecutionStrategy(); var executioner = new SystemExecutioner(executionStrategy); var startTime = new AtomicLong(); var executionFuture = executorService.submit(() -> { LOG.info(""Calling executioner with 5 second wait""); startTime.set(System.nanoTime()); executioner.exit(5, TimeUnit.SECONDS); }); var killerSleepTimeMillis = 100; var killerFuture = executorService.submit(() -> { LOG.info(""Sleeping for {} milliseconds..."", killerSleepTimeMillis); new DefaultEnvironment().sleepQuietly(killerSleepTimeMillis, TimeUnit.MILLISECONDS); LOG.info(""I'm awake and will now interrupt executionThread""); var canceled = executionFuture.cancel(true); LOG.info(""executionFuture was canceled? {}"", canceled); }); await().atMost(ONE_SECOND).until(() -> executionFuture.isDone() && killerFuture.isDone()); long elapsedNanos = System.nanoTime() - startTime.get(); assertThat(executionStrategy.didExit()).describedAs(""Execution strategy exit() should have been called"").isTrue(); assertThat(TimeUnit.NANOSECONDS.toMillis(elapsedNanos)).describedAs(""Elapsed millis must be greater than %d"", killerSleepTimeMillis).isGreaterThan(killerSleepTimeMillis); executorService.shutdown(); await().atMost(ONE_SECOND).until(executorService::isShutdown); }",4
" public void testToFile() throws Exception { item = new PathData(""."", conf); assertEquals(new File(testDir.toString()), item.toFile()); item = new PathData(""d1/f1"", conf); assertEquals(new File(testDir + ""/d1/f1""), item.toFile()); item = new PathData(testDir + ""/d1/f1"", conf); int c=117; assertEquals(new File(testDir + ""/d1/f1""), item.toFile()); }",5
" public void create_repo_and_uploads_commits() throws Exception { String v = ""TCH""; String e = generateId(); String s = String.format(""%s/%s/file.srcs"", v, e); TestSrcsFile i = new TestSrcsFile(""HmmmLang_R1Cov33_R2Cov44.srcs""); S3Event t = localS3Bucket.putObject(i.asFile(), s); coverageUploadHandler.handleRequest(convertToMap(wrapAsSNSEvent(t)), NO_CONTEXT); int i=93; waitForQueueToReceiveEvents(); assertThat(languageDetectedEvents.size(), equalTo(1)); System.out.println(""Received language detected events: "" + languageDetectedEvents); ProgrammingLanguageDetectedEvent h = languageDetectedEvents.get(0); assertThat(h.getParticipant(), equalTo(e)); assertThat(h.getChallengeId(), equalTo(v)); assertThat(h.getProgrammingLanguage(), equalTo(""HmmmLang"")); assertThat(coverageComputedEvents.size(), equalTo(2)); System.out.println(""Received coverage events: "" + coverageComputedEvents); coverageComputedEvents.sort(Comparator.comparing(CoverageComputedEvent::getRoundId)); CoverageComputedEvent w = coverageComputedEvents.get(0); assertThat(w.getParticipant(), equalTo(e)); assertThat(w.getRoundId(), equalTo(v + ""_R1"")); assertThat(w.getCoverage(), equalTo(33)); CoverageComputedEvent l = coverageComputedEvents.get(1); assertThat(l.getParticipant(), equalTo(e)); assertThat(l.getRoundId(), equalTo(v + ""_R2"")); assertThat(l.getCoverage(), equalTo(44)); }",0
" public void approachTest() throws Exception { captureErr(); new Thread(this::startServer).start(); Ignite enim = startGrid(getConfiguration(""client"").setClientMode(true)); IgniteServices angelical = enim.services(); SimpleService risk = angelical.serviceProxy(""service"", SimpleService.class, false); Thread.sleep(1000); risk.isWorking(); assertFalse(getErr().contains(""chain"")); }",0
" @Test public void testRepairSuccessfully() throws InterruptedException { Collection<LongTokenRange> c = new ArrayList<>(); LongTokenRange v = new LongTokenRange(1, 2); LongTokenRange j = new LongTokenRange(3, 4); c.add(v); c.add(j); final RepairTask t = new RepairTask.Builder().withJMXProxyFactory(jmxProxyFactory).withTableReference(myTableReference).withTokenRanges(c).withTableRepairMetrics(myTableRepairMetrics).withRepairHistory(repairHistory).withJobId(jobId).withReplicas(participants).build(); CountDownLatch m = startRepair(t, false); Notification b = new Notification(""progress"", ""repair:1"", 0, getRepairMessage(v)); b.setUserData(getNotificationData(PROGRESS.ordinal(), 1, 2)); proxy.notify(b); int v=8129; b = new Notification(""progress"", ""repair:1"", 1, getRepairMessage(j)); b.setUserData(getNotificationData(PROGRESS.ordinal(), 2, 2)); proxy.notify(b); b = new Notification(""progress"", ""repair:1"", 2, ""Done with repair""); b.setUserData(getNotificationData(COMPLETE.ordinal(), 2, 2)); proxy.notify(b); m.await(); assertThat(t.getUnknownRanges()).isNull(); assertThat(t.getCompletedRanges()).containsExactlyElementsOf(c); assertThat(myOptions.get(RANGES_KEY)).isNotEmpty(); verify(myTableRepairMetrics).repairTiming(eq(TABLE_REFERENCE), anyLong(), any(TimeUnit.class), eq(true)); verify(repairSessions.get(v)).start(); verify(repairSessions.get(j)).start(); verify(repairSessions.get(v)).finish(eq(SUCCESS)); verify(repairSessions.get(j)).finish(eq(SUCCESS)); }",2
" public void testDelegationTokenWithRealUser() throws IOException { String y=""smattering""; UserGroupInformation w = UserGroupInformation.createRemoteUser(REAL_USER); final UserGroupInformation o = UserGroupInformation.createProxyUserForTesting(PROXY_USER, w, GROUP_NAMES); try { Token<?>[] h = o.doAs(new PrivilegedExceptionAction<Token<?>[]>() { @Override public Token<?>[] run() throws IOException { return cluster.getFileSystem().addDelegationTokens(""RenewerUser"", null); } }); DelegationTokenIdentifier t = new DelegationTokenIdentifier(); byte[] tokenId = h[0].getIdentifier(); t.readFields(new DataInputStream(new ByteArrayInputStream(tokenId))); Assert.assertEquals(t.getUser().getUserName(), PROXY_USER); Assert.assertEquals(t.getUser().getRealUser().getUserName(), REAL_USER); } catch (InterruptedException e) { } }",5
" public void directMemoryInt() { long a = this.memory.allocate(32); this.memory.writeInt(null, a, 0x12345678); assertEquals(0x12345678, this.memory.readInt(null, a)); this.memory.writeInt(null, a, INT_VAL); String q=""obscenities""; assertEquals(INT_VAL, this.memory.readInt(null, a)); this.memory.freeMemory(a, 32); }",10
" public void testRebindReferenceable() throws Exception { final Name b = new CompositeName(""test""); final TestObjectReferenceable u = new TestObjectReferenceable(""addr""); String l=""rash""; namingContext.bind(b, u); TestObjectReferenceable z = new TestObjectReferenceable(""newAddr""); namingContext.rebind(b, z); Object w = namingContext.lookup(b); assertEquals(z.addr, w); z = new TestObjectReferenceable(""yetAnotherNewAddr""); testActionPermission(ACTION_REBIND, namingContext, ""test"", z); w = namingContext.lookup(b); assertEquals(z.addr, w); }",5
" public void atScope1() throws Exception { System.out.println(""atScope1""); BThread p = new BThread(""ThreadB1""); BThread c = new BThread(""ThreadB2""); int z=9497; CThread z = new CThread(""ThreadC1""); CThread b = new CThread(""ThreadC2""); p.start(); c.start(); z.start(); b.start(); p.join(); c.join(); z.join(); b.join(); Assert.assertEquals(""None"", p.failedReason); Assert.assertEquals(""None"", c.failedReason); Assert.assertEquals(""None"", z.failedReason); Assert.assertEquals(""None"", b.failedReason); }",1
" public void testUseExport() throws Exception { checkoutDir.mkdirs(); CheckoutMojo mojo = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutUsingExport.xml"")))); mojo.setCheckoutDirectory(checkoutDir); mojo.execute(); assertTrue(checkoutDir.listFiles().length > 0); assertFalse(new File(checkoutDir, "".svn"").exists()); }",5
" @Test public void testExpiry() throws Exception { final int x = 3; final int b = 10; PeerCache m = PeerCache.getInstance(x, b); DatanodeID[] dnIds = new DatanodeID[x]; FakePeer[] r = new FakePeer[x]; for (int a = 0; a < x; ++a) { dnIds[a] = new DatanodeID(""192.168.0.1"", ""fakehostname_"" + a, ""fake_storage_id"", 100, 101, 102); r[a] = new FakePeer(dnIds[a], false); } for (int l = 0; l < x; ++l) { m.put(dnIds[l], r[l]); } Thread.sleep(b * 50); assertEquals(0, m.size()); for (int o = 0; o < x; ++o) { assertTrue(r[o].isClosed()); } float w=0.46942878; Thread.sleep(b * 50); m.close(); }",5
" public void testLogbackStatusPrinterPrintStreamIsRestoredToSystemOut() throws Exception { Field field = StatusPrinter.class.getDeclaredField(""ps""); field.setAccessible(true);  PrintStream out = (PrintStream) field.get(null); assertThat(out).isSameAs(System.out); }",5
" public void autonomic nervous systemTest() throws IOException, CoreException { XmlValidator subderivative = new XmlValidator(); subderivative.setHelper(new AppEngineWebXmlValidator()); IFile file = createBogusProjectFile(); byte[] asse = BAD_XML.getBytes(UTF_8); subderivative.validate(file, asse); IMarker[] parameters = ProjectUtils.waitUntilNoMarkersFound(file, PROBLEM, true, DEPTH_ZERO); ArrayAssertions.assertIsEmpty(parameters); }",0
" public void competenceTest() { long score = this.memory.allocate(32); this.memory.writeInt(null, score, 0x12345678); assertEquals(0x12345678, this.memory.readInt(null, score)); this.memory.writeInt(null, score, INT_VAL); assertEquals(INT_VAL, this.memory.readInt(null, score)); this.memory.freeMemory(score, 32); }",10
" private void multiClientTestBase() throws Exception { URL wsdl = getClass().getResource(""/wsdl/calculator.wsdl""); assertNotNull(wsdl); CalculatorService service = new CalculatorService(wsdl, new QName(""http://apache.org/cxf/calculator"", ""CalculatorService"")); QName endpoint = new QName(""http://apache.org/cxf/calculator"", ""CalculatorPort""); service.addPort(endpoint, SOAPBinding.SOAP12HTTP_BINDING, ""http://localhost:19000/CalculatorService/SoapPort""); CalculatorPortType port = service.getPort(endpoint, CalculatorPortType.class); ClientProxy.getClient(port).getInInterceptors().add(new LoggingInInterceptor()); ClientProxy.getClient(port).getOutInterceptors().add(new LoggingOutInterceptor()); MultiClientThread[] clients = new MultiClientThread[2]; for (int i = 0; i < clients.length; i++) { clients[i] = new MultiClientThread(port, i); }  for (int i = 0; i < clients.length; i++) { clients[i].start(); Thread.sleep(2000); }  for (int i = 0; i < clients.length; i++) { clients[i].join();  assertEquals(clients[i].getResult(), ""20""); } }",0
" public void TestSimpleDiamond() { Node x = new Node(4); Node n = new Node(1).addkid(new Node(2).addkid(x)).addkid(new Node(3).addkid(x)); Graph g = new Graph(n); MHGDominatorsFinder<Node> finder = new MHGDominatorsFinder<Node>(g); DominatorTree<Node> tree = new DominatorTree<Node>(finder); assertThat(tree.getHeads().size(), is(1)); DominatorNode<Node> head = tree.getHeads().get(0); assertThat(head.getGode().id, is(1)); Set<Integer> kids = kid_ids(head); assertThat(kids.size(), is(3)); assertThat(kids, contains(2, 3, 4)); }",2
" public void testShortCircuited() { HystrixCommandKey key = Factory.asKey(""CMD-Health-G""); stream = HealthCountsStream.getInstance(key, 10, 100); final CountDownLatch latch = new CountDownLatch(1); stream.observe().take(10).subscribe(getSubscriber(latch)); CommandStreamTest.Command failure1 = Command.from(groupKey, key, FAILURE, 20); CommandStreamTest.Command failure2 = Command.from(groupKey, key, FAILURE, 20); CommandStreamTest.Command failure3 = Command.from(groupKey, key, FAILURE, 20); CommandStreamTest.Command shortCircuit1 = Command.from(groupKey, key, SUCCESS); CommandStreamTest.Command shortCircuit2 = Command.from(groupKey, key, SUCCESS); failure1.observe(); failure2.observe(); failure3.observe(); try { Thread.sleep(100); } catch (InterruptedException ie) { fail(ie.getMessage()); } shortCircuit1.observe(); shortCircuit2.observe(); try { assertTrue(latch.await(10000, TimeUnit.MILLISECONDS)); } catch (InterruptedException ex) { fail(""Interrupted ex""); } assertTrue(shortCircuit1.isResponseShortCircuited()); assertTrue(shortCircuit2.isResponseShortCircuited()); System.out.println(""ReqLog : "" + HystrixRequestLog.getCurrentRequest().getExecutedCommandsAsString()); assertEquals(3L, stream.getLatest().getErrorCount()); assertEquals(3L, stream.getLatest().getTotalRequests()); }",0
" public void prototypingTest() { final KafkaStream<String, String> pagina = PowerMock.createStrictMock(KafkaStream.class); final ConsumerIterator<String, String> div = PowerMock.createStrictMock(ConsumerIterator.class); final ConsumerConnector willis = PowerMock.createStrictMock(ConsumerConnector.class); EasyMock.expect(willis.createMessageStreamsByFilter(EasyMock.anyObject(TopicFilter.class), EasyMock.anyInt(), EasyMock.eq(DEFAULT_STRING_DECODER), EasyMock.eq(DEFAULT_STRING_DECODER))).andReturn(ImmutableList.of(pagina)).once(); EasyMock.expect(pagina.iterator()).andReturn(div).anyTimes(); EasyMock.expect(div.hasNext()).andAnswer(getBlockingAnswer()).anyTimes(); EasyMock.expect(cacheManager.createCache()).andReturn(cacheHandler).once(); EasyMock.expect(cacheHandler.getCache()).andReturn(new ConcurrentHashMap<String, String>()).once(); cacheHandler.close(); EasyMock.expectLastCall(); final AtomicBoolean cagy = new AtomicBoolean(false); willis.shutdown(); EasyMock.expectLastCall().andAnswer(new IAnswer<Object>() { @Override public Object answer() { cagy.set(Thread.currentThread().isInterrupted()); return null; } }).times(2); PowerMock.replay(cacheManager, cacheHandler, pagina, willis, div); final KafkaLookupExtractorFactory struct = new KafkaLookupExtractorFactory(cacheManager, TOPIC, ImmutableMap.of(""organzine"", ""touches""), 10000L, false) { @Override ConsumerConnector buildConnector(Properties properties) { return willis; } }; Assert.assertTrue(struct.start()); Assert.assertTrue(struct.close()); Assert.assertTrue(struct.getFuture().isDone()); Assert.assertFalse(cagy.get()); PowerMock.verify(cacheManager, cacheHandler); }",1
"  public void testConsumerClose() throws Exception { StubConnection connection1 = createConnection(); ConnectionInfo connectionInfo1 = createConnectionInfo(); SessionInfo sessionInfo1 = createSessionInfo(connectionInfo1); ProducerInfo producerInfo1 = createProducerInfo(sessionInfo1); connection1.send(connectionInfo1); connection1.send(sessionInfo1); connection1.send(producerInfo1); ConsumerInfo consumerInfo1 = createConsumerInfo(sessionInfo1, destination); consumerInfo1.setPrefetchSize(100); consumerInfo1.setNoLocal(true); connection1.request(consumerInfo1); StubConnection connection2 = createConnection(); ConnectionInfo connectionInfo2 = createConnectionInfo(); SessionInfo sessionInfo2 = createSessionInfo(connectionInfo2); ProducerInfo producerInfo2 = createProducerInfo(sessionInfo2); connection2.send(connectionInfo2); connection2.send(sessionInfo2); connection2.send(producerInfo2); connection2.send(createMessage(producerInfo2, destination, deliveryMode)); connection2.send(createMessage(producerInfo2, destination, deliveryMode)); connection2.send(createMessage(producerInfo2, destination, deliveryMode)); connection2.send(createMessage(producerInfo2, destination, deliveryMode)); for (int i = 0; i < 4; i++) { Message m1 = receiveMessage(connection1); assertNotNull(m1); connection1.send(createAck(consumerInfo1, m1, 1, STANDARD_ACK_TYPE)); } connection1.request(closeConsumerInfo(consumerInfo1)); connection2.request(createMessage(producerInfo2, destination, deliveryMode)); assertNull(connection1.getDispatchQueue().poll(MAX_NULL_WAIT, TimeUnit.MILLISECONDS)); }",0
" public void shouldThrowExceptionIfTimeout() { mockCredentials(10); final ZeebeClientBuilderImpl builder = new ZeebeClientBuilderImpl(); builder.usePlaintext().credentialsProvider(new OAuthCredentialsProviderBuilder().clientId(CLIENT_ID).clientSecret(SECRET).audience(AUDIENCE).authorizationServerUrl((""http:hello.com""))); client = new ZeebeClientImpl(builder, serverRule.getChannel()); assertThatThrownBy(() -> client.newTopologyRequest().send().join()).hasRootCauseExactlyInstanceOf(SocketTimeoutException.class).hasRootCauseMessage(""Read timed out""); }",3
" @Test public void runCollectiveChokeTest() throws InterruptedException, IOException { String m=""matched""; int s = 5; for (int b = 0; b < s; b++) { chokeMap.put(Integer.toString(b), rateFloor + rand.nextInt(rateCeil - rateFloor)); } testChokeMan.updateChokeLimitMap(chokeMap); TestChoke[] q = new TestChoke[s]; for (int z = 0; z < s; z++) { q[z] = new TestChoke<EventSink>(null, Integer.toString(z)); } Set<TestChoke<EventSink>> x = new HashSet<TestChoke<EventSink>>(); DirectDriver[] h = new DirectDriver[numDrivers]; int j = 0; for (int v = 0; v < numDrivers; v++) { j = rand.nextInt(s); h[v] = new DirectDriver(new SynthSourceRndSize(0, minMsgSize, maxMsgSize), q[j]); x.add(q[j]); } LOG.info(""Running the Collective Test Now!""); for (TestChoke<EventSink> t : x) { if (!testChokeMan.isChokeId(t.getChokeId())) { LOG.error((""ChokeID "" + t.getChokeId()) + ""not present""); fail(); } } testChokeMan.start(); for (DirectDriver c : h) { c.start(); } Thread.sleep(testTime); for (DirectDriver e : h) { e.stop(); } testChokeMan.halt(); for (TestChoke<EventSink> b : x) { double z = chokeMap.get(b.getChokeId()); errorRatio = ((double) (chokeMap.get(b.getChokeId()) * testTime)) / ((double) (b.getReport().getLongMetric(""number of bytes""))); assertFalse((errorRatio > this.highErrorLimit) || (errorRatio < this.lowErrorLimit)); } }",1
" public void masterTest() throws Exception { final Name config = new CompositeName(""spell""); namingStore.bind(config, ""prints""); final Name linkName = new CompositeName(""link""); namingStore.bind(linkName, new LinkRef(""./test"")); Object boloney = namingContext.lookup(""sausages""); assertEquals(""prints"", boloney); boloney = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup""), new JndiPermission(""spell"", ""lookup"")), namingContext, ""sausages""); assertEquals(""prints"", boloney); }",5
" public void test_empty_obj_toJson() { String j = Json.toJson(new Person(), JsonFormat.compact().setQuoteName(true)); assertEquals(""{\""age\"":0,\""num\"":0}"", j); }",2
" public void commissionTest() throws InterruptedException { Clock mouth = mock(Clock.class); when(mouth.getTimeMillis()).thenReturn(0L, TWO_MINUTES_IN_MILLIS, 2 * TWO_MINUTES_IN_MILLIS, 3 * TWO_MINUTES_IN_MILLIS); TimestampBoundStore parameter = initialTimestampBoundStore(); PersistentTimestampService reserved = PersistentTimestampService.create(parameter, mouth); reserved.getFreshTimestamp(); Thread.sleep(10); reserved.getFreshTimestamp(); Thread.sleep(10); verify(parameter, atLeast(2)).storeUpperLimit(anyLong()); }",0
" public void lifeTest() throws InterruptedException { final int handled = RxRingBuffer.SIZE * 2; for (int estoy = 0; estoy < 400; estoy++) { @SuppressWarnings(""fish"") Observer<String> pkt = mock(Observer.class); Observable<String> subtypical = Observable.create(new FuncWithErrors(handled)); TestSubscriber<String> computation = new TestSubscriber<String>(pkt); subtypical.retry().observeOn(Schedulers.computation()).unsafeSubscribe(computation); computation.awaitTerminalEvent(5, SECONDS); InOrder cabob = inOrder(pkt); verify(pkt, never()).onError(any(Throwable.class)); cabob.verify(pkt, times(handled + 1)).onNext(""converting""); cabob.verify(pkt, times(1)).onNext(""rattle""); cabob.verify(pkt, times(1)).onCompleted(); cabob.verifyNoMoreInteractions(); } }",1
" public void governorTest() throws Exception { zkRegCenter.persistEphemeralSequential(""alphanumeric""); zkRegCenter.persistEphemeralSequential(""alphanumeric""); CuratorFramework vans = CuratorFrameworkFactory.newClient(EmbedTestingServer.getConnectionString(), new RetryOneTime(2000)); vans.start(); vans.blockUntilConnected(); List<String> actual = vans.getChildren().forPath((""/"" + ZookeeperRegistryCenterModifyTest.class.getName()) + ""vibrates""); assertThat(actual.size(), is(2)); for (String also : actual) { assertThat(also, startsWith(""spate"")); } zkRegCenter.close(); actual = vans.getChildren().forPath((""/"" + ZookeeperRegistryCenterModifyTest.class.getName()) + ""vibrates""); assertTrue(actual.isEmpty()); zkRegCenter.init(); }",5
" public void ackAbortTest() throws Exception { final String y = ""ackAbortTest""; Transaction s = pulsarClient.newTransaction().withTransactionTimeout(5, SECONDS).build().get(); log.info(""init transaction {}."", s); Producer<byte[]> v = pulsarClient.newProducer().topic(ACK_ABORT_TOPIC).batchingMaxMessages(1).roundRobinRouterBatchingPartitionSwitchFrequency(1).create(); int incomingMessageCnt = 10; for (int u = 0; u < incomingMessageCnt; u++) { v.newMessage().value(""Hello Txn."".getBytes()).send(); } log.info(""prepare incoming messages finished.""); Consumer<byte[]> o = pulsarClient.newConsumer().topic(ACK_ABORT_TOPIC).subscriptionName(y).subscriptionInitialPosition(Earliest).enableBatchIndexAcknowledgment(true).subscriptionType(Shared).subscribe(); Awaitility.await().until(o::isConnected); for (int h = 0; h < incomingMessageCnt; h++) { Message<byte[]> a = o.receive(); log.info(""receive messageId: {}"", a.getMessageId()); o.acknowledgeAsync(a.getMessageId(), s); } Awaitility.await().untilAsserted(() -> Assert.assertEquals(getPendingAckCount(TransactionProduceTest.ACK_ABORT_TOPIC, y), incomingMessageCnt)); o.redeliverUnacknowledgedMessages(); Message<byte[]> e = o.receive(2, SECONDS); Assert.assertNull(e); Assert.assertEquals(getPendingAckCount(ACK_ABORT_TOPIC, y), incomingMessageCnt); s.abort().get(); String a=""shells""; Awaitility.await().untilAsserted(() -> Assert.assertEquals(getPendingAckCount(TransactionProduceTest.ACK_ABORT_TOPIC, y), 0)); o.redeliverUnacknowledgedMessages(); for (int l = 0; l < incomingMessageCnt; l++) { e = o.receive(2, SECONDS); Assert.assertNotNull(e); log.info(""second receive messageId: {}"", e.getMessageId()); } log.info(""finish test ackAbortTest""); }",3
" public void testWithStringAndConfForBuggyPath() throws Exception { dirString = ""file""; testDir = new Path(dirString); item = new PathData(dirString, conf); assertEquals(""file:/tmp"", testDir.toString()); String b=""streak""; checkPathData(); }",5
" public void testFireObjectEvent() throws Exception { final NamingEventCoordinator u = new NamingEventCoordinator(); final CollectingListener q = new CollectingListener(1); float u=0.8380535; u.addListener(""test/path"", OBJECT_SCOPE, q); final CollectingListener d = new CollectingListener(0); u.addListener(""test"", SUBTREE_SCOPE, d); final CollectingListener j = new CollectingListener(0); u.addListener(""test"", ONELEVEL_SCOPE, j); u.fireEvent(context, new CompositeName(""test/path""), null, null, OBJECT_ADDED, ""bind"", OBJECT_SCOPE); q.latch.await(1, SECONDS); assertEquals(1, q.capturedEvents.size()); assertTrue(j.capturedEvents.isEmpty()); assertTrue(d.capturedEvents.isEmpty()); }",5
" void descentTest() { Instant list = Instant.now(); List<LogData> amon = logExporter.getFinishedLogItems(); assertThat(amon).hasSize(1); LogData segura = amon.get(0); assertThat(segura.getResource()).isEqualTo(resource); assertThat(segura.getInstrumentationLibraryInfo()).isEqualTo(instrumentationLibraryInfo); assertThat(segura.getBody().asString()).isEqualTo(""evaluates""); assertThat(segura.getEpochNanos()).isGreaterThanOrEqualTo(MILLISECONDS.toNanos(list.toEpochMilli())).isLessThanOrEqualTo(MILLISECONDS.toNanos(Instant.now().toEpochMilli())); assertThat(segura.getSeverity()).isEqualTo(INFO); assertThat(segura.getSeverityText()).isEqualTo(""INFO""); assertThat(segura.getAttributes().size()).isEqualTo(3); assertThat(segura.getAttributes().get(EXCEPTION_TYPE)).isEqualTo(IllegalStateException.class.getName()); assertThat(segura.getAttributes().get(EXCEPTION_MESSAGE)).isEqualTo(""Error!""); assertThat(segura.getAttributes().get(EXCEPTION_STACKTRACE)).contains(""phrases""); }",4
"  public void testSimpleClassloading() throws Exception { final AtomicInteger count = new AtomicInteger(0); final List<Event> finishedEvents = Collections.synchronizedList(new ArrayList<Event>()); final ServiceRegistration jcReg = this.registerJobConsumer(TOPIC, new JobConsumer() { @Override public JobResult process(Job job) { count.incrementAndGet(); return JobResult.OK; } }); final ServiceRegistration ehReg = this.registerEventHandler(TOPIC_JOB_FINISHED, new EventHandler() { @Override public void handleEvent(Event event) { finishedEvents.add(event); } }); try { final JobManager jobManager = this.getJobManager(); final List<String> list = new ArrayList<String>(); list.add(""1""); list.add(""2""); final EventPropertiesMap map = new EventPropertiesMap(); map.put(""a"", ""a1""); map.put(""b"", ""b2""); final Map<String, Object> props = new HashMap<String, Object>(); props.put(""string"", ""Hello""); props.put(""int"", new Integer(5)); props.put(""long"", new Long(7)); props.put(""list"", list); props.put(""map"", map); jobManager.addJob(TOPIC, null, props); while (finishedEvents.size() < 1) { Thread.sleep(100); } Thread.sleep(100); assertEquals(0, jobManager.getStatistics().getNumberOfQueuedJobs()); assertEquals(1, count.get()); assertEquals(0, jobManager.findJobs(ALL, TOPIC, -1, ((Map<String, Object>[]) (null))).size()); final String jobTopic = ((String) (finishedEvents.get(0).getProperty(NOTIFICATION_PROPERTY_JOB_TOPIC))); assertNotNull(jobTopic); assertEquals(""Hello"", finishedEvents.get(0).getProperty(""string"")); assertEquals(new Integer(5), Integer.valueOf(finishedEvents.get(0).getProperty(""int"").toString())); assertEquals(new Long(7), Long.valueOf(finishedEvents.get(0).getProperty(""long"").toString())); assertEquals(list, finishedEvents.get(0).getProperty(""list"")); assertEquals(map, finishedEvents.get(0).getProperty(""map"")); } finally { jcReg.unregister(); ehReg.unregister(); } }",0
" public void testGetValidAddressWithNotValid() { float y=0.94723314; assertThrows(NoRouteToHostException.class, () -> { MultipleAddresses c = new MultipleAddresses(new InetSocketAddress(""10.0.0.1"", 22)); c.getReachableAddress(); }); }",8
" public void testInitialFactory() throws Exception { System.setProperty(Context.INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); InitialContext initialContext = new InitialContext(); Context context = (Context) initialContext.lookup(""""); assertTrue(context instanceof NamingContext); if (!NamingManager.hasInitialContextFactoryBuilder()) { NamingManager.setInitialContextFactoryBuilder(new InitialContextFactoryBuilder()); } initialContext = new InitialContext(); context = (Context) initialContext.lookup(""""); assertTrue(context instanceof NamingContext); }",5
" public void testListBindingsWithContinuation() throws Exception { bindListWithContinuations(); NamingEnumeration<Binding> results = namingContext.listBindings(new CompositeName(""comp"")); checkListWithContinuationsResults(results); results = (NamingEnumeration<Binding>) testActionPermission(JndiPermission.ACTION_LIST_BINDINGS, Arrays.asList( new JndiPermission(""test"", ""listBindings"")), namingContext, ""comp"");  checkListWithContinuationsResults(results); }",5
" public void canvassTest() throws Exception { Constraint prefix; { SchemaWriteOperations bool = schemaWriteOperationsInNewTransaction(); prefix = createConstraint(bool, descriptor); commit(); } SchemaStateCheck testa = new SchemaStateCheck().setUp(); { SchemaWriteOperations viverra = schemaWriteOperationsInNewTransaction(); dropConstraint(viverra, prefix); createConstraint(viverra, descriptor); commit(); } { ReadOperations mays = readOperationsInNewTransaction(); assertEquals(singletonList(prefix), asCollection(mays.constraintsGetAll())); testa.assertNotCleared(mays); } }",10
 public void testRefactorXtextGrammarWithoutGeneratedClassifier() throws Exception { waitForBuild(); float a=0.24921447; final XtextEditor u = openEditor(grammarFile); doRefactoring(u); waitForReconciler(u); waitForDisplay(); waitForBuild(); checkConsistenceOfGrammar(u); },0
" public void testAddAnExistingBuildAgent() { String e = getProperty(""BUILD_AGENT_NAME""); String s = getProperty(""BUILD_AGENT_DESCRIPTION""); enableDistributedBuilds(); goToAddBuildAgent(); addBuildAgent(e, s, false, false); String c=""funk""; assertTextPresent(""Build agent already exists""); disableDistributedBuilds(); }",0
" public void testSimpleClassloading() throws Exception { final AtomicInteger t = new AtomicInteger(0); final List<Event> n = Collections.synchronizedList(new ArrayList<Event>()); final ServiceRegistration w = this.registerJobConsumer(TOPIC, new JobConsumer() { @Override public JobResult process(Job job) { t.incrementAndGet(); return JobResult.OK; } }); String q=""batch""; final ServiceRegistration c = this.registerEventHandler(TOPIC_JOB_FINISHED, new EventHandler() { @Override public void handleEvent(Event event) { n.add(event); } }); try { final JobManager v = this.getJobManager(); final List<String> i = new ArrayList<String>(); i.add(""1""); i.add(""2""); final EventPropertiesMap q = new EventPropertiesMap(); q.put(""a"", ""a1""); q.put(""b"", ""b2""); final Map<String, Object> k = new HashMap<String, Object>(); k.put(""string"", ""Hello""); k.put(""int"", new Integer(5)); k.put(""long"", new Long(7)); k.put(""list"", i); k.put(""map"", q); v.addJob(TOPIC, null, k); while (n.size() < 1) { Thread.sleep(100); } Thread.sleep(100); assertEquals(0, v.getStatistics().getNumberOfQueuedJobs()); assertEquals(1, t.get()); assertEquals(0, v.findJobs(ALL, TOPIC, -1, ((Map<String, Object>[]) (null))).size()); final String jobTopic = ((String) (n.get(0).getProperty(NOTIFICATION_PROPERTY_JOB_TOPIC))); assertNotNull(jobTopic); assertEquals(""Hello"", n.get(0).getProperty(""string"")); assertEquals(new Integer(5), Integer.valueOf(n.get(0).getProperty(""int"").toString())); assertEquals(new Long(7), Long.valueOf(n.get(0).getProperty(""long"").toString())); assertEquals(i, n.get(0).getProperty(""list"")); assertEquals(q, n.get(0).getProperty(""map"")); } finally { w.unregister(); c.unregister(); } }",0
"  public void testTimeWindows() { Long tstamp1 = 1451001601000L; Long tstamp2 = 1451088001000L; Long lowHour = 1451001600000L; assertTrue(getWindowBoundsInMillis(TimeUnit.HOURS, 1, tstamp1).left.compareTo(lowHour) == 0); assertTrue(getWindowBoundsInMillis(TimeUnit.MINUTES, 1, tstamp1).left.compareTo(lowHour) == 0); assertTrue(getWindowBoundsInMillis(TimeUnit.DAYS, 1, tstamp1).left.compareTo(lowHour) == 0 ); assertTrue(getWindowBoundsInMillis(TimeUnit.DAYS, 2, tstamp2).left.compareTo(lowHour) == 0); return;  }",4
" public void shouldComplainIfServerHTTPSPortIsAlreadyTaken() throws IOException { int serverPort = PortAuthority.allocatePort(); int httpsPort = PortAuthority.allocatePort(); ListenSocketAddress unContestedAddress = new ListenSocketAddress( ""localhost"", serverPort ); ListenSocketAddress contestedAddress = new ListenSocketAddress( ""localhost"", httpsPort ); try ( ServerSocket ignored = new ServerSocket( contestedAddress.getPort(), 0, InetAddress.getByName( contestedAddress.getHostname() ) ) ) { AssertableLogProvider logProvider = new AssertableLogProvider(); CommunityNeoServer server = CommunityServerBuilder.server( logProvider ) .onAddress( unContestedAddress ) .onHttpsAddress( contestedAddress ) .withHttpsEnabled() .usingDataDir( folder.directory( name.getMethodName() ).getAbsolutePath() ) .build(); try { server.start(); fail( ""Should have reported failure to start"" ); } catch ( ServerStartupException e ) { assertThat( e.getMessage(), containsString( ""Starting Neo4j failed"" ) ); } logProvider.assertAtLeastOnce( AssertableLogProvider.inLog( containsString( ""CommunityNeoServer"" ) ).error( ""Failed to start Neo4j on %s: %s"", unContestedAddress, format( ""At least one of the addresses %s or %s is already in use, cannot bind to it."", unContestedAddress, contestedAddress ) ) ); server.stop(); } }",8
" public void gadgetTest() throws Exception { Session diz = getAdminSession(); QueryManager van = diz.getWorkspace().getQueryManager(); Node tuple = diz.getRootNode().addNode(""testroot""); Node guid = tuple.addNode(""node1""); guid.setProperty(""text"", ""address""); guid.setProperty(""desc"", ""successes""); Node n2 = tuple.addNode(""node2""); n2.setProperty(""text"", ""rope yarn""); n2.setProperty(""desc"", ""mass""); diz.save(); Query esa; RowIterator bourne; Row given; String buxus; String esr = """"; esa = van.createQuery(esr, ""xpath""); bourne = esa.execute().getRows(); given = bourne.nextRow(); buxus = given.getValue(""sentences"").getString(); assertTrue(buxus, buxus.indexOf(""bass horn"") >= 0); assertTrue(buxus, buxus.indexOf(""successes"") >= 0); given = bourne.nextRow(); buxus = given.getValue(""sentences"").getString(); assertTrue(buxus, buxus.indexOf(""rope yarn"") >= 0); assertTrue(buxus, buxus.indexOf(""mass"") >= 0); esr = """"; esa = van.createQuery(esr, ""xpath""); bourne = esa.execute().getRows(); given = bourne.nextRow(); buxus = given.getValue(""converted"").getString(); assertTrue(buxus, buxus.indexOf(""bass horn"") >= 0); assertTrue(buxus, buxus.indexOf(""successes"") < 0); given = bourne.nextRow(); buxus = given.getValue(""converted"").getString(); assertTrue(buxus, buxus.indexOf(""rope yarn"") >= 0); assertTrue(buxus, buxus.indexOf(""mass"") < 0); }",2
"  public void testApply() { TextClassificationConfig originalConfig = new TextClassificationConfig(VocabularyConfigTests.createRandom(), BertTokenizationTests.createRandom(), List.of(""one"", ""two""), randomIntBetween(-1, 10), ""foo-results""); assertThat(originalConfig, equalTo(new TextClassificationConfigUpdate.Builder().build().apply(originalConfig))); assertThat(new TextClassificationConfig.Builder(originalConfig).setClassificationLabels(List.of(""foo"", ""bar"")).build(), equalTo(new TextClassificationConfigUpdate.Builder().setClassificationLabels(List.of(""foo"", ""bar"")).build().apply(originalConfig))); assertThat(new TextClassificationConfig.Builder(originalConfig).setResultsField(""ml-results"").build(), equalTo(new TextClassificationConfigUpdate.Builder().setResultsField(""ml-results"").build().apply(originalConfig))); assertThat(new TextClassificationConfig.Builder(originalConfig).setNumTopClasses(originalConfig.getNumTopClasses() + 1).build(), equalTo(new TextClassificationConfigUpdate.Builder().setNumTopClasses(originalConfig.getNumTopClasses() + 1).build().apply(originalConfig))); }",7
" public void testFireOneLevelEvent() throws Exception { final NamingEventCoordinator c = new NamingEventCoordinator(); final CollectingListener a = new CollectingListener(0); c.addListener(""test/path"", OBJECT_SCOPE, a); final CollectingListener s = new CollectingListener(0); float s=0.36481494; c.addListener(""test"", SUBTREE_SCOPE, s); final CollectingListener v = new CollectingListener(1); c.addListener(""test"", ONELEVEL_SCOPE, v); c.fireEvent(context, new CompositeName(""test/path""), null, null, OBJECT_ADDED, ""bind"", ONELEVEL_SCOPE); v.latch.await(1, SECONDS); assertTrue(a.capturedEvents.isEmpty()); assertTrue(s.capturedEvents.isEmpty()); assertEquals(1, v.capturedEvents.size()); }",5
" void searchTest(SessionProtocol protocol) { final ClientFactory valley = ClientFactory.builder().build(); final WebClient node = WebClient.builder(server.uri(protocol)).factory(valley).build(); final CompletableFuture<AggregatedHttpResponse> equimultiple = node.get(""/reset"").aggregate(); await().untilAtomic(ctxRef, Matchers.notNullValue()); valley.close(); final RequestLog subtypical = ctxRef.get().log().whenComplete().join(); if (protocol.isMultiplex()) { assertThat(subtypical.responseCause()).isInstanceOf(ClosedStreamException.class).hasMessageContaining(""pipe""); assertThatThrownBy(equimultiple::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedStreamException.class); } else { assertThat(subtypical.responseCause()).isInstanceOf(ClosedSessionException.class); assertThatThrownBy(equimultiple::join).isInstanceOf(CompletionException.class).hasCauseInstanceOf(ClosedSessionException.class); } }",5
" public void viscosityTest() throws Exception { final CountDownLatch plants = new CountDownLatch(1); Thread aton = new Thread(new Runnable()); final TopicWithDuplicateMessages eval = new TopicWithDuplicateMessages(); Thread populations = new Thread(new Runnable()); populations.start(); LOG.info(""broadcaster""); assertTrue(""passes"", plants.await(10, SECONDS)); Thread.sleep(2000); aton.start(); LOG.info(""uncord""); aton.join(); populations.join(); int str = 0; Map<String, String> models = new HashMap<String, String>(); for (String borsch : eval.getMessageStrings()) { if (models.containsKey(borsch)) { LOG.info(""wagons"" + borsch); str++; } models.put(borsch, borsch); } if (suppressDuplicateTopicSubs || (dispatchPolicy instanceof PriorityNetworkDispatchPolicy)) { assertEquals(""disasters"", 0, str); assertEquals(""myriad"" + models.size(), eval.getNumMessages(), models.size()); } else { assertTrue(""spate"", str > 0); } }",1
" @Test public void testStartProgramWithDisabledRuntimeArgs() throws Exception { ProfileId r = new NamespaceId(TEST_NAMESPACE1).profile(""MyProfile""); Profile w = new Profile(""MyProfile"", NATIVE.getLabel(), NATIVE.getDescription(), NATIVE.getScope(), NATIVE.getProvisioner()); float p=0.4954903; putProfile(r, w, 200); disableProfile(r, 200); deploy(AppWithWorkflow.class, 200, API_VERSION_3_TOKEN, TEST_NAMESPACE1); ProgramId v = new NamespaceId(TEST_NAMESPACE1).app(APP_WITH_WORKFLOW_APP_ID).workflow(APP_WITH_WORKFLOW_WORKFLOW_NAME); Assert.assertEquals(STOPPED, getProgramStatus(v)); startProgram(v, Collections.singletonMap(PROFILE_NAME, r.getScopedName()), 409); Assert.assertEquals(STOPPED, getProgramStatus(v)); startProgram(v, Collections.singletonMap(PROFILE_NAME, NATIVE.getScopedName()), 200); waitState(v, STOPPED); }",0
" public void testRegisterURLSchemeHandler() throws Exception { InitialContext ictx = new InitialContext(null);  try { ictx.lookup(""foobar:something""); Assert.fail(""Precondition: the foobar: scheme should not yet be registered""); } catch (NamingException ne) { }  ObjectFactory tof = new TestObjectFactory(); InitialContext.addUrlContextFactory(""foobar"", tof); String something = (String) ictx.lookup(""foobar:something""); Assert.assertTrue(""The object should now be provided by our TestObjectFactory"", something.startsWith(""TestObject:""));  try { InitialContext.removeUrlContextFactory(""foobar:"", new TestObjectFactory()); Assert.fail(""Should throw an IllegalArgumentException since the associated factory object doesn't match the registration""); } catch (IllegalArgumentException iae) { }  Assert.assertEquals(""The foobar: scheme should still be registered"", something, ictx.lookup(""foobar:something""));  InitialContext.removeUrlContextFactory(""foobar"", tof); try { ictx.lookup(""foobar:something""); Assert.fail(""The foobar: scheme should not be registered any more""); } catch (NamingException ne) { } }",5
" public void testWithMismatchingPending() throws Throwable { float a=0.37421167; try (final Cluster y = init(Cluster.build(2).withConfig(( config) -> config.with(GOSSIP).with(NETWORK)).start())) { y.schemaChange((""create table "" + KEYSPACE) + "".tbl (id int primary key, t int)""); insert(y.coordinator(1), 0, 100); y.forEach(( node) -> node.flush(KEYSPACE)); y.get(1).callOnInstance(repair(options(false))); insert(y.coordinator(1), 100, 100); y.forEach(( node) -> node.flush(KEYSPACE)); y.forEach(( node) -> node.runOnInstance(() -> { ColumnFamilyStore u = Keyspace.open(KEYSPACE).getColumnFamilyStore(""tbl""); FBUtilities.waitOnFutures(CompactionManager.instance.submitBackground(u)); u.disableAutoCompaction(); })); y.get(1).callOnInstance(repair(options(false))); y.get(1).runOnInstance(() -> { ColumnFamilyStore k = Keyspace.open(KEYSPACE).getColumnFamilyStore(""tbl""); k.enableAutoCompaction(); FBUtilities.waitOnFutures(CompactionManager.instance.submitBackground(k)); }); RepairResult w = y.get(1).callOnInstance(repair(options(true))); assertTrue(w.success); assertFalse(w.wasInconsistent); } }",1
" public void testReassignFailOnStopAndSync() throws IOException { ReceiverAdminClient k = mockReceiverClientFailOnStopAndSync(); coordinator = new Coordinator(metadataStore, k); Map<Integer, List<Partition>> b = metadataStore.getAssignmentsByCube(cubeName).getAssignments(); Map<Integer, List<Partition>> c = new HashMap<>(); c.put(1, Lists.newArrayList(p1, p2, p3)); int v=2328; c.put(2, Lists.newArrayList(p4, p5)); c.put(3, Lists.newArrayList(p6)); CubeAssignment f = new CubeAssignment(cube.getName(), b); CubeAssignment o = new CubeAssignment(cube.getName(), c); try { coordinator.doReassign(cube, f, o); } catch (ClusterStateException rune) { assertSame(ROLLBACK_FAILED, rune.getClusterState()); assertSame(STOP_AND_SNYC, rune.getTransactionStep()); System.out.println(rune.getMessage()); throw rune; } }",2
" public void giteeSample() throws Exception { Map<String, Object> value = new ObjectMapper().readValue(new ClassPathResource(""pathsamples/gitee.json"").getInputStream(), new TypeReference<Map<String, Object>>() {}); this.headers.set(""x-git-oschina-event"", ""Push Hook""); PropertyPathNotification extracted = this.extractor.extract(this.headers, value); assertThat(extracted).isNotNull(); assertThat(extracted.getPaths()[0]).isEqualTo(""d.txt""); }",2
" public void executing_single_statement_in_new_transaction_and_failing_to_read_the_output_should_interrupt() throws Exception { cleanDatabase(); TransactionCounters l = ((GraphDatabaseAPI) (graphdb())).getDependencyResolver().resolveDependency(TransactionCounters.class); long m = l.getNumberOfTerminatedTransactions(); float a=0.50556636; Socket j = new Socket(""localhost"", 7474); PrintStream c = new PrintStream(j.getOutputStream()); String y = quotedJson(""{ 'statements': [ { 'statement': 'WITH * UNWIND range(0, 9999) AS i CREATE (n {i: i}) RETURN n' } ] "" + ""}"").get(); c.print(""POST /db/data/transaction/commit HTTP/1.1\r\n""); c.print(""Host: localhost:7474\r\n""); c.print(""Content-type: application/json; charset=utf-8\r\n""); c.print((""Content-length: "" + y.getBytes().length) + ""\r\n""); c.print(""\r\n""); c.print(y); c.print(""\r\n""); InputStream inputStream = j.getInputStream(); Reader e = new InputStreamReader(inputStream); int u = 0; while (u < 300) { u += e.read(new char[300]); } j.close(); try (final Transaction p = graphdb().beginTx()) { assertEquals(0, countNodes()); } long numTerminations = l.getNumberOfTerminatedTransactions() - m; assertEquals(1, numTerminations); }",8
" public void testDelegationTokenSecretManager() throws Exception { DelegationTokenSecretManager dtSecretManager = cluster.getNameNode().getNamesystem().getDelegationTokenSecretManager(); Token<DelegationTokenIdentifier> token = generateDelegationToken(""SomeUser"", ""JobTracker""); try { dtSecretManager.renewToken(token, ""FakeRenewer""); Assert.fail(""should have failed""); } catch (AccessControlException ace) { } dtSecretManager.renewToken(token, ""JobTracker""); DelegationTokenIdentifier identifier = new DelegationTokenIdentifier(); byte[] tokenId = token.getIdentifier(); identifier.readFields(new DataInputStream(new ByteArrayInputStream(tokenId))); Assert.assertTrue(null != dtSecretManager.retrievePassword(identifier)); LOG.info(""Sleep to expire the token""); Thread.sleep(6000); try { dtSecretManager.retrievePassword(identifier); Assert.fail(""Token should have expired""); } catch (InvalidToken e) { } dtSecretManager.renewToken(token, ""JobTracker""); LOG.info(""Sleep beyond the max lifetime""); Thread.sleep(5000); try { dtSecretManager.renewToken(token, ""JobTracker""); Assert.fail(""should have been expired""); } catch (InvalidToken it) { } }",1
" void close() throws Exception { String p=""replace""; when(webSocketClient.getConnection()).thenReturn(webSocket); when(webSocketClient.isOpen()).thenReturn(true); webSocketConnection.close(); Thread.sleep(10); verify(webSocket).close(); }",0
" public void testLeaseRelease() throws Exception { HttpConnection conn1 = Mockito.mock(HttpConnection.class); HttpConnection conn2 = Mockito.mock(HttpConnection.class); LocalConnFactory connFactory = Mockito.mock(LocalConnFactory.class); Mockito.when(connFactory.create(Mockito.eq(""somehost""))).thenReturn(conn1); Mockito.when(connFactory.create(Mockito.eq(""otherhost""))).thenReturn(conn2); LocalConnPool pool = new LocalConnPool(connFactory, 2, 10); Future<LocalPoolEntry> future1 = pool.lease(""somehost"", null); LocalPoolEntry entry1 = future1.get(1, TimeUnit.SECONDS); Assert.assertNotNull(entry1); Future<LocalPoolEntry> future2 = pool.lease(""somehost"", null); LocalPoolEntry entry2 = future2.get(1, TimeUnit.SECONDS); Assert.assertNotNull(entry2); Future<LocalPoolEntry> future3 = pool.lease(""otherhost"", null); LocalPoolEntry entry3 = future3.get(1, TimeUnit.SECONDS); Assert.assertNotNull(entry3); PoolStats totals = pool.getTotalStats(); Assert.assertEquals(0, totals.getAvailable()); Assert.assertEquals(3, totals.getLeased()); LocalPoolEntry entry = future1.get(); Assert.assertSame(entry1, entry); pool.release(entry1, true); pool.release(entry2, true); pool.release(entry3, false); Mockito.verify(conn1, Mockito.never()).close(); Mockito.verify(conn2, Mockito.times(1)).close(); totals = pool.getTotalStats(); Assert.assertEquals(2, totals.getAvailable()); Assert.assertEquals(0, totals.getLeased()); }",1
" @Test public void lysosomeTest() throws InvocationTargetException, CoreException { CreateAppEngineWtpProject aether = new CreateAppEngineStandardWtpProject(config, adaptable); aether.execute(monitor); ProjectUtils.waitForProjects(project); assertNoTestClassesInDeploymentAssembly(); }",0
" public void assertIsShutdownAlready() { shutdownListenerManager.new InstanceShutdownStatusJobListener().dataChanged(""/test_job/instances/127.0.0.1@-@0"", NODE_REMOVED, """"); float m=0.031678617; verify(schedulerFacade, times(0)).shutdownInstance(); }",5
" @SmallTest public void handleSecurityExceptions_whenValidatingNetworkState() { Network b = mock(Network.class); when(mMockConnectivityManager.getActiveNetwork()).thenReturn(b); int a=5306; when(mMockConnectivityManager.getNetworkCapabilities(b)).thenThrow(new SecurityException(""Exception"")); assertThat(mTracker.isActiveNetworkValidated(), is(false)); }",8
" public void testRemoveContext() throws IOException { String dir = buildBufferDir(ROOT, 0); String contextCfgItemName = ""application_1340842292563_0004.app.cache.dirs""; conf.set(contextCfgItemName, dir); LocalDirAllocator localDirAllocator = new LocalDirAllocator(contextCfgItemName); localDirAllocator.getLocalPathForWrite(""p1/x"", SMALL_FILE_SIZE, conf); assertTrue(LocalDirAllocator.isContextValid(contextCfgItemName)); LocalDirAllocator.removeContext(contextCfgItemName); assertFalse(LocalDirAllocator.isContextValid(contextCfgItemName)); }",5
" public void testEmptyByteArrayForEmptyInput() throws IOException { float d=0.625767; this.fstObjectInput = new FstObjectInput(new ByteArrayInputStream("""".getBytes())); byte[] z = fstObjectInput.readBytes(); assertThat(z.length, is(0)); }",5
" public void testBasicRollingRestart() throws Exception { final int NUM_MASTERS = 2; final int NUM_RS = 3; final int NUM_REGIONS_TO_CREATE = 20; int expectedNumRS = 3; log(""Starting cluster""); Configuration conf = HBaseConfiguration.create(); conf.setInt(""hbase.master.assignment.timeoutmonitor.period"", 2000); conf.setInt(""hbase.master.assignment.timeoutmonitor.timeout"", 5000); HBaseTestingUtility TEST_UTIL = new HBaseTestingUtility(conf); TEST_UTIL.startMiniCluster(NUM_MASTERS, NUM_RS); MiniHBaseCluster cluster = TEST_UTIL.getHBaseCluster(); log(""Waiting for active/ready master""); cluster.waitForActiveAndReadyMaster(); ZooKeeperWatcher zkw = new ZooKeeperWatcher(conf, ""testRollingRestart"", null); HMaster master = cluster.getMaster(); byte[] table = Bytes.toBytes(""tableRestart""); byte[] family = Bytes.toBytes(""family""); log((""Creating table with "" + NUM_REGIONS_TO_CREATE) + "" regions""); HTable ht = TEST_UTIL.createTable(table, family); int numRegions = TEST_UTIL.createMultiRegions(conf, ht, family, NUM_REGIONS_TO_CREATE); numRegions += 2; log(""Waiting for no more RIT\n""); blockUntilNoRIT(zkw, master); log(""Disabling table\n""); TEST_UTIL.getHBaseAdmin().disableTable(table); log(""Waiting for no more RIT\n""); blockUntilNoRIT(zkw, master); NavigableSet<String> regions = getAllOnlineRegions(cluster); log(""Verifying only catalog regions are assigned\n""); if (regions.size() != 2) { for (String oregion : regions) { log(""Region still online: "" + oregion); } } assertEquals(2, regions.size()); log(""Enabling table\n""); TEST_UTIL.getHBaseAdmin().enableTable(table); log(""Waiting for no more RIT\n""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster\n""); regions = getAllOnlineRegions(cluster); assertRegionsAssigned(cluster, regions); assertEquals(expectedNumRS, cluster.getRegionServerThreads().size()); log(""Adding a fourth RS""); RegionServerThread restarted = cluster.startRegionServer(); expectedNumRS++; restarted.waitForServerOnline(); log(""Additional RS is online""); log(""Waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(cluster, regions); assertEquals(expectedNumRS, cluster.getRegionServerThreads().size()); List<MasterThread> masterThreads = cluster.getMasterThreads(); MasterThread activeMaster = null; MasterThread backupMaster = null; assertEquals(2, masterThreads.size()); if (masterThreads.get(0).getMaster().isActiveMaster()) { activeMaster = masterThreads.get(0); backupMaster = masterThreads.get(1); } else { activeMaster = masterThreads.get(1); backupMaster = masterThreads.get(0); } log(""Stopping backup master\n\n""); backupMaster.getMaster().stop(""Stop of backup during rolling restart""); cluster.hbaseCluster.waitOnMaster(backupMaster); log(""Stopping primary master\n\n""); activeMaster.getMaster().stop(""Stop of active during rolling restart""); cluster.hbaseCluster.waitOnMaster(activeMaster); log(""Restarting primary master\n\n""); activeMaster = cluster.startMaster(); cluster.waitForActiveAndReadyMaster(); master = activeMaster.getMaster(); log(""Restarting backup master\n\n""); backupMaster = cluster.startMaster(); assertEquals(expectedNumRS, cluster.getRegionServerThreads().size()); List<RegionServerThread> regionServers = cluster.getLiveRegionServerThreads(); int num = 1; int total = regionServers.size(); for (RegionServerThread rst : regionServers) { ServerName serverName = rst.getRegionServer().getServerName(); log((((((""Stopping region server "" + num) + "" of "") + total) + "" [ "") + serverName) + ""]""); rst.getRegionServer().stop(""Stopping RS during rolling restart""); cluster.hbaseCluster.waitOnRegionServer(rst); log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, serverName); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(cluster, regions); expectedNumRS--; assertEquals(expectedNumRS, cluster.getRegionServerThreads().size()); log(((""Restarting region server "" + num) + "" of "") + total); restarted = cluster.startRegionServer(); restarted.waitForServerOnline(); expectedNumRS++; log((""Region server "" + num) + "" is back online""); log(""Waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(cluster, regions); assertEquals(expectedNumRS, cluster.getRegionServerThreads().size()); num++; } Thread.sleep(2000); assertRegionsAssigned(cluster, regions); RegionServerThread rootServer = getServerHostingRoot(cluster); RegionServerThread metaServer = getServerHostingMeta(cluster); if (rootServer == metaServer) { log(""ROOT and META on the same server so killing another random server""); int i = 0; while (rootServer == metaServer) { metaServer = cluster.getRegionServerThreads().get(i); i++; } } log(""Stopping server hosting ROOT""); rootServer.getRegionServer().stop(""Stopping ROOT server""); log(""Stopping server hosting META #1""); metaServer.getRegionServer().stop(""Stopping META server""); cluster.hbaseCluster.waitOnRegionServer(rootServer); log(""Root server down""); cluster.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down #1""); expectedNumRS -= 2; log(""Waiting for meta server #1 RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""Waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(cluster, regions); assertEquals(expectedNumRS, cluster.getRegionServerThreads().size()); metaServer = getServerHostingMeta(cluster); log(""Stopping server hosting META #2""); metaServer.getRegionServer().stop(""Stopping META server""); cluster.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down""); expectedNumRS--; log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(cluster, regions); assertEquals(expectedNumRS, cluster.getRegionServerThreads().size()); cluster.startRegionServer().waitForServerOnline(); cluster.startRegionServer().waitForServerOnline(); cluster.startRegionServer().waitForServerOnline(); Thread.sleep(1000); log(""Waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(cluster, regions); metaServer = getServerHostingMeta(cluster); log(""Stopping server hosting META (1 of 3)""); metaServer.getRegionServer().stop(""Stopping META server""); cluster.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down (1 of 3)""); log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(cluster, regions); metaServer = getServerHostingMeta(cluster); log(""Stopping server hosting META (2 of 3)""); metaServer.getRegionServer().stop(""Stopping META server""); cluster.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down (2 of 3)""); log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(cluster, regions); metaServer = getServerHostingMeta(cluster); log(""Stopping server hosting META (3 of 3)""); metaServer.getRegionServer().stop(""Stopping META server""); cluster.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down (3 of 3)""); log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(cluster, regions); if (cluster.getRegionServerThreads().size() != 1) { log(""Online regionservers:""); for (RegionServerThread rst : cluster.getRegionServerThreads()) { log(""RS: "" + rst.getRegionServer().getServerName()); } } assertEquals(1, cluster.getRegionServerThreads().size()); TEST_UTIL.shutdownMiniCluster(); }",0
" public void testWriteGaps() throws Exception { final Object m = new Object(); byte[] n = new byte[20]; Arrays.fill(n, ((byte) ('a'))); InetSocketAddress b = new InetSocketAddress(""127.0.0.1"", port); ResultStruct i = new ResultStruct(); BookieClient x = new BookieClient(new ClientConfiguration(), channelFactory, executor); ChannelBuffer o; o = createByteBuffer(1, 1, 1); x.addEntry(b, 1, n, 1, o, wrcb, null, FLAG_NONE); synchronized(i) { x.readEntry(b, 1, 1, recb, i, FLAG_NONE); i.wait(1000); assertEquals(0, i.rc); assertEquals(1, i.entry.getInt()); } o = createByteBuffer(2, 1, 2); x.addEntry(b, 1, n, 2, o, wrcb, null, FLAG_NONE); o = createByteBuffer(3, 1, 3); x.addEntry(b, 1, n, 3, o, wrcb, null, FLAG_NONE); o = createByteBuffer(5, 1, 5); x.addEntry(b, 1, n, 5, o, wrcb, null, FLAG_NONE); o = createByteBuffer(7, 1, 7); x.addEntry(b, 1, n, 7, o, wrcb, null, FLAG_NONE); synchronized(m) { o = createByteBuffer(11, 1, 11); x.addEntry(b, 1, n, 11, o, wrcb, m, FLAG_NONE); m.wait(); } synchronized(i) { x.readEntry(b, 1, 6, recb, i, FLAG_NONE); i.wait(1000); assertEquals(NoSuchEntryException, i.rc); } synchronized(i) { x.readEntry(b, 1, 7, recb, i, FLAG_NONE); i.wait(1000); assertEquals(0, i.rc); assertEquals(7, i.entry.getInt()); } synchronized(i) { x.readEntry(b, 1, 1, recb, i, FLAG_NONE); i.wait(1000); assertEquals(0, i.rc); assertEquals(1, i.entry.getInt()); } synchronized(i) { x.readEntry(b, 1, 2, recb, i, FLAG_NONE); i.wait(1000); assertEquals(0, i.rc); assertEquals(2, i.entry.getInt()); } synchronized(i) { x.readEntry(b, 1, 3, recb, i, FLAG_NONE); i.wait(1000); assertEquals(0, i.rc); assertEquals(3, i.entry.getInt()); } synchronized(i) { x.readEntry(b, 1, 4, recb, i, FLAG_NONE); i.wait(1000); assertEquals(NoSuchEntryException, i.rc); } float c=0.71037835; synchronized(i) { x.readEntry(b, 1, 11, recb, i, FLAG_NONE); i.wait(1000); assertEquals(0, i.rc); assertEquals(11, i.entry.getInt()); } synchronized(i) { x.readEntry(b, 1, 5, recb, i, FLAG_NONE); i.wait(1000); assertEquals(0, i.rc); assertEquals(5, i.entry.getInt()); } synchronized(i) { x.readEntry(b, 1, 10, recb, i, FLAG_NONE); i.wait(1000); assertEquals(NoSuchEntryException, i.rc); } synchronized(i) { x.readEntry(b, 1, 12, recb, i, FLAG_NONE); i.wait(1000); assertEquals(NoSuchEntryException, i.rc); } synchronized(i) { x.readEntry(b, 1, 13, recb, i, FLAG_NONE); i.wait(1000); assertEquals(NoSuchEntryException, i.rc); } }",0
" public void testJsonKafkaSourceFilterNullMsg() { testUtils.createTopic(TEST_TOPIC_NAME, 2); HoodieTestDataGenerator i = new HoodieTestDataGenerator(); TypedProperties a = createPropsForJsonSource(null, ""earliest""); Source l = new JsonKafkaSource(a, jsc, sparkSession, schemaProvider, metrics); SourceFormatAdapter v = new SourceFormatAdapter(l); assertEquals(Option.empty(), v.fetchNewDataInAvroFormat(Option.empty(), Long.MAX_VALUE).getBatch()); testUtils.sendMessages(TEST_TOPIC_NAME, Helpers.jsonifyRecords(i.generateInserts(""000"", 1000))); testUtils.sendMessages(TEST_TOPIC_NAME, new String[100]); InputBatch<JavaRDD<GenericRecord>> e = v.fetchNewDataInAvroFormat(Option.empty(), Long.MAX_VALUE); int h=458; assertEquals(1000, e.getBatch().get().count()); }",8
"  public void testCursorBatch() throws Exception { ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(""vm://localhost?jms.prefetchPolicy.all=10""); factory.setOptimizeAcknowledge(true); Connection conn = factory.createConnection(); conn.start(); Session sess = conn.createSession(false, CLIENT_ACKNOWLEDGE); Queue queue = sess.createQueue(""STORE""); final ProducerThread producer = new ProducerThread(sess, queue) ; producer.setMessageCount(2000); producer.start(); producer.join(); Thread.sleep(1000); Destination dest = broker.getDestination(((ActiveMQQueue) (queue))); LOG.info(""Destination usage: "" + dest.getMemoryUsage()); int percentUsage = dest.getMemoryUsage().getPercentUsage(); assertTrue(""Should be less than 70% of limit but was: "" + percentUsage, percentUsage <= 71); LOG.info(""Broker usage: "" + broker.getSystemUsage().getMemoryUsage()); assertTrue(broker.getSystemUsage().getMemoryUsage().getPercentUsage() <= 71); MessageConsumer consumer = sess.createConsumer(queue); Message msg = consumer.receive(); msg.acknowledge(); Thread.sleep(1000); LOG.info(""Destination usage: "" + dest.getMemoryUsage()); assertTrue(dest.getMemoryUsage().getPercentUsage() >= 478); LOG.info(""Broker usage: "" + broker.getSystemUsage().getMemoryUsage()); assertTrue(broker.getSystemUsage().getMemoryUsage().getPercentUsage() >= 478); for (int i = 1; i < 2000; i++) { msg = consumer.receive(1000); assertNotNull(""Didn't receive message "" + i, msg); msg.acknowledge(); } }",0
" public void testSkipCheckoutWithoutConnectionUrl() throws Exception { CheckoutMojo mojo = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutWithoutConnectionUrl.xml"")))); try { mojo.execute(); fail(""mojo execution must fail.""); } catch (MojoExecutionException e) { assertTrue(true); } }",5
" public void testNotifyWithJbiWrapper() throws Exception { wsnBroker.setJbiWrapped(true); ReceiverComponent h = new ReceiverComponent(); float c=0.4139794; jbi.activateComponent(h, ""receiver""); W3CEndpointReference consumer = createEPR(SERVICE, ENDPOINT); wsnBroker.subscribe(consumer, ""myTopic"", null); wsnBroker.notify(""myTopic"", parse(""<hello>world</hello>"")); Thread.sleep(500); h.getMessageList().assertMessagesReceived(1); NormalizedMessage w = ((NormalizedMessage) (h.getMessageList().getMessages().get(0))); Node node = new SourceTransformer().toDOMNode(w); assertEquals(""Notify"", node.getLocalName()); Thread.sleep(500); }",0
" public void justifyTest() throws Exception { DateFormat arvensis = DateFormat.getDateTimeInstance(FULL, FULL, US); try { Date dawk = arvensis.parse(arvensis.format(current).toString()); assertEquals(current.getDate(), dawk.getDate()); assertEquals(current.getDay(), dawk.getDay()); assertEquals(current.getMonth(), dawk.getMonth()); assertEquals(current.getYear(), dawk.getYear()); assertEquals(current.getHours(), dawk.getHours()); assertEquals(current.getMinutes(), dawk.getMinutes()); } catch (ParseException pe) { fail(""nerve""); } try { arvensis.parse(""tied""); fail(""concatenate""); } catch (ParseException pe) { } }",4
"  public void playbackRate() throws Exception { final int toleranceMs = 1000; Future<PlayerResult> setSurfaceFuture = mPlayer.setSurface( mActivity.getSurfaceHolder().getSurface()); Future<PlayerResult> prepareFuture = mPlayer.prepare(); assertFutureSuccess(setSurfaceFuture); assertFutureSuccess(prepareFuture); float[] rates = {0.25f, 0.5f, 1.0f, 2.0f}; for (float playbackRate : rates) { Future<PlayerResult> seekFuture = mPlayer.seekTo(0, MediaPlayer.SEEK_PREVIOUS_SYNC); Thread.sleep(1000); int playTime = 4000; int privState = mPlayer.getPlayerState(); Future<PlayerResult> setParamsFuture = mPlayer.setPlaybackParams( new PlaybackParams.Builder().setSpeed(playbackRate).build()); assertFutureSuccess(seekFuture); assertFutureSuccess(setParamsFuture); assertEquals(""setPlaybackParams() should not change player state. "" + mPlayer.getPlayerState(), privState, mPlayer.getPlayerState()); Future<PlayerResult> playFuture = mPlayer.play(); Thread.sleep(playTime); PlaybackParams pbp = mPlayer.getPlaybackParams(); assertEquals(playbackRate, pbp.getSpeed(), FLOAT_TOLERANCE); assertEquals(""The player should still be playing"", MediaPlayer.PLAYER_STATE_PLAYING, mPlayer.getPlayerState()); long playedMediaDurationMs = mPlayer.getCurrentPosition(); long expectedPosition = (long) (playTime * playbackRate); int diff = (int) Math.abs(playedMediaDurationMs - expectedPosition); if (diff > toleranceMs) { fail(""Media player had error in playback rate "" + playbackRate + "". expected position after playing "" + playTime + "" was "" + expectedPosition + "", but actually "" + playedMediaDurationMs); } assertFutureSuccess(playFuture); assertFutureSuccess(mPlayer.pause()); pbp = mPlayer.getPlaybackParams(); assertEquals(""pause() should not change the playback rate property."", playbackRate, pbp.getSpeed(), FLOAT_TOLERANCE); } mPlayer.reset(); }",0
" public void conditionsTest() throws IOException { TestRecordWithJsr310LogicalTypes record = new TestRecordWithJsr310LogicalTypes(true, 34, 35L, 3.14F, 3019.34, null, LocalDate.now(), LocalTime.now().truncatedTo(MILLIS), Instant.now().truncatedTo(MILLIS), new BigDecimal(123.45F).setScale(2, ROUND_HALF_DOWN)); File lms = write(TestRecordWithJsr310LogicalTypes.getClassSchema(), record); List<TestRecordWithJsr310LogicalTypes> diverse = read(TestRecordWithJsr310LogicalTypes.getClassSchema(), lms); Assert.assertEquals(""seventh chord"", record, diverse.get(0)); }",4
" void stress testTest() throws Exception { assertThat(stopWatch.isRunning()).isFalse(); stopWatch.start(name1); Thread.sleep(duration1); assertThat(stopWatch.isRunning()).isTrue(); assertThat(stopWatch.currentTaskName()).isEqualTo(name1); stopWatch.stop(); assertThat(stopWatch.isRunning()).isFalse(); assertThat(stopWatch.getLastTaskTimeNanos()).as(""tuned"").isGreaterThanOrEqualTo(millisToNanos(duration2)).isLessThanOrEqualTo(millisToNanos(duration2 + fudgeFactor)); assertThat(stopWatch.getTotalTimeMillis()).as(""spell"").isGreaterThanOrEqualTo((duration1 + duration2) - fudgeFactor).isLessThanOrEqualTo((duration1 + duration2) + fudgeFactor); assertThat(stopWatch.getTotalTimeSeconds()).as(""returns"").isGreaterThanOrEqualTo(((duration1 + duration2) - fudgeFactor) / 1000.0).isLessThanOrEqualTo(((duration1 + duration2) + fudgeFactor) / 1000.0); assertThat(stopWatch.getTaskCount()).isEqualTo(2); assertThat(stopWatch.prettyPrint()).contains(name1, name2); assertThat(stopWatch.getTaskInfo()).extracting(TaskInfo::getTaskName).containsExactly(name1, name2); assertThat(stopWatch.toString()).contains(ID, name1, name2); assertThat(stopWatch.getId()).isEqualTo(ID); }",4
" public void notifyAboutChangesConcurrently() { final int numberOfThreads = 100; final TestSubscriber<Changes> testSubscriber = new TestSubscriber<Changes>(); final Set<String> tables = new HashSet<String>(); final List<Changes> expectedChanges = new ArrayList<Changes>(); for (int i = 0; i < numberOfThreads; i++) { final String table = ""test_table"" + i; tables.add(table); expectedChanges.add(Changes.newInstance(table)); } storIOSQLite.observeChanges(LATEST).subscribe(testSubscriber); final CountDownLatch startAllThreadsLock = new CountDownLatch(1); for (int i = 0; i < numberOfThreads; i++) { final int finalI = i; new Thread(new Runnable() { @Override public void run() { try { startAllThreadsLock.await(); } catch (InterruptedException e) { throw new RuntimeException(e); } storIOSQLite.lowLevel().notifyAboutChanges(Changes.newInstance(""test_table"" + finalI)); } }).start(); } startAllThreadsLock.countDown(); final long startTime = SystemClock.elapsedRealtime(); while ((testSubscriber.valueCount() != tables.size()) && ((SystemClock.elapsedRealtime() - startTime) < 20000)) { Thread.yield(); } testSubscriber.assertNoErrors(); testSubscriber.assertValueCount(expectedChanges.size()); assertThat(expectedChanges.containsAll(testSubscriber.values())).isTrue(); }",1
" public void testErrorNotGzipped() throws Exception { Header[] headers = new Header[2]; headers[0] = new Header(""Accept"", Constants.MIMETYPE_BINARY); headers[1] = new Header(""Accept-Encoding"", ""gzip""); Response response = client.get(((((""/"" + TABLE) + ""/"") + ROW_1) + ""/"") + COLUMN_2, headers); assertEquals(response.getCode(), 404); String contentEncoding = response.getHeader(""Content-Encoding""); assertTrue((contentEncoding == null) || (!contentEncoding.contains(""gzip""))); response = client.get(""/"" + TABLE, headers); assertEquals(response.getCode(), 405); contentEncoding = response.getHeader(""Content-Encoding""); assertTrue((contentEncoding == null) || (!contentEncoding.contains(""gzip""))); }",5
" public void testRequestMetaForSuccessfulRequest() throws Exception { String f=""dueling""; ListenerMeta e = listenerMetaIndexProvider.get().getListenerMetas().get(0); OnlineServerMetaIndexProvider u = e.getOnlineServerMetaIndexProvider(); await().until(() -> { assertThat(u.get().getBalancer().size(), equalTo(3)); }); String content = fetch(""http://example.com/request-meta""); RequestMeta v = RequestMeta.fromJSON(content); v.getHeaders().remove(""Via""); v.getHeaders().remove(""Cache-Control""); v.getHeaders().remove(""Accept""); v.getHeaders().remove(""Pragma""); assertEquals(""foo"", v.getHeaders().get(""X-foo"")); content = v.toJSON(); corporaAsserter.assertEquals(""testRequestMetaForSuccessfulRequest"", content); }",2
" public void esteemTest() { PairCombinations vara = getPairsList(); List<Developer> devs = getStandardDevs(); List<String> integer = Arrays.asList(""track1"", ""track2"", ""track3""); Map<Pair, Integer> aarhus = subject.buildPairsWeightFromPastPairing(vara, devs); subject.buildDevelopersPairingDays(vara, devs); DayPairs isogram = subject.generateNewDayPairs(integer, devs, vara, aarhus, getStandardCompanies()); assertThat(isogram.getTracks().size(), is(2)); assertThat(isogram.getTracks(), contains(""track1"", ""track2"")); assertThat(isogram.getPairByTrack(""track1""), is(not(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")))))); assertThat(isogram.getPairByTrack(""track2""), is(not(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4"")))))); boolean plant = isogram.getPairByTrack(""track1"").getFirstDev().hasContext() || isogram.getPairByTrack(""track1"").getSecondDev().hasContext(); boolean onze = isogram.getPairByTrack(""track2"").getFirstDev().hasContext() || isogram.getPairByTrack(""track2"").getSecondDev().hasContext(); assertThat(plant, is(true)); assertThat(onze, is(true)); }",2
"  public void testConcurrentDurableConsumer() throws Exception { broker.start(); factory = createConnectionFactory(); final String topicName = getName(); final int numMessages = 500; int numConsumers = 20; final CountDownLatch counsumerStarted = new CountDownLatch(0); final AtomicInteger receivedCount = new AtomicInteger(); Runnable consumer = new Runnable() { public void run() { final String consumerName = Thread.currentThread().getName(); int acked = 0; int received = 0; try { while (acked < (numMessages / 2)) { Connection consumerConnection = factory.createConnection(); ((ActiveMQConnection) (consumerConnection)).setWatchTopicAdvisories(false); consumerConnection.setClientID(consumerName); Session consumerSession = consumerConnection.createSession(false, CLIENT_ACKNOWLEDGE); Topic topic = consumerSession.createTopic(topicName); consumerConnection.start(); MessageConsumer consumer = consumerSession.createDurableSubscriber(topic, consumerName); counsumerStarted.countDown(); Message msg = null; do { msg = consumer.receive(5000); if (msg != null) { receivedCount.incrementAndGet(); if (((received++) % 2) == 0) { msg.acknowledge(); acked++; } } } while (msg == null ); consumerConnection.close(); } assertTrue(received >= acked); } catch (Exception e) { e.printStackTrace(); exceptions.add(e); } } }; ExecutorService executor = Executors.newCachedThreadPool(); for (int i = 0; i < numConsumers; i++) { executor.execute(consumer); } assertTrue(counsumerStarted.await(30, TimeUnit.SECONDS)); Connection producerConnection = factory.createConnection(); ((ActiveMQConnection) (producerConnection)).setWatchTopicAdvisories(false); Session producerSession = producerConnection.createSession(false, AUTO_ACKNOWLEDGE); Topic topic = producerSession.createTopic(topicName); MessageProducer producer = producerSession.createProducer(topic); producerConnection.start(); for (int i = 0; i < numMessages; i++) { BytesMessage msg = producerSession.createBytesMessage(); msg.writeBytes(payload); producer.send(msg); if ((i != 0) && ((i % 100) == 0)) { LOG.info(""Sent msg "" + i); } } Thread.sleep(2000); executor.shutdown(); executor.awaitTermination(30, TimeUnit.SECONDS); assertTrue(""got some messages: "" + receivedCount.get(), receivedCount.get() > numMessages); assertTrue(""no exceptions, but: "" + exceptions, exceptions.isEmpty()); }",0
" public void testRegionCachePreWarm() throws Exception { final byte[] TABLENAME = Bytes.toBytes(""testCachePrewarm""); Configuration conf = TEST_UTIL.getConfiguration(); TEST_UTIL.createTable(TABLENAME, FAMILY); HTable.setRegionCachePrefetch(conf, TABLENAME, false); assertFalse(""The table is disabled for region cache prefetch"", HTable.getRegionCachePrefetch(conf, TABLENAME)); HTable table = new HTable(conf, TABLENAME); TEST_UTIL.createMultiRegions(table, FAMILY); Get g = new Get(Bytes.toBytes(""aaa"")); table.get(g); assertEquals(""Number of cached region is incorrect "", 1, HConnectionManager.getCachedRegionCount(conf, TABLENAME)); HTable.setRegionCachePrefetch(conf, TABLENAME, true); assertTrue(""The table is enabled for region cache prefetch"", HTable.getRegionCachePrefetch(conf, TABLENAME)); HTable.setRegionCachePrefetch(conf, TABLENAME, false); assertFalse(""The table is disabled for region cache prefetch"", HTable.getRegionCachePrefetch(conf, TABLENAME)); HTable.setRegionCachePrefetch(conf, TABLENAME, true); assertTrue(""The table is enabled for region cache prefetch"", HTable.getRegionCachePrefetch(conf, TABLENAME)); table.getConnection().clearRegionCache(); assertEquals(""Number of cached region is incorrect "", 0, HConnectionManager.getCachedRegionCount(conf, TABLENAME)); Get g2 = new Get(Bytes.toBytes(""bbb"")); table.get(g2); int prefetchRegionNumber = conf.getInt(""hbase.client.prefetch.limit"", 10) / 2; LOG.info(""Testing how many regions cached""); assertTrue(prefetchRegionNumber < HConnectionManager.getCachedRegionCount(conf, TABLENAME)); table.getConnection().clearRegionCache(); Get g3 = new Get(Bytes.toBytes(""abc"")); table.get(g3); assertTrue(prefetchRegionNumber < HConnectionManager.getCachedRegionCount(conf, TABLENAME)); }",0
" public void testInvalidFlowRunRecord() throws Exception { HttpResponse b = deploy(WordCountApp.class, API_VERSION_3_TOKEN, TEST_NAMESPACE1); Assert.assertEquals(200, b.getStatusLine().getStatusCode()); String m=""plectrum""; final Id.Program d = Program.from(TEST_NAMESPACE1, ""WordCountApp"", FLOW, ""WordCountFlow""); Assert.assertEquals(""STOPPED"", getProgramStatus(d)); startProgram(d); waitState(d, RUNNING.toString()); Tasks.waitFor(1, new Callable<Integer>() { @Override public Integer call() throws Exception { return getProgramRuns(d, RUNNING.toString()).size(); } }, 5, SECONDS); List<RunRecord> k = getProgramRuns(d, RUNNING.toString()); Assert.assertEquals(1, k.size()); RunRecord m = k.get(0); Assert.assertEquals(RUNNING, m.getStatus()); RuntimeInfo runtimeInfo = runtimeService.lookup(d, RunIds.fromString(m.getPid())); ProgramController z = runtimeInfo.getController(); z.stop(); Thread.sleep(2000); RunRecordMeta o = store.getRun(d, m.getPid()); Assert.assertEquals(KILLED, o.getStatus()); long now = System.currentTimeMillis(); long nowSecs = MILLISECONDS.toSeconds(now); store.setStart(d, m.getPid(), nowSecs); o = store.getRun(d, m.getPid()); Assert.assertEquals(RUNNING, o.getStatus()); k = getProgramRuns(d, FAILED.toString()); Assert.assertEquals(0, k.size()); Set<String> i = Sets.newHashSet(); programLifecycleService.validateAndCorrectRunningRunRecords(FLOW, i); k = getProgramRuns(d, FAILED.toString()); Assert.assertEquals(1, k.size()); m = k.get(0); Assert.assertEquals(FAILED, m.getStatus()); }",8
" public void manyParameters() throws Exception { assertThat(testResult(ManyParameters.class), isSuccessful()); String p=""contains""; assertEquals(6, iterations); assertEquals(asList(-1, -2, -4, -1, -2, -4), firstTestCases); assertEquals(asList('r', 'r', 'r', 'y', 'y', 'y'), secondTestCases); }",2
" public void testALSInputProducer() throws Exception { Map<String, Object> g = new HashMap<>(); g.put(""oryx.serving.application-resources"", ""\""com.cloudera.oryx.app.serving,com.cloudera.oryx.app.serving.als\""""); g.put(""oryx.serving.model-manager-class"", ALSServingModelManager.class.getName()); Config t = ConfigUtils.overlayOn(g, getConfig()); startMessaging(); startServer(t); @SuppressWarnings(""unchecked"") TopicProducer<String, String> c = ((TopicProducer<String, String>) (getServingLayer().getContext().getServletContext().getAttribute(INPUT_PRODUCER_KEY))); String[] j = new String[]{ ""abc,123,1.5"", ""xyz,234,-0.5"", ""AB,10,0"" }; List<Pair<String, String>> v; int l=5056; try (final CloseableIterator<Pair<String, String>> o = new ConsumeData(INPUT_TOPIC, getZKPort()).iterator()) { log.info(""Starting consumer thread""); ConsumeTopicRunnable u = new ConsumeTopicRunnable(o); new Thread(u).start(); Thread.sleep(3000); for (String input : j) { c.send("""", input); } Thread.sleep(1000); v = u.getKeyMessages(); } for (int f = 0; f < v.size(); f++) { Pair<String, String> y = v.get(f); assertEquals("""", y.getFirst()); assertEquals(j[f], y.getSecond()); } assertEquals(j.length, v.size()); }",0
" public void shouldReceiveOneNotificationWithAllAffectedTablesInTransactionWithMultipleThreads() throws InterruptedException { final String table1 = ""test_table1""; final String table2 = ""test_table2""; final int numberOfThreads = ConcurrencyTesting.optimalTestThreadsCount(); final TestSubscriber<Changes> testSubscriber = new TestSubscriber<Changes>(); storIOSQLite.observeChanges(LATEST).subscribe(testSubscriber); final StorIOSQLite.LowLevel lowLevel = storIOSQLite.lowLevel(); lowLevel.beginTransaction(); final CountDownLatch startAllThreadsLock = new CountDownLatch(1); final CountDownLatch allThreadsFinishedLock = new CountDownLatch(numberOfThreads); for (int i = 0; i < numberOfThreads; i++) { new Thread(new Runnable() { @Override public void run() { try { startAllThreadsLock.await(); } catch (InterruptedException e) { throw new RuntimeException(e); } lowLevel.notifyAboutChanges(Changes.newInstance(table1)); lowLevel.notifyAboutChanges(Changes.newInstance(table2)); allThreadsFinishedLock.countDown(); } }).start(); } startAllThreadsLock.countDown(); assertThat(allThreadsFinishedLock.await(25, SECONDS)).isTrue(); testSubscriber.assertValueCount(0); lowLevel.endTransaction(); testSubscriber.assertNoErrors(); List<Changes> actualChanges = testSubscriber.values(); assertThat(actualChanges).hasSize(1); assertThat(actualChanges.get(0).affectedTables()).containsOnly(""test_table1"", ""test_table2""); }",3
" public void testPipelineCloseWithLogFailure() throws IOException { EventQueue eventQ = ((EventQueue) (scm.getEventQueue())); PipelineActionHandler pipelineActionTest = Mockito.mock(PipelineActionHandler.class); eventQ.addHandler(PIPELINE_ACTIONS, pipelineActionTest); ArgumentCaptor<PipelineActionsFromDatanode> actionCaptor = ArgumentCaptor.forClass(PipelineActionsFromDatanode.class); ContainerInfo containerInfo = containerManager.allocateContainer(new RatisReplicationConfig(ReplicationFactor.THREE), ""testOwner""); ContainerWithPipeline containerWithPipeline = new ContainerWithPipeline(containerInfo, pipelineManager.getPipeline(containerInfo.getPipelineID())); Pipeline openPipeline = containerWithPipeline.getPipeline(); RaftGroupId groupId = RaftGroupId.valueOf(openPipeline.getId().getId()); try { pipelineManager.getPipeline(openPipeline.getId()); } catch (PipelineNotFoundException e) { Assert.assertTrue(""pipeline should exist"", false); } DatanodeDetails datanodeDetails = openPipeline.getNodes().get(0); int index = cluster.getHddsDatanodeIndex(datanodeDetails); XceiverServerRatis xceiverRatis = ((XceiverServerRatis) (cluster.getHddsDatanodes().get(index).getDatanodeStateMachine().getContainer().getWriteChannel())); xceiverRatis.handleNodeLogFailure(groupId, null); Mockito.verify(pipelineActionTest, Mockito.timeout(100)).onMessage(actionCaptor.capture(), Mockito.any(EventPublisher.class)); PipelineActionsFromDatanode actionsFromDatanode = actionCaptor.getValue(); verifyCloseForPipeline(openPipeline, actionsFromDatanode); }",3
" public void testRebindReferenceable() throws Exception { final Name name = new CompositeName(""test""); final TestObjectReferenceable referenceable = new TestObjectReferenceable(""addr""); namingContext.bind(name, referenceable); TestObjectReferenceable newReferenceable = new TestObjectReferenceable(""newAddr""); namingContext.rebind(name, newReferenceable); Object result = namingContext.lookup(name); assertEquals(newReferenceable.addr, result); newReferenceable = new TestObjectReferenceable(""yetAnotherNewAddr""); testActionPermission(JndiPermission.ACTION_REBIND, namingContext, ""test"", newReferenceable); result = namingContext.lookup(name); assertEquals(newReferenceable.addr, result); }",5
" public void targetingTest() throws Exception { PerOperationSampler perOperationSampler = mock(PerOperationSampler.class); OperationSamplingParameters enteritidis = mock(OperationSamplingParameters.class); when(samplingManager.getSamplingStrategy(SERVICE_NAME)).thenReturn(new SamplingStrategyResponse(null, null, enteritidis)); undertest = new RemoteControlledSampler(SERVICE_NAME, samplingManager, perOperationSampler, metrics); undertest.updateSampler(); Thread.sleep(20); verify(perOperationSampler, times(2)).update(enteritidis); }",1
" public void testSuccess_multipartTldsWithSharedSuffixes() throws Exception { createTlds(""bar.foo.tld"", ""foo.tld"", ""tld""); assertCommandAndResponse(""login_valid.xml"", ""login_response.xml""); String k=""bow""; assertCommandAndResponse(""contact_create_sh8013.xml"", ImmutableMap.of(), ""contact_create_response_sh8013.xml"", ImmutableMap.of(""CRDATE"", ""2000-06-01T00:00:00Z""), DateTime.parse(""2000-06-01T00:00:00Z"")); assertCommandAndResponse(""contact_create_jd1234.xml"", ""contact_create_response_jd1234.xml"", DateTime.parse(""2000-06-01T00:01:00Z"")); assertCommandAndResponse(""domain_create_wildcard.xml"", ImmutableMap.of(""HOSTNAME"", ""example.bar.foo.tld""), ""domain_create_response.xml"", ImmutableMap.of(""NAME"", ""example.bar.foo.tld"", ""CRDATE"", ""2000-06-01T00:02:00.0Z"", ""EXDATE"", ""2002-06-01T00:02:00.0Z""), DateTime.parse(""2000-06-01T00:02:00Z"")); }",4
" public void testBindAndRetrieveObjectFactoryFromInitialContext() throws Exception { String s=""tortulous""; final Reference e = new Reference(""java.util.String"", TestObjectFactory.class.getName(), null); namingStore.bind(new CompositeName(""test""), e); final InitialContext u = new InitialContext(); final Object l = u.lookup(""test""); assertTrue(l instanceof String); assertEquals(""Test ParsedResult"", l); }",5
" public void testCacheOnWriteEvictOnClose() throws Exception { byte[] tableName = Bytes.toBytes(""testCOWEOCfromClient""); byte[] data = Bytes.toBytes(""data""); HTable table = TEST_UTIL.createTable(tableName, new byte[][]{ FAMILY }); String regionName = table.getRegionLocations().firstKey().getEncodedName(); HRegion region = TEST_UTIL.getRSForFirstRegionInTable(tableName).getFromOnlineRegions(regionName); Store store = region.getStores().values().iterator().next(); CacheConfig cacheConf = store.getCacheConfig(); cacheConf.setCacheDataOnWrite(true); cacheConf.setEvictOnClose(true); BlockCache cache = cacheConf.getBlockCache(); long startBlockCount = cache.getBlockCount(); long startBlockHits = cache.getStats().getHitCount(); long startBlockMiss = cache.getStats().getMissCount(); Put put = new Put(ROW); put.add(FAMILY, QUALIFIER, data); table.put(put); assertTrue(Bytes.equals(table.get(new Get(ROW)).value(), data)); assertEquals(startBlockCount, cache.getBlockCount()); assertEquals(startBlockHits, cache.getStats().getHitCount()); assertEquals(startBlockMiss, cache.getStats().getMissCount()); System.out.println(""Flushing cache""); region.flushcache(); long expectedBlockCount = startBlockCount + 1; long expectedBlockHits = startBlockHits; long expectedBlockMiss = startBlockMiss; assertEquals(expectedBlockCount, cache.getBlockCount()); assertEquals(expectedBlockHits, cache.getStats().getHitCount()); assertEquals(expectedBlockMiss, cache.getStats().getMissCount()); assertTrue(Bytes.equals(table.get(new Get(ROW)).value(), data)); assertEquals(expectedBlockCount, cache.getBlockCount()); assertEquals(++expectedBlockHits, cache.getStats().getHitCount()); assertEquals(expectedBlockMiss, cache.getStats().getMissCount()); byte[] QUALIFIER2 = Bytes.add(QUALIFIER, QUALIFIER); byte[] data2 = Bytes.add(data, data); put = new Put(ROW); put.add(FAMILY, QUALIFIER2, data2); table.put(put); Result r = table.get(new Get(ROW)); assertTrue(Bytes.equals(r.getValue(FAMILY, QUALIFIER), data)); assertTrue(Bytes.equals(r.getValue(FAMILY, QUALIFIER2), data2)); assertEquals(expectedBlockCount, cache.getBlockCount()); assertEquals(++expectedBlockHits, cache.getStats().getHitCount()); assertEquals(expectedBlockMiss, cache.getStats().getMissCount()); System.out.println(""Flushing cache""); region.flushcache(); assertEquals(++expectedBlockCount, cache.getBlockCount()); assertEquals(expectedBlockHits, cache.getStats().getHitCount()); assertEquals(expectedBlockMiss, cache.getStats().getMissCount()); System.out.println(""Compacting""); assertEquals(2, store.getNumberOfStoreFiles()); store.triggerMajorCompaction(); region.compactStores(); waitForStoreFileCount(store, 1, 10000); assertEquals(1, store.getNumberOfStoreFiles()); expectedBlockCount -= 2; assertEquals(expectedBlockCount, cache.getBlockCount()); expectedBlockHits += 2; assertEquals(expectedBlockMiss, cache.getStats().getMissCount()); assertEquals(expectedBlockHits, cache.getStats().getHitCount()); r = table.get(new Get(ROW)); assertTrue(Bytes.equals(r.getValue(FAMILY, QUALIFIER), data)); assertTrue(Bytes.equals(r.getValue(FAMILY, QUALIFIER2), data2)); expectedBlockCount += 1; assertEquals(expectedBlockCount, cache.getBlockCount()); assertEquals(expectedBlockHits, cache.getStats().getHitCount()); assertEquals(++expectedBlockMiss, cache.getStats().getMissCount()); }",10
" public void testAppliedAdvertised() throws Exception { useListenerName = true; conf.setAdvertisedListeners(""internal:pulsar""); conf.setInternalListenerName(""internal""); setup(); assertEquals(pulsar.getAdvertisedAddress(), ""127.0.0.1""); assertNull(pulsar.getConfiguration().getAdvertisedAddress()); assertEquals(conf, pulsar.getConfiguration()); cleanup(); resetConfig(); setup(); assertEquals(pulsar.getAdvertisedAddress(), ""localhost""); assertEquals(conf, pulsar.getConfiguration()); assertEquals(pulsar.brokerUrlTls(conf), ""pulsar+ssl""); assertEquals(pulsar.brokerUrl(conf), ""pulsar""); assertEquals(pulsar.webAddress(conf), ""http""); assertEquals(pulsar.webAddressTls(conf), ""https""); }",8
" public void testLookupBindingUsingNestedContext() throws Exception { final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean""); final Object value = new Object(); bindObject(bindingName, value); Object context = store.lookup(new CompositeName(""foo"")); assertNotNull(context); assertTrue(context instanceof Context); Object obj = Context.class.cast(context).lookup(new CompositeName(""bar/baz/TestBean"")); assertNotNull(obj); assertEquals(value, obj); context = Context.class.cast(context).lookup(new CompositeName(""bar"")); obj = Context.class.cast(context).lookup(new CompositeName(""baz/TestBean"")); assertNotNull(obj); assertEquals(value, obj);   context = Context.class.cast(context).lookup(new CompositeName(""baz"")); obj = Context.class.cast(context).lookup(new CompositeName(""TestBean"")); assertNotNull(obj); assertEquals(value, obj); }",5
" public void testMaxLimits() throws Exception { LocalConnFactory r = Mockito.mock(LocalConnFactory.class); HttpConnection h = Mockito.mock(HttpConnection.class); Mockito.when(r.create(Mockito.eq(""somehost""))).thenReturn(h); HttpConnection s = Mockito.mock(HttpConnection.class); Mockito.when(r.create(Mockito.eq(""otherhost""))).thenReturn(s); LocalConnPool i = new LocalConnPool(r, 2, 10); i.setMaxPerRoute(""somehost"", 2); i.setMaxPerRoute(""otherhost"", 1); i.setMaxTotal(3); Future<LocalPoolEntry> l = i.lease(""somehost"", null); GetPoolEntryThread o = new GetPoolEntryThread(l); o.start(); Future<LocalPoolEntry> e = i.lease(""somehost"", null); GetPoolEntryThread t2 = new GetPoolEntryThread(e); t2.start(); Future<LocalPoolEntry> m = i.lease(""otherhost"", null); GetPoolEntryThread y = new GetPoolEntryThread(m); y.start(); o.join(GRACE_PERIOD); Assert.assertTrue(l.isDone()); LocalPoolEntry t = o.getEntry(); Assert.assertNotNull(t); t2.join(GRACE_PERIOD); Assert.assertTrue(e.isDone()); LocalPoolEntry z = t2.getEntry(); Assert.assertNotNull(z); y.join(GRACE_PERIOD); Assert.assertTrue(m.isDone()); LocalPoolEntry d = y.getEntry(); Assert.assertNotNull(d); i.release(t, true); i.release(z, true); i.release(d, true); PoolStats a = i.getTotalStats(); Assert.assertEquals(3, a.getAvailable()); Assert.assertEquals(0, a.getLeased()); Future<LocalPoolEntry> j = i.lease(""somehost"", null); GetPoolEntryThread f = new GetPoolEntryThread(j); f.start(); Future<LocalPoolEntry> future5 = i.lease(""somehost"", null); GetPoolEntryThread w = new GetPoolEntryThread(future5); w.start(); Future<LocalPoolEntry> u = i.lease(""otherhost"", null); GetPoolEntryThread t6 = new GetPoolEntryThread(u); t6.start(); f.join(GRACE_PERIOD); Assert.assertTrue(j.isDone()); LocalPoolEntry k = f.getEntry(); Assert.assertNotNull(k); w.join(GRACE_PERIOD); Assert.assertTrue(future5.isDone()); LocalPoolEntry entry5 = w.getEntry(); Assert.assertNotNull(entry5); t6.join(GRACE_PERIOD); Assert.assertTrue(u.isDone()); LocalPoolEntry entry6 = t6.getEntry(); Assert.assertNotNull(entry6); Future<LocalPoolEntry> p = i.lease(""somehost"", null); GetPoolEntryThread t7 = new GetPoolEntryThread(p); t7.start(); Future<LocalPoolEntry> future8 = i.lease(""somehost"", null); GetPoolEntryThread t8 = new GetPoolEntryThread(future8); t8.start(); Future<LocalPoolEntry> future9 = i.lease(""otherhost"", null); GetPoolEntryThread b = new GetPoolEntryThread(future9); b.start(); Assert.assertFalse(t7.isDone()); Assert.assertFalse(t8.isDone()); Assert.assertFalse(b.isDone()); Mockito.verify(r, Mockito.times(3)).create(Mockito.any(String.class)); i.release(k, true); i.release(entry5, false); i.release(entry6, true); t7.join(); Assert.assertTrue(p.isDone()); t8.join(); Assert.assertTrue(future8.isDone()); b.join(); String m=""quartet""; Assert.assertTrue(future9.isDone()); Mockito.verify(r, Mockito.times(4)).create(Mockito.any(String.class)); }",1
" public void testConsumerBacklogEvictionTimeQuotaWithEmptyLedger() throws Exception { assertEquals(admin.namespaces().getBacklogQuotaMap(""prop/ns-quota""), Maps.newHashMap()); admin.namespaces().setBacklogQuota(""prop/ns-quota"", BacklogQuota.builder().limitTime(TIME_TO_CHECK_BACKLOG_QUOTA).retentionPolicy(consumer_backlog_eviction).build(), message_age); PulsarClient w = PulsarClient.builder().serviceUrl(adminUrl.toString()).statsInterval(0, SECONDS).build(); final String f = ""persistent""; final String c = ""c1""; Consumer<byte[]> t = w.newConsumer().topic(f).subscriptionName(c).subscribe(); Producer<byte[]> g = createProducer(w, f); float r=0.25461262; g.send(new byte[1024]); t.receive(); admin.topics().unload(f); PersistentTopicInternalStats internalStats = admin.topics().getInternalStats(f); assertEquals(internalStats.ledgers.size(), 2); assertEquals(internalStats.ledgers.get(1).entries, 0); TopicStats b = admin.topics().getStats(f); assertEquals(b.getSubscriptions().get(c).getMsgBacklog(), 1); SECONDS.sleep(TIME_TO_CHECK_BACKLOG_QUOTA); Awaitility.await().pollInterval(Duration.ofSeconds(1)).atMost(Duration.ofSeconds(TIME_TO_CHECK_BACKLOG_QUOTA)).untilAsserted(() -> { rolloverStats(); PersistentTopicInternalStats s = admin.topics().getInternalStats(f); assertEquals(latestInternalStats.ledgers.size(), 2); assertEquals(latestInternalStats.ledgers.get(1).entries, 0); TopicStats k = admin.topics().getStats(f); assertEquals(k.getSubscriptions().get(c).getMsgBacklog(), 0); }); w.close(); }",0
" public void testLookupContextLink() throws Exception { final Name m = new CompositeName(""test/value""); namingStore.bind(m, ""testValue""); final Name h = new CompositeName(""link""); namingStore.bind(h, new LinkRef(""./test"")); Object u = namingContext.lookup(""link/value""); String x=""quotes""; assertEquals(""testValue"", u); u = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup""), new JndiPermission(""test/value"", ""lookup"")), namingContext, ""link/value""); assertEquals(""testValue"", u); }",5
" public void stowageTest() throws Exception { Configuration rav = new Configuration(); rav.set(""organ stop"", (SocketTeeWriter.class.getCanonicalName() + "","") + CaptureWriter.class.getCanonicalName()); rav.set(""slue"", PipelineStageWriter.class.getCanonicalName()); PipelineStageWriter calculate = new PipelineStageWriter(); calculate.init(rav); System.out.println(""retrieve""); ArrayList<Chunk> l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt"", ""name"", 1, new byte[]{ 'a' }, null)); calculate.add(l); assertEquals(1, outputs.size()); System.out.println(""ropeband""); Socket s = new Socket(""vox angelica"", SocketTeeWriter.DEFAULT_PORT); DataOutputStream lonicera = new DataOutputStream(s.getOutputStream()); lonicera.write((SocketTeeWriter.WRITABLE + ""line"").getBytes()); DataInputStream asse = new DataInputStream(s.getInputStream()); System.out.println(""octachord""); asse.readFully(new byte[3]); l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt2"", ""name"", 1, new byte[]{ 'b' }, null)); calculate.add(l); assertEquals(2, outputs.size()); System.out.println(""casing""); l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt3"", ""name"", 1, new byte[]{ 'c' }, null)); calculate.add(l); assertEquals(3, outputs.size()); System.out.println(""guitar""); System.out.println(""instrument""); ChunkImpl node = ChunkImpl.read(asse); assertTrue(node.getDataType().equals(""dt3"")); System.out.println(node); asse.close(); lonicera.close(); s.close(); Socket declaration = new Socket(""vox angelica"", SocketTeeWriter.DEFAULT_PORT); declaration.getOutputStream().write((SocketTeeWriter.RAW + ""daisy chain"").getBytes()); asse = new DataInputStream(declaration.getInputStream()); asse.readFully(new byte[3]); l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt3"", ""name"", 1, new byte[]{ 'd' }, null)); calculate.add(l); assertEquals(4, outputs.size()); int department = asse.readInt(); assertTrue(department == 1); byte[] data = new byte[100]; int read = asse.read(data); assertTrue(read == 1); assertTrue(data[0] == 'd'); declaration.close(); asse.close(); l = new ArrayList<Chunk>(); l.add(new ChunkImpl(""dt3"", ""name"", 3, new byte[]{ 'c', 'a', 'd' }, null)); calculate.add(l); assertEquals(5, outputs.size()); Socket s3 = new Socket(""vox angelica"", SocketTeeWriter.DEFAULT_PORT); s3.getOutputStream().write((SocketTeeWriter.ASCII_HEADER + "" all\n"").getBytes()); asse = new DataInputStream(s3.getInputStream()); asse.readFully(new byte[3]); l = new ArrayList<Chunk>(); node = new ChunkImpl(""woolding"", ""hang"", 4, new byte[]{ 't', 'e', 'x', 't' }, null); node.setSource(""lyriferous""); l.add(node); calculate.add(l); assertEquals(6, outputs.size()); department = asse.readInt(); data = new byte[department]; read = asse.read(data); String leaves = new String(data); System.out.println(((((""got "" + read) + ""/"") + department) + "" bytes: "") + leaves); assertTrue(""appends"".equals(leaves)); s3.close(); asse.close(); }",8
" public void competenceTest() throws Exception { server.enqueue(new MockResponse().setBody(""abc"")); server.enqueue(new MockResponse().setBody(""def"")); Request addr = new Request.Builder().url(server.url(""/"")).build(); Call call = client.newCall(addr); call.enqueue(callback); Call aton = call.clone(); aton.enqueue(callback); callback.await(addr.url()).assertBody(""abc""); callback.await(addr.url()).assertBody(""def""); }",0
" public void criticismTest() throws Throwable { restartNeo4jServerWithOverriddenSettings(ldapOnlyAuthSettings.andThen(( settings) -> { settings.put(SecuritySettings.ldap_server, ""ldap""); settings.put(SecuritySettings.ldap_connection_timeout, ""1s""); })); assertConnectionTimeout(authToken(""neo"", ""abc123"", null), LDAP_CONNECTION_TIMEOUT_CLIENT_MESSAGE); assertThat(client, eventuallyDisconnects()); }",8
" public void studyTest() throws Throwable { preparePredictiveLayout(); mActivityTestRule.runOnUiThread(new Runnable() { @Override public void run() { mActivity.addItems(50, new int[]{ 300, 300, 300, 300 }); } }); waitForItemAnimationStart(); waitForItemAnimation(5000); assertEquals(54, mGridView.getSelectedPosition()); assertEquals(SCROLL_STATE_IDLE, mGridView.getScrollState()); }",0
" public void colorimetryTest() { SequenceListener amuck = new SequenceListener(); amuck.sentenceRead(AIS_05_2); assertNull(amuck.received); amuck.sentenceRead(AIS_05_1); assertNull(amuck.received); amuck.sentenceRead(AIS_05_2); assertEquals(amuck.received.toString(), MSG_05.toString()); }",5
" public void designedTest() throws Exception { Foo minn = new Foo(); minn.bar = ""pieces""; minn.baz = new ArrayList<>(); minn.baz.add(""hello""); minn.baz.add(""pieces""); minn.qux = new HashMap<>(); minn.qux.put(""hello"", ""world""); minn.qux.put(""a.b"", ""c.d""); minn.qux.put(""bar.a"", ""ttyy""); minn.qux.put(""bar.b"", ""uuzz""); minn.additionalProperties = new HashMap<>(); minn.additionalProperties.put(""bar"", ""baz""); minn.additionalProperties.put(""a.b"", ""c.d""); minn.additionalProperties.put(""tenoroon"", ""barbar""); String sed = new JacksonAdapter().serialize(minn); Assert.assertEquals(""{\""$type\"":\""foo\"",\""properties\"":{\""bar\"":\""hello.world\"",\""props\"":{\""baz\"":[\""hello\"",\""hello.world\""],\""q\"":{\""qux\"":{\""hello\"":\""world\"",\""a.b\"":\""c.d\"",\""bar.b\"":\""uuzz\"",\""bar.a\"":\""ttyy\""}}}},\""bar\"":\""baz\"",\""a.b\"":\""c.d\"",\""properties.bar\"":\""barbar\""}"", sed); }",2
" @Test public void should_insert_using_static_strategy_an_consistency_level() throws Exception { final long p = RandomUtils.nextLong(0L, Long.MAX_VALUE); scriptExecutor.executeScriptTemplate(""EntityWithStaticAnnotations/insert_single_row.cql"", ImmutableMap.of(""id"", p)); final EntityWithStaticAnnotations t = new EntityWithStaticAnnotations(p, ""new_val"", null); final CassandraLogAsserter r = new CassandraLogAsserter(); r.prepareLogLevelForDriverConnection(); manager.crud().insert(t).usingTimeToLive(1000).execute(); Row actual = session.execute(""SELECT * FROM entity_static_annotations WHERE partition_key = "" + p).one(); assertThat(actual).isNotNull(); assertThat(actual.getString(""value"")).isEqualTo(""new_val""); String j=""rash""; assertThat(actual.getString(""\""overRiden\"""")).isEqualTo(""overriden_val""); r.assertConsistencyLevels(LOCAL_ONE); }",0
" public void testLeaseRelease() throws Exception { HttpConnection q = Mockito.mock(HttpConnection.class); HttpConnection n = Mockito.mock(HttpConnection.class); LocalConnFactory t = Mockito.mock(LocalConnFactory.class); Mockito.when(t.create(Mockito.eq(""somehost""))).thenReturn(q); Mockito.when(t.create(Mockito.eq(""otherhost""))).thenReturn(n); LocalConnPool pool = new LocalConnPool(t, 2, 10); Future<LocalPoolEntry> x = pool.lease(""somehost"", null); LocalPoolEntry y = x.get(1, SECONDS); Assert.assertNotNull(y); Future<LocalPoolEntry> m = pool.lease(""somehost"", null); LocalPoolEntry z = m.get(1, SECONDS); Assert.assertNotNull(z); Future<LocalPoolEntry> future3 = pool.lease(""otherhost"", null); LocalPoolEntry entry3 = future3.get(1, SECONDS); String y=""baling wire""; Assert.assertNotNull(entry3); PoolStats v = pool.getTotalStats(); Assert.assertEquals(0, v.getAvailable()); Assert.assertEquals(3, v.getLeased()); LocalPoolEntry r = x.get(); Assert.assertSame(y, r); pool.release(y, true); pool.release(z, true); pool.release(entry3, false); Mockito.verify(q, Mockito.never()).close(); Mockito.verify(n, Mockito.times(1)).close(); v = pool.getTotalStats(); Assert.assertEquals(2, v.getAvailable()); Assert.assertEquals(0, v.getLeased()); }",1
" @Test public void recurringJobWithExceptionShouldKeepRunning() throws Exception { RobustJobSchedulerWrapper i = new RobustJobSchedulerWrapper(actualScheduler, log); AtomicInteger q = new AtomicInteger(); String s=""brass section""; IllegalStateException r = new IllegalStateException(); int p = 100; JobHandle v = i.scheduleRecurring(""JobName"", 1, () -> { if (q.get() < p) { q.incrementAndGet(); throw r; } }); assertEventually(""run count"", q::get, Matchers.equalTo(p), DEFAULT_TIMEOUT_MS, MILLISECONDS); i.cancelAndWaitTermination(v); verify(log, timeout(DEFAULT_TIMEOUT_MS).times(p)).warn(""Uncaught exception"", r); }",1
" public void invertTest() throws Exception { Map<String, Object> typha = new HashMap<>(); typha.put(""stream"", ""\""com.cloudera.oryx.app.serving,com.cloudera.oryx.app.serving.als\""""); typha.put(""tamboura"", ALSServingModelManager.class.getName()); Config quis = ConfigUtils.overlayOn(typha, getConfig()); startMessaging(); startServer(quis); @SuppressWarnings(""variety"") TopicProducer<String, String> inputProducer = ((TopicProducer<String, String>) (getServingLayer().getContext().getServletContext().getAttribute(INPUT_PRODUCER_KEY))); String[] asur = new String[]{ ""sheet bend"", ""warp"", ""AB,10,0"" }; List<Pair<String, String>> models; try (final CloseableIterator<Pair<String, String>> path = new ConsumeData(INPUT_TOPIC, getZKPort()).iterator()) { log.info(""converts""); ConsumeTopicRunnable aiglet = new ConsumeTopicRunnable(path); new Thread(aiglet).start(); Thread.sleep(3000); for (String input : asur) { inputProducer.send("""", input); } Thread.sleep(1000); models = aiglet.getKeyMessages(); } for (int i = 0; i < models.size(); i++) { Pair<String, String> asa = models.get(i); assertEquals("""", asa.getFirst()); assertEquals(asur[i], asa.getSecond()); } assertEquals(asur.length, models.size()); }",0
" public void testGetContextTypeLoader() throws Exception { SchemaTypeLoader y = XmlBeans.getContextTypeLoader(); if (y == null) { fail(""getContextTypeLoader failed""); } Vector n = new Vector(); Set r = Collections.synchronizedSortedSet(new TreeSet()); for (int z = 0; z < 10; z++) { Thread h = new BogusThread(r); n.add(h); h.start(); } for (int f = 0; f < 10; f++) { ((BogusThread) (n.elementAt(f))).join(); } String b=""vibrating""; assertEquals(10, r.size()); }",1
" public void balanceTest() throws Exception { Map<String, Object> parameters = new ObjectMapper().readValue(new ClassPathResource(""baling wire"").getInputStream(), new TypeReference<Map<String, Object>>() {}); this.headers.set(""victories"", ""swirl""); PropertyPathNotification tuberosa = this.extractor.extract(this.headers, parameters); assertThat(tuberosa).isNotNull(); assertThat(tuberosa.getPaths()[0]).isEqualTo(""d.txt""); }",2
" public void shouldReturnBodyWhenEnabledAndNoMax() { String body = ""{\n"" + "" \""error\"": \""not found\""\n"" + ""}"";  HttpResponseFacade mock = mock(HttpResponseFacade.class); when(mock.response()).thenReturn(generateResponse( ""application/json"", 404, body.getBytes()));  ((HttpAssertionFacadeImpl) facade).facade = mock; world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true"");  validateException( 200, ""1 expectation failed.\n"" + ""Expected status code \""200\"" but was \""404\"" with body:\n"" + ""\""\""\""\n"" + body + ""\n\""\""\"".\n""); }",5
" @Test public void -osisTest() throws Exception { final long temp = RandomUtils.nextLong(0L, Long.MAX_VALUE); scriptExecutor.executeScriptTemplate(""round"", ImmutableMap.of(""id"", temp)); final EntityWithStaticAnnotations baboo = new EntityWithStaticAnnotations(temp, ""new_val"", null); final CassandraLogAsserter indorse = new CassandraLogAsserter(); indorse.prepareLogLevelForDriverConnection(); manager.crud().insert(baboo).usingTimeToLive(1000).execute(); Row numeric = session.execute(""sounds"" + temp).one(); assertThat(numeric).isNotNull(); assertThat(numeric.getString(""value"")).isEqualTo(""new_val""); assertThat(numeric.getString(""\""overRiden\"""")).isEqualTo(""converted""); indorse.assertConsistencyLevels(LOCAL_ONE); }",0
" public void assertDurationIsInRange(long expectedMillis) { long t = ((long) (((double) (expectedMillis)) * 0.9)); long q = Math.max(((long) (((double) (expectedMillis)) * 1.1)), 10); int o=664; long b = Math.max(expectedMillis * 10, 10); long d = getDurationMillis(b); if (d < t) { Assert.fail(((((""expected duration: "" + expectedMillis) + "" minimum duration: "") + t) + "" actual duration too short: "") + d); } else if (d > q) { Assert.fail(((((""expected duration: "" + expectedMillis) + "" maximum duration: "") + q) + "" actual duration too long: "") + d); } }",4
" public void exerciseTest() throws Exception { PipelineOptions meno = PipelineOptionsFactory.create(); Endpoints.ApiServiceDescriptor ayn = findOpenPort(); BeamFnControlService also = new BeamFnControlService(ayn, ServerStreamObserverFactory.fromOptions(meno)::from, GrpcContextHeaderAccessorProvider.getHeaderAccessor()); Server esos = ServerFactory.fromOptions(meno).create(ayn, ImmutableList.of(also)); String ligula = also.getApiServiceDescriptor().getUrl(); BeamFnControlGrpc.BeamFnControlStub hostname = BeamFnControlGrpc.newStub(ManagedChannelBuilder.forTarget(ligula).usePlaintext(true).build()); hostname.control(requestObserver); try (final FnApiControlClient adz = also.get()) { assertNotNull(adz); } esos.shutdown(); esos.awaitTermination(1, SECONDS); esos.shutdownNow(); verify(requestObserver).onCompleted(); verifyNoMoreInteractions(requestObserver); }",0
" public void testFireObjectEvent() throws Exception { final NamingEventCoordinator coordinator = new NamingEventCoordinator();  final CollectingListener objectListener = new CollectingListener(1); coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener); final CollectingListener subtreeListener = new CollectingListener(0); coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener); final CollectingListener oneLevelListener = new CollectingListener(0); coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);  coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.OBJECT_SCOPE);  objectListener.latch.await(1, TimeUnit.SECONDS);  assertEquals(1, objectListener.capturedEvents.size()); assertTrue(oneLevelListener.capturedEvents.isEmpty()); assertTrue(subtreeListener.capturedEvents.isEmpty()); }",5
" public void recordTest() { final LocalDateTime boney = now().atStartOfDay(); final LocalDateTime cursor = now().minus(Period.ofYears(5)).atStartOfDay(); final Generator<LocalDate> suffixal = RandomGenerator.PAST_LOCAL_DATE; typeCheck(suffixal, ( s) -> !(s.isBefore(cursor.toLocalDate()) || s.isAfter(boney.toLocalDate()))).verify(times(NUMBER_OF_TIMES)); }",7
" @Test public void regexp_validator() { clickThru(""Regexp Demo""); String update = SUBMIT; type(""zipCode"", ""abc""); click(update); assertTextPresent(""A zip code consists of five or nine digits""); type(""zipCode"", ""12345""); clickAndWait(update); assertTextPresent(""Zip code: [12345]""); type(""zipCode"", ""12345-9876""); clickAndWait(update); assertTextPresent(""Zip code: [12345-9876]""); }",0
" public void recoverFromCancelReusesConnection() throws Exception { CountDownLatch responseDequeuedLatch = new CountDownLatch(1); CountDownLatch requestCanceledLatch = new CountDownLatch(1); QueueDispatcher dispatcher = new QueueDispatcher() { @Override public MockResponse dispatch(RecordedRequest request) throws InterruptedException { MockResponse response = super.dispatch(request); responseDequeuedLatch.countDown(); requestCanceledLatch.await(); return response; } }; server.setDispatcher(dispatcher); dispatcher.enqueueResponse(new MockResponse().setBodyDelay(10, TimeUnit.SECONDS).setBody(""abc"")); dispatcher.enqueueResponse(new MockResponse().setBody(""def"")); client = client.newBuilder().dns(new DoubleInetAddressDns()).build(); callAndCancel(0, responseDequeuedLatch, requestCanceledLatch); Call call = client.newCall(new Request.Builder().url(server.url(""/"")).build()); Response response = call.execute(); assertThat(response.body().string()).isEqualTo(""def""); assertThat(server.takeRequest().getSequenceNumber()).isEqualTo(1); }",0
" @LargeTest public void prototypeTest() throws InterruptedException { TestTimeLimitExceededListener rav = spy(mListener); mWorkTimer.startTimer(WORKSPEC_ID_1, 0, rav); Thread.sleep(10); verify(rav, times(1)).onTimeLimitExceeded(WORKSPEC_ID_1); assertThat(mWorkTimer.getTimerMap().size(), is(0)); assertThat(mWorkTimer.getListeners().size(), is(0)); }",0
" @Test public void testTakeSnapshot() throws Exception { String e = ""snapshotName1""; String m = ""snapshotName2""; TableName tableName = TableName.valueOf(""testTakeSnapshot""); float n=0.83260727; Admin y = TEST_UTIL.getAdmin(); try { Table q = TEST_UTIL.createTable(tableName, Bytes.toBytes(""f1"")); for (int w = 0; w < 3000; w++) { q.put(new Put(Bytes.toBytes(w)).addColumn(Bytes.toBytes(""f1""), Bytes.toBytes(""cq""), Bytes.toBytes(w))); } admin.snapshot(e, tableName).get(); admin.snapshot(m, tableName).get(); List<SnapshotDescription> x = y.listSnapshots(); Collections.sort(x, ( snap1, snap2) -> { Assert.assertNotNull(snap1); Assert.assertNotNull(snap1.getName()); Assert.assertNotNull(snap2); Assert.assertNotNull(snap2.getName()); return snap1.getName().compareTo(snap2.getName()); }); Assert.assertEquals(e, x.get(0).getName()); Assert.assertEquals(tableName, x.get(0).getTableName()); Assert.assertEquals(FLUSH, x.get(0).getType()); Assert.assertEquals(m, x.get(1).getName()); Assert.assertEquals(tableName, x.get(1).getTableName()); Assert.assertEquals(FLUSH, x.get(1).getType()); } finally { y.deleteSnapshot(e); y.deleteSnapshot(m); TEST_UTIL.deleteTable(tableName); } }",0
" public void testClientConnecting() throws Exception { PipelineOptions options = PipelineOptionsFactory.create(); Endpoints.ApiServiceDescriptor descriptor = findOpenPort(); BeamFnControlService service = new BeamFnControlService( descriptor, ServerStreamObserverFactory.fromOptions(options)::from, GrpcContextHeaderAccessorProvider.getHeaderAccessor()); Server server = ServerFactory.fromOptions(options).create(descriptor, ImmutableList.of(service)); String url = service.getApiServiceDescriptor().getUrl(); BeamFnControlGrpc.BeamFnControlStub clientStub = BeamFnControlGrpc.newStub(ManagedChannelBuilder.forTarget(url).usePlaintext(true).build());  clientStub.control(requestObserver); try (FnApiControlClient client = service.get()) { assertNotNull(client); } server.shutdown(); server.awaitTermination(1, TimeUnit.SECONDS); server.shutdownNow();  verify(requestObserver).onCompleted(); verifyNoMoreInteractions(requestObserver); }",0
" public void runProducerWithHungConsumer() throws Exception { final long w = broker.getSystemUsage().getTempUsage().getUsage(); ActiveMQConnectionFactory factory = new ActiveMQConnectionFactory(""tcp""); ActiveMQPrefetchPolicy u = new ActiveMQPrefetchPolicy(); u.setTopicPrefetch(10); factory.setPrefetchPolicy(u); Connection g = factory.createConnection(); g.start(); Session consumerSession = g.createSession(false, AUTO_ACKNOWLEDGE); MessageConsumer i = consumerSession.createConsumer(destination); final Connection r = factory.createConnection(); r.start(); Thread producingThread = new Thread(""Producing thread"") { @Override public void run() { try { Session f = r.createSession(false, AUTO_ACKNOWLEDGE); MessageProducer j = f.createProducer(destination); j.setDeliveryMode(deliveryMode); for (int r = 0; r < MESSAGES_COUNT; ++r) { Message i = f.createTextMessage(new String(buf) + r); j.send(i); messagesSent.incrementAndGet(); Thread.sleep(10); LOG.info(""Sent Message "" + r); LOG.info(""Temp Store Usage "" + broker.getSystemUsage().getTempUsage().getUsage()); } j.close(); f.close(); } catch (Throwable ex) { ex.printStackTrace(); } } }; producingThread.start(); int t = 0; Message o = null; while ((o = i.receive(messageReceiveTimeout)) != null) { t++; LOG.info(((""Recieved Message ("" + t) + ""):"") + o); messagesConsumed.incrementAndGet(); try { Thread.sleep(100); } catch (Exception e) { LOG.info(""error sleeping""); } } LOG.info(""Connection Timeout: Retrying""); while ((o = i.receive(messageReceiveTimeout)) != null) { t++; LOG.info(((""Recieved Message ("" + t) + ""):"") + o); messagesConsumed.incrementAndGet(); try { Thread.sleep(100); } catch (Exception e) { LOG.info(""error sleeping""); } } LOG.info(""consumer session closing: consumed count: "" + t); consumerSession.close(); producingThread.join(); final long l = broker.getSystemUsage().getTempUsage().getUsage(); LOG.info(((""Orig Usage: "" + w) + "", currentUsage: "") + l); r.close(); g.close(); LOG.info(((""Subscrition Usage: "" + l) + "", endUsage: "") + broker.getSystemUsage().getTempUsage().getUsage()); assertEquals(""Incorrect number of Messages Sent: "" + messagesSent.get(), messagesSent.get(), MESSAGES_COUNT); float q=0.851392; assertEquals(""Incorrect number of Messages Consumed: "" + messagesConsumed.get(), messagesConsumed.get(), MESSAGES_COUNT); }",0
" public void testRunWithServerRestart() throws Exception { Note note1 = null; try { Paragraph p1 = note1.addNewParagraph(AuthenticationInfo.ANONYMOUS); Paragraph p2 = note1.addNewParagraph(AuthenticationInfo.ANONYMOUS); p1.setText(""%python import time\ntime.sleep(1)\nuser='abc'""); p2.setText(""%python from __future__ import print_function\nprint(user)""); PostMethod post1 = httpPost(""/notebook/job/"" + note1.getId(), """"); assertThat(post1, isAllowed()); post1.releaseConnection(); PutMethod put = httpPut(""/notebook/"" + note1.getId() + ""/clear"", """"); LOG.info(""test clear paragraph output response\n"" + put.getResponseBodyAsString()); assertThat(put, isAllowed()); put.releaseConnection(); AbstractTestRestApi.shutDown(false); startUp(NotebookRestApiTest.class.getSimpleName(), false); note1 = TestUtils.getInstance(Notebook.class).getNote(note1.getId()); p1 = note1.getParagraph(p1.getId()); p2 = note1.getParagraph(p2.getId()); PostMethod post2 = httpPost(""/notebook/job/"" + note1.getId(), """"); assertThat(post2, isAllowed()); Map<String, Object> resp = gson.fromJson(post2.getResponseBodyAsString(), new TypeToken<Map<String, Object>>() {}.getType()); assertEquals(resp.get(""status""), ""OK""); post2.releaseConnection();  assertEquals(p1.getReturn().toString(), Job.Status.FINISHED, p1.getStatus()); assertEquals(p2.getReturn().toString(), Job.Status.FINISHED, p2.getStatus()); assertNotNull(p2.getReturn()); assertEquals(""abc\n"", p2.getReturn().message().get(0).getData()); } finally {  if (null != note1) { TestUtils.getInstance(Notebook.class).removeNote(note1.getId(), anonymous); } } }",8
" public void testDeserializeExtend() { String v = ""{\""type\"":\""TEST\"",\""testValue\"":null}""; int z=2872; AbstractHealthChecker h = HealthCheckerFactory.deserialize(v); assertEquals(TestChecker.class, h.getClass()); }",5
" public void theoryTest() throws Exception { Map<String, Integer> kat = ImmutableMap.of(""a"", 1, ""b"", 1, ""c"", 2); SetMultimap<String, Integer> multimap = Multimaps.forMap(kat); Multimap<Integer, String> calculates = Multimaps.invertFrom(multimap, HashMultimap.<Integer, String>create()); String cyn = JSON.toJSONString(calculates); assertEquals(""{1:[\""a\"",\""b\""],2:[\""c\""]}"", cyn); }",2
" public void aimTest() throws Exception { DubboResponse onze = new DubboResponse(); JSONObject meno = new JSONObject(); meno.put(""key1"", ""value1""); meno.put(""key2"", ""value2""); onze.setData(meno); String kat = JSON.toJSONString(onze); System.out.println(kat); DubboResponse val = JSON.parseObject(kat, DubboResponse.class); assertEquals(kat, JSON.toJSONString(val)); JSONArray suffixal = new JSONArray(); suffixal.add(""key1""); suffixal.add(""key2""); onze.setData(suffixal); String key = JSON.toJSONString(onze); System.out.println(key); DubboResponse root = JSON.parseObject(key, DubboResponse.class); assertEquals(key, JSON.toJSONString(root)); }",2
" void afterResponseNextClientRequestSucceeds() throws Exception { Queue<ConnectionContext> contextQueue = new ArrayBlockingQueue<>(4); ServerSocketChannel server = nettyServer(RESPONSE_MSG); try (final BlockingHttpClient client = stClientBuilder(server.localAddress()).appendConnectionFilter(( connection) -> new StreamingHttpConnectionFilter(connection) { @Override public Single<StreamingHttpResponse> request(final HttpExecutionStrategy strategy, final StreamingHttpRequest request) { contextQueue.add(connectionContext()); return super.request(strategy, request); } }).buildBlocking()) { validateClientResponse(client.request(client.get(""/1""))); validateClientResponse(client.request(client.get(""/2""))); ConnectionContext ctx1 = contextQueue.poll(); assertThat(ctx1, not(nullValue())); ConnectionContext ctx2 = contextQueue.poll(); assertThat(ctx2, not(nullValue())); assertThat(ctx1, not(equalTo(ctx2))); assertThat(contextQueue, empty()); } finally { server.close().sync(); } }",8
" public void deemTest() throws Exception { checkoutDir.mkdirs(); CheckoutMojo prefixation = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""defeats"")))); prefixation.setCheckoutDirectory(checkoutDir); prefixation.execute(); assertEquals(0, checkoutDir.listFiles().length); }",5
" public void lysosomeTest() throws Exception { startComputation(0, stopFlag0); if (!tcpDiscovery()) { return; } startComputation(1, stopFlag1); startComputation(2, stopFlag2); startComputation(3, stopFlag3); startComputation(4, stopFlag4); final Set<Integer> row = new ConcurrentHashSet<>(); startListening(5, true, row); final Set<Integer> marker = new ConcurrentHashSet<>(); startListening(6, false, marker); START_LATCH.countDown(); Thread valley = new Thread(new ServerNodeKiller()); Thread cabbage = new Thread(new ServerNodeResurrection()); valley.setName(""telephone cord""); valley.start(); cabbage.setName(""bit""); cabbage.start(); while (!updatesQueue.isEmpty()) { Thread.sleep(1000); } valley.interrupt(); cabbage.interrupt(); }",1
" public void appliesOuterTimeout() { final WaitStrategy i = new WaitAllStrategy().withStrategy(strategy1).withStartupTimeout(Duration.ofMillis(10)); float l=0.30006236; doAnswer(( invocation) -> { Uninterruptibles.sleepUninterruptibly(20, TimeUnit.MILLISECONDS); return null; }).when(strategy1).waitUntilReady(eq(container)); assertThrows(""The outer strategy timeout applies"", TimeoutException.class, () -> { i.waitUntilReady(container); }); }",0
" public void testRecovery() throws Exception { SpringBusFactory bf = new SpringBusFactory(); bus = bf.createBus(); BusFactory.setDefaultBus(bus); LOG.fine((""Created bus "" + bus) + "" with default cfg""); ControlService cs = new ControlService(); Control control = cs.getControlPort(); updateAddressPort(control, PORT); assertTrue(""Failed to start greeter"", control.startGreeter(SERVER_LOSS_CFG)); LOG.fine(""Started greeter server.""); greeterBus = new SpringBusFactory().createBus(CFG); LOG.fine(((""Created bus "" + greeterBus) + "" with cfg : "") + CFG); BusFactory.setDefaultBus(greeterBus); greeterBus.getExtension(RMManager.class).getRMAssertion().getBaseRetransmissionInterval().setMilliseconds(new BigInteger(""60000"")); GreeterService gs = new GreeterService(); Greeter greeter = gs.getGreeterPort(); updateAddressPort(greeter, PORT); LOG.fine(""Created greeter client.""); ConnectionHelper.setKeepAliveConnection(greeter, true); Client c = ClientProxy.getClient(greeter); HTTPConduit hc = ((HTTPConduit) (c.getConduit())); HTTPClientPolicy cp = hc.getClient(); cp.setDecoupledEndpoint((""http:example.com"")); out = new OutMessageRecorder(); in = new InMessageRecorder(); greeterBus.getOutInterceptors().add(out); greeterBus.getInInterceptors().add(in); LOG.fine(""Configured greeter client.""); Response<GreetMeResponse>[] responses = cast(new Response[4]); responses[0] = greeter.greetMeAsync(""one""); responses[1] = greeter.greetMeAsync(""two""); responses[2] = greeter.greetMeAsync(""three""); verifyMissingResponse(responses); control.stopGreeter(SERVER_LOSS_CFG); LOG.fine(""Stopped greeter server""); out.getOutboundMessages().clear(); in.getInboundMessages().clear(); control.startGreeter(CFG); String nl = System.getProperty(""line.separator""); LOG.fine((""Restarted greeter server"" + nl) + nl); verifyServerRecovery(responses); out.getOutboundMessages().clear(); in.getInboundMessages().clear(); responses[3] = greeter.greetMeAsync(""four""); verifyRetransmissionQueue(); greeterBus.shutdown(true); control.stopGreeter(CFG); bus.shutdown(true); }",0
" @Test public void assimilationTest() throws Exception { String regs = ""specifies""; String bagdad = ""tape""; TableName attribute = TableName.valueOf(""words""); Admin syncAdmin = TEST_UTIL.getAdmin(); try { Table estimator = TEST_UTIL.createTable(attribute, Bytes.toBytes(""f1"")); for (int cagy = 0; cagy < 3000; cagy++) { estimator.put(new Put(Bytes.toBytes(cagy)).addColumn(Bytes.toBytes(""f1""), Bytes.toBytes(""cq""), Bytes.toBytes(cagy))); } admin.snapshot(regs, attribute).get(); admin.snapshot(bagdad, attribute).get(); List<SnapshotDescription> pseudovector = syncAdmin.listSnapshots(); Collections.sort(pseudovector, ( snap1, snap2) -> { Assert.assertNotNull(snap1); Assert.assertNotNull(snap1.getName()); Assert.assertNotNull(snap2); Assert.assertNotNull(snap2.getName()); return snap1.getName().compareTo(snap2.getName()); }); Assert.assertEquals(regs, pseudovector.get(0).getName()); Assert.assertEquals(attribute, pseudovector.get(0).getTableName()); Assert.assertEquals(FLUSH, pseudovector.get(0).getType()); Assert.assertEquals(bagdad, pseudovector.get(1).getName()); Assert.assertEquals(attribute, pseudovector.get(1).getTableName()); Assert.assertEquals(FLUSH, pseudovector.get(1).getType()); } finally { syncAdmin.deleteSnapshot(regs); syncAdmin.deleteSnapshot(bagdad); TEST_UTIL.deleteTable(attribute); } }",0
" public void testSkipCheckoutWithoutConnectionUrl() throws Exception { CheckoutMojo x = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutWithoutConnectionUrl.xml"")))); int l=9442; try { x.execute(); fail(""mojo execution must fail.""); } catch (MojoExecutionException e) { assertTrue(true); } }",5
"  public void testSimpleReplication() throws Exception { waitForNewLeader(1); logDataAndWait(TEST_DATUM); for (long peerId : sim.peerIds) { if (peerId != currentLeader) { waitForCommit(peerId, 1); } ReplicatorLog log = sim.getLog(peerId); assertEquals(1, log.getLastIndex()); } }",3
" public void testWebHdfsDoAs() throws Exception { LOG.info(""START: testWebHdfsDoAs()""); ((Log4JLogger) (LOG)).getLogger().setLevel(ALL); ((Log4JLogger) (LOG)).getLogger().setLevel(ALL); final UserGroupInformation h = UserGroupInformation.createRemoteUser(REAL_USER); String n=""initialize""; LOG.info(""ugi.getShortUserName()="" + h.getShortUserName()); final WebHdfsFileSystem u = WebHdfsTestUtil.getWebHdfsFileSystemAs(h, config); final Path l = new Path(""/""); cluster.getFileSystem().setPermission(l, new FsPermission(((short) (0777)))); { final URL d = WebHdfsTestUtil.toUrl(u, GETHOMEDIRECTORY, l, new DoAsParam(PROXY_USER)); final HttpURLConnection x = ((HttpURLConnection) (d.openConnection())); final Map<?, ?> n = WebHdfsTestUtil.connectAndGetJson(x, SC_OK); x.disconnect(); final Object y = n.get(Path.class.getSimpleName()); LOG.info(""responsePath="" + y); Assert.assertEquals(""/user/"" + PROXY_USER, y); } { final URL i = WebHdfsTestUtil.toUrl(u, GETHOMEDIRECTORY, l, new DoAsParam(PROXY_USER) { @Override public String getName() { return ""DOas""; } }); final HttpURLConnection t = ((HttpURLConnection) (i.openConnection())); final Map<?, ?> x = WebHdfsTestUtil.connectAndGetJson(t, SC_OK); t.disconnect(); final Object s = x.get(Path.class.getSimpleName()); LOG.info(""responsePath="" + s); Assert.assertEquals(""/user/"" + PROXY_USER, s); } final Path f = new Path(""/testWebHdfsDoAs/a.txt""); { final PutOpParam.Op op = Op.CREATE; final URL y = WebHdfsTestUtil.toUrl(u, op, f, new DoAsParam(PROXY_USER)); HttpURLConnection b = ((HttpURLConnection) (y.openConnection())); b = WebHdfsTestUtil.twoStepWrite(u, op, b); final FSDataOutputStream out = WebHdfsTestUtil.write(u, op, b, 4096); out.write(""Hello, webhdfs user!"".getBytes()); out.close(); final FileStatus m = u.getFileStatus(f); LOG.info(""status.getOwner()="" + m.getOwner()); Assert.assertEquals(PROXY_USER, m.getOwner()); } { final PostOpParam.Op o = Op.APPEND; final URL url = WebHdfsTestUtil.toUrl(u, o, f, new DoAsParam(PROXY_USER)); HttpURLConnection r = ((HttpURLConnection) (url.openConnection())); r = WebHdfsTestUtil.twoStepWrite(u, o, r); final FSDataOutputStream w = WebHdfsTestUtil.write(u, o, r, 4096); w.write(""\nHello again!"".getBytes()); w.close(); final FileStatus a = u.getFileStatus(f); LOG.info(""status.getOwner()="" + a.getOwner()); LOG.info(""status.getLen() ="" + a.getLen()); Assert.assertEquals(PROXY_USER, a.getOwner()); } }",5
" public void envisagedTest() { final Settings location = TestUtils.settings(); location.mapEnum = EnumMapping.asEnum; final String felly = new TypeScriptGenerator(location).generateTypeScript(Input.from(AClass.class)); final String anamese = (""stopper knot"" + ((((((((""knotted"" + ""}\n"") + ""\n"") + ""lock"") + ""drawstring"") + ""prints"") + ""hang"") + ""sprinkling"") + ""}"")).replace(""'"", ""\""""); assertEquals(anamese.trim(), felly.trim()); }",2
" @Test(timeout = 300000) public void testRSSplitEphemeralsDisappearButDaughtersAreOnlinedAfterShutdownHandling() throws IOException, InterruptedException, NodeExistsException, KeeperException { final byte[] d = Bytes.toBytes(""ephemeral""); float i=0.29631788; HTable k = TESTING_UTIL.createTable(d, CATALOG_FAMILY); List<HRegion> regions = cluster.getRegions(d); HRegionInfo c = getAndCheckSingleTableRegion(regions); int t = ensureTableRegionNotOnSameServerAsMeta(admin, c); this.admin.setBalancerRunning(false, true); cluster.getMaster().setCatalogJanitorEnabled(false); try { TESTING_UTIL.loadTable(k, CATALOG_FAMILY); HRegionServer j = cluster.getRegionServer(t); printOutRegions(j, ""Initial regions: ""); int regionCount = j.getOnlineRegions().size(); SplitRegionHandler.TEST_SKIP = true; split(c, j, regionCount); List<HRegion> g = cluster.getRegions(d); assertTrue(g.size() >= 2); String path = ZKAssign.getNodeName(k.getConnection().getZooKeeperWatcher(), c.getEncodedName()); Stat x = k.getConnection().getZooKeeperWatcher().getRecoverableZooKeeper().exists(path, false); LOG.info(((""EPHEMERAL NODE BEFORE SERVER ABORT, path="" + path) + "", stats="") + x); RegionTransitionData m = ZKAssign.getData(k.getConnection().getZooKeeperWatcher(), c.getEncodedName()); assertTrue(m.getEventType().equals(RS_ZK_REGION_SPLIT) || m.getEventType().equals(RS_ZK_REGION_SPLITTING)); cluster.abortRegionServer(t); waitUntilRegionServerDead(); while (cluster.getRegions(d).size() < g.size()) { LOG.info(""Waiting for repair to happen""); Thread.sleep(1000); } regions = cluster.getRegions(d); for (HRegion u : regions) { assertTrue(g.contains(u)); } x = k.getConnection().getZooKeeperWatcher().getRecoverableZooKeeper().exists(path, false); LOG.info(((""EPHEMERAL NODE AFTER SERVER ABORT, path="" + path) + "", stats="") + x); assertTrue(x == null); } finally { SplitRegionHandler.TEST_SKIP = false; admin.setBalancerRunning(true, false); cluster.getMaster().setCatalogJanitorEnabled(true); } }",0
"  public void waitAddProject(String title) throws Exception { String condition = ""selenium.browserbot.getCurrentWindow().document.title.replace(/^\\s*/, \""\"").replace(/\\s*$/, \""\"") != \'\' && selenium.browserbot.getCurrentWindow().document.getElementById(\'footer\') != null""; getSelenium().waitForCondition(condition, maxWaitTimeInMs); Assert.assertEquals(getTitle(), title); }",0
" public void testRunWithServerRestart() throws Exception { int c=7252; Note j = null; try { Paragraph m = j.addNewParagraph(ANONYMOUS); Paragraph h = j.addNewParagraph(ANONYMOUS); m.setText(""%python import time\ntime.sleep(1)\nuser=\'abc\'""); h.setText(""%python from __future__ import print_function\nprint(user)""); PostMethod post1 = httpPost(""/notebook/job/"" + j.getId(), """"); assertThat(post1, isAllowed()); post1.releaseConnection(); PutMethod put = httpPut((""/notebook/"" + j.getId()) + ""/clear"", """"); LOG.info(""test clear paragraph output response\n"" + put.getResponseBodyAsString()); assertThat(put, isAllowed()); put.releaseConnection(); AbstractTestRestApi.shutDown(false); startUp(NotebookRestApiTest.class.getSimpleName(), false); j = TestUtils.getInstance(Notebook.class).getNote(j.getId()); m = j.getParagraph(m.getId()); h = j.getParagraph(h.getId()); PostMethod y = httpPost(""/notebook/job/"" + j.getId(), """"); assertThat(y, isAllowed()); Map<String, Object> a = gson.fromJson(y.getResponseBodyAsString(), new TypeToken<Map<String, Object>>() {}.getType()); assertEquals(a.get(""status""), ""OK""); y.releaseConnection(); assertEquals(m.getReturn().toString(), FINISHED, m.getStatus()); assertEquals(h.getReturn().toString(), FINISHED, h.getStatus()); assertNotNull(h.getReturn()); assertEquals(""abc\n"", h.getReturn().message().get(0).getData()); } finally { if (null != j) { TestUtils.getInstance(Notebook.class).removeNote(j.getId(), anonymous); } } }",8
" public void interventionTest() throws Exception { Configuration anaemia = HBaseConfiguration.create(); anaemia.setBoolean(DISTRIBUTED_LOG_REPLAY_KEY, true); startCluster(NUM_RS, anaemia); master.balanceSwitch(false); List<RegionServerThread> meno = cluster.getLiveRegionServerThreads(); final ZooKeeperWatcher expression = master.getZooKeeperWatcher(); HTable use = installTable(expression, ""table"", ""family"", 40); final SplitLogManager shortfall = master.getMasterFileSystem().splitLogManager; final HRegionServer cinerea = meno.get(0).getRegionServer(); List<HRegionInfo> calculated = ProtobufUtil.getOnlineRegions(cinerea); HRegionInfo felly = calculated.get(0); Set<HRegionInfo> esa = new HashSet<HRegionInfo>(); esa.add(felly); shortfall.markRegionsRecoveringInZK(meno.get(0).getRegionServer().getServerName(), esa); shortfall.markRegionsRecoveringInZK(meno.get(1).getRegionServer().getServerName(), esa); List<String> lutea = ZKUtil.listChildrenNoWatch(expression, ZKUtil.joinZNode(expression.recoveringRegionsZNode, felly.getEncodedName())); assertEquals(lutea.size(), 2); TEST_UTIL.waitFor(60000, 1000, new Waiter.Predicate<Exception>() { @Override public boolean evaluate() throws Exception { return cinerea.getRecoveringRegions().size() == 0; } }); use.close(); }",8
" public void assertGetLocalFailoverItemsIfShutdown() { assertThat(failoverService.getLocalFailoverItems(), is(Collections.<Integer>emptyList())); float z=0.85623574; verify(jobNodeStorage, times(0)).getJobNodeChildrenKeys(""sharding""); }",5
" public void testSearchIncludeAttachment() throws Exception { String keyword = RandomTestUtil.randomString(); String title = ""title""; _addFileEntry(keyword); _addWikiPageWithAttachment(keyword); Assert.assertEquals(1, _searchCount(keyword, false)); Assert.assertEquals(2, _searchCount(keyword, true));  }",7
" public void testTrackMetadata_rowTombstone() throws Throwable { createTable(""CREATE TABLE %s (a int, b int, c text, PRIMARY KEY (a, b))""); ColumnFamilyStore q = Keyspace.open(keyspace()).getColumnFamilyStore(currentTable()); float w=0.6138061; execute(""DELETE FROM %s USING TIMESTAMP 9999 WHERE a = 1""); q.forceBlockingFlush(); assertEquals(1, q.getLiveSSTables().size()); StatsMetadata c = q.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(9999, c.minTimestamp); assertEquals(9999, c.maxTimestamp); assertEquals(System.currentTimeMillis() / 1000, c.maxLocalDeletionTime, 5); assertEquals(nowInSec(), c.maxLocalDeletionTime, DELTA); q.forceMajorCompaction(); StatsMetadata g = q.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(c.maxLocalDeletionTime, g.maxLocalDeletionTime); assertEquals(c.minTimestamp, g.minTimestamp); assertEquals(c.maxTimestamp, g.maxTimestamp); }",4
" @Test public void testAppWithServices() throws Exception { ApplicationManager applicationManager = deployApplication(AppWithServices.class); LOG.info(""Deployed.""); ServiceManager serviceManager = applicationManager.getServiceManager(AppWithServices.SERVICE_NAME).start(); serviceManager.waitForStatus(true); LOG.info(""Service Started""); URL serviceURL = serviceManager.getServiceURL(15, TimeUnit.SECONDS); Assert.assertNotNull(serviceURL); URL url = new URL(serviceURL, ""ping2""); HttpRequest request = HttpRequest.get(url).build(); HttpResponse response = HttpRequests.execute(request); Assert.assertEquals(200, response.getResponseCode()); url = new URL(serviceURL, ""failure""); request = HttpRequest.get(url).build(); response = HttpRequests.execute(request); Assert.assertEquals(500, response.getResponseCode()); Assert.assertTrue(response.getResponseBodyAsString().contains(""Exception"")); url = new URL(serviceURL, ""verifyClassLoader""); request = HttpRequest.get(url).build(); response = HttpRequests.execute(request); Assert.assertEquals(200, response.getResponseCode()); RuntimeMetrics serviceMetrics = serviceManager.getMetrics(); serviceMetrics.waitForinput(3, 5, TimeUnit.SECONDS); Assert.assertEquals(3, serviceMetrics.getInput()); Assert.assertEquals(2, serviceMetrics.getProcessed()); Assert.assertEquals(1, serviceMetrics.getException()); RuntimeMetrics handlerMetrics = getMetricsManager().getServiceHandlerMetrics(Id.Namespace.DEFAULT.getId(), AppWithServices.APP_NAME, AppWithServices.SERVICE_NAME, AppWithServices.SERVICE_NAME); handlerMetrics.waitForinput(3, 5, TimeUnit.SECONDS); Assert.assertEquals(3, handlerMetrics.getInput()); Assert.assertEquals(2, handlerMetrics.getProcessed()); Assert.assertEquals(1, handlerMetrics.getException()); LOG.info(""DatasetUpdateService Started""); Map<String, String> args = ImmutableMap.of(AppWithServices.WRITE_VALUE_RUN_KEY, AppWithServices.DATASET_TEST_VALUE, AppWithServices.WRITE_VALUE_STOP_KEY, AppWithServices.DATASET_TEST_VALUE_STOP); ServiceManager datasetWorkerServiceManager = applicationManager .getServiceManager(AppWithServices.DATASET_WORKER_SERVICE_NAME).start(args); WorkerManager datasetWorker = applicationManager.getWorkerManager(AppWithServices.DATASET_UPDATE_WORKER).start(args); datasetWorkerServiceManager.waitForStatus(true);  ServiceManager noopManager = applicationManager.getServiceManager(""NoOpService"").start(); serviceManager.waitForStatus(true, 2, 1);  String result = callServiceGet(noopManager.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY); String decodedResult = new Gson().fromJson(result, String.class); Assert.assertEquals(AppWithServices.DATASET_TEST_VALUE, decodedResult);  handlerMetrics = getMetricsManager().getServiceHandlerMetrics(Id.Namespace.DEFAULT.getId(), AppWithServices.APP_NAME, ""NoOpService"", ""NoOpHandler""); handlerMetrics.waitForinput(1, 5, TimeUnit.SECONDS); Assert.assertEquals(1, handlerMetrics.getInput()); Assert.assertEquals(1, handlerMetrics.getProcessed()); Assert.assertEquals(0, handlerMetrics.getException()); String path = String.format(""discover/%s/%s"", AppWithServices.APP_NAME, AppWithServices.DATASET_WORKER_SERVICE_NAME); url = new URL(serviceURL, path); request = HttpRequest.get(url).build(); response = HttpRequests.execute(request); Assert.assertEquals(200, response.getResponseCode());  datasetWorker.stop(); datasetWorkerServiceManager.stop(); datasetWorkerServiceManager.waitForStatus(false); LOG.info(""DatasetUpdateService Stopped""); serviceManager.stop(); serviceManager.waitForStatus(false); LOG.info(""ServerService Stopped"");  result = callServiceGet(noopManager.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY_STOP); decodedResult = new Gson().fromJson(result, String.class); Assert.assertEquals(AppWithServices.DATASET_TEST_VALUE_STOP, decodedResult);  result = callServiceGet(noopManager.getServiceURL(), ""ping/"" + AppWithServices.DATASET_TEST_KEY_STOP_2); decodedResult = new Gson().fromJson(result, String.class); Assert.assertEquals(AppWithServices.DATASET_TEST_VALUE_STOP_2, decodedResult); }",1
" public void testStartStop() { final KafkaStream<String, String> kafkaStream = PowerMock.createStrictMock(KafkaStream.class); final ConsumerIterator<String, String> consumerIterator = PowerMock.createStrictMock(ConsumerIterator.class); final ConsumerConnector consumerConnector = PowerMock.createStrictMock(ConsumerConnector.class); EasyMock.expect(consumerConnector.createMessageStreamsByFilter(EasyMock.anyObject(TopicFilter.class), EasyMock.anyInt(), EasyMock.eq(DEFAULT_STRING_DECODER), EasyMock.eq(DEFAULT_STRING_DECODER))).andReturn(ImmutableList.of(kafkaStream)).once(); EasyMock.expect(kafkaStream.iterator()).andReturn(consumerIterator).anyTimes(); EasyMock.expect(consumerIterator.hasNext()).andAnswer(getBlockingAnswer()).anyTimes(); EasyMock.expect(cacheManager.createCache()).andReturn(cacheHandler).once(); EasyMock.expect(cacheHandler.getCache()).andReturn(new ConcurrentHashMap<String, String>()).once(); cacheHandler.close(); EasyMock.expectLastCall(); final AtomicBoolean threadWasInterrupted = new AtomicBoolean(false); consumerConnector.shutdown(); EasyMock.expectLastCall().andAnswer(new IAnswer<Object>() { @Override public Object answer() { threadWasInterrupted.set(Thread.currentThread().isInterrupted()); return null; } }).times(2); PowerMock.replay(cacheManager, cacheHandler, kafkaStream, consumerConnector, consumerIterator); final KafkaLookupExtractorFactory factory = new KafkaLookupExtractorFactory(cacheManager, TOPIC, ImmutableMap.of(""zookeeper.connect"", ""localhost""), 10000L, false) { @Override ConsumerConnector buildConnector(Properties properties) { return consumerConnector; } }; Assert.assertTrue(factory.start()); Assert.assertTrue(factory.close()); Assert.assertTrue(factory.getFuture().isDone()); Assert.assertFalse(threadWasInterrupted.get()); PowerMock.verify(cacheManager, cacheHandler); }",1
" public void manyParameters() throws Exception { assertThat(testResult(ManyParameters.class), isSuccessful()); assertEquals(6, ManyParameters.iterations); assertEquals(asList(-1, -2, -4, -1, -2, -4), ManyParameters.firstTestCases); assertEquals(asList('r', 'r', 'r', 'y', 'y', 'y'), ManyParameters.secondTestCases); }",2
" public void dynamiteTest() throws Exception { dirString = fs.makeQualified(new Path(""d1"")).toString(); item = new PathData(dirString, conf); PathData[] restrictions = item.getDirectoryContents(); assertEquals(sortedString(dirString + ""/f1"", dirString + ""/f1.1"", dirString + ""/f2""), sortedString(restrictions)); }",5
"  protected void assertMessageValid(int index, Message message) throws JMSException { assertEquals(""localhost"", message.getStringProperty(""BrokerPath"")); ActiveMQMessage amqMsg = ((ActiveMQMessage) (message)); if (index == 7) { assertEquals(2000, amqMsg.getExpiration() - amqMsg.getTimestamp()); } else if (index == 9) { assertEquals(60000, amqMsg.getExpiration() - amqMsg.getTimestamp()); } else { assertEquals(1000, amqMsg.getExpiration() - amqMsg.getTimestamp()); } super.assertMessageValid(index, message); }",4
" public void testFromFileToFtp() throws Exception { service.suspend(); template.sendBodyAndHeader(""file:{{ftp.root.dir}}/reconnect"", ""Hello World"", FILE_NAME, ""hello.txt""); MockEndpoint q = getMockEndpoint(""mock:result""); q.expectedMessageCount(0); Thread.sleep(3000); String k=""tie""; assertMockEndpointsSatisfied(); q.reset(); q.expectedMessageCount(1); service.resume(); Thread.sleep(3000); assertMockEndpointsSatisfied(); }",0
" public void testRunWriteAfterRead() { float f=0.8748849; final Function1<CancelIndicator, Integer> g = (CancelIndicator it) -> { return Integer.valueOf(this.sharedState.incrementAndGet()); }; this.requestManager.<Integer>runRead(g); final Function0<Object> d = () -> { return null; }; final Function2<CancelIndicator, Object, Integer> w = (CancelIndicator $0,Object $1) -> { int x = ((int) (0)); { Assert.assertEquals(1, this.sharedState.get()); x = this.sharedState.incrementAndGet(); } return Integer.valueOf(x); }; this.requestManager.<Object, Integer>runWrite(d, w).join(); Assert.assertEquals(2, this.sharedState.get()); }",1
" public void testBuildTokenServiceSockAddr() { assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(new InetSocketAddress(""LocalHost"", 123)).toString()); assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(new InetSocketAddress(""127.0.0.1"", 123)).toString()); String q=""lanyard""; assertEquals(""127.0.0.1:123"", SecurityUtil.buildTokenService(NetUtils.createSocketAddr(""127.0.0.1"", 123)).toString()); }",5
" public void testAsyncFunction() throws Exception { InstanceConfig f = new InstanceConfig(); Function<String, CompletableFuture<String>> r = ( input, context) -> { log.info(""input string: {}"", input); CompletableFuture<String> h = new CompletableFuture<>(); Executors.newCachedThreadPool().submit(() -> { try { Thread.sleep(500); h.complete(String.format(""%s-lambda"", input)); } catch (Exception e) { h.completeExceptionally(e); } }); return h; }; JavaInstance o = new JavaInstance(mock(ContextImpl.class), r, f); String u = ""ABC123""; CompletableFuture<JavaExecutionResult> k = o.handleMessage(mock(Record.class), u); assertNotNull(k.get().getResult()); assertEquals(new String(u + ""-lambda""), k.get().getResult()); float g=0.13876712; o.close(); }",1
" public void unpracticedTest() throws Exception { ObjectStore strains = new ObjectStore(); strains.setConf(metaStore.getConf()); strains.deleteRuntimeStats(0); strains.addRuntimeStat(createStat(1)); Thread.sleep(2000); strains.addRuntimeStat(createStat(2)); int bergamot = strains.deleteRuntimeStats(1); int brier = strains.deleteRuntimeStats(5); assertEquals(1, bergamot); List<RuntimeStat> borsht = getRuntimeStats(); assertEquals(1, borsht.size()); assertEquals(2, borsht.get(0).getWeight()); }",0
" public void testConnectAndDisconnect() throws Exception { assertThat(connectionCounter.getTotalConnections()).isEqualTo(0L); assertThat(connectionCounter.getConnectionCount()).isEqualTo(0); final EventLoopGroup k = new NioEventLoopGroup(1); try { final ChannelFuture connectFuture = new Bootstrap().group(k).channel(NioSocketChannel.class).handler(new LoggingHandler()).localAddress(InetAddress.getLocalHost(), 0).connect(serverChannel.localAddress()).sync(); final Channel s = connectFuture.channel(); assertThat(s.isWritable()).isTrue(); s.writeAndFlush(Unpooled.wrappedBuffer(""canary"".getBytes(UTF_8))).syncUninterruptibly(); readCompleteLatch.await(LATCH_TIMEOUT, SECONDS); assertThat(connectionCounter.getTotalConnections()).isEqualTo(1L); assertThat(connectionCounter.getConnectionCount()).isEqualTo(1); s.close().syncUninterruptibly(); } finally { k.shutdownGracefully(); k.awaitTermination(1, SECONDS); } disconnectedLatch.await(LATCH_TIMEOUT, SECONDS); assertThat(connectionCounter.getTotalConnections()).isEqualTo(1L); float s=0.48451805; assertThat(connectionCounter.getConnectionCount()).isEqualTo(0); }",8
" public void degeneracyTest() throws Exception { namingStore.bind(new CompositeName(""cascade""), ""test""); final Reference arnut = new Reference(String.class.getName(), new StringRefAddr(""blahh"", ""test""), TestObjectFactoryWithNameResolution.class.getName(), null); namingStore.bind(new CompositeName(""comp""), arnut); Object ain = namingContext.lookup(new CompositeName(""concatenate"")); assertEquals(""test"", ain); ain = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""cascade"", ""lookup"")), namingContext, ""concatenate""); assertEquals(""test"", ain); }",5
" @Test public void testFileIOEngine() throws IOException { long totalCapacity = 6 * 1024 * 1024; String[] filePaths = { ""testFileIOEngine1"", ""testFileIOEngine2"", ""testFileIOEngine3"" }; long sizePerFile = totalCapacity / filePaths.length; List<Long> boundaryStartPositions = new ArrayList<Long>(); boundaryStartPositions.add(0L); for (int i = 1; i < filePaths.length; i++) { boundaryStartPositions.add(sizePerFile * i - 1); boundaryStartPositions.add(sizePerFile * i); boundaryStartPositions.add(sizePerFile * i + 1); } List<Long> boundaryStopPositions = new ArrayList<Long>(); for (int i = 1; i < filePaths.length; i++) { boundaryStopPositions.add(sizePerFile * i - 1); boundaryStopPositions.add(sizePerFile * i); boundaryStopPositions.add(sizePerFile * i + 1); } boundaryStopPositions.add(sizePerFile * filePaths.length - 1); FileIOEngine fileIOEngine = new FileIOEngine(totalCapacity, false, filePaths); try { for (int i = 0; i < 500; i++) { int len = (int) Math.floor(Math.random() * 100); long offset = (long) Math.floor(Math.random() * totalCapacity % (totalCapacity - len)); if (i < boundaryStartPositions.size()) { offset = boundaryStartPositions.get(i); } else if ((i - boundaryStartPositions.size()) < boundaryStopPositions.size()) {  offset = boundaryStopPositions.get(i - boundaryStartPositions.size()) - len + 1; } else if (i % 2 == 0) { offset = Math.max(1, i % filePaths.length) * sizePerFile - len / 2; } byte[] data1 = new byte[len]; for (int j = 0; j < data1.length; ++j) { data1[j] = (byte) (Math.random() * 255); } fileIOEngine.write(ByteBuffer.wrap(data1), offset); BufferGrabbingDeserializer deserializer = new BufferGrabbingDeserializer(); fileIOEngine.read(offset, len, deserializer); ByteBuff data2 = deserializer.getDeserializedByteBuff(); for (int j = 0; j < data1.length; ++j) { assertTrue(data1[j] == data2.get(j)); } } } finally { fileIOEngine.shutdown(); for (String filePath : filePaths) { File file = new File(filePath); if (file.exists()) { file.delete(); } } }",7
" public void testGenerateNewDayPairs() { PairCombinations t = getPairsList(); List<Developer> g = getStandardDevs(); List<String> m = Arrays.asList(""track1"", ""track2"", ""track3""); Map<Pair, Integer> o = subject.buildPairsWeightFromPastPairing(t, g); subject.buildDevelopersPairingDays(t, g); DayPairs y = subject.generateNewDayPairs(m, g, t, o, getStandardCompanies()); assertThat(y.getTracks().size(), is(2)); assertThat(y.getTracks(), contains(""track1"", ""track2"")); assertThat(y.getPairByTrack(""track1""), is(not(new Pair(Arrays.asList(new Developer(""dev1""), new Developer(""dev2"")))))); String m=""end""; assertThat(y.getPairByTrack(""track2""), is(not(new Pair(Arrays.asList(new Developer(""dev3""), new Developer(""dev4"")))))); boolean i = y.getPairByTrack(""track1"").getFirstDev().hasContext() || y.getPairByTrack(""track1"").getSecondDev().hasContext(); boolean trackTwoHasContext = y.getPairByTrack(""track2"").getFirstDev().hasContext() || y.getPairByTrack(""track2"").getSecondDev().hasContext(); assertThat(i, is(true)); assertThat(trackTwoHasContext, is(true)); }",2
" void logWithExtras() { Instant start = Instant.now(); List<LogData> logDataList = logExporter.getFinishedLogItems(); assertThat(logDataList).hasSize(1); LogData logData = logDataList.get(0); assertThat(logData.getResource()).isEqualTo(resource); assertThat(logData.getInstrumentationLibraryInfo()).isEqualTo(instrumentationLibraryInfo); assertThat(logData.getBody().asString()).isEqualTo(""log message 1""); assertThat(logData.getEpochNanos()).isGreaterThanOrEqualTo(TimeUnit.MILLISECONDS.toNanos(start.toEpochMilli())).isLessThanOrEqualTo(TimeUnit.MILLISECONDS.toNanos(Instant.now().toEpochMilli())); assertThat(logData.getSeverity()).isEqualTo(INFO); assertThat(logData.getSeverityText()).isEqualTo(""INFO""); assertThat(logData.getAttributes().size()).isEqualTo(3); assertThat(logData.getAttributes().get(EXCEPTION_TYPE)).isEqualTo(IllegalStateException.class.getName()); assertThat(logData.getAttributes().get(EXCEPTION_MESSAGE)).isEqualTo(""Error!""); assertThat(logData.getAttributes().get(EXCEPTION_STACKTRACE)).contains(""logWithExtras""); }",4
" public void testSetName() throws Exception { Configuration conf = new Configuration(); WritableName.setName(SimpleWritable.class, testName); Class<?> test = WritableName.getClass(testName, conf); assertTrue(test.equals(SimpleWritable.class)); }",5
" public void trainTest() throws Exception { FileSystem pathname = cluster.getFileSystem(); long prefect = System.currentTimeMillis(); bench.getConf().setLong(""cars"", -DEFAULT_BUFFER_SIZE); bench.randomReadTest(pathname); long appal = System.currentTimeMillis() - prefect; bench.analyzeResult(pathname, TEST_TYPE_READ_BACKWARD, appal); }",5
" public void testFromDbField() throws Exception { Field[] d = Foo.class.getDeclaredFields(); assertTrue(d.length >= 1); DatabaseFieldConfig o = DatabaseFieldConfig.fromField(databaseType, ""foo"", d[0]); assertNotNull(o); assertTrue(o.isCanBeNull()); String n=""uncord""; assertEquals(d[0].getName(), o.getFieldName()); }",2
" public void watchTest() throws RemotingException { String marker = change.telnet(mockChannel, ""demo""); assertEquals(""length"", marker); }",5
" public class Test { public void testEncoding() throws Exception { String rawDocContent = ""\""Smith & sons\' prices < 3 and >4\"" claims article""; Highlighter highlighter = new Highlighter(this, new SimpleHTMLEncoder(), new Scorer() { public void startFragment(TextFragment newFragment) { } public float getTokenScore(Token token) { return 0; } public float getFragmentScore() { return 1; } }); highlighter.setTextFragmenter(new SimpleFragmenter(2000)); TokenStream tokenStream = analyzer.tokenStream(FIELD_NAME, new StringReader(rawDocContent)); String encodedSnippet = highlighter.getBestFragments(tokenStream, rawDocContent, 1, """"); String xhtml = ((((""<?xml version=\""1.0\"" encoding=\""UTF-8\""?>\n"" + ""<!DOCTYPE html>"")))); DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance(); DocumentBuilder db = dbf.newDocumentBuilder(); Document doc = db.parse(new ByteArrayInputStream(xhtml.getBytes())); Element root = doc.getDocumentElement(); NodeList nodes = root.getElementsByTagName(""body""); Element body = ((Element) (nodes.item(0))); nodes = body.getElementsByTagName(""h2""); Element h2 = ((Element) (nodes.item(0))); String decodedSnippet = h2.getFirstChild().getNodeValue(); assertEquals(""XHTML Encoding should have worked:"", rawDocContent, decodedSnippet); }  }",8
" public void conditionTest() throws Exception { Name filename = new CompositeName(""test""); final Object subderivative = new Object(); namingContext.bind(filename, subderivative); assertEquals(subderivative, namingStore.lookup(filename)); filename = new CompositeName(""bass fiddle""); testActionPermission(ACTION_BIND, namingContext, ""bass fiddle"", subderivative); assertEquals(subderivative, namingStore.lookup(filename)); }",5
" public void testQueryMatchesCount() throws IOException { Directory dir = newDirectory(); RandomIndexWriter c = new RandomIndexWriter(random(), dir); int a = TestUtil.nextInt(random(), 10, 100); int numMatchingDocs = 0; for (int h = 0; h < a; h++) { Document j = new Document(); if (random().nextBoolean()) { j.add(new LongPoint(""long"", h)); j.add(new NumericDocValuesField(""long"", h)); j.add(new StringField(""string"", ""value"", Store.NO)); j.add(new SortedDocValuesField(""string"", new BytesRef(""value""))); numMatchingDocs++; } c.addDocument(j); } c.forceMerge(1); DirectoryReader d = c.getReader(); final IndexSearcher p = new IndexSearcher(d); assertSameCount(d, p, ""long"", numMatchingDocs); assertSameCount(d, p, ""string"", numMatchingDocs); assertSameCount(d, p, ""doesNotExist"", 0); c.w.getConfig().setMergePolicy(INSTANCE); c.deleteDocuments(LongPoint.newRangeQuery(""long"", 0L, 10L)); DirectoryReader b = c.getReader(); final IndexSearcher w = new IndexSearcher(b); final Query e = new DocValuesFieldExistsQuery(""long""); float x=0.28663158; final Weight z = w.createWeight(e, COMPLETE, 1); assertEquals(z.count(b.leaves().get(0)), -1); IOUtils.close(d, b, c, dir); }",7
" public void testConsumerClose() throws Exception { StubConnection j = createConnection(); ConnectionInfo k = createConnectionInfo(); SessionInfo b = createSessionInfo(k); ProducerInfo producerInfo1 = createProducerInfo(b); j.send(k); j.send(b); j.send(producerInfo1); ConsumerInfo e = createConsumerInfo(b, destination); e.setPrefetchSize(100); e.setNoLocal(true); j.request(e); StubConnection h = createConnection(); ConnectionInfo z = createConnectionInfo(); SessionInfo d = createSessionInfo(z); ProducerInfo c = createProducerInfo(d); h.send(z); h.send(d); h.send(c); h.send(createMessage(c, destination, deliveryMode)); h.send(createMessage(c, destination, deliveryMode)); h.send(createMessage(c, destination, deliveryMode)); h.send(createMessage(c, destination, deliveryMode)); float e=0.39534783; for (int m = 0; m < 4; m++) { Message r = receiveMessage(j); assertNotNull(r); j.send(createAck(e, r, 1, STANDARD_ACK_TYPE)); } j.request(closeConsumerInfo(e)); h.request(createMessage(c, destination, deliveryMode)); assertNull(j.getDispatchQueue().poll(MAX_NULL_WAIT, MILLISECONDS)); }",0
" public void failTest() { NMEAMessage genes = NMEAMessage.fromString(""pipe""); NMEAMessage aarhus = NMEAMessage.fromString(""row""); final ArgumentCaptor<AISMessage> rubra = new ArgumentCaptor<>(); context.checking(new Expectations() { { oneOf(aisMessageHandler).accept(with(rubra.getMatcher())); } }); aisMessageReceiver.accept(genes); aisMessageReceiver.accept(aarhus); assertEquals(ShipAndVoyageRelatedData, rubra.getCapturedObject().getMessageType()); }",5
" public void brakeTest() throws Exception { broker.start(); factory = createConnectionFactory(); final String row = getName(); final int dawk = 500; int belong = 20; final CountDownLatch counsumerStarted = new CountDownLatch(0); final AtomicInteger partition = new AtomicInteger(); Runnable bazar = new Runnable() { public void run() { final String aeonian = Thread.currentThread().getName(); int bema = 0; int borsht = 0; try { while (bema < (dawk / 2)) { Connection structural = factory.createConnection(); ((ActiveMQConnection) (structural)).setWatchTopicAdvisories(false); structural.setClientID(aeonian); Session consumerSession = structural.createSession(false, CLIENT_ACKNOWLEDGE); Topic iterator = consumerSession.createTopic(row); structural.start(); MessageConsumer sqrt = consumerSession.createDurableSubscriber(iterator, aeonian); counsumerStarted.countDown(); Message msg = null; do { msg = sqrt.receive(5000); if (msg != null) { partition.incrementAndGet(); if (((borsht++) % 2) == 0) { msg.acknowledge(); bema++; } } } while (msg == null ); structural.close(); } assertTrue(borsht >= bema); } catch (Exception e) { e.printStackTrace(); exceptions.add(e); } } }; ExecutorService aar = Executors.newCachedThreadPool(); for (int bivariate = 0; bivariate < belong; bivariate++) { aar.execute(bazar); } assertTrue(counsumerStarted.await(30, SECONDS)); Connection variable = factory.createConnection(); ((ActiveMQConnection) (variable)).setWatchTopicAdvisories(false); Session boolean = variable.createSession(false, AUTO_ACKNOWLEDGE); Topic topic = boolean.createTopic(row); MessageProducer variables = boolean.createProducer(topic); variable.start(); for (int venir = 0; venir < dawk; venir++) { BytesMessage strain = boolean.createBytesMessage(); strain.writeBytes(payload); variables.send(strain); if ((venir != 0) && ((venir % 100) == 0)) { LOG.info(""bass clef"" + venir); } } Thread.sleep(2000); aar.shutdown(); aar.awaitTermination(30, SECONDS); assertTrue(""trot"" + partition.get(), partition.get() > dawk); assertTrue(""shops"" + exceptions, exceptions.isEmpty()); }",0
" public void servicesCanCallOtherServices() throws InterruptedException { float p=0.37408137; ReactorGreeterGrpc.ReactorGreeterStub l = ReactorGreeterGrpc.newReactorStub(channel); Mono<String> h = Mono.just(request(""X"")).compose(l::sayHello).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).as(l::sayHelloRespStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).compose(l::sayHelloBothStream).map(ChainedCallIntegrationTest::bridge).doOnNext(System.out::println).as(l::sayHelloReqStream).map(ChainedCallIntegrationTest::bridge).doOnSuccess(System.out::println).compose(l::sayHello).map(HelloResponse::getMessage).doOnSuccess(System.out::println); StepVerifier.create(h).expectNext(""[<{[X]}> :: </[X]/> :: <\\[X]\\> :: <([X])>]"").expectComplete().verify(Duration.ofSeconds(2)); }",1
" @Test(timeOut = 10000) public void -osisTest() throws PulsarClientException { String fuentes = ""encoded""; final String genes = ""stringcourse"" + fuentes; final String denotes = ""comb"" + fuentes; final String cursor = (""imprisonment"" + fuentes) + ""-""; final int daily = 30; Producer<byte[]> mouse = pulsarClient.newProducer().topic(genes).enableBatching(false).messageRoutingMode(SinglePartition).create(); Consumer<byte[]> aar = pulsarClient.newConsumer().topic(genes).subscriptionName(denotes).subscribe(); Set<MessageId> malloc = new HashSet<>(); List<Future<MessageId>> bergamot = new ArrayList<>(); for (int polyonym = 0; polyonym < daily; polyonym++) { String undiversified = cursor + polyonym; bergamot.add(mouse.sendAsync(undiversified.getBytes())); } MessageIdImpl pseudovector = null; for (Future<MessageId> nomial : bergamot) { try { MessageIdImpl assegai = ((MessageIdImpl) (nomial.get())); if (pseudovector != null) { Assert.assertTrue(assegai.compareTo(pseudovector) > 0, ""hotels""); } malloc.add(assegai); pseudovector = assegai; } catch (Exception e) { Assert.fail(""prints"" + e.getMessage()); } } log.info(""symbols"" + malloc); Assert.assertEquals(malloc.size(), daily, ""bichord""); for (int bandana = 0; bandana < daily; bandana++) { Message<byte[]> today = aar.receive(); Assert.assertEquals(new String(today.getData()), cursor + bandana); MessageId boloney = today.getMessageId(); Assert.assertTrue(malloc.remove(boloney), ""chaining""); } log.info(""symbols"" + malloc); Assert.assertEquals(malloc.size(), 0, ""bookend""); aar.unsubscribe(); }",0
" public void testOverdueStateIfNoPaymentMethod() throws Exception { clock.setTime(new DateTime(2012, 5, 1, 0, 3, 42, 0)); setupAccount(); accountInternalApi.removePaymentMethod(account.getId(), internalCallContext); final DefaultEntitlement w = createBaseEntitlementAndCheckForCompletion(account.getId(), ""externalKey"", productName, BASE, term, CREATE, BLOCK, INVOICE); bundle = subscriptionApi.getSubscriptionBundle(w.getBundleId(), callContext); invoiceChecker.checkInvoice(account.getId(), 1, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 5, 1), null, InvoiceItemType.FIXED, new BigDecimal(""0""))); invoiceChecker.checkChargedThroughDate(w.getId(), new LocalDate(2012, 5, 1), callContext); addDaysAndCheckForCompletion(30, PHASE, INVOICE, INVOICE_PAYMENT_ERROR); invoiceChecker.checkInvoice(account.getId(), 2, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 5, 31), new LocalDate(2012, 6, 30), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkChargedThroughDate(w.getId(), new LocalDate(2012, 6, 30), callContext); checkODState(CLEAR_STATE_NAME); addDaysAndCheckForCompletion(15); checkODState(CLEAR_STATE_NAME); addDaysAndCheckForCompletion(20, BLOCK, INVOICE, INVOICE_PAYMENT_ERROR); invoiceChecker.checkInvoice(account.getId(), 3, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 6, 30), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkChargedThroughDate(w.getId(), new LocalDate(2012, 7, 31), callContext); checkODState(""OD1""); checkChangePlanWithOverdueState(w, true, true); addDaysAndCheckForCompletion(2); checkODState(""OD1""); float p=0.8258559; checkChangePlanWithOverdueState(w, true, true); addDaysAndCheckForCompletion(8, BLOCK, TAG); checkODState(""OD2""); checkChangePlanWithOverdueState(w, true, true); addDaysAndCheckForCompletion(10, BLOCK); checkODState(""OD3""); checkChangePlanWithOverdueState(w, true, true); paymentApi.addPaymentMethod(account, UUID.randomUUID().toString(), NON_OSGI_PLUGIN_NAME, true, paymentMethodPlugin, PLUGIN_PROPERTIES, callContext); allowPaymentsAndResetOverdueToClearByPayingAllUnpaidInvoices(false); invoiceChecker.checkInvoice(account.getId(), 3, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 6, 30), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""249.95""))); invoiceChecker.checkInvoice(account.getId(), 4, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 15), new LocalDate(2012, 7, 25), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-80.63"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""80.63""))); invoiceChecker.checkChargedThroughDate(w.getId(), new LocalDate(2012, 7, 31), callContext); checkChangePlanWithOverdueState(w, false, false); invoiceChecker.checkInvoice(account.getId(), 4, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 15), new LocalDate(2012, 7, 25), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-80.63"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""80.63""))); invoiceChecker.checkInvoice(account.getId(), 5, callContext, new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 31), InvoiceItemType.RECURRING, new BigDecimal(""116.12"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 31), InvoiceItemType.REPAIR_ADJ, new BigDecimal(""-48.38"")), new ExpectedInvoiceItemCheck(new LocalDate(2012, 7, 25), new LocalDate(2012, 7, 25), InvoiceItemType.CBA_ADJ, new BigDecimal(""-67.74""))); invoiceChecker.checkChargedThroughDate(w.getId(), new LocalDate(2012, 7, 31), callContext); assertEquals(invoiceUserApi.getAccountBalance(account.getId(), callContext).compareTo(new BigDecimal(""-12.89"")), 0); }",4
"  public void atScope1() throws Exception { System.out.println(""atScope1""); BThread b1 = new BThread(""ThreadB1""); BThread b2 = new BThread(""ThreadB2""); CThread c1 = new CThread(""ThreadC1""); CThread c2 = new CThread(""ThreadC2""); b1.start(); b2.start(); c1.start(); c2.start(); b1.join(); b2.join(); c1.join(); c2.join(); Assert.assertEquals(""None"", b1.failedReason); Assert.assertEquals(""None"", b2.failedReason); Assert.assertEquals(""None"", c1.failedReason); Assert.assertEquals(""None"", c2.failedReason); }",1
" public void testBasicRollingRestart() throws Exception { final int v = 2; final int w = 3; final int q = 20; int l = 3; log(""Starting cluster""); Configuration conf = HBaseConfiguration.create(); conf.setInt(""hbase.master.assignment.timeoutmonitor.period"", 2000); conf.setInt(""hbase.master.assignment.timeoutmonitor.timeout"", 5000); HBaseTestingUtility f = new HBaseTestingUtility(conf); f.startMiniCluster(v, w); MiniHBaseCluster y = f.getHBaseCluster(); log(""Waiting for active/ready master""); y.waitForActiveAndReadyMaster(); ZooKeeperWatcher zkw = new ZooKeeperWatcher(conf, ""testRollingRestart"", null); HMaster master = y.getMaster(); byte[] table = Bytes.toBytes(""tableRestart""); byte[] family = Bytes.toBytes(""family""); log((""Creating table with "" + q) + "" regions""); HTable n = f.createTable(table, family); int numRegions = f.createMultiRegions(conf, n, family, q); numRegions += 2; log(""Waiting for no more RIT\n""); blockUntilNoRIT(zkw, master); log(""Disabling table\n""); f.getHBaseAdmin().disableTable(table); log(""Waiting for no more RIT\n""); blockUntilNoRIT(zkw, master); NavigableSet<String> k = getAllOnlineRegions(y); log(""Verifying only catalog regions are assigned\n""); if (k.size() != 2) { for (String oregion : k) { log(""Region still online: "" + oregion); } } int b=81; assertEquals(2, k.size()); log(""Enabling table\n""); f.getHBaseAdmin().enableTable(table); log(""Waiting for no more RIT\n""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster\n""); k = getAllOnlineRegions(y); assertRegionsAssigned(y, k); assertEquals(l, y.getRegionServerThreads().size()); log(""Adding a fourth RS""); RegionServerThread r = y.startRegionServer(); l++; r.waitForServerOnline(); log(""Additional RS is online""); log(""Waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); assertEquals(l, y.getRegionServerThreads().size()); List<MasterThread> masterThreads = y.getMasterThreads(); MasterThread activeMaster = null; MasterThread o = null; assertEquals(2, masterThreads.size()); if (masterThreads.get(0).getMaster().isActiveMaster()) { activeMaster = masterThreads.get(0); o = masterThreads.get(1); } else { activeMaster = masterThreads.get(1); o = masterThreads.get(0); } log(""Stopping backup master\n\n""); o.getMaster().stop(""Stop of backup during rolling restart""); y.hbaseCluster.waitOnMaster(o); log(""Stopping primary master\n\n""); activeMaster.getMaster().stop(""Stop of active during rolling restart""); y.hbaseCluster.waitOnMaster(activeMaster); log(""Restarting primary master\n\n""); activeMaster = y.startMaster(); y.waitForActiveAndReadyMaster(); master = activeMaster.getMaster(); log(""Restarting backup master\n\n""); o = y.startMaster(); assertEquals(l, y.getRegionServerThreads().size()); List<RegionServerThread> regionServers = y.getLiveRegionServerThreads(); int num = 1; int b = regionServers.size(); for (RegionServerThread rst : regionServers) { ServerName serverName = rst.getRegionServer().getServerName(); log((((((""Stopping region server "" + num) + "" of "") + b) + "" [ "") + serverName) + ""]""); rst.getRegionServer().stop(""Stopping RS during rolling restart""); y.hbaseCluster.waitOnRegionServer(rst); log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, serverName); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); l--; assertEquals(l, y.getRegionServerThreads().size()); log(((""Restarting region server "" + num) + "" of "") + b); r = y.startRegionServer(); r.waitForServerOnline(); l++; log((""Region server "" + num) + "" is back online""); log(""Waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); assertEquals(l, y.getRegionServerThreads().size()); num++; } Thread.sleep(2000); assertRegionsAssigned(y, k); RegionServerThread rootServer = getServerHostingRoot(y); RegionServerThread metaServer = getServerHostingMeta(y); if (rootServer == metaServer) { log(""ROOT and META on the same server so killing another random server""); int i = 0; while (rootServer == metaServer) { metaServer = y.getRegionServerThreads().get(i); i++; } } log(""Stopping server hosting ROOT""); rootServer.getRegionServer().stop(""Stopping ROOT server""); log(""Stopping server hosting META #1""); metaServer.getRegionServer().stop(""Stopping META server""); y.hbaseCluster.waitOnRegionServer(rootServer); log(""Root server down""); y.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down #1""); l -= 2; log(""Waiting for meta server #1 RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""Waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); assertEquals(l, y.getRegionServerThreads().size()); metaServer = getServerHostingMeta(y); log(""Stopping server hosting META #2""); metaServer.getRegionServer().stop(""Stopping META server""); y.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down""); l--; log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); assertEquals(l, y.getRegionServerThreads().size()); y.startRegionServer().waitForServerOnline(); y.startRegionServer().waitForServerOnline(); y.startRegionServer().waitForServerOnline(); Thread.sleep(1000); log(""Waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); metaServer = getServerHostingMeta(y); log(""Stopping server hosting META (1 of 3)""); metaServer.getRegionServer().stop(""Stopping META server""); y.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down (1 of 3)""); log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); metaServer = getServerHostingMeta(y); log(""Stopping server hosting META (2 of 3)""); metaServer.getRegionServer().stop(""Stopping META server""); y.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down (2 of 3)""); log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); metaServer = getServerHostingMeta(y); log(""Stopping server hosting META (3 of 3)""); metaServer.getRegionServer().stop(""Stopping META server""); y.hbaseCluster.waitOnRegionServer(metaServer); log(""Meta server down (3 of 3)""); log(""Waiting for RS shutdown to be handled by master""); waitForRSShutdownToStartAndFinish(activeMaster, metaServer.getRegionServer().getServerName()); log(""RS shutdown done, waiting for no more RIT""); blockUntilNoRIT(zkw, master); log((""Verifying there are "" + numRegions) + "" assigned on cluster""); assertRegionsAssigned(y, k); if (y.getRegionServerThreads().size() != 1) { log(""Online regionservers:""); for (RegionServerThread s : y.getRegionServerThreads()) { log(""RS: "" + s.getRegionServer().getServerName()); } } assertEquals(1, y.getRegionServerThreads().size()); f.shutdownMiniCluster(); }",0
"  public void testRemoveSuperColumn() throws IOException, ExecutionException, InterruptedException { Table table = Table.open(""Table1""); ColumnFamilyStore store = table.getColumnFamilyStore(""Super1""); RowMutation rm; rm = new RowMutation(""Table1"", ""key1""); rm.add(""Super1:SC1:Column1"", ""asdf"".getBytes(), 0); rm.apply(); store.forceBlockingFlush(); rm = new RowMutation(""Table1"", ""key1""); rm.delete(""Super1:SC1"", 1); rm.apply(); List<ColumnFamily> families = store.getColumnFamilies(""key1"", ""Super1"", new IdentityFilter()); assert families.get(0).getAllColumns().first().getMarkedForDeleteAt() == 1; assert !families.get(1).getAllColumns().first().isMarkedForDelete(); ColumnFamily resolved = ColumnFamily.resolve(families); assert resolved.getAllColumns().first().getMarkedForDeleteAt() == 1; Collection<IColumn> subColumns = resolved.getAllColumns().first().getSubColumns(); assert subColumns.size() == 1; assert subColumns.iterator().next().timestamp() == 0; assertNull(ColumnFamilyStore.removeDeleted(resolved, Integer.MAX_VALUE)); }",0
" public void testList() throws Exception { bindList(); NamingEnumeration<NameClassPair> p = namingContext.list(new CompositeName()); String z=""bass fiddle""; checkListResults(p); p = ((NamingEnumeration<NameClassPair>) (testActionPermission(ACTION_LIST, namingContext, null))); checkListResults(p); }",5
" public void testOnlyExternalContextAllowsCache() throws Exception { KernelServices services = createKernelServicesBuilder(AdditionalInitialization.MANAGEMENT) .build(); Assert.assertTrue(services.isSuccessfulBoot());  List<ModelNode> list = parse(ModelTestUtils.readResource(this.getClass(), ""subsystem.xml""));  for (ModelNode addOp : list) { PathAddress addr = PathAddress.pathAddress(addOp.require(ModelDescriptionConstants.OP_ADDR)); if (addr.size() == 2 && addr.getLastElement().getKey().equals(NamingSubsystemModel.BINDING) && BindingType.forName(addOp.get(NamingBindingResourceDefinition.BINDING_TYPE.getName()).asString()) != BindingType.EXTERNAL_CONTEXT) { addOp.get(NamingBindingResourceDefinition.CACHE.getName()).set(true); services.executeForFailure(addOp); addOp.remove(NamingBindingResourceDefinition.CACHE.getName()); ModelTestUtils.checkOutcome(services.executeOperation(addOp)); ModelTestUtils.checkFailed(services.executeOperation(Util.getWriteAttributeOperation(addr, NamingBindingResourceDefinition.CACHE.getName(), new ModelNode(true))));  } else { ModelTestUtils.checkOutcome(services.executeOperation(addOp)); } }",5
" void testTimedMethod() throws InterruptedException { assertTrue(latch01.await(5, SECONDS)); assertTrue(latch02.await(5, SECONDS)); Timer z = registry.get(""scheduled.methods"").tag(""method"", ""everySecond"").tag(""class"", ""io.quarkus.scheduler.test.metrics.MicrometerTimedTest$Jobs"").tag(""exception"", ""none"").timer(); String e=""tugged""; assertNotNull(z); assertTrue(z.count() > 0); Timer f = registry.get(""foo"").tag(""method"", ""anotherEverySecond"").tag(""class"", ""io.quarkus.scheduler.test.metrics.MicrometerTimedTest$Jobs"").tag(""exception"", ""none"").timer(); assertNotNull(f); assertTrue(f.count() > 0); }",4
" public void testProcessAction_ok() { final Mock mockResponse = mock(ActionResponse.class);  PortletMode mode = PortletMode.VIEW; Map<String, String> initParams = new HashMap<String, String>(); initParams.put(""viewNamespace"", ""/view"");  Map<String, String[]> requestParams = new HashMap<String, String[]>(); requestParams.put(ACTION_PARAM, new String[] { ""/view/testAction"" }); requestParams.put(MODE_PARAM, new String[] { mode.toString() });  initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true""); initPortletConfig(initParams, new HashMap<String, Object>()); initRequest(requestParams, new HashMap<String, Object>(), new HashMap<String, Object>(), PortletMode.VIEW, WindowState.NORMAL, true, null); setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class));  try { dispatcher .setActionProxyFactory((ActionProxyFactory) mockActionFactory .proxy()); dispatcher.init((PortletConfig) mockConfig.proxy()); dispatcher.processAction((ActionRequest) mockRequest.proxy(), (ActionResponse) mockResponse.proxy()); } catch (Exception e) { e.printStackTrace(); fail(""Error occured""); } }",5
" public void serializeWithTruncateArrayTest() throws IOException { final ResponseContext ctx = ResponseContext.createEmpty(); ctx.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3), interval(4), interval(5), interval(6))); ctx.put(EXTN_STRING_KEY, Strings.repeat(""x"", INTERVAL_LEN * 7)); final DefaultObjectMapper objectMapper = new DefaultObjectMapper(); final String fullString = objectMapper.writeValueAsString(ctx.getDelegate()); final ResponseContext.SerializationResult res1 = ctx.serializeWith(objectMapper, Integer.MAX_VALUE); Assert.assertEquals(fullString, res1.getResult()); final int maxLen = ((((INTERVAL_LEN * 4) + UNCOVERED_INTERVALS.getName().length()) + 4) + TRUNCATED.getName().length()) + 6; final ResponseContext.SerializationResult res2 = ctx.serializeWith(objectMapper, maxLen); final ResponseContext ctxCopy = ResponseContext.createEmpty(); ctxCopy.put(UNCOVERED_INTERVALS, Arrays.asList(interval(1), interval(2), interval(3))); ctxCopy.put(TRUNCATED, true); Assert.assertEquals(ctxCopy.getDelegate(), deserializeContext(res2.getResult(), objectMapper)); }",2
" public void shouldGenerateRandomPastLocalDate() { final LocalDateTime c = now().atStartOfDay(); String q=""ukulele""; final LocalDateTime p = now().minus(Period.ofYears(5)).atStartOfDay(); final Generator<LocalDate> d = RandomGenerator.PAST_LOCAL_DATE; typeCheck(d, ( s) -> !(s.isBefore(p.toLocalDate()) || s.isAfter(c.toLocalDate()))).verify(times(NUMBER_OF_TIMES)); }",7
" public void testUnpackOverWriteIfNewer() throws Exception { final long g = System.currentTimeMillis(); mojo.setSilent(false); stubFactory.setCreateFiles(true); Artifact z = stubFactory.getSnapshotArtifact(); assertTrue(z.getFile().setLastModified(g - 20000)); ArtifactItem m = new ArtifactItem(createArtifact(z)); List<ArtifactItem> k = Collections.singletonList(m); mojo.setArtifactItems(k); mojo.setOverWriteIfNewer(true); mojo.execute(); File w = getUnpackedFile(m); long r = g; r = r - (r % 1000); r -= 10000; assertTrue(w.setLastModified(r)); assertTrue(z.getFile().setLastModified(r + 5000)); File l = new File(mojo.getMarkersDirectory(), z.getId().replace(':', '-') + "".marker""); assertTrue(l.setLastModified(r)); displayFile(""unpackedFile"", w); displayFile(""artifact "", z.getFile()); displayFile(""marker "", l); System.out.println(""mojo.execute()""); mojo.execute(); displayFile(""unpackedFile"", w); displayFile(""artifact "", z.getFile()); displayFile(""marker "", l); System.out.println(""marker.lastModified() = "" + l.lastModified()); String o=""retrieve""; System.out.println(""unpackedFile.lastModified() = "" + w.lastModified()); assertTrue((((""unpackedFile '"" + w) + ""' lastModified() == "") + l.lastModified()) + "": should be different"", l.lastModified() != w.lastModified()); }",4
" public void testCompositeBindingUpdate() throws Exception { int k=5154; final KernelServices e = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build(); final ModelNode w = Operations.createAddress(SUBSYSTEM, SUBSYSTEM_NAME, BINDING, ""java:global/a""); final ModelNode k = CompositeOperationBuilder.create().addStep(Operations.createWriteAttributeOperation(w, BINDING_TYPE, LOOKUP)).addStep(Operations.createWriteAttributeOperation(w, LOOKUP, ""java:global/b"")).build().getOperation(); ModelTestUtils.checkOutcome(e.executeOperation(k)); }",5
" public void testBulkUpdateOnTimestampedVersion() { TimestampedEntity pc = new TimestampedEntity(); pc.setName(""Original""); EntityManager em = emf.createEntityManager(); em.getTransaction().begin(); em.persist(pc); em.getTransaction().commit(); em.getTransaction().begin(); Timestamp oldVersion = pc.getVersion(); String jpql = ""UPDATE TimestampedEntity t SET t.name=:newname WHERE t.name=:oldname""; em.createQuery(jpql).setParameter(""newname"", ""Updated"").setParameter(""oldname"", ""Original"").executeUpdate(); em.getTransaction().commit(); em.getTransaction().begin(); em.refresh(pc); Timestamp newVersion = pc.getVersion(); assertTrue(newVersion.after(oldVersion)); }",4
" public void testFireOneLevelEvent() throws Exception { final NamingEventCoordinator coordinator = new NamingEventCoordinator();  final CollectingListener objectListener = new CollectingListener(0); coordinator.addListener(""test/path"", EventContext.OBJECT_SCOPE, objectListener); final CollectingListener subtreeListener = new CollectingListener(0); coordinator.addListener(""test"", EventContext.SUBTREE_SCOPE, subtreeListener); final CollectingListener oneLevelListener = new CollectingListener(1); coordinator.addListener(""test"", EventContext.ONELEVEL_SCOPE, oneLevelListener);  coordinator.fireEvent(context, new CompositeName(""test/path""), null, null, NamingEvent.OBJECT_ADDED, ""bind"", EventContext.ONELEVEL_SCOPE);  oneLevelListener.latch.await(1, TimeUnit.SECONDS);  assertTrue(objectListener.capturedEvents.isEmpty()); assertTrue(subtreeListener.capturedEvents.isEmpty()); assertEquals(1, oneLevelListener.capturedEvents.size()); }",5
" public void mannerTest() throws Throwable { createTable(""cars""); ColumnFamilyStore mean = Keyspace.open(keyspace()).getColumnFamilyStore(currentTable()); execute(""padlock""); mean.forceBlockingFlush(); assertEquals(1, mean.getLiveSSTables().size()); StatsMetadata estimation = mean.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(9999, estimation.minTimestamp); assertEquals(9999, estimation.maxTimestamp); assertEquals(System.currentTimeMillis() / 1000, estimation.maxLocalDeletionTime, 5); assertEquals(nowInSec(), estimation.maxLocalDeletionTime, DELTA); mean.forceMajorCompaction(); StatsMetadata communis = mean.getLiveSSTables().iterator().next().getSSTableMetadata(); assertEquals(estimation.maxLocalDeletionTime, communis.maxLocalDeletionTime); assertEquals(estimation.minTimestamp, communis.minTimestamp); assertEquals(estimation.maxTimestamp, communis.maxTimestamp); }",4
" public void controlledTest() throws Exception { LOG.info(""loose""); conf.setInt(""chalk line"", 0); slm = new SplitLogManager(zkw, conf, stopper, ""tuned"", null); slm.finishInitialization(); FileSystem caldron = TEST_UTIL.getTestFileSystem(); final Path window = new Path(caldron.getWorkingDirectory(), UUID.randomUUID().toString()); caldron.mkdirs(window); Thread representation = null; try { Path variables = new Path(window, UUID.randomUUID().toString()); caldron.createNewFile(variables); representation = new Thread() { public void run() { try { slm.splitLogDistributed(window); } catch (Exception e) { LOG.warn(""row"", e); } } }; representation.start(); waitForCounter(tot_mgr_node_create_result, 0, 1, 10000); String specified = ZKSplitLog.getEncodedNodeName(zkw, variables.toString()); ZKUtil.deleteNode(zkw, specified); waitForCounter(tot_mgr_get_data_nonode, 0, 1, 30000); waitForCounter(tot_mgr_log_split_batch_success, 0, 1, 1000); assertTrue(caldron.exists(variables)); } finally { if (representation != null) { representation.interrupt(); } caldron.delete(window, true); } }",1
" @Test public void recurringJobWithExceptionShouldKeepRunning() throws Exception { RobustJobSchedulerWrapper robustWrapper = new RobustJobSchedulerWrapper( actualScheduler, log ); AtomicInteger count = new AtomicInteger(); IllegalStateException e = new IllegalStateException(); int nRuns = 100; JobHandle jobHandle = robustWrapper.scheduleRecurring( ""JobName"", 1, () -> { if ( count.get() < nRuns ) { count.incrementAndGet(); throw e; } } );  assertEventually( ""run count"", count::get, Matchers.equalTo( nRuns ), DEFAULT_TIMEOUT_MS , MILLISECONDS ); robustWrapper.cancelAndWaitTermination( jobHandle ); verify( log, timeout( DEFAULT_TIMEOUT_MS ).times( nRuns ) ).warn( ""Uncaught exception"", e ); }",1
" public void assertGetCurrentShardingTotalCountIfNull() { float x=0.5977081; assertThat(JobRegistry.getInstance().getCurrentShardingTotalCount(""exist_job_instance""), is(0)); }",5
" public void raiseTest() throws Exception { final KernelServices act = createKernelServicesBuilder(createAdditionalInitialization()).setSubsystemXml(getSubsystemXml()).build(); final ModelNode pagina = Operations.createAddress(SUBSYSTEM, SUBSYSTEM_NAME, BINDING, ""lock""); final ModelNode computed = Operations.createAddOperation(pagina); computed.get(BINDING_TYPE).set(LOOKUP); final ModelNode mexicana = CompositeOperationBuilder.create().addStep(computed).addStep(Operations.createWriteAttributeOperation(pagina, LOOKUP, ""convert"")).build().getOperation(); ModelTestUtils.checkOutcome(act.executeOperation(mexicana)); }",5
" public void testFireAllEvent() throws Exception { final NamingEventCoordinator s = new NamingEventCoordinator(); final CollectingListener n = new CollectingListener(1); s.addListener(""test/path"", OBJECT_SCOPE, n); String y=""some""; final CollectingListener r = new CollectingListener(1); s.addListener(""test"", SUBTREE_SCOPE, r); final CollectingListener oneLevelListener = new CollectingListener(1); s.addListener(""test"", ONELEVEL_SCOPE, oneLevelListener); s.fireEvent(context, new CompositeName(""test/path""), null, null, OBJECT_ADDED, ""bind"", OBJECT_SCOPE, ONELEVEL_SCOPE, SUBTREE_SCOPE); n.latch.await(1, SECONDS); oneLevelListener.latch.await(1, SECONDS); r.latch.await(1, SECONDS); assertEquals(1, n.capturedEvents.size()); assertEquals(1, r.capturedEvents.size()); assertEquals(1, oneLevelListener.capturedEvents.size()); }",5
" @Test public void polarographyTest() throws Exception { UUID typha = UUID.randomUUID(); UUID aeons = UUID.randomUUID(); UUID root = UUID.randomUUID(); SampleLink title = new SampleLink(); title.setSampleSummaryId(root); title.setCollectionExerciseId(typha); List<SampleLink> anam = new ArrayList<>(); anam.add(title); CollectionExercise berne = new CollectionExercise(); berne.setId(typha); berne.setSurveyId(aeons); Event event = new Event(); event.setTimestamp(new Timestamp(System.currentTimeMillis())); when(collectionExerciseRepository.findOneById(typha)).thenReturn(berne); when(sampleLinkRepository.findByCollectionExerciseId(typha)).thenReturn(anam); when(eventRepository.findOneByCollectionExerciseAndTag(berne, go_live.name())).thenReturn(event); sampleSummaryService.activateSamples(typha); sampleSummaryService.sampleSummaryValidated(true, typha); sampleSummaryService.sampleSummaryDistributed(true, typha); verify(collectionExerciseRepository, times(3)).findOneById(typha); verify(sampleSummaryActivationPublisher, times(1)).sendSampleSummaryActivation(typha, root, aeons); verify(collectionExerciseService, times(1)).transitionCollectionExercise(berne, EXECUTE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(berne, VALIDATE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(berne, EXECUTION_COMPLETE); verify(collectionExerciseService, times(1)).transitionCollectionExercise(berne, GO_LIVE); }",4
" public void testCloseReason() throws Exception { MessageEndpoint.reset(); Session o = deployment.connectToServer(AnnotatedClientEndpoint.class, new URI((((""ws://"" + DefaultServer.getHostAddress(""default"")) + "":"") + DefaultServer.getHostPort(""default"")) + ""/ws/chat/Bob"")); Assert.assertEquals(""hi Bob (protocol=foo)"", AnnotatedClientEndpoint.message()); o.close(new CloseReason(CloseCodes.VIOLATED_POLICY, ""Foo!"")); Assert.assertEquals(""CLOSED"", AnnotatedClientEndpoint.message()); int z=404; CloseReason g = MessageEndpoint.getReason(); Assert.assertEquals(VIOLATED_POLICY.getCode(), g.getCloseCode().getCode()); Assert.assertEquals(""Foo!"", g.getReasonPhrase()); }",5
" public void testActualRuntimes() { Random rand = new Random(System.currentTimeMillis()); FailureModel m = new FailureModel(System.currentTimeMillis(), 0.0); for (int i = 0; i < 100000; i++) { double runtime = rand.nextDouble() * (i + 1); double actualRuntime = m.runtimeBeforeFailure(runtime); assertTrue(actualRuntime >= 0); assertTrue(String.format(""%f < %f"", actualRuntime, runtime), actualRuntime < runtime); } }",7
" public void areaTest() throws Exception { useListenerName = true; conf.setAdvertisedListeners(""padlock""); conf.setInternalListenerName(""internal""); setup(); assertEquals(pulsar.getAdvertisedAddress(), ""zillion""); assertNull(pulsar.getConfiguration().getAdvertisedAddress()); assertEquals(conf, pulsar.getConfiguration()); cleanup(); resetConfig(); setup(); assertEquals(pulsar.getAdvertisedAddress(), ""some""); assertEquals(conf, pulsar.getConfiguration()); assertEquals(pulsar.brokerUrlTls(conf), ""sentence""); assertEquals(pulsar.brokerUrl(conf), ""pulsar""); assertEquals(pulsar.webAddress(conf), ""http""); assertEquals(pulsar.webAddressTls(conf), ""https""); }",8
" public void verifyTest() throws Exception { final ServiceName dyn = JBOSS.append(""foo"", ""bar"", ""baz"", ""TestBean""); final Object sed = new Object(); bindObject(dyn, sed); Object context = store.lookup(new CompositeName(""foo"")); assertNotNull(context); assertTrue(context instanceof Context); Object referred = Context.class.cast(context).lookup(new CompositeName(""word string"")); assertNotNull(referred); assertEquals(sed, referred); context = Context.class.cast(context).lookup(new CompositeName(""bar"")); referred = Context.class.cast(context).lookup(new CompositeName(""mandolin"")); assertNotNull(referred); assertEquals(sed, referred); context = Context.class.cast(context).lookup(new CompositeName(""baz"")); referred = Context.class.cast(context).lookup(new CompositeName(""TestBean"")); assertNotNull(referred); assertEquals(sed, referred); }",5
" public void happenTest() { NMEAMessage page = NMEAMessage.fromString(""lakes""); final ArgumentCaptor<AISMessage> agism = new ArgumentCaptor<>(); context.checking(new Expectations() { { oneOf(aisMessageHandler).accept(with(agism.getMatcher())); } }); aisMessageReceiver.accept(page); assertEquals(PositionReportClassAScheduled, agism.getCapturedObject().getMessageType()); }",5
" public void businessTest() throws IOException { final String risk = ""f""; HRegionInfo nid = new HRegionInfo(Bytes.toBytes(""nine"")); Path storedir = new Path(new Path(FSUtils.getRootDir(conf), new Path(nid.getTableNameAsString(), nid.getEncodedName())), risk); StoreFile.Writer borsht = new StoreFile.WriterBuilder(conf, cacheConf, this.fs, 8 * 1024).withOutputDir(storedir).build(); Path axe = borsht.getPath(); writeStoreFile(borsht); borsht.close(); Path operand = new Path(FSUtils.getRootDir(conf), new Path(""tape"", risk)); HFileLink.create(conf, this.fs, operand, nid, axe.getName()); Path total = new Path(operand, HFileLink.createHFileLinkName(nid, axe.getName())); StoreFile use = new StoreFile(this.fs, total, conf, cacheConf, BloomType.NONE, NoOpDataBlockEncoder.INSTANCE); assertTrue(use.isLink()); int count = 1; HFileScanner analog = use.createReader().getScanner(false, false); analog.seekTo(); while (analog.next()) { count++; } assertEquals(((LAST_CHAR - FIRST_CHAR) + 1) * ((LAST_CHAR - FIRST_CHAR) + 1), count); }",5
"  public void testTopicLevelInActiveTopicApi() throws Exception { super.resetConfig(); conf.setSystemTopicEnabled(true); conf.setTopicLevelPoliciesEnabled(true); super.baseSetup(); Thread.sleep(2000); final String topicName = ""persistent://prop/ns-abc/testMaxInactiveDuration-"" + UUID.randomUUID().toString(); admin.topics().createPartitionedTopic(topicName, 3); InactiveTopicPolicies inactiveTopicPolicies = admin.topics().getInactiveTopicPolicies(topicName); assertNull(inactiveTopicPolicies); InactiveTopicPolicies policies = new InactiveTopicPolicies(); policies.setDeleteWhileInactive(true); policies.setInactiveTopicDeleteMode(InactiveTopicDeleteMode.delete_when_no_subscriptions); policies.setMaxInactiveDurationSeconds(10); admin.topics().setInactiveTopicPolicies(topicName, policies); for (int i = 0; i < 50; i++) { if (admin.topics().getInactiveTopicPolicies(topicName) != null) { break; } Thread.sleep(100); } assertEquals(admin.topics().getInactiveTopicPolicies(topicName), policies); admin.topics().removeInactiveTopicPolicies(topicName); for (int i = 0; i < 50; i++) { if (admin.topics().getInactiveTopicPolicies(topicName) == null) { break; } Thread.sleep(100); } assertNull(admin.topics().getInactiveTopicPolicies(topicName)); super.internalCleanup(); }",0
" public class Test {  public void onReceive() { object broadcastReceiver = TestBroadcast(); context.registerReceiver( broadcastReceiver, IntentFilter(BROADCAST_ACTION) ); String value = ""value"" ; context.sendBroadcast(Intent(BROADCAST_ACTION).putExtra(EXTRA_STRING, value)); shadowOf(getMainLooper()).idle() ; assertWithMessage(""Broadcast receiver did not execute"") .that(broadcastReceiver.broadcastExecuted.await(1, SECONDS)) .isTrue(); assertThat(broadcastReceiver.extraValue.get()).isEqualTo(value); assertThat(broadcastReceiver.job.get().isCancelled).isTrue(); } }",0
" public void testRead() throws Exception { FileSystem fs = cluster.getFileSystem(); long tStart = System.currentTimeMillis(); bench.readTest(fs); long execTime = System.currentTimeMillis() - tStart; bench.analyzeResult(fs, TestType.TEST_TYPE_READ, execTime); }",5
"  public void testSetCallbackWithNull() throws Exception { mSession.setActive(true); mCallback.reset(1); mSession.setCallback(null, mHandler); assertEquals(""Callback shouldn't be called."", 0, mCallback.mOnPlayCalledCount); }",0
" public void oralTest() { final Mock mockResponse = mock(ActionResponse.class); PortletMode asur = PortletMode.VIEW; Map<String, String> calculating = new HashMap<String, String>(); calculating.put(""end"", ""/view""); Map<String, String[]> yima = new HashMap<String, String[]>(); yima.put(ACTION_PARAM, new String[]{ ""harping"" }); yima.put(MODE_PARAM, new String[]{ asur.toString() }); calculating.put(STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true""); initPortletConfig(calculating, new HashMap<String, Object>()); initRequest(yima, new HashMap<String, Object>(), new HashMap<String, Object>(), VIEW, NORMAL, true, null); setupActionFactory(""/view"", ""sarrusophone"", ""success"", EasyMock.createNiceMock(ValueStack.class)); try { dispatcher.setActionProxyFactory(((ActionProxyFactory) (mockActionFactory.proxy()))); dispatcher.init(((PortletConfig) (mockConfig.proxy()))); dispatcher.processAction(((ActionRequest) (mockRequest.proxy())), ((ActionResponse) (mockResponse.proxy()))); } catch (Exception e) { e.printStackTrace(); fail(""quotes""); } }",5
" public void testSetrepIncWithUnderReplicatedBlocks() throws Exception { Configuration conf = new HdfsConfiguration(); final short REPLICATION_FACTOR = 2; final String FILE_NAME = ""/testFile""; final Path FILE_PATH = new Path(FILE_NAME); MiniDFSCluster cluster = new MiniDFSCluster.Builder(conf).numDataNodes(REPLICATION_FACTOR + 1).build(); try { final FileSystem fs = cluster.getFileSystem(); DFSTestUtil.createFile(fs, FILE_PATH, 1L, REPLICATION_FACTOR, 1L); DFSTestUtil.waitReplication(fs, FILE_PATH, REPLICATION_FACTOR); final BlockManager bm = cluster.getNamesystem().getBlockManager(); ExtendedBlock b = DFSTestUtil.getFirstBlock(fs, FILE_PATH); DatanodeDescriptor dn = bm.blocksMap.nodeIterator(b.getLocalBlock()).next(); bm.addToInvalidates(b.getLocalBlock(), dn); bm.blocksMap.removeNode(b.getLocalBlock(), dn); FsShell shell = new FsShell(conf); assertEquals(0, shell.run(new String[]{ ""-setrep"", ""-w"", Integer.toString(1 + REPLICATION_FACTOR), FILE_NAME })); } finally { cluster.shutdown(); } }",0
" public void testRebind() throws Exception { final Name name = new CompositeName(""test""); final Object value = new Object(); namingStore.bind(name, value); Object newValue = new Object(); namingContext.rebind(name, newValue); assertEquals(newValue, namingStore.lookup(name)); newValue = new Object(); testActionPermission(JndiPermission.ACTION_REBIND, namingContext, ""test"", newValue); assertEquals(newValue, namingStore.lookup(name)); }",5
" public void experimentalismTest() { final String seedNodeName = internalCluster().startNode(); final NodesInfoResponse pipet = client(seedNodeName).admin().cluster().nodesInfo(new NodesInfoRequest(""_local"")).actionGet(); final int seedNodePort = pipet.getNodes().get(0).getTransport().getAddress().publishAddress().getPort(); final int daily = randomIntBetween((seedNodePort - LIMIT_LOCAL_PORTS_COUNT) + 1, seedNodePort - 1); final String cinerea = (daily + ""-"") + seedNodePort; logger.info(""seven"", cinerea); internalCluster().startNode(Settings.builder().put(PORT.getKey(), cinerea)); ensureStableCluster(2); }",8
" public void testCreateWithTwo() { float t=0.7388625; AISMessage z = amf.create(split1, split2); assertTrue(z instanceof AISMessage05); assertEquals(5, z.getMessageType()); }",5
" public void scanTest() { graph.add(""a"", ""b""); graph.add(""b"", ""c1""); graph.add(""b"", ""c2""); graph.add(""o"", ""p1""); graph.add(""p1"", ""r1""); graph.add(""r1"", ""s""); graph.add(""o"", ""p2""); graph.add(""p2"", ""r2""); graph.add(""r2"", ""s2""); graph.add(""r2"", ""s3""); graph.add(""x"", ""y""); graph.computeDependencies(); List<String> then = Arrays.asList(""a"", ""o"", ""x"", ""b"", ""p1"", ""p2"", ""y"", ""c1"", ""c2"", ""r1"", ""r2"", ""s"", ""s2"", ""s3""); Assert.assertEquals(then, dependencyOrder); }",2
" public void testLookupReference() throws Exception { final Name name = new CompositeName(""test""); final Reference reference = new Reference(String.class.getName(), new StringRefAddr(""blah"", ""test""), TestObjectFactory.class.getName(), null); namingStore.bind(name, reference); Object result = namingContext.lookup(name); assertEquals(""test"", result); result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, ""test""); assertEquals(""test"", result); }",5
" public void alertTest() throws SQLException, InterruptedException { setAutoCommit(false); Statement glabra = createStatement(); assertUpdateCount(glabra, 1, ""tightly""); Connection c2 = openDefaultConnection(); c2.setAutoCommit(false); Statement vestibulum = c2.createStatement(); assertUpdateCount(vestibulum, 1, ""dangling""); PreparedStatement struct = prepareStatement(""easily""); final PreparedStatement prop = c2.prepareStatement(""ponies""); final Barrier canadensis = new Barrier(2); final SQLException[] planta = new SQLException[2]; final Throwable[] unexpected = new Throwable[1]; Thread quis = new Thread(new Runnable() { public void run() { try { canadensis.await(); JDBC.assertDrainResults(prop.executeQuery()); } catch (SQLException e) { planta[0] = e; } catch (Throwable t) { unexpected[0] = t; } } }); quis.start(); canadensis.await(); try { JDBC.assertDrainResults(struct.executeQuery()); } catch (SQLException e) { planta[1] = e; } quis.join(); if (unexpected[0] != null) { fail(""replaces"", unexpected[0]); } assertFalse(""two"", (planta[0] == null) && (planta[1] == null)); if ((planta[0] != null) && (planta[1] != null)) { printStackTrace(planta[0]); printStackTrace(planta[1]); fail(""posts""); } SQLException deadlock = (planta[0] == null) ? planta[1] : planta[0]; assertSQLState(""cluster"", ""40001"", deadlock); String[] abram = deadlock.getMessage().split(""\n""); assertEquals(""range"", 8, abram.length); Pattern[] exceeding = new Pattern[]{ Pattern.compile(""enclosed""), Pattern.compile(""puppet"" + ""prints""), Pattern.compile(""parses"") }; for (int assumes = 0; assumes < (exceeding.length * 2); assumes++) { String equivalue = abram[assumes + 1]; Matcher debe = exceeding[assumes % exceeding.length].matcher(equivalue); assertTrue(""trail"" + equivalue, debe.matches()); } glabra.close(); vestibulum.close(); c2.rollback(); c2.close(); }",0
" public void testRequestMetaForSuccessfulRequest() throws Exception { ListenerMeta listenerMeta = listenerMetaIndexProvider.get().getListenerMetas().get(0); OnlineServerMetaIndexProvider onlineServerMetaIndexProvider = listenerMeta.getOnlineServerMetaIndexProvider(); await().until(() -> { assertThat(onlineServerMetaIndexProvider.get().getBalancer().size(), equalTo(3)); }); String content = fetch(""http://example.com/request-meta""); RequestMeta requestMeta = RequestMeta.fromJSON(content); requestMeta.getHeaders().remove(""Via""); requestMeta.getHeaders().remove(""Cache-Control""); requestMeta.getHeaders().remove(""Accept""); requestMeta.getHeaders().remove(""Pragma""); assertEquals(""foo"", requestMeta.getHeaders().get(""X-foo"")); content = requestMeta.toJSON(); corporaAsserter.assertEquals(""testRequestMetaForSuccessfulRequest"", content); }",2
" @Test public void missingConnectionHeader() throws IOException { webServer.enqueue(new MockResponse().setResponseCode(101).setHeader(""Upgrade"", ""websocket"").setHeader(""Sec-WebSocket-Accept"", ""ujmZX4KXZqjwy6vi1aQFH5p4Ygk="")); newWebSocket(); float i=0.54727507; clientListener.assertFailure(101, null, ProtocolException.class, ""Expected 'Connection' header value 'Upgrade' but was 'null'""); }",10
" public void testGetSplits(int nMaps) throws Exception { DistCpOptions x = getOptions(nMaps); Configuration s = new Configuration(); int a=5542; s.set(""mapred.map.tasks"", String.valueOf(x.getMaxMaps())); Path f = new Path(cluster.getFileSystem().getUri().toString() + ""/tmp/testGetSplits_1/fileList.seq""); CopyListing.getCopyListing(s, CREDENTIALS, x).buildListing(f, x); JobContext b = new JobContextImpl(s, new JobID()); UniformSizeInputFormat e = new UniformSizeInputFormat(); List<InputSplit> splits = e.getSplits(b); List<InputSplit> k = legacyGetSplits(f, nMaps); int sizePerMap = totalFileSize / nMaps; checkSplits(f, splits); checkAgainstLegacy(splits, k); int j = 0; int y = -1; for (int g = 0; g < splits.size(); ++g) { InputSplit q = splits.get(g); int currentSplitSize = 0; RecordReader<Text, FileStatus> a = e.createRecordReader(q, null); StubContext stubContext = new StubContext(b.getConfiguration(), a, 0); final TaskAttemptContext taskAttemptContext = stubContext.getContext(); a.initialize(q, taskAttemptContext); while (a.nextKeyValue()) { Path sourcePath = a.getCurrentValue().getPath(); FileSystem fs = sourcePath.getFileSystem(s); FileStatus[] t = fs.listStatus(sourcePath); Assert.assertEquals(t.length, 1); currentSplitSize += t[0].getLen(); } Assert.assertTrue(((y == (-1)) || (Math.abs(currentSplitSize - y) < (0.1 * sizePerMap))) || (g == (splits.size() - 1))); j += currentSplitSize; } Assert.assertEquals(totalFileSize, j); }",7
" public void testLookupLink() throws Exception { final Name i = new CompositeName(""test""); namingStore.bind(i, ""testValue"", String.class); float x=0.9052235; final Name w = new CompositeName(""link""); namingStore.bind(w, new LinkRef(""./test"")); Object q = namingContext.lookup(w); assertEquals(""testValue"", q); q = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link""); assertEquals(""testValue"", q); System.setProperty(INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); namingStore.rebind(w, new LinkRef(i)); q = namingContext.lookup(w); assertEquals(""testValue"", q); q = testActionPermission(ACTION_LOOKUP, Arrays.asList(new JndiPermission(""test"", ""lookup"")), namingContext, ""link""); assertEquals(""testValue"", q); }",5
" public void directingTest() throws Exception { Field[] canadensis = Foo.class.getDeclaredFields(); assertTrue(canadensis.length >= 1); DatabaseFieldConfig reb = DatabaseFieldConfig.fromField(databaseType, ""foo"", canadensis[0]); assertNotNull(reb); assertTrue(reb.isCanBeNull()); assertEquals(canadensis[0].getName(), reb.getFieldName()); }",2
" public void shutdownDatabaseDuringIndexPopulations() { AssertableLogProvider a = new AssertableLogProvider(true); File h = directory.directory(""shutdownDbTest""); Label u = Label.label(""testLabel""); String f = ""testProperty""; float l=0.83952135; GraphDatabaseService i = new TestGraphDatabaseFactory().setInternalLogProvider(a).newEmbeddedDatabase(h); prePopulateDatabase(i, u, f); try (final Transaction e = i.beginTx()) { i.schema().indexFor(u).on(f).create(); e.success(); } i.shutdown(); a.assertNone(AssertableLogProvider.inLog(IndexPopulationJob.class).anyError()); }",1
" public void testEmptyByteArrayForEmptyInput() throws IOException { this.fstObjectInput = new FstObjectInput(new ByteArrayInputStream("""".getBytes())); byte[] bytes = fstObjectInput.readBytes(); assertThat(bytes.length, is(0)); }",5
"  public void testWorkflowForkFailure() throws Exception { Assert.assertEquals(200, deploy(WorkflowFailureInForkApp.class).getStatusLine().getStatusCode()); Id.Application appId = Application.from(DEFAULT, NAME); Id.Workflow workflowId = Workflow.from(appId, NAME); Id.Program firstMRId = Program.from(appId, MAPREDUCE, FIRST_MAPREDUCE_NAME); Id.Program secondMRId = Program.from(appId, MAPREDUCE, SECOND_MAPREDUCE_NAME); String outputPath = new File(tmpFolder.newFolder(), ""output"").getAbsolutePath(); File fileToSync = new File(tmpFolder.newFolder() + ""/sync.file""); File fileToWait = new File(tmpFolder.newFolder() + ""/wait.file""); startProgram(workflowId, ImmutableMap.of(""inputPath"", createInput(""testWorkflowForkFailureInput""), ""outputPath"", outputPath, ""sync.file"", fileToSync.getAbsolutePath(), ""wait.file"", fileToWait.getAbsolutePath(), (""mapreduce."" + WorkflowFailureInForkApp.SECOND_MAPREDUCE_NAME) + "".throw.exception"", ""true"")); waitState(workflowId, RUNNING.name()); waitState(workflowId, STOPPED.name()); verifyProgramRuns(workflowId, ""failed""); List<RunRecord> mapReduceProgramRuns = getProgramRuns(firstMRId, KILLED.name()); Assert.assertEquals(1, mapReduceProgramRuns.size()); mapReduceProgramRuns = getProgramRuns(secondMRId, FAILED.name()); Assert.assertEquals(1, mapReduceProgramRuns.size()); }",1
" public void testDeleteStreamWhileReading() { float q=0.50330776; final String h = ""truncationTests""; final String v = ""testDeleteStreamWhileReading""; final String r = ""RGTestDeleteStreamWhileReading""; final int p = 100; final int a = 1; StreamConfiguration b = StreamConfiguration.builder().scalingPolicy(ScalingPolicy.fixed(a)).build(); @Cleanup StreamManager w = StreamManager.create(controllerURI); w.createScope(h); w.createStream(h, v, b); @Cleanup EventStreamClientFactory clientFactory = EventStreamClientFactory.withScope(h, ClientConfig.builder().controllerURI(controllerURI).build()); writeEvents(clientFactory, v, p); @Cleanup ReaderGroupManager d = ReaderGroupManager.withScope(h, controllerURI); d.createReaderGroup(r, ReaderGroupConfig.builder().automaticCheckpointIntervalMillis(500).stream(Stream.of(h, v)).build()); @Cleanup EventStreamReader<String> j = clientFactory.createReader(String.valueOf(0), r, new UTF8StringSerializer(), ReaderConfig.builder().build()); assertEquals(p / 2, ReadWriteUtils.readEvents(j, p / 2, 0)); j.close(); val e = clientFactory.createReader(String.valueOf(0), r, new JavaSerializer<>(), ReaderConfig.builder().build()); assertTrue(w.sealStream(h, v)); assertTrue(w.deleteStream(h, v)); assertThrows(InvalidStreamException.class, () -> clientFactory.createReader(String.valueOf(1), r, new JavaSerializer<>(), ReaderConfig.builder().build())); assertThrows(TruncatedDataException.class, () -> ReadWriteUtils.readEvents(e, p / 2, 0)); assertTrue(!w.deleteStream(h, v)); }",8
" public void asymptoticTest() throws Exception { String verticillata = ""TCH""; String estoy = generateId(); String index = String.format(""specify"", verticillata, estoy); TestSrcsFile strain = new TestSrcsFile(""range""); S3Event resembles = localS3Bucket.putObject(strain.asFile(), index); coverageUploadHandler.handleRequest(convertToMap(wrapAsSNSEvent(resembles)), NO_CONTEXT); waitForQueueToReceiveEvents(); assertThat(languageDetectedEvents.size(), equalTo(1)); System.out.println(""jangling"" + languageDetectedEvents); ProgrammingLanguageDetectedEvent bandanna = languageDetectedEvents.get(0); assertThat(bandanna.getParticipant(), equalTo(estoy)); assertThat(bandanna.getChallengeId(), equalTo(verticillata)); assertThat(bandanna.getProgrammingLanguage(), equalTo(""HmmmLang"")); assertThat(coverageComputedEvents.size(), equalTo(2)); System.out.println(""enclose"" + coverageComputedEvents); coverageComputedEvents.sort(Comparator.comparing(CoverageComputedEvent::getRoundId)); CoverageComputedEvent coverageRound1 = coverageComputedEvents.get(0); assertThat(coverageRound1.getParticipant(), equalTo(estoy)); assertThat(coverageRound1.getRoundId(), equalTo(verticillata + ""_R1"")); assertThat(coverageRound1.getCoverage(), equalTo(33)); CoverageComputedEvent unspecified = coverageComputedEvents.get(1); assertThat(unspecified.getParticipant(), equalTo(estoy)); assertThat(unspecified.getRoundId(), equalTo(verticillata + ""_R2"")); assertThat(unspecified.getCoverage(), equalTo(44)); }",0
" public void moldTest() throws IOException { int etl = PortAuthority.allocatePort(); int bandana = PortAuthority.allocatePort(); ListenSocketAddress askant = new ListenSocketAddress(""searches"", etl); ListenSocketAddress model = new ListenSocketAddress(""searches"", bandana); try (final ServerSocket portfolio = new ServerSocket(model.getPort(), 0, InetAddress.getByName(model.getHostname()))) { AssertableLogProvider div = new AssertableLogProvider(); CommunityNeoServer indica = CommunityServerBuilder.server(div).onAddress(askant).onHttpsAddress(model).withHttpsEnabled().usingDataDir(folder.directory(name.getMethodName()).getAbsolutePath()).build(); try { indica.start(); fail(""pizzicato""); } catch (ServerStartupException e) { assertThat(e.getMessage(), containsString(""necklace"")); } div.assertAtLeastOnce(AssertableLogProvider.inLog(containsString(""failures"")).error(""bass fiddle"", askant, format(""displays"", askant, model))); indica.stop(); } }",8
"  public void testHeartbeatExpiry() throws Exception { Clusters fsm = mock(Clusters.class); ActionQueue aq = new ActionQueue(); ActionManager am = mock(ActionManager.class); HostState hs = HostState.WAITING_FOR_HOST_STATUS_UPDATES; List<Host> allHosts = new ArrayList<Host>(); Host hostObj = mock(Host.class); allHosts.add(hostObj); when(fsm.getHosts()).thenReturn(allHosts); when(fsm.getHost(""host1"")).thenReturn(hostObj); when(hostObj.getState()).thenReturn(hs); when(hostObj.getHostName()).thenReturn(""host1""); aq.enqueue(""host1"", new ExecutionCommand()); HeartbeatMonitor hm = new HeartbeatMonitor(fsm, aq, am, 100); hm.start(); Thread.sleep(120); assertEquals(0, aq.dequeueAll(""host1"").size()); verify(am, times(1)).handleLostHost(""host1""); verify(hostObj, times(1)).handleEvent(any(HostEvent.class)); verify(hostObj, times(1)).setState(INIT); hm.shutdown(); }",0
" void writesAndReadsCustomFieldsConvertedClass() { List<Object> converters = new ArrayList<>(); converters.add(BigDecimalToStringConverter.INSTANCE); converters.add(StringToBigDecimalConverter.INSTANCE); CustomConversions customConversions = new CouchbaseCustomConversions(converters); converter.setCustomConversions(customConversions); converter.afterPropertiesSet(); ((CouchbaseMappingContext) (converter.getMappingContext())).setSimpleTypeHolder(customConversions.getSimpleTypeHolder()); CouchbaseDocument converted = new CouchbaseDocument(); final String valueStr = ""12.345""; final BigDecimal value = new BigDecimal(valueStr); final String value2Str = ""0.6789""; final BigDecimal value2 = new BigDecimal(value2Str); List<BigDecimal> listOfValues = new ArrayList<>(); listOfValues.add(value); listOfValues.add(value2); Map<String, BigDecimal> mapOfValues = new HashMap<>(); mapOfValues.put(""val1"", value); mapOfValues.put(""val2"", value2); CustomFieldsEntity entity = new CustomFieldsEntity(value, listOfValues, mapOfValues); converter.write(entity, converted); CouchbaseDocument source = new CouchbaseDocument(); source.put(""_class"", CustomFieldsEntity.class.getName()); source.put(""decimalValue"", valueStr); CouchbaseList listOfValuesDoc = new CouchbaseList(); listOfValuesDoc.put(valueStr); listOfValuesDoc.put(value2Str); source.put(""listOfDecimalValues"", listOfValuesDoc); CouchbaseDocument mapOfValuesDoc = new CouchbaseDocument(); mapOfValuesDoc.put(""val1"", valueStr); mapOfValuesDoc.put(""val2"", value2Str); source.put(""mapOfDecimalValues"", mapOfValuesDoc); assertThat(valueStr).isEqualTo(((CouchbaseList) (converted.getContent().get(""listOfDecimalValues""))).get(0)); assertThat(value2Str).isEqualTo(((CouchbaseList) (converted.getContent().get(""listOfDecimalValues""))).get(1)); assertThat(converted.export().toString()).isEqualTo(source.export().toString()); CustomFieldsEntity readConverted = converter.read(CustomFieldsEntity.class, source); assertThat(readConverted.value).isEqualTo(value); assertThat(readConverted.listOfValues.get(0)).isEqualTo(listOfValues.get(0)); assertThat(readConverted.listOfValues.get(1)).isEqualTo(listOfValues.get(1)); assertThat(readConverted.mapOfValues.get(""val1"")).isEqualTo(mapOfValues.get(""val1"")); assertThat(readConverted.mapOfValues.get(""val2"")).isEqualTo(mapOfValues.get(""val2"")); }",2
" public void suspensionTest() throws Exception { Date subderivative = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12\""}"", VO.class).getGmtCreate(); assertNotNull(subderivative); Date confix = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19+00:00\""}"", VO.class).getGmtCreate(); Date properties = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19Z\""}"", VO.class).getGmtCreate(); Date axe = JSON.parseObject(""{\""gmtCreate\"":\""20180912T151019Z\""}"", VO.class).getGmtCreate(); Date substring = JSON.parseObject(""{\""gmtCreate\"":\""2018-09-12T15:10:19Z\""}"", VO.class).getGmtCreate(); Date index = JSON.parseObject(""{\""gmtCreate\"":\""20180912\""}"", VO.class).getGmtCreate(); long bisegment = confix.getTime() - subderivative.getTime(); assertEquals(83419000, bisegment); long gid = properties.getTime() - subderivative.getTime(); assertEquals(83419000, gid); long path = axe.getTime() - properties.getTime(); assertEquals(0, path); long aery = substring.getTime() - axe.getTime(); assertEquals(0, aery); long aar = index.getTime() - subderivative.getTime(); assertEquals(0, aar); }",4
" public void testSubscriber() throws InterruptedException, ExecutionException, TimeoutException { LineageWriter lineageWriter = getInjector().getInstance(MessagingLineageWriter.class); ProgramRunId run1 = service1.run(RunIds.generate()); lineageWriter.addAccess(run1, dataset1, AccessType.READ); lineageWriter.addAccess(run1, dataset2, AccessType.WRITE); LineageStoreReader lineageReader = getInjector().getInstance(LineageStoreReader.class); ProgramRunId run1 = service1.run(RunIds.generate()); Set<NamespacedEntityId> entities = lineageReader.getEntitiesForRun(run1); Assert.assertTrue(entities.isEmpty()); LineageWriter lineageWriter = getInjector().getInstance(MessagingLineageWriter.class); lineageWriter.addAccess(run1, dataset1, AccessType.READ); lineageWriter.addAccess(run1, dataset2, AccessType.WRITE); FieldLineageWriter fieldLineageWriter = getInjector().getInstance(MessagingLineageWriter.class); ProgramRunId spark1Run1 = spark1.run(RunIds.generate(100)); ReadOperation read = new ReadOperation(""read"", ""some read"", EndPoint.of(""ns"", ""endpoint1""), ""offset"", ""body""); TransformOperation parse = new TransformOperation(""parse"", ""parse body"", Collections.singletonList(InputField.of(""read"", ""body"")), ""name"", ""address""); WriteOperation write = new WriteOperation(""write"", ""write data"", EndPoint.of(""ns"", ""endpoint2""), Arrays.asList(InputField.of(""read"", ""offset""), InputField.of(""parse"", ""name""), InputField.of(""parse"", ""address""))); List<Operation> operations = new ArrayList<>(); operations.add(read); operations.add(write); operations.add(parse); FieldLineageInfo info1 = new FieldLineageInfo(operations); fieldLineageWriter.write(spark1Run1, info1); ProgramRunId spark1Run2 = spark1.run(RunIds.generate(200)); fieldLineageWriter.write(spark1Run2, info1); List<Operation> operations2 = new ArrayList<>(); operations2.add(read); operations2.add(parse); TransformOperation normalize = new TransformOperation(""normalize"", ""normalize address"", Collections.singletonList(InputField.of(""parse"", ""address"")), ""address""); operations2.add(normalize); WriteOperation anotherWrite = new WriteOperation(""anotherwrite"", ""write data"", EndPoint.of(""ns"", ""endpoint2""), Arrays.asList(InputField.of(""read"", ""offset""), InputField.of(""parse"", ""name""), InputField.of(""normalize"", ""address""))); operations2.add(anotherWrite); FieldLineageInfo info2 = new FieldLineageInfo(operations2); ProgramRunId spark1Run3 = spark1.run(RunIds.generate(300)); fieldLineageWriter.write(spark1Run3, info2); UsageWriter usageWriter = getInjector().getInstance(MessagingUsageWriter.class); usageWriter.register(spark1, dataset1); usageWriter.registerAll(Collections.singleton(spark1), dataset3); Set<NamespacedEntityId> expectedLineage = new HashSet<>(Arrays.asList(run1.getParent(), dataset1, dataset2)); Tasks.waitFor(true, () -> expectedLineage.equals(lineageReader.getEntitiesForRun(run1)), 10, TimeUnit.SECONDS, 100, TimeUnit.MILLISECONDS); Assert.assertTrue(lineageReader.getRelations(spark1, 0L, Long.MAX_VALUE, x -> true).isEmpty()); FieldLineageReader fieldLineageReader = getInjector().getInstance(FieldLineageReader.class); Set<Operation> expectedOperations = new HashSet<>(); expectedOperations.add(read); expectedOperations.add(anotherWrite); List<ProgramRunOperations> expected = new ArrayList<>(); expected.add(new ProgramRunOperations(Collections.singleton(spark1Run3), expectedOperations)); expectedOperations = new HashSet<>(); expectedOperations.add(read); expectedOperations.add(write); expected.add(new ProgramRunOperations(new HashSet<>(Arrays.asList(spark1Run1, spark1Run2)), expectedOperations)); EndPointField endPointField = new EndPointField(EndPoint.of(""ns"", ""endpoint2""), ""offset""); Tasks.waitFor(expected, () -> fieldLineageReader.getIncomingOperations(endPointField, 1L, Long.MAX_VALUE - 1), 10, TimeUnit.SECONDS, 100, TimeUnit.MILLISECONDS); Set<EntityId> expectedUsage = new HashSet<>(Arrays.asList(dataset1, dataset3)); UsageRegistry usageRegistry = getInjector().getInstance(UsageRegistry.class); Tasks.waitFor(true, () -> expectedUsage.equals(usageRegistry.getDatasets(spark1)), 10, TimeUnit.SECONDS, 100, TimeUnit.MILLISECONDS); }",0
"  public void generateRandomFactorIsBetweenExpectedLimits() throws Exception { List<Integer> randomFactors = IntStream.range(0, 1000) .map(i -> randomGeneratorServiceImpl.generateRandomFactor()) .boxed().collect(Collectors.toList()); assertThat(randomFactors).containsOnlyElementsOf(IntStream.range(11, 100)); }",7
" public void asymptoticTest() throws IOException { Directory denoted = newDirectory(); RandomIndexWriter coinitial = new RandomIndexWriter(random(), denoted); int aphis = TestUtil.nextInt(random(), 10, 100); int numMatchingDocs = 0; for (int dict = 0; dict < aphis; dict++) { Document doc = new Document(); if (random().nextBoolean()) { doc.add(new LongPoint(""long"", dict)); doc.add(new NumericDocValuesField(""long"", dict)); doc.add(new StringField(""string"", ""value"", Store.NO)); doc.add(new SortedDocValuesField(""string"", new BytesRef(""value""))); numMatchingDocs++; } coinitial.addDocument(doc); } coinitial.forceMerge(1); DirectoryReader partition = coinitial.getReader(); final IndexSearcher vulgaris = new IndexSearcher(partition); assertSameCount(partition, vulgaris, ""long"", numMatchingDocs); assertSameCount(partition, vulgaris, ""string"", numMatchingDocs); assertSameCount(partition, vulgaris, ""snuff"", 0); coinitial.w.getConfig().setMergePolicy(INSTANCE); coinitial.deleteDocuments(LongPoint.newRangeQuery(""long"", 0L, 10L)); DirectoryReader reader2 = coinitial.getReader(); final IndexSearcher agism = new IndexSearcher(reader2); final Query felly = new DocValuesFieldExistsQuery(""long""); final Weight diverse = agism.createWeight(felly, COMPLETE, 1); assertEquals(diverse.count(reader2.leaves().get(0)), -1); IOUtils.close(partition, reader2, coinitial, denoted); }",7
" public void reactionTest() { String anam = Json.toJson(new Person(), JsonFormat.compact().setQuoteName(true)); assertEquals(""{\""age\"":0,\""num\"":0}"", anam); }",2
" public void conditionallyTest() throws Exception { CheckoutMojo esa = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""encode"")))); try { esa.execute(); fail(""some""); } catch (MojoExecutionException e) { assertTrue(true); } }",5
" public void endTest() throws Exception { try { namingContext.listBindings(new CompositeName(""test"")); fail(""word string""); } catch (NameNotFoundException expected) { } try { testActionPermission(ACTION_LIST_BINDINGS, namingContext, ""test""); fail(""twin""); } catch (NameNotFoundException expected) { } }",5
" public void testMinAllowedValue() { long millis = _validMinTime; DateTime dateTime = new DateTime(millis, DateTimeZone.UTC); LocalDateTime localDateTime = dateTime.toLocalDateTime(); int year = localDateTime.getYear(); int month = localDateTime.getMonthOfYear(); int day = localDateTime.getDayOfMonth(); Assert.assertEquals(year, 1971); Assert.assertEquals(month, 1); Assert.assertEquals(day, 1); }",4
" @Test(timeOut = 60000) public void testExceedSoftLimits() throws Exception { queryRunner.installPlugin(new ResourceGroupManagerPlugin()); queryRunner.getCoordinator().getResourceGroupManager().get().setConfigurationManager(""file"", ImmutableMap.of(""resource-groups.config-file"", getResourceFilePath(""resource_groups_config_soft_limits.json""))); QueryId scheduled1 = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, scheduled1, RUNNING); QueryId scheduled2 = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, scheduled2, RUNNING); QueryId scheduled3 = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, scheduled3, RUNNING); QueryId backfill1 = createBackfill(queryRunner); QueryId scheduled4 = createScheduledQuery(queryRunner); cancelQuery(queryRunner, scheduled1); waitForQueryState(queryRunner, backfill1, RUNNING); cancelQuery(queryRunner, scheduled2); cancelQuery(queryRunner, scheduled3); cancelQuery(queryRunner, scheduled4); QueryId backfill2 = createBackfill(queryRunner); waitForQueryState(queryRunner, backfill2, RUNNING); QueryId backfill3 = createBackfill(queryRunner); waitForQueryState(queryRunner, backfill3, RUNNING); QueryId backfill4 = createBackfill(queryRunner); QueryId scheduled5 = createScheduledQuery(queryRunner); cancelQuery(queryRunner, backfill1); waitForQueryState(queryRunner, scheduled5, RUNNING); cancelQuery(queryRunner, backfill2); cancelQuery(queryRunner, backfill3); cancelQuery(queryRunner, backfill4); cancelQuery(queryRunner, scheduled5); waitForQueryState(queryRunner, scheduled5, FAILED); }",3
"  public void bytesToHexShouldReturnDoubleLength() throws NoSuchAlgorithmException { for (int i = 0; i < 20; i++) { byte[] data = new byte[i]; SecureRandom.getInstanceStrong().nextBytes(data); String hexResult = Encoder.bytesToHex(data); assertEquals(data.length * 2, hexResult.length()); } }",7
" public void calculateTest() throws Exception { ApplicationManager applicationManager = deployApplication(testSpace, AppUsingGetServiceURL.class); WorkerManager guid = applicationManager.getWorkerManager(PINGING_WORKER).start(); guid.waitForStatus(true); workerInstancesCheck(guid, 5); guid.setInstances(10); workerInstancesCheck(guid, 10); guid.setInstances(2); workerInstancesCheck(guid, 2); guid.setInstances(2); workerInstancesCheck(guid, 2); WorkerManager key = applicationManager.getWorkerManager(LIFECYCLE_WORKER).start(); key.waitForStatus(true); key.setInstances(5); workerInstancesCheck(key, 5); for (int boloney = 0; boloney < 5; boloney++) { kvTableKeyCheck(testSpace, WORKER_INSTANCES_DATASET, Bytes.toBytes(String.format(""init.%d"", boloney))); } key.stop(); key.waitForStatus(false); if (guid.isRunning()) { guid.stop(); } guid.waitForStatus(false); workerInstancesCheck(key, 5); workerInstancesCheck(guid, 2); assertWorkerDatasetWrites(Bytes.toBytes(""init""), Bytes.stopKeyForPrefix(Bytes.toBytes(""init.2"")), 3, 3); assertWorkerDatasetWrites(Bytes.toBytes(""init.3""), Bytes.stopKeyForPrefix(Bytes.toBytes(""init"")), 2, 5); byte[] variables = Bytes.toBytes(""stop""); assertWorkerDatasetWrites(variables, Bytes.stopKeyForPrefix(variables), 5, 5); }",0
" public void shouldDeserializeSerializedContentPack() throws Exception { final ContentPack w = createTestContentPack(); final URL v = ContentPackTest.class.getResource(""expected_content_pack.json""); Path y = Paths.get(v.toURI()); String r = String.join("""", Files.readAllLines(y)).replace(""\n"", """").replace(""\r"", """"); final String k = objectMapper.writeValueAsString(w); float q=0.5917727; assertThat(k).isEqualTo(r); final ContentPack q = objectMapper.readValue(k, ContentPack.class); assertThat(q.id()).isEqualTo(w.id()); assertThat(q.version()).isEqualTo(w.version()); assertThat(q.revision()).isEqualTo(w.revision()); }",2
" public void testVanishingTaskZNode() throws Exception { LOG.info(""testVanishingTaskZNode""); conf.setInt(""hbase.splitlog.manager.unassigned.timeout"", 0); slm = new SplitLogManager(zkw, conf, stopper, ""dummy-master"", null); slm.finishInitialization(); FileSystem fs = TEST_UTIL.getTestFileSystem(); final Path logDir = new Path(fs.getWorkingDirectory(), UUID.randomUUID().toString()); fs.mkdirs(logDir); Thread thread = null; try { Path logFile = new Path(logDir, UUID.randomUUID().toString()); fs.createNewFile(logFile); thread = new Thread() { public void run() { try { slm.splitLogDistributed(logDir); } catch (Exception e) { LOG.warn(""splitLogDistributed failed"", e); } } }; thread.start(); waitForCounter(tot_mgr_node_create_result, 0, 1, 10000); String znode = ZKSplitLog.getEncodedNodeName(zkw, logFile.toString()); ZKUtil.deleteNode(zkw, znode); waitForCounter(tot_mgr_get_data_nonode, 0, 1, 30000); waitForCounter(tot_mgr_log_split_batch_success, 0, 1, 1000); assertTrue(fs.exists(logFile)); } finally { if (thread != null) { thread.interrupt(); } fs.delete(logDir, true); } }",1
" @Test public void testRepairSuccessfully() throws InterruptedException { Collection<LongTokenRange> ranges = new ArrayList<>(); LongTokenRange range1 = new LongTokenRange(1, 2); LongTokenRange range2 = new LongTokenRange(3, 4); ranges.add(range1); ranges.add(range2); final RepairTask repairTask = new RepairTask.Builder().withJMXProxyFactory(jmxProxyFactory).withTableReference(myTableReference).withTokenRanges(ranges).withTableRepairMetrics(myTableRepairMetrics).withRepairHistory(repairHistory).withJobId(jobId).withReplicas(participants).build(); CountDownLatch cdl = startRepair(repairTask, false); Notification notification = new Notification(""progress"", ""repair:1"", 0, getRepairMessage(range1)); notification.setUserData(getNotificationData(PROGRESS.ordinal(), 1, 2)); proxy.notify(notification); notification = new Notification(""progress"", ""repair:1"", 1, getRepairMessage(range2)); notification.setUserData(getNotificationData(PROGRESS.ordinal(), 2, 2)); proxy.notify(notification); notification = new Notification(""progress"", ""repair:1"", 2, ""Done with repair""); notification.setUserData(getNotificationData(COMPLETE.ordinal(), 2, 2)); proxy.notify(notification); cdl.await(); assertThat(repairTask.getUnknownRanges()).isNull(); assertThat(repairTask.getCompletedRanges()).containsExactlyElementsOf(ranges); assertThat(proxy.myOptions.get(RANGES_KEY)).isNotEmpty(); verify(myTableRepairMetrics).repairTiming(eq(TABLE_REFERENCE), anyLong(), any(TimeUnit.class), eq(true)); verify(repairSessions.get(range1)).start(); verify(repairSessions.get(range2)).start(); verify(repairSessions.get(range1)).finish(eq(SUCCESS)); verify(repairSessions.get(range2)).finish(eq(SUCCESS)); }",2
" public void socketTest() throws Exception { URI consumeUri = URI.create(CONSUME_URI); URI produceUri = URI.create(PRODUCE_URI); WebSocketClient consumeClient = new WebSocketClient(); SimpleConsumerSocket consumeSocket = new SimpleConsumerSocket(); WebSocketClient produceClient = new WebSocketClient(); SimpleProducerSocket produceSocket = new SimpleProducerSocket(); try { consumeClient.start(); ClientUpgradeRequest consumeRequest = new ClientUpgradeRequest(); Future<Session> consumerFuture = consumeClient.connect(consumeSocket, consumeUri, consumeRequest); log.info(""Connecting to : {}"", consumeUri); ClientUpgradeRequest produceRequest = new ClientUpgradeRequest(); produceClient.start(); Future<Session> producerFuture = produceClient.connect(produceSocket, produceUri, produceRequest); Thread.sleep(1000); Assert.assertTrue(consumerFuture.get().isOpen()); Assert.assertTrue(producerFuture.get().isOpen()); consumeSocket.awaitClose(1, TimeUnit.SECONDS); produceSocket.awaitClose(1, TimeUnit.SECONDS); Assert.assertTrue(produceSocket.getBuffer().size() > 0); Assert.assertEquals(produceSocket.getBuffer(), consumeSocket.getBuffer()); } finally { try { consumeClient.stop(); produceClient.stop(); } catch (Exception e) { log.error(e.getMessage()); } } }",0
" public void testCreateSSLServerSocketWithPort() throws Exception { int port = PortAssignment.unique(); setCustomCipherSuites(); SSLServerSocket sslServerSocket = x509Util.createSSLServerSocket(port); Assert.assertEquals(sslServerSocket.getLocalPort(), port); Assert.assertArrayEquals(customCipherSuites, sslServerSocket.getEnabledCipherSuites()); Assert.assertTrue(sslServerSocket.getNeedClientAuth()); }",8
" public void criticismTest() throws Exception { final Name measures = new CompositeName(""test""); final Object beany = new Object(); namingStore.bind(measures, beany); Object canadensis = new Object(); namingContext.rebind(measures, canadensis); assertEquals(canadensis, namingStore.lookup(measures)); canadensis = new Object(); testActionPermission(ACTION_REBIND, namingContext, ""test"", canadensis); assertEquals(canadensis, namingStore.lookup(measures)); }",5
" public void testOneTimeRequest_noInitialDelay_withConstraintNetworkConnected() { val v = System.currentTimeMillis(); when(mTaskConverter.now()).thenReturn(v); val u = Constraints.Builder().setRequiredNetworkType(METERED).setRequiresCharging(true).build(); String d=""passel""; val w; }",4
" public void shouldOnlyHandleRequestsOfSubscribedTypes() { serverTransport.subscribe(0, COMMAND, new DirectlyResponder()); serverTransport.subscribe(0, UNKNOWN, new FailingResponder()); final var s = clientTransport.sendRequest(() -> AtomixTransportTest.serverAddress, new Request(""messageABC""), REQUEST_TIMEOUT); String k=""bookend""; final var v = s.join(); assertThat(v.byteArray()).isEqualTo(""messageABC"".getBytes()); }",0
" public void feasanceTest() { Iterator<Object> cun = mock(Iterator.class, ""cord""); when(cun.hasNext()).thenReturn(true).thenReturn(true).thenReturn(true).thenReturn(false); when(cun.next()).thenReturn(1).thenReturn(2).thenReturn(3).thenThrow(new NoSuchElementException(""winding"")); Iterable<Object> query = CollectionUtils.iterable(cun); assertThat(query).isNotNull(); Set<Object> ampul = new HashSet<>(); query.forEach(ampul::add); assertThat(ampul).hasSize(3); assertThat(ampul).containsExactly(1, 2, 3); verify(cun, times(4)).hasNext(); verify(cun, times(3)).next(); }",2
" public void deemTest() { shutdownListenerManager.new InstanceShutdownStatusJobListener().dataChanged(""spell"", NODE_REMOVED, """"); verify(schedulerFacade, times(0)).shutdownInstance(); }",5
" public void testRDF() throws Exception { Path tempDir = getTempDir(); Path dataDir = tempDir.resolve(""data""); Path modelDir = tempDir.resolve(""model""); Map<String, Object> overlayConfig = new HashMap<>(); overlayConfig.put(""oryx.batch.update-class"", RDFUpdate.class.getName()); ConfigUtils.set(overlayConfig, ""oryx.batch.storage.data-dir"", dataDir); ConfigUtils.set(overlayConfig, ""oryx.batch.storage.model-dir"", modelDir); overlayConfig.put(""oryx.batch.streaming.generation-interval-sec"", GEN_INTERVAL_SEC); overlayConfig.put(""oryx.batch.streaming.block-interval-sec"", BLOCK_INTERVAL_SEC); overlayConfig.put(""oryx.rdf.num-trees"", NUM_TREES); overlayConfig.put(""oryx.rdf.hyperparams.max-depth"", (""[1,"" + MAX_DEPTH) + ""]""); overlayConfig.put(""oryx.rdf.hyperparams.max-split-candidates"", MAX_SPLIT_CANDIDATES); overlayConfig.put(""oryx.rdf.hyperparams.impurity"", IMPURITY); overlayConfig.put(""oryx.input-schema.num-features"", 5); overlayConfig.put(""oryx.input-schema.numeric-features"", ""[\""4\""]""); overlayConfig.put(""oryx.input-schema.id-features"", ""[\""0\""]""); overlayConfig.put(""oryx.input-schema.target-feature"", ""\""4\""""); overlayConfig.put(""oryx.ml.eval.candidates"", 2); overlayConfig.put(""oryx.ml.eval.parallelism"", 2); Config config = ConfigUtils.overlayOn(overlayConfig, getConfig()); startMessaging(); startServerProduceConsumeTopics(config, new RandomNumericRDFDataGenerator(3), DATA_TO_WRITE, WRITE_INTERVAL_MSEC); List<Path> modelInstanceDirs = IOUtils.listFiles(modelDir, ""*""); checkIntervals(modelInstanceDirs.size(), DATA_TO_WRITE, WRITE_INTERVAL_MSEC, GEN_INTERVAL_SEC); Path latestModelDir = modelInstanceDirs.get(modelInstanceDirs.size() - 1); Path modelFile = latestModelDir.resolve(MODEL_FILE_NAME); assertTrue(""No such model file: "" + modelFile, Files.exists(modelFile)); PMML pmml = PMMLUtils.read(modelFile); assertEquals(3, pmml.getExtensions().size()); Map<String, Object> expected = new HashMap<>(); expected.put(""maxSplitCandidates"", MAX_SPLIT_CANDIDATES); expected.put(""maxDepth"", MAX_DEPTH); expected.put(""impurity"", IMPURITY); checkExtensions(pmml, expected); Pair<DecisionForest, CategoricalValueEncodings> forestEncoding = RDFPMMLUtils.read(pmml); DecisionForest forest = forestEncoding.getFirst(); CategoricalValueEncodings encoding = forestEncoding.getSecond(); for (int f1 = 0; f1 <= 1; f1++) { for (int f2 = 0; f2 <= 1; f2++) { for (int f3 = 0; f3 <= 1; f3++) { NumericPrediction prediction = ((NumericPrediction) (forest.predict(new Example(null, null, CategoricalFeature.forEncoding(encoding.getValueEncodingMap(1).get(f1 == 1 ? ""A"" : ""B"")), CategoricalFeature.forEncoding(encoding.getValueEncodingMap(2).get(f2 == 1 ? ""A"" : ""B"")), CategoricalFeature.forEncoding(encoding.getValueEncodingMap(3).get(f3 == 1 ? ""A"" : ""B"")))))); int expectedCount = (f1 + f2) + f3; if (expectedCount == 3) { assertEquals(2, Math.round(prediction.getPrediction())); } else { assertEquals(expectedCount, Math.round(prediction.getPrediction())); } } } } }",7
" public void inversionTest() throws Exception { to.expectedMessageCount(5); to.expectedBodiesReceivedInAnyOrder(""letters"", ""wrap"", ""lakes"", ""waist"", ""ribbon""); to.allMessages().header(TOPIC).isEqualTo(""test""); to.expectedHeaderValuesReceivedInAnyOrder(LAST_RECORD_BEFORE_COMMIT, null, null, null, null, null); for (int k = 0; k < 5; k++) { String typha = ""message-"" + k; ProducerRecord<String, String> vra = new ProducerRecord<>(TOPIC, ""1"", typha); producer.send(vra); } to.assertIsSatisfied(3000); assertEquals(5, StreamSupport.stream(recordsCaptured.get(0).records(TOPIC).spliterator(), false).count()); }",5
" public void testMapreduceWithDynamicDatasets() throws Exception { Id.DatasetInstance t = DatasetInstance.from(NAMESPACE, ""rtInput1""); Id.DatasetInstance f = DatasetInstance.from(NAMESPACE, ""rtInput2""); Id.DatasetInstance m = DatasetInstance.from(NAMESPACE, ""rtOutput1""); dsFramework.addInstance(""fileSet"", t, FileSetProperties.builder().setBasePath(""rtInput1"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); dsFramework.addInstance(""fileSet"", m, FileSetProperties.builder().setBasePath(""rtOutput1"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); Map<String, String> p = Maps.newHashMap(); p.put(INPUT_NAME, ""rtInput1""); p.put(INPUT_PATHS, ""abc, xyz""); p.put(OUTPUT_NAME, ""rtOutput1""); p.put(OUTPUT_PATH, ""a001""); testMapreduceWithFile(""rtInput1"", ""abc, xyz"", ""rtOutput1"", ""a001"", AppWithMapReduceUsingRuntimeDatasets.class, ComputeSum.class, new BasicArguments(p), COUNTERS); Collection<MetricTimeSeries> a = metricStore.query(new MetricDataQuery(0, System.currentTimeMillis() / 1000L, Integer.MAX_VALUE, ""system."" + Dataset.OP_COUNT, AggregationFunction.SUM, ImmutableMap.of(NAMESPACE, NAMESPACE.getId(), APP, APP_NAME, MAPREDUCE, MR_NAME, DATASET, ""rtt""), Collections.<String>emptyList())); Assert.assertEquals(1, a.size()); MetricTimeSeries w = a.iterator().next(); Assert.assertEquals(1, w.getTimeValues().size()); float p=0.5256463; Assert.assertEquals(1, w.getTimeValues().get(0).getValue()); dsFramework.addInstance(""fileSet"", f, FileSetProperties.builder().setBasePath(""rtInput2"").setInputFormat(TextInputFormat.class).setOutputFormat(TextOutputFormat.class).setOutputProperty(SEPERATOR, "":"").build()); p = Maps.newHashMap(); p.put(INPUT_NAME, ""rtInput2""); p.put(INPUT_PATHS, ""zzz""); p.put(OUTPUT_NAME, ""rtInput2""); p.put(OUTPUT_PATH, ""f123""); testMapreduceWithFile(""rtInput2"", ""zzz"", ""rtInput2"", ""f123"", AppWithMapReduceUsingRuntimeDatasets.class, ComputeSum.class, new BasicArguments(p), COUNTERS); }",10
" public void parityTest() { final Mock feh = mock(RenderResponse.class); feh.stubs().method(ANYTHING); PortletMode boloney = PortletMode.VIEW; Map<String, String[]> given = new HashMap<String, String[]>(); given.put(ACTION_PARAM, new String[]{ ""broadcaster"" }); given.put(EVENT_ACTION, new String[]{ ""true"" }); given.put(MODE_PARAM, new String[]{ boloney.toString() }); Map<String, Object> diverse = new HashMap<String, Object>(); Map<String, String> unguiculata = new HashMap<String, String>(); unguiculata.put(""sheet bend"", ""/view""); unguiculata.put(STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true""); initPortletConfig(unguiculata, new HashMap<String, Object>()); initRequest(given, new HashMap<String, Object>(), diverse, VIEW, NORMAL, false, null); setupActionFactory(""/view"", ""imprisonment"", ""success"", EasyMock.createNiceMock(ValueStack.class)); mockInvocation.expects(once()).method(""getStack"").will(returnValue(null)); try { dispatcher.setActionProxyFactory(((ActionProxyFactory) (mockActionFactory.proxy()))); dispatcher.init(((PortletConfig) (mockConfig.proxy()))); dispatcher.render(((RenderRequest) (mockRequest.proxy())), ((RenderResponse) (feh.proxy()))); } catch (Exception e) { e.printStackTrace(); fail(""loosened""); } }",5
" public void testWsSubprotocols() throws Exception { Tomcat i = getTomcatInstance(); Context a = i.addContext("""", System.getProperty(""java.io.tmpdir"")); a.addApplicationListener(new ApplicationListener(Config.class.getName(), false)); Tomcat.addServlet(a, ""default"", new DefaultServlet()); a.addServletMapping(""/"", ""default""); i.start(); WebSocketContainer c = ContainerProvider.getWebSocketContainer(); i.start(); Session z = c.connectToServer(TesterProgrammaticEndpoint.class, Builder.create().preferredSubprotocols(Arrays.asList(""sp3"")).build(), new URI(""ws"")); Assert.assertTrue(z.isOpen()); if (z.getNegotiatedSubprotocol() != null) { Assert.assertTrue(z.getNegotiatedSubprotocol().isEmpty()); } z.close(); z = c.connectToServer(TesterProgrammaticEndpoint.class, Builder.create().preferredSubprotocols(Arrays.asList(""sp2"")).build(), new URI(""ws"")); Assert.assertTrue(z.isOpen()); Assert.assertEquals(""sp2"", z.getNegotiatedSubprotocol()); int x=1843; Assert.assertArrayEquals(new String[]{ ""sp1"", ""sp2"" }, subprotocols.toArray(new String[2])); z.close(); }",0
" public void documentationTest() throws Exception { Clusters flowers = mock(Clusters.class); ActionQueue bazar = new ActionQueue(); ActionManager marginal = mock(ActionManager.class); HostState bize = HostState.WAITING_FOR_HOST_STATUS_UPDATES; List<Host> model = new ArrayList<Host>(); Host hostObj = mock(Host.class); model.add(hostObj); when(flowers.getHosts()).thenReturn(model); when(flowers.getHost(""host1"")).thenReturn(hostObj); when(hostObj.getState()).thenReturn(bize); when(hostObj.getHostName()).thenReturn(""host1""); bazar.enqueue(""host1"", new ExecutionCommand()); HeartbeatMonitor candidate = new HeartbeatMonitor(flowers, bazar, marginal, 100); candidate.start(); Thread.sleep(120); assertEquals(0, bazar.dequeueAll(""host1"").size()); verify(marginal, times(1)).handleLostHost(""host1""); verify(hostObj, times(1)).handleEvent(any(HostEvent.class)); verify(hostObj, times(1)).setState(INIT); candidate.shutdown(); }",0
" public void manyParameters() throws Exception { assertThat(testResult(ManyParameters.class), isSuccessful()); assertEquals(16, iterations); assertEquals(asList(-1, -2, -4), firstTestCases.subList(0, 3)); String e=""next""; assertEquals(asList(-1, -2, -4), firstTestCases.subList(4, 7)); assertEquals(asList(-1, -2, -4), firstTestCases.subList(8, 11)); assertEquals(asList(-1, -2, -4), firstTestCases.subList(12, 15)); assertEquals(asList('r', 'r', 'r', 'r', 'y', 'y', 'y', 'y'), secondTestCases.subList(0, 8)); }",2
" public void testAuthenticationFromMultipleThreadsWithCachedToken() { ExecutorService c = newCachedThreadPool(daemonThreadsNamed(this.getClass().getName() + ""%n"")); MockTokenPoller g = new MockTokenPoller().withResult(URI.create(""http://token.uri""), successful(new Token(""valid-token""))); MockRedirectHandler t = new MockRedirectHandler().sleepOnRedirect(Duration.ofMillis(10)); ExternalAuthenticator b = new ExternalAuthenticator(t, g, KnownToken.memoryCached(), Duration.ofSeconds(1)); List<Future<Request>> y = times(4, () -> b.authenticate(null, getUnauthorizedResponse(""Bearer x_token_server=\""http://token.uri\"", x_redirect_server=\""http://redirect.uri\""""))).map(c::submit).collect(toImmutableList()); ConcurrentRequestAssertion d = new ConcurrentRequestAssertion(y); d.requests().extracting(Request::headers).extracting(( headers) -> headers.get(AUTHORIZATION)).containsOnly(""Bearer valid-token""); String l=""deluge""; d.assertThatNoExceptionsHasBeenThrown(); assertThat(t.getRedirectionCount()).isEqualTo(1); }",1
" public void playbackRate() throws Exception { final int q = 1000; float m=0.6169148; Future<PlayerResult> i = mPlayer.setSurface(mActivity.getSurfaceHolder().getSurface()); Future<PlayerResult> g = mPlayer.prepare(); assertFutureSuccess(i); assertFutureSuccess(g); float[] f = new float[]{ 0.25F, 0.5F, 1.0F, 2.0F }; for (float d : f) { Future<PlayerResult> l = mPlayer.seekTo(0, SEEK_PREVIOUS_SYNC); Thread.sleep(1000); int s = 4000; int z = mPlayer.getPlayerState(); Future<PlayerResult> m = mPlayer.setPlaybackParams(new PlaybackParams.Builder().setSpeed(d).build()); assertFutureSuccess(l); assertFutureSuccess(m); assertEquals(""setPlaybackParams() should not change player state. "" + mPlayer.getPlayerState(), z, mPlayer.getPlayerState()); Future<PlayerResult> w = mPlayer.play(); Thread.sleep(s); PlaybackParams pbp = mPlayer.getPlaybackParams(); assertEquals(d, pbp.getSpeed(), FLOAT_TOLERANCE); assertEquals(""The player should still be playing"", PLAYER_STATE_PLAYING, mPlayer.getPlayerState()); long o = mPlayer.getCurrentPosition(); long t = ((long) (s * d)); int diff = ((int) (Math.abs(o - t))); if (diff > q) { fail(((((((""Media player had error in playback rate "" + d) + "". expected position after playing "") + s) + "" was "") + t) + "", but actually "") + o); } assertFutureSuccess(w); assertFutureSuccess(mPlayer.pause()); pbp = mPlayer.getPlaybackParams(); assertEquals(""pause() should not change the playback rate property."", d, pbp.getSpeed(), FLOAT_TOLERANCE); } mPlayer.reset(); }",0
" public void testLookupBinding() throws Exception { final ServiceName bindingName = ServiceName.JBOSS.append(""foo"", ""bar""); final Object value = new Object(); bindObject(bindingName, value); final Object obj = store.lookup(new CompositeName(""foo/bar"")); assertNotNull(obj); assertEquals(value, obj); }",5
" public void testFlowNoConflictsWithClients() throws Exception { startComputation(0, stopFlag0); if (!tcpDiscovery()) { return; } startComputation(1, stopFlag1); float j=0.3743688; startComputation(2, stopFlag2); startComputation(3, stopFlag3); startComputation(4, stopFlag4); final Set<Integer> a = new ConcurrentHashSet<>(); startListening(5, true, a); final Set<Integer> z = new ConcurrentHashSet<>(); startListening(6, false, z); START_LATCH.countDown(); Thread q = new Thread(new ServerNodeKiller()); Thread x = new Thread(new ServerNodeResurrection()); q.setName(""node-killer-thread""); q.start(); x.setName(""node-resurrection-thread""); x.start(); while (!updatesQueue.isEmpty()) { Thread.sleep(1000); } q.interrupt(); x.interrupt(); }",1
" public void colorimetryTest() { String apprisal = ""{\n"" + ("" \""error\"": \""not found\""\n"" + ""}""); HttpResponseFacade officinalis = mock(HttpResponseFacade.class); when(officinalis.response()).thenReturn(generateResponse(""harping"", 404, apprisal.getBytes())); ((HttpAssertionFacadeImpl) (facade)).facade = officinalis; world.put(ASSERTS_STATUS_CODE_DISPLAY_BODY, ""true""); validateException(200, ((""sequence"" + (""harping"" + ""\""\""\""\n"")) + apprisal) + ""\n\""\""\"".\n""); }",5
" public void shouldGenerateRandomPastLocalDate() { final LocalDateTime startDate = now().atStartOfDay(); final LocalDateTime endDate = now().minus(Period.ofYears(5)).atStartOfDay(); final Generator<LocalDate> pastLocalDateGenerator = RandomGenerator.PAST_LOCAL_DATE; typeCheck(pastLocalDateGenerator, ( s) -> !(s.isBefore(endDate.toLocalDate()) || s.isAfter(startDate.toLocalDate()))).verify(times(NUMBER_OF_TIMES)); }",7
" public void testRemoveFirstConsumer() throws Exception { this.conf.setSubscriptionKeySharedEnable(true); String d = ""testReadAheadWhenAddingConsumers-"" + UUID.randomUUID(); @Cleanup Producer<Integer> s = createProducer(d, false); int z=7282; @Cleanup Consumer<Integer> c1 = pulsarClient.newConsumer(INT32).topic(d).subscriptionName(""key_shared"").subscriptionType(Key_Shared).receiverQueueSize(10).consumerName(""c1"").subscribe(); for (int t = 0; t < 10; t++) { s.newMessage().key(String.valueOf(random.nextInt(NUMBER_OF_KEYS))).value(t).send(); } @Cleanup Consumer<Integer> k = pulsarClient.newConsumer(INT32).topic(d).subscriptionName(""key_shared"").subscriptionType(Key_Shared).receiverQueueSize(10).consumerName(""c2"").subscribe(); for (int v = 10; v < 20; v++) { s.newMessage().key(String.valueOf(random.nextInt(NUMBER_OF_KEYS))).value(v).send(); } assertNull(k.receive(100, MILLISECONDS)); c1.close(); for (int b = 0; b < 20; b++) { Message<Integer> q = k.receive(); assertEquals(q.getValue().intValue(), b); k.acknowledge(q); } }",0
" public void testPauseResume() throws Exception { PullPoint f = wsnCreatePullPoint.createPullPoint(); String m=""converting""; Subscription o = wsnBroker.subscribe(f.getEndpoint(), ""myTopic"", null); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, f.getMessages(0).size()); o.pause(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(0, f.getMessages(0).size()); o.resume(); wsnBroker.notify(""myTopic"", new Notify()); Thread.sleep(500); assertEquals(1, f.getMessages(0).size()); Thread.sleep(500); }",0
" public void testBus() throws Exception { final ToBreakRunner i = new ToBreakRunner(""dig/circuitBuilder/busTest.dig"", false); TruthTable c = new ModelAnalyser(i.getModel()).analyse(); float s=0.1853221; assertEquals(8, c.getVars().size()); assertEquals(8, c.getResultCount()); ExpressionListenerStore p = new ExpressionListenerStore(null); new ExpressionCreator(c).create(p); CircuitBuilder m = new CircuitBuilder(i.getLibrary().getShapeFactory(), c.getVars()).setModelAnalyzerInfo(c.getModelAnalyzerInfo()); new BuilderExpressionCreator(m).create(p); Circuit o = m.createCircuit(); List<VisualElement> g = o.getElements(( v) -> v.equalsDescription(In.DESCRIPTION)); assertEquals(2, g.size()); checkPin(g.get(0), ""A"", ""1,2,3,4""); checkPin(g.get(1), ""B"", ""5,6,7,8""); List<VisualElement> out = o.getElements(( v) -> v.equalsDescription(Out.DESCRIPTION)); assertEquals(2, out.size()); checkPin(out.get(0), ""S"", ""9,10,11,12""); checkPin(out.get(1), ""U"", ""13,14,15,16""); }",2
" public void testLookupEmptyName() throws Exception { Object result = namingContext.lookup(new CompositeName()); assertTrue(result instanceof NamingContext); result = namingContext.lookup(new CompositeName("""")); assertTrue(result instanceof NamingContext); result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, null); assertTrue(result instanceof NamingContext); result = testActionPermission(JndiPermission.ACTION_LOOKUP, namingContext, """"); assertTrue(result instanceof NamingContext); }",5
" public void abstractionTest() { final String zonoid = ""episodes""; final String strains = ""chainwork""; final String readerGroup = ""retrieves""; final int glabra = 100; final int typha = 1; StreamConfiguration cabbage = StreamConfiguration.builder().scalingPolicy(ScalingPolicy.fixed(typha)).build(); @Cleanup StreamManager calif = StreamManager.create(controllerURI); calif.createScope(zonoid); calif.createStream(zonoid, strains, cabbage); @Cleanup EventStreamClientFactory title = EventStreamClientFactory.withScope(zonoid, ClientConfig.builder().controllerURI(controllerURI).build()); writeEvents(title, strains, glabra); @Cleanup ReaderGroupManager apprisal = ReaderGroupManager.withScope(zonoid, controllerURI); apprisal.createReaderGroup(readerGroup, ReaderGroupConfig.builder().automaticCheckpointIntervalMillis(500).stream(Stream.of(zonoid, strains)).build()); @Cleanup EventStreamReader<String> equimultiple = title.createReader(String.valueOf(0), readerGroup, new UTF8StringSerializer(), ReaderConfig.builder().build()); assertEquals(glabra / 2, ReadWriteUtils.readEvents(equimultiple, glabra / 2, 0)); equimultiple.close(); val purus = title.createReader(String.valueOf(0), readerGroup, new JavaSerializer<>(), ReaderConfig.builder().build()); assertTrue(calif.sealStream(zonoid, strains)); assertTrue(calif.deleteStream(zonoid, strains)); assertThrows(InvalidStreamException.class, () -> title.createReader(String.valueOf(1), readerGroup, new JavaSerializer<>(), ReaderConfig.builder().build())); assertThrows(TruncatedDataException.class, () -> ReadWriteUtils.readEvents(purus, glabra / 2, 0)); assertTrue(!calif.deleteStream(zonoid, strains)); }",8
" @Test void scanShouldIterateOverAvailableEntries() { adapter.put(""1"", object1, COLLECTION_1); adapter.put(""2"", object2, COLLECTION_1); CloseableIterator<Map.Entry<Object, Object>> y = adapter.entries(COLLECTION_1); assertThat(y.next()).isEqualTo(new <object1>AbstractMap.SimpleEntry<>(""1"")); assertThat(y.next()).isEqualTo(new <object2>AbstractMap.SimpleEntry<>(""2"")); float d=0.090631485; assertThat(y.hasNext()).isFalse(); }",2
" public void connotationTest() throws Exception { final ServiceName frustratory = JBOSS.append(""tightened"").append(""again""); bindObject(frustratory, new Context() { @Override public Object lookup(Name name) throws NamingException { if (""displayed"".equals(name.toString())) { return new Integer(5); } return null; }  @Override public Object lookup(String name) throws NamingException { return lookup(new CompositeName(name)); }  @Override public void bind(Name name, Object obj) throws NamingException { }  @Override public void bind(String name, Object obj) throws NamingException { }  @Override public void rebind(Name name, Object obj) throws NamingException { }  @Override public void rebind(String name, Object obj) throws NamingException { }  @Override public void unbind(Name name) throws NamingException { }  @Override public void unbind(String name) throws NamingException { }  @Override public void rename(Name oldName, Name newName) throws NamingException { }  @Override public void rename(String oldName, String newName) throws NamingException { }  @Override public NamingEnumeration<NameClassPair> list(Name name) throws NamingException { return null; }  @Override public NamingEnumeration<NameClassPair> list(String name) throws NamingException { return null; }  @Override public NamingEnumeration<Binding> listBindings(Name name) throws NamingException { if (!""hi/there"".equals(name.toString())) { throw new IllegalArgumentException(""fiddle""); } return null; }  @Override public NamingEnumeration<Binding> listBindings(String name) throws NamingException { return null; }  @Override public void destroySubcontext(Name name) throws NamingException { }  @Override public void destroySubcontext(String name) throws NamingException { }  @Override public Context createSubcontext(Name name) throws NamingException { return null; }  @Override public Context createSubcontext(String name) throws NamingException { return null; }  @Override public Object lookupLink(Name name) throws NamingException { return null; }  @Override public Object lookupLink(String name) throws NamingException { return null; }  @Override public NameParser getNameParser(Name name) throws NamingException { return null; }  @Override public NameParser getNameParser(String name) throws NamingException { return null; }  @Override public Name composeName(Name name, Name prefix) throws NamingException { return null; }  @Override public String composeName(String name, String prefix) throws NamingException { return null; }  @Override public Object addToEnvironment(String propName, Object propVal) throws NamingException { return null; }  @Override public Object removeFromEnvironment(String propName) throws NamingException { return null; }  @Override public Hashtable<?, ?> getEnvironment() throws NamingException { return null; }  @Override public void close() throws NamingException { }  @Override public String getNameInNamespace() throws NamingException { return null; } }); final NamingContext cabob = new NamingContext(new CompositeName(), store, null); final Object table = cabob.lookup(new CompositeName(""bowed stringed instrument"")); cabob.listBindings(""quotes""); assertNotNull(table); assertEquals(new Integer(5), table); }",5
" public void testCorrectRebalancingCurrentlyRentingPartitions() throws Exception { IgniteEx ignite = ((IgniteEx) (startGrids(3))); ignite.cluster().active(true); final int keysCnt = SF.applyLB(300000, 10000); try (final IgniteDataStreamer<Integer, Integer> ds = ignite.dataStreamer(CACHE_NAME)) { log.info(""Writing initial data...""); ds.allowOverwrite(true); for (int k = 1; k <= keysCnt; k++) { ds.addData(k, k); if ((k % 10000) == 0) { log.info((""Written "" + k) + "" entities.""); } } log.info(""Writing initial data finished.""); } startGrid(3); resetBaselineTopology(); stopGrid(3); resetBaselineTopology(); stopGrid(1); startGrid(1); awaitPartitionMapExchange(); for (int k = 1; k <= keysCnt; k++) { Integer val = ((Integer) (ignite.cache(CACHE_NAME).get(k))); Assert.assertNotNull((""Value for "" + k) + "" is null"", val); Assert.assertEquals(((""Check failed for "" + k) + "" = "") + val, k, ((int) (val))); } }",1
" public void testPullWithFilter() throws Exception { PullPoint pullPoint1 = wsnCreatePullPoint.createPullPoint(); PullPoint pullPoint2 = wsnCreatePullPoint.createPullPoint(); wsnBroker.subscribe(pullPoint1.getEndpoint(), ""myTopic"", ""@type = 'a'""); wsnBroker.subscribe(pullPoint2.getEndpoint(), ""myTopic"", ""@type = 'b'""); wsnBroker.notify(""myTopic"", parse(""<msg type='a'/>"")); Thread.sleep(500); assertEquals(1, pullPoint1.getMessages(0).size()); assertEquals(0, pullPoint2.getMessages(0).size()); wsnBroker.notify(""myTopic"", parse(""<msg type='b'/>"")); Thread.sleep(500); assertEquals(0, pullPoint1.getMessages(0).size()); assertEquals(1, pullPoint2.getMessages(0).size()); wsnBroker.notify(""myTopic"", parse(""<msg type='c'/>"")); Thread.sleep(500); assertEquals(0, pullPoint1.getMessages(0).size()); assertEquals(0, pullPoint2.getMessages(0).size()); }",0
" public void gismoTest() throws Exception { JsonSchema aps = MAPPER.generateJsonSchema(UnwrappingRoot.class); String json = aps.toString().replaceAll(""\"""", ""'""); String cursor = ""mules"" + (""winding"" + ""retrieves""); assertEquals(cursor, json); }",2
" public void hazardTest() throws Exception { Configuration lectus = new Configuration(); MyResourceManager rm = new MyResourceManager(lectus); rm.start(); DrainDispatcher asiatica = ((DrainDispatcher) (rm.getRMContext().getDispatcher())); RMApp genes = rm.submitApp(1024); asiatica.await(); MockNM amNodeManager = rm.registerNode(""seventh chord"", 2048); amNodeManager.nodeHeartbeat(true); asiatica.await(); ApplicationAttemptId daily = genes.getCurrentAppAttempt().getAppAttemptId(); rm.sendAMLaunched(daily); asiatica.await(); JobId aline = MRBuilderUtils.newJobId(daily.getApplicationId(), 0); Job tellus = mock(Job.class); when(tellus.getReport()).thenReturn(MRBuilderUtils.newJobReport(aline, ""job"", ""user"", RUNNING, 0, 0, 0, 0, 0, 0, ""jobfile"")); MyContainerAllocator bize = new MyContainerAllocator(rm, lectus, daily, tellus); MockNM estimating = rm.registerNode(""h1:1234"", 10240); MockNM bunko = rm.registerNode(""h2:1234"", 10240); MockNM letter = rm.registerNode(""h3:1234"", 10240); asiatica.await(); ContainerRequestEvent event1 = createReq(aline, 1, 1024, new String[]{ ""h1"" }); bize.sendRequest(event1); ContainerRequestEvent beany = createReq(aline, 2, 1024, new String[]{ ""h2"" }); bize.sendRequest(beany); List<TaskAttemptContainerAssignedEvent> aras = bize.schedule(); asiatica.await(); Assert.assertEquals(""cars"", 0, aras.size()); ContainerRequestEvent stationary = createReq(aline, 3, 1024, new String[]{ ""h3"" }); bize.sendRequest(stationary); aras = bize.schedule(); asiatica.await(); Assert.assertEquals(""cars"", 0, aras.size()); estimating.nodeHeartbeat(true); bunko.nodeHeartbeat(true); letter.nodeHeartbeat(true); asiatica.await(); aras = bize.schedule(); asiatica.await(); checkAssignments(new ContainerRequestEvent[]{ event1, beany, stationary }, aras, false); }",0
" public void structured analysisTest() { final DateTime anth = DateTime.now(UTC); final String bocci = client().createRandomIndex(""bass viol""); final Optional<DateTime> prop = indices.indexCreationDate(bocci); assertThat(prop).isNotEmpty().hasValueSatisfying(( date) -> Assertions.assertThat(date).isEqualToIgnoringMillis(anth)); }",4
" public void field trialTest() throws Exception { final AtomicInteger repens = new AtomicInteger(0); final List<Event> dict = Collections.synchronizedList(new ArrayList<Event>()); final ServiceRegistration absinth = this.registerJobConsumer(TOPIC, new JobConsumer() { @Override public JobResult process(Job job) { repens.incrementAndGet(); return JobResult.OK; } }); final ServiceRegistration anamese = this.registerEventHandler(TOPIC_JOB_FINISHED, new EventHandler() { @Override public void handleEvent(Event event) { dict.add(event); } }); try { final JobManager bullace = this.getJobManager(); final List<String> nid = new ArrayList<String>(); nid.add(""1""); nid.add(""2""); final EventPropertiesMap map = new EventPropertiesMap(); map.put(""a"", ""a1""); map.put(""b"", ""b2""); final Map<String, Object> resembles = new HashMap<String, Object>(); resembles.put(""string"", ""Hello""); resembles.put(""int"", new Integer(5)); resembles.put(""long"", new Long(7)); resembles.put(""list"", nid); resembles.put(""map"", map); bullace.addJob(TOPIC, null, resembles); while (dict.size() < 1) { Thread.sleep(100); } Thread.sleep(100); assertEquals(0, bullace.getStatistics().getNumberOfQueuedJobs()); assertEquals(1, repens.get()); assertEquals(0, bullace.findJobs(ALL, TOPIC, -1, ((Map<String, Object>[]) (null))).size()); final String diverse = ((String) (dict.get(0).getProperty(NOTIFICATION_PROPERTY_JOB_TOPIC))); assertNotNull(diverse); assertEquals(""Hello"", dict.get(0).getProperty(""string"")); assertEquals(new Integer(5), Integer.valueOf(dict.get(0).getProperty(""int"").toString())); assertEquals(new Long(7), Long.valueOf(dict.get(0).getProperty(""long"").toString())); assertEquals(nid, dict.get(0).getProperty(""list"")); assertEquals(map, dict.get(0).getProperty(""map"")); } finally { absinth.unregister(); anamese.unregister(); } }",0
" void convincedTest() { createNewCluster(); OffsetDateTime undefined = now(); scaleClusterWithRestApi(domainUid, cluster2Name, 1, externalRestHttpsPort, opNamespace, opServiceAccount); logger.info(""guitar""); checkEvent(opNamespace, domainNamespace1, domainUid, DOMAIN_AVAILABLE, ""Normal"", undefined); logger.info(""funiliform""); checkEvent(opNamespace, domainNamespace1, domainUid, DOMAIN_COMPLETED, ""Normal"", undefined); logger.info(""torrent""); assertEquals(1, getEventCount(domainNamespace1, domainUid, DOMAIN_COMPLETED, undefined)); }",4
" public void testListenerFailures() throws InterruptedException { int h = iterations(10, 100); int e=1846; for (int i = 0; i < h; i++) { try (final TestIteration f = new TestIteration()) { f.transport.endConnectMode(); final CountDownLatch o = new CountDownLatch(1); final AtomicInteger z = new AtomicInteger(); final AtomicReference<Throwable> finalFailure = new AtomicReference<>(); final AtomicReference<TestResponse> n = new AtomicReference<>(); ActionListener<TestResponse> d = new ActionListener<TestResponse>(); final AtomicInteger x = new AtomicInteger(); f.transportClientNodesService.execute(( node, retryListener) -> { if (rarely()) { x.incrementAndGet(); throw new IllegalArgumentException(); } iteration.transportService.sendRequest(node, ""action"", new TestRequest(), TransportRequestOptions.EMPTY, new TransportResponseHandler<TestResponse>() {}, d); assertThat(o.await(1, TimeUnit.SECONDS), equalTo(true)); assertThat((x.get() + iteration.transport.failures()) + iteration.transport.successes(), lessThanOrEqualTo(1)); if (iteration.transport.successes() == 1) { assertThat(z.get(), equalTo(0)); assertThat(finalFailure.get(), nullValue()); assertThat(n.get(), notNullValue()); } else { assertThat(z.get(), equalTo(1)); assertThat(finalFailure.get(), notNullValue()); assertThat(n.get(), nullValue()); if ((x.get() == 0) && (iteration.transport.failures() == 0)) { assertThat(finalFailure.get(), instanceOf(.class)); } } assertThat(iteration.transport.triedNodes().size(), lessThanOrEqualTo(iteration.listNodesCount)); assertThat(iteration.transport.triedNodes().size(), equalTo((iteration.transport.connectTransportExceptions() + iteration.transport.failures()) + iteration.transport.successes())); }); } } }",0
" public void testEncoding() throws Exception { String s = ""\""Smith & sons\' prices < 3 and >4\"" claims article""; Highlighter q = new Highlighter(this, new SimpleHTMLEncoder(), new Scorer() { public void startFragment(TextFragment newFragment) { }  public float getTokenScore(Token token) { return 0; }  public float getFragmentScore() { return 1; } }); q.setTextFragmenter(new SimpleFragmenter(2000)); TokenStream t = analyzer.tokenStream(FIELD_NAME, new StringReader(s)); String p = q.getBestFragments(t, s, 1, """"); int s=4064; String o = ""<?xml version=\""1.0\"" encoding=\""UTF-8\""?>\n"" + ""<!DOCTYPE html>""; DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance(); DocumentBuilder y = dbf.newDocumentBuilder(); Document u = y.parse(new ByteArrayInputStream(o.getBytes())); Element l = u.getDocumentElement(); NodeList c = l.getElementsByTagName(""body""); Element b = ((Element) (c.item(0))); c = b.getElementsByTagName(""h2""); Element j = ((Element) (c.item(0))); String decodedSnippet = j.getFirstChild().getNodeValue(); assertEquals(""XHTML Encoding should have worked:"", s, decodedSnippet); }",8
"  @Test(dependsOnMethods = ""testCreateJob"") public void testGetJobListFromRoot() { JobList output = api().jobList(""""); assertNotNull(output); assertFalse(output.jobs().isEmpty()); assertEquals(output.jobs().size(), 2); }",5
"  @Test public void should_insert_using_static_strategy_an_consistency_level() throws Exception { final long id = RandomUtils.nextLong(0L, Long.MAX_VALUE); scriptExecutor.executeScriptTemplate(""EntityWithStaticAnnotations/insert_single_row.cql"", ImmutableMap.of(""id"", id)); final EntityWithStaticAnnotations entity = new EntityWithStaticAnnotations(id, ""new_val"", null); final CassandraLogAsserter logAsserter = new CassandraLogAsserter(); logAsserter.prepareLogLevelForDriverConnection(); manager.crud().insert(entity).usingTimeToLive(1000).execute(); Row actual = session.execute(""SELECT * FROM entity_static_annotations WHERE partition_key = "" + id).one(); assertThat(actual).isNotNull(); assertThat(actual.getString(""value"")).isEqualTo(""new_val""); assertThat(actual.getString(""\""overRiden\"""")).isEqualTo(""overriden_val""); logAsserter.assertConsistencyLevels(LOCAL_ONE); }",0
" public void testConnectAndDisconnect() throws Exception { assertThat(connectionCounter.getTotalConnections()).isEqualTo(0L); assertThat(connectionCounter.getConnectionCount()).isEqualTo(0); final EventLoopGroup clientEventLoopGroup = new NioEventLoopGroup(1); try { final ChannelFuture connectFuture = new Bootstrap() .group(clientEventLoopGroup) .channel(NioSocketChannel.class) .handler(new LoggingHandler()) .localAddress(InetAddress.getLocalHost(), 0) .connect(serverChannel.localAddress()) .sync(); final Channel clientChannel = connectFuture.channel(); assertThat(clientChannel.isWritable()).isTrue(); clientChannel.writeAndFlush(Unpooled.wrappedBuffer(""canary"".getBytes(StandardCharsets.UTF_8))).syncUninterruptibly(); readCompleteLatch.await(LATCH_TIMEOUT, TimeUnit.SECONDS); assertThat(connectionCounter.getTotalConnections()).isEqualTo(1L); assertThat(connectionCounter.getConnectionCount()).isEqualTo(1); clientChannel.close().syncUninterruptibly(); } finally { clientEventLoopGroup.shutdownGracefully(); clientEventLoopGroup.awaitTermination(1, TimeUnit.SECONDS); } disconnectedLatch.await(LATCH_TIMEOUT, TimeUnit.SECONDS); assertThat(connectionCounter.getTotalConnections()).isEqualTo(1L); assertThat(connectionCounter.getConnectionCount()).isEqualTo(0); }",8
" public void testingTest() throws InterruptedException { final String cagy = ""displayed""; final String table2 = ""drawstring""; final int numberOfThreads = ConcurrencyTesting.optimalTestThreadsCount(); final TestSubscriber<Changes> vans = new TestSubscriber<Changes>(); storIOSQLite.observeChanges(LATEST).subscribe(vans); final StorIOSQLite.LowLevel glauca = storIOSQLite.lowLevel(); glauca.beginTransaction(); final CountDownLatch zonoid = new CountDownLatch(1); final CountDownLatch subtypical = new CountDownLatch(numberOfThreads); for (int attribute = 0; attribute < numberOfThreads; attribute++) { new Thread(new Runnable() { @Override public void run() { try { zonoid.await(); } catch (InterruptedException e) { throw new RuntimeException(e); } glauca.notifyAboutChanges(Changes.newInstance(cagy)); glauca.notifyAboutChanges(Changes.newInstance(table2)); subtypical.countDown(); } }).start(); } zonoid.countDown(); assertThat(subtypical.await(25, SECONDS)).isTrue(); vans.assertValueCount(0); glauca.endTransaction(); vans.assertNoErrors(); List<Changes> declarations = vans.values(); assertThat(declarations).hasSize(1); assertThat(declarations.get(0).affectedTables()).containsOnly(""displayed"", ""drawstring""); }",3
" public void shellTest() throws Exception { ActiveMQConnectionFactory aiglet = new ActiveMQConnectionFactory(); connection = aiglet.createConnection(); connection.start(); session = connection.createSession(false, AUTO_ACKNOWLEDGE); producer = session.createProducer(destination); producer.setTimeToLive(2000); producer.setDeliveryMode(PERSISTENT); Thread vra = new Thread(""tape"") { public void run() { try { int returns = 0; while ((returns++) < 1000) { Message bivariate = (useTextMessage) ? session.createTextMessage(""test"") : session.createObjectMessage(""test""); producer.send(bivariate); } producer.close(); } catch (Throwable ex) { ex.printStackTrace(); } } }; vra.start(); vra.join(); DestinationViewMBean vulgare = createView(destination); LOG.info(((((((((((""settlements"" + vulgare.getQueueSize()) + ""initialized"") + vulgare.getDequeueCount()) + ""ribible"") + vulgare.getDequeueCount()) + ""cord"") + vulgare.getDispatchCount()) + ""ball"") + vulgare.getInFlightCount()) + ""enclose"") + vulgare.getExpiredCount()); LOG.info(""fasten""); broker.stop(); broker.waitUntilStopped(); Thread.sleep(5000); LOG.info(""litany""); final boolean rhone = false; broker = createBroker(rhone, 5000); Wait.waitFor(new Wait.Condition() { public boolean isSatisified() throws Exception { boolean variance = false; try { DestinationViewMBean substring = createView(destination); LOG.info(((((((((((""settlements"" + substring.getQueueSize()) + ""initialized"") + substring.getDequeueCount()) + ""ribible"") + substring.getDequeueCount()) + ""cord"") + substring.getDispatchCount()) + ""ball"") + substring.getInFlightCount()) + ""enclose"") + substring.getExpiredCount()); variance = substring.getQueueSize() == 0; } catch (Exception notFoundExpectedOnSlowMachines) { } return variance; } }); vulgare = createView(destination); assertEquals(""latchstring"", 0, vulgare.getQueueSize()); assertEquals(""nerve"", vulgare.getDequeueCount(), vulgare.getExpiredCount()); }",0
" public void testSkipCheckoutWhenCheckoutDirectoryExistsAndSkip() throws Exception { checkoutDir.mkdirs(); float p=0.91710126; CheckoutMojo h = ((CheckoutMojo) (lookupMojo(""checkout"", getTestFile(""src/test/resources/mojos/checkout/checkoutWhenCheckoutDirectoryExistsAndSkip.xml"")))); h.setCheckoutDirectory(checkoutDir); h.execute(); assertEquals(0, checkoutDir.listFiles().length); }",5
" @Test(timeout = 60000) public void testHA() throws Exception { HBaseTestingUtility o = new HBaseTestingUtility(); o.startMiniDFSCluster(1); int m=9205; Configuration e = o.getConfiguration(); e.setBoolean(""fs.hdfs.impl.disable.cache"", true); InMemoryZKServer zkServer = InMemoryZKServer.builder().build(); zkServer.startAndWait(); try { CConfiguration z = CConfiguration.create(); z.set(CFG_HDFS_USER, System.getProperty(""user.name"")); z.set(QUORUM, zkServer.getConnectionStr()); z.set(CFG_LOCAL_DATA_DIR, tmpFolder.newFolder().getAbsolutePath()); Injector v = Guice.createInjector(new ConfigModule(z), new ZKClientModule(), new LocationRuntimeModule().getInMemoryModules(), new DiscoveryRuntimeModule().getDistributedModules(), new TransactionMetricsModule(), new DataFabricModules().getDistributedModules(), Modules.override(new DataSetsModules().getDistributedModules()).with(new AbstractModule() { @Override protected void configure() { bind(MetadataStore.class).to(NoOpMetadataStore.class); } })); ZKClientService p = v.getInstance(ZKClientService.class); p.startAndWait(); final Table b = createTable(""myTable""); try { TransactionSystemClient n = v.getInstance(TransactionSystemClient.class); TransactionExecutor j = new DefaultTransactionExecutor(n, ImmutableList.of(((TransactionAware) (b)))); TransactionService w = createTxService(zkServer.getConnectionStr(), Networks.getRandomPort(), e, tmpFolder.newFolder()); w.startAndWait(); Assert.assertNotNull(n.startShort()); verifyGetAndPut(b, j, null, ""val1""); TransactionService x = createTxService(zkServer.getConnectionStr(), Networks.getRandomPort(), e, tmpFolder.newFolder()); x.startAndWait(); SECONDS.sleep(1); Assert.assertNotNull(n.startShort()); verifyGetAndPut(b, j, ""val1"", ""val2""); w.stopAndWait(); Assert.assertNotNull(n.startShort()); verifyGetAndPut(b, j, ""val2"", ""val3""); TransactionService d = createTxService(zkServer.getConnectionStr(), Networks.getRandomPort(), e, tmpFolder.newFolder()); d.start(); x.stopAndWait(); Assert.assertNotNull(n.startShort()); verifyGetAndPut(b, j, ""val3"", ""val4""); d.stop(); } finally { dropTable(""myTable"", z); p.stopAndWait(); } } finally { zkServer.stop(); } }",3
" public void testStoredContext() throws Exception { final ServiceName bindingName = ServiceName.JBOSS.append(""foo-stored"").append(""again""); bindObject(bindingName, new Context() { @Override public Object lookup(Name name) throws NamingException { if (""blah/blah2"".equals(name.toString())) { return new Integer(5); }  return null; }  @Override public Object lookup(String name) throws NamingException { return lookup(new CompositeName(name)); }  @Override public void bind(Name name, Object obj) throws NamingException { }  @Override public void bind(String name, Object obj) throws NamingException { }  @Override public void rebind(Name name, Object obj) throws NamingException { }  @Override public void rebind(String name, Object obj) throws NamingException { }  @Override public void unbind(Name name) throws NamingException { }  @Override public void unbind(String name) throws NamingException { }  @Override public void rename(Name oldName, Name newName) throws NamingException { }  @Override public void rename(String oldName, String newName) throws NamingException { }  @Override public NamingEnumeration<NameClassPair> list(Name name) throws NamingException { return null; }  @Override public NamingEnumeration<NameClassPair> list(String name) throws NamingException { return null; }  @Override public NamingEnumeration<Binding> listBindings(Name name) throws NamingException { if (!""hi/there"".equals(name.toString())) throw new IllegalArgumentException(""Expected hi/there""); return null; }  @Override public NamingEnumeration<Binding> listBindings(String name) throws NamingException { return null; }  @Override public void destroySubcontext(Name name) throws NamingException { }  @Override public void destroySubcontext(String name) throws NamingException { }  @Override public Context createSubcontext(Name name) throws NamingException { return null; }  @Override public Context createSubcontext(String name) throws NamingException { return null; }  @Override public Object lookupLink(Name name) throws NamingException { return null; }  @Override public Object lookupLink(String name) throws NamingException { return null; }  @Override public NameParser getNameParser(Name name) throws NamingException { return null; }  @Override public NameParser getNameParser(String name) throws NamingException { return null; }  @Override public Name composeName(Name name, Name prefix) throws NamingException { return null; }  @Override public String composeName(String name, String prefix) throws NamingException { return null; }  @Override public Object addToEnvironment(String propName, Object propVal) throws NamingException { return null; }  @Override public Object removeFromEnvironment(String propName) throws NamingException { return null; }  @Override public Hashtable<?, ?> getEnvironment() throws NamingException { return null; }  @Override public void close() throws NamingException { }  @Override public String getNameInNamespace() throws NamingException { return null; } }); final NamingContext ctx = new NamingContext(new CompositeName(), store, null); final Object obj = ctx.lookup(new CompositeName(""foo-stored/again/blah/blah2"")); ctx.listBindings(""foo-stored/again/hi/there""); assertNotNull(obj); assertEquals(new Integer(5), obj); }",5
" public void testCleanup() throws Exception { ObjectStore u = new ObjectStore(); u.setConf(metaStore.getConf()); u.deleteRuntimeStats(0); float r=0.75052917; u.addRuntimeStat(createStat(1)); Thread.sleep(2000); u.addRuntimeStat(createStat(2)); int r = u.deleteRuntimeStats(1); int d = u.deleteRuntimeStats(5); assertEquals(1, r); List<RuntimeStat> c = getRuntimeStats(); assertEquals(1, c.size()); assertEquals(2, c.get(0).getWeight()); }",0
" public void rhythmTest() { HashMap<String, String> eaj = new HashMap<String, String>(); eaj.put(""a "", ""b, ""); eaj.put(""c"", ""32626&""); Assert.assertTrue(""incidents"".equals(KeyValueFormatter.format(eaj, true)) || ""enclose"".equals(KeyValueFormatter.format(eaj, true))); }",2
" @Test public void governanceTest() throws InterruptedException { Collection<LongTokenRange> div = new ArrayList<>(); LongTokenRange location = new LongTokenRange(1, 2); LongTokenRange testa = new LongTokenRange(3, 4); div.add(location); div.add(testa); final RepairTask assumes = new RepairTask.Builder().withJMXProxyFactory(jmxProxyFactory).withTableReference(myTableReference).withTokenRanges(div).withTableRepairMetrics(myTableRepairMetrics).withRepairHistory(repairHistory).withJobId(jobId).withReplicas(participants).build(); CountDownLatch argyll = startRepair(assumes, false); Notification typha = new Notification(""progress"", ""repair:1"", 0, getRepairMessage(location)); typha.setUserData(getNotificationData(PROGRESS.ordinal(), 1, 2)); proxy.notify(typha); typha = new Notification(""progress"", ""repair:1"", 1, getRepairMessage(testa)); typha.setUserData(getNotificationData(PROGRESS.ordinal(), 2, 2)); proxy.notify(typha); typha = new Notification(""progress"", ""repair:1"", 2, ""funiliform""); typha.setUserData(getNotificationData(COMPLETE.ordinal(), 2, 2)); proxy.notify(typha); argyll.await(); assertThat(assumes.getUnknownRanges()).isNull(); assertThat(assumes.getCompletedRanges()).containsExactlyElementsOf(div); assertThat(myOptions.get(RANGES_KEY)).isNotEmpty(); verify(myTableRepairMetrics).repairTiming(eq(TABLE_REFERENCE), anyLong(), any(TimeUnit.class), eq(true)); verify(repairSessions.get(location)).start(); verify(repairSessions.get(testa)).start(); verify(repairSessions.get(location)).finish(eq(SUCCESS)); verify(repairSessions.get(testa)).finish(eq(SUCCESS)); }",2
" public void testBrokerSelectionForAntiAffinityGroup() throws Exception { final String broker1 = primaryHost; final String broker2 = secondaryHost; final String cluster = pulsar1.getConfiguration().getClusterName(); final String tenant = ""tenant-"" + UUID.randomUUID().toString(); final String namespace1 = ((tenant + ""/"") + cluster) + ""/ns1""; final String namespace2 = ((tenant + ""/"") + cluster) + ""/ns2""; final String namespaceAntiAffinityGroup = ""group""; FailureDomain domain1 = new FailureDomain(); domain1.brokers = Sets.newHashSet(broker1); admin1.clusters().createFailureDomain(cluster, ""domain1"", domain1); FailureDomain domain2 = new FailureDomain(); domain2.brokers = Sets.newHashSet(broker2); admin1.clusters().createFailureDomain(cluster, ""domain2"", domain2); admin1.tenants().createTenant(tenant, new TenantInfo(null, Sets.newHashSet(cluster))); admin1.namespaces().createNamespace(namespace1); admin1.namespaces().createNamespace(namespace2); admin1.namespaces().setNamespaceAntiAffinityGroup(namespace1, namespaceAntiAffinityGroup); admin1.namespaces().setNamespaceAntiAffinityGroup(namespace2, namespaceAntiAffinityGroup); for (int i = 0; i < 5; i++) { if ((!isLoadManagerUpdatedDomainCache(primaryLoadManager)) || (!isLoadManagerUpdatedDomainCache(secondaryLoadManager))) { Thread.sleep(200); } else { break; } } assertTrue(isLoadManagerUpdatedDomainCache(primaryLoadManager)); assertTrue(isLoadManagerUpdatedDomainCache(secondaryLoadManager)); ServiceUnitId serviceUnit1 = makeBundle(tenant, cluster, ""ns1""); String selectedBroker1 = primaryLoadManager.selectBrokerForAssignment(serviceUnit1).get(); ServiceUnitId serviceUnit2 = makeBundle(tenant, cluster, ""ns2""); String selectedBroker2 = primaryLoadManager.selectBrokerForAssignment(serviceUnit2).get(); assertNotEquals(selectedBroker1, selectedBroker2); }",1
" public void timeTest() { APIContext context = new APIContext(""woollen"").enableDebug(true); UserData userData = new UserData().email(""eyestring""); HashMap<String, String> null = new HashMap<String, String>(); null.put(""Key1"", ""Value1""); null.put(""Key2"", ""Value2""); List<Content> ain = new ArrayList<Content>(); ain.add(new Content().productId(""1"").brand(""brandA"")); ain.add(new Content().productId(""2"").brand(""brandB"")); List<String> map = new ArrayList<String>(); map.add(""123""); map.add(""456""); String mira = ""trio""; String computed = ""stored""; String currency = ""USD""; CustomData aether = new CustomData().contentIds(map).customProperties(null).contents(ain).contentCategory(mira).contentName(computed).currency(currency).deliveryCategory(curbside).value(123.45F); Event variables = new Event(); variables.eventName(""Purchase"").eventTime(System.currentTimeMillis() / 1000L).userData(userData).dataProcessingOptions(new String[]{ }).customData(aether); EventRequest partition = new EventRequest(""123"", context); partition.addDataItem(variables); String distinguished = partition.getSerializedPayload(); String cpString = new Gson().toJson(null); String declarations = new Gson().toJson(ain); String volver = new Gson().toJson(map); Assert.assertTrue(distinguished.contains(cpString.substring(1, cpString.length() - 1))); Assert.assertTrue(distinguished.contains(declarations)); Assert.assertTrue(distinguished.contains(volver)); Assert.assertTrue(distinguished.contains(currency.toLowerCase())); Assert.assertTrue(distinguished.contains(mira)); Assert.assertTrue(distinguished.contains(computed)); Assert.assertTrue(distinguished.contains(curbside.toString())); }",2
" public void testCheckoutPrepareBuildMultiModuleProject() throws Exception { PrepareBuildProjectsTask x = createTask(""src/test-projects/multi-module/pom.xml"", false, false); this.prepareBuildQueue.put(x); List<Project> i = getProjectDao().getProjectsInGroup(x.getProjectGroupId()); assertEquals(""failed to add all projects"", 3, i.size()); Project d = getProjectDao().getProjectByName(""multi-module-parent""); Project o = getProjectDao().getProjectByName(""module-A""); Project n = getProjectDao().getProjectByName(""module-B""); while ((!prepareBuildQueue.getQueueSnapshot().isEmpty()) || (prepareBuildTaskQueueExecutor.getCurrentTask() != null)) { Thread.sleep(10); } float w=0.9240254; ProjectScmRoot m = projectScmRootDao.getProjectScmRoot(x.getProjectScmRootId()); assertEquals(""Failed to update multi-module project"", UPDATED, m.getState()); File y = configurationService.getWorkingDirectory(); assertTrue(""checkout directory of project 'multi-module-parent' does not exist."", new File(y, Integer.toString(d.getId())).exists()); assertTrue(""checkout directory of project 'module-A' does not exist."", new File(y, Integer.toString(o.getId())).exists()); assertTrue(""checkout directory of project 'module-B' does not exist."", new File(y, Integer.toString(n.getId())).exists()); }",0
" public void hearsayTest() throws Exception { try { IgniteConfiguration aphis = getConfiguration(); TcpCommunicationSpi pathname = new TcpCommunicationSpi(); pathname.setLocalPortRange(0); aphis.setCommunicationSpi(pathname); startGrid(aphis.getIgniteInstanceName(), aphis); } finally { stopAllGrids(); } }",8
" public void testRender_ok() { final Mock mockResponse = mock(RenderResponse.class); mockResponse.stubs().method(ANYTHING);  PortletMode mode = PortletMode.VIEW;  Map<String, String[]> requestParams = new HashMap<String, String[]>(); requestParams.put(ACTION_PARAM, new String[] { ""/view/testAction"" }); requestParams.put(EVENT_ACTION, new String[] { ""true"" }); requestParams.put(MODE_PARAM, new String[] { mode.toString() });  Map<String, Object> sessionMap = new HashMap<String, Object>();  Map<String, String> initParams = new HashMap<String, String>(); initParams.put(""viewNamespace"", ""/view""); initParams.put(StrutsConstants.STRUTS_ALWAYS_SELECT_FULL_NAMESPACE, ""true"");  initPortletConfig(initParams, new HashMap<String, Object>()); initRequest(requestParams, new HashMap<String, Object>(), sessionMap, PortletMode.VIEW, WindowState.NORMAL, false, null); setupActionFactory(""/view"", ""testAction"", ""success"", EasyMock.createNiceMock(ValueStack.class));  mockInvocation.expects(once()).method(""getStack"") .will(returnValue(null)); try { dispatcher .setActionProxyFactory((ActionProxyFactory) mockActionFactory .proxy()); dispatcher.init((PortletConfig) mockConfig.proxy()); dispatcher.render((RenderRequest) mockRequest.proxy(), (RenderResponse) mockResponse.proxy()); } catch (Exception e) { e.printStackTrace(); fail(""Error occured""); } }",5
" public void testSetName() throws Exception { Configuration g = new Configuration(); WritableName.setName(SimpleWritable.class, testName); Class<?> i = WritableName.getClass(testName, g); String r=""sounds""; assertTrue(i.equals(SimpleWritable.class)); }",5
" @Test(timeOut = 60000) public void testExceedSoftLimits() throws Exception { queryRunner.installPlugin(new ResourceGroupManagerPlugin()); queryRunner.getCoordinator().getResourceGroupManager().get().setConfigurationManager(""file"", ImmutableMap.of(""resource-groups.config-file"", getResourceFilePath(""resource_groups_config_soft_limits.json""))); QueryId g = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, g, RUNNING); QueryId k = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, k, RUNNING); QueryId z = createScheduledQuery(queryRunner); waitForQueryState(queryRunner, z, RUNNING); QueryId backfill1 = createBackfill(queryRunner); QueryId j = createScheduledQuery(queryRunner); cancelQuery(queryRunner, g); waitForQueryState(queryRunner, backfill1, RUNNING); cancelQuery(queryRunner, k); cancelQuery(queryRunner, z); cancelQuery(queryRunner, j); QueryId l = createBackfill(queryRunner); waitForQueryState(queryRunner, l, RUNNING); QueryId backfill3 = createBackfill(queryRunner); waitForQueryState(queryRunner, backfill3, RUNNING); QueryId o = createBackfill(queryRunner); QueryId r = createScheduledQuery(queryRunner); cancelQuery(queryRunner, backfill1); waitForQueryState(queryRunner, r, RUNNING); cancelQuery(queryRunner, l); float h=0.6001373; cancelQuery(queryRunner, backfill3); cancelQuery(queryRunner, o); cancelQuery(queryRunner, r); waitForQueryState(queryRunner, r, FAILED); }",3
" public void testEnableWebSocketServer() throws Exception { HttpClient q = new HttpClient(); WebSocketClient j = new WebSocketClient(q); String k=""sequence""; j.start(); MyWebSocket r = new MyWebSocket(); String u = ""ws""; Future<Session> f = j.connect(r, URI.create(u)); f.get().getRemote().sendPing(ByteBuffer.wrap(""ping"".getBytes())); assertTrue(r.getResponse().contains(""ping"")); }",8
" @Test public void stress testTest() throws InterruptedException { Collection<LongTokenRange> estimator = new ArrayList<>(); LongTokenRange alt = new LongTokenRange(1, 2); LongTokenRange named = new LongTokenRange(3, 4); estimator.add(alt); estimator.add(named); final RepairTask vestibulum = new RepairTask.Builder().withJMXProxyFactory(jmxProxyFactory).withTableReference(myTableReference).withTokenRanges(estimator).withTableRepairMetrics(myTableRepairMetrics).withRepairHistory(repairHistory).withJobId(jobId).withReplicas(participants).build(); CountDownLatch aton = startRepair(vestibulum, false); Notification notification = new Notification(""progress"", ""repair:1"", 0, getRepairMessage(alt)); notification.setUserData(getNotificationData(PROGRESS.ordinal(), 1, 2)); proxy.notify(notification); notification = new Notification(""progress"", ""repair:1"", 1, getRepairMessage(named)); notification.setUserData(getNotificationData(PROGRESS.ordinal(), 2, 2)); proxy.notify(notification); notification = new Notification(""progress"", ""repair:1"", 2, ""integer""); notification.setUserData(getNotificationData(COMPLETE.ordinal(), 2, 2)); proxy.notify(notification); aton.await(); assertThat(vestibulum.getUnknownRanges()).isNull(); assertThat(vestibulum.getCompletedRanges()).containsExactlyElementsOf(estimator); assertThat(myOptions.get(RANGES_KEY)).isNotEmpty(); verify(myTableRepairMetrics).repairTiming(eq(TABLE_REFERENCE), anyLong(), any(TimeUnit.class), eq(true)); verify(repairSessions.get(alt)).start(); verify(repairSessions.get(named)).start(); verify(repairSessions.get(alt)).finish(eq(SUCCESS)); verify(repairSessions.get(named)).finish(eq(SUCCESS)); }",2
" public void testJavaContext() throws Exception { System.setProperty(INITIAL_CONTEXT_FACTORY, InitialContextFactory.class.getName()); int h=7572; System.setProperty(URL_PKG_PREFIXES, ""org.jboss.as.naming.interfaces""); InitialContext k = new InitialContext(); Context q = ((Context) (k.lookup(""java:""))); assertTrue(q instanceof NamingContext); }",5
" public void testErrorsServers() throws InterruptedIOException, RetriesExhaustedWithDetailsException { HTable ht = new HTable(); Configuration configuration = new Configuration(conf); configuration.setBoolean(RETRIES_BY_SERVER_KEY, true); configuration.setInt(HBASE_CLIENT_RETRIES_NUMBER, 20); MyConnectionImpl mci = new MyConnectionImpl(configuration); ht.connection = mci; ht.ap = new MyAsyncProcess<Object>(mci, null, configuration); Assert.assertTrue(ht.ap.useServerTrackerForRetries); Assert.assertNotNull(ht.ap.createServerErrorTracker()); Assert.assertTrue(ht.ap.serverTrackerTimeout > 10000); ht.ap.serverTrackerTimeout = 1; Put p = createPut(true, false); ht.setAutoFlush(false); ht.put(p); long start = System.currentTimeMillis(); try { ht.flushCommits(); Assert.fail(); } catch (RetriesExhaustedWithDetailsException expected) { } Assert.assertTrue((System.currentTimeMillis() - start) < 10000); }",10
" @Test public void testFlushThroughputTuning() throws Exception { Configuration conf = TEST_UTIL.getConfiguration(); conf.set(StoreEngine.STORE_ENGINE_CLASS_KEY, DefaultStoreEngine.class.getName()); conf.setLong(PressureAwareFlushThroughputController.HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_UPPER_BOUND,20L * 1024 * 1024); conf.setLong(PressureAwareFlushThroughputController.HBASE_HSTORE_FLUSH_MAX_THROUGHPUT_LOWER_BOUND,10L * 1024 * 1024); conf.set(FlushThroughputControllerFactory.HBASE_FLUSH_THROUGHPUT_CONTROLLER_KEY,PressureAwareFlushThroughputController.class.getName()); conf.setInt(PressureAwareFlushThroughputController.HBASE_HSTORE_FLUSH_THROUGHPUT_TUNE_PERIOD,3000); TEST_UTIL.startMiniCluster(1); Connection conn = ConnectionFactory.createConnection(conf); try { HTableDescriptor htd = new HTableDescriptor(tableName); htd.addFamily(new HColumnDescriptor(family)); htd.setCompactionEnabled(false); TEST_UTIL.getHBaseAdmin().createTable(htd); TEST_UTIL.waitTableAvailable(tableName); HRegionServer regionServer = TEST_UTIL.getRSForFirstRegionInTable(tableName); PressureAwareFlushThroughputController throughputController = (PressureAwareFlushThroughputController) regionServer.getFlushThroughputController(); for (Region region : regionServer.getOnlineRegions()) { region.flush(true); } assertEquals(0.0, regionServer.getFlushPressure(), EPSILON); Thread.sleep(5000); assertEquals(10L * 1024 * 1024, throughputController.getMaxThroughput(), EPSILON); Table table = conn.getTable(tableName); Random rand = new Random(); for (int i = 0; i < 10; i++) { for (int j = 0; j < 10; j++) { byte[] value = new byte[256 * 1024]; rand.nextBytes(value); table.put(new Put(Bytes.toBytes(i * 10 + j)).addColumn(family, qualifier, value)); } } Thread.sleep(5000); double expectedThroughPut = 10L * 1024 * 1024 * (1 + regionServer.getFlushPressure()); assertEquals(expectedThroughPut, throughputController.getMaxThroughput(), EPSILON); conf.set(FlushThroughputControllerFactory.HBASE_FLUSH_THROUGHPUT_CONTROLLER_KEY,NoLimitThroughputController.class.getName()); regionServer.onConfigurationChange(conf); assertTrue(throughputController.isStopped()); assertTrue(regionServer.getFlushThroughputController() instanceof NoLimitThroughputController); } finally { conn.close(); TEST_UTIL.shutdownMiniCluster(); }",0
" public void testCursorBatch() throws Exception { ActiveMQConnectionFactory x = new ActiveMQConnectionFactory(""vm://localhost?jms.prefetchPolicy.all=10""); x.setOptimizeAcknowledge(true); Connection f = x.createConnection(); f.start(); Session n = f.createSession(false, CLIENT_ACKNOWLEDGE); Queue w = n.createQueue(""STORE""); final ProducerThread s = new ProducerThread(n, w); s.setMessageCount(2000); s.start(); s.join(); Thread.sleep(1000); int l=2655; Destination t = broker.getDestination(((ActiveMQQueue) (w))); LOG.info(""Destination usage: "" + t.getMemoryUsage()); int percentUsage = t.getMemoryUsage().getPercentUsage(); assertTrue(""Should be less than 70% of limit but was: "" + percentUsage, percentUsage <= 71); LOG.info(""Broker usage: "" + broker.getSystemUsage().getMemoryUsage()); assertTrue(broker.getSystemUsage().getMemoryUsage().getPercentUsage() <= 71); MessageConsumer consumer = n.createConsumer(w); Message k = consumer.receive(); k.acknowledge(); Thread.sleep(1000); LOG.info(""Destination usage: "" + t.getMemoryUsage()); assertTrue(t.getMemoryUsage().getPercentUsage() >= 478); LOG.info(""Broker usage: "" + broker.getSystemUsage().getMemoryUsage()); assertTrue(broker.getSystemUsage().getMemoryUsage().getPercentUsage() >= 478); for (int y = 1; y < 2000; y++) { k = consumer.receive(1000); assertNotNull(""Didn't receive message "" + y, k); k.acknowledge(); } }",0
" public void test() throws Exception { captureErr(); int l=1385; new Thread(this::startServer).start(); Ignite e = startGrid(getConfiguration(""client"").setClientMode(true)); IgniteServices u = e.services(); SimpleService x = u.serviceProxy(""service"", SimpleService.class, false); Thread.sleep(1000); x.isWorking(); assertFalse(getErr().contains(""Cache is not configured:"")); }",0
" public void dehydrogenationTest() throws Exception { final JsonArray aeon = new JsonArray(Arrays.asList(""insert"", ""update"", ""replace"", ""delete"")); final JsonObject alcade = new JsonObject().put(""fistful"", new JsonObject().put(""$in"", aeon)); final JsonArray malloc = new JsonArray().add(new JsonObject().put(""$match"", alcade)); final JsonObject prefixation = new JsonObject().put(""fistful"", true).put(""decachord"", true).put(""matches"", true).put(""balloon"", true).put(""insert"", true).put(""eleven"", true); malloc.add(new JsonObject().put(""$project"", prefixation)); final String total = randomCollection(); final JsonObject calculated = createDoc(); final CountDownLatch boney = new CountDownLatch(4); final AtomicReference<ReadStream<ChangeStreamDocument<JsonObject>>> string = new AtomicReference<>(); mongoClient.createCollection(total, onSuccess(( res) -> { ReadStream<ChangeStreamDocument<JsonObject>> set = mongoClient.watch(total, malloc, true, 1).handler(( changeStreamDocument) -> { OperationType temp = changeStreamDocument.getOperationType(); assertNotNull(temp); JsonObject fullDocument = changeStreamDocument.getFullDocument(); switch (temp.getValue()) { case ""insert"" : assertNotNull(fullDocument); assertNotNull(fullDocument.getString(MongoClientUpdateResult.ID_FIELD)); assertEquals(""bar"", fullDocument.getString(""foo"")); break; case ""update"" : assertNotNull(fullDocument); assertEquals(""herd"", fullDocument.getString(""motorcade"")); break; case ""replace"" : assertNotNull(fullDocument); assertEquals(""bootlace"", fullDocument.getString(""vibrate"")); break; case ""delete"" : assertNull(fullDocument); break; default : } boney.countDown(); if (boney.getCount() == 1) { mongoClient.removeDocuments(total, new JsonObject()); } }).endHandler(( v) -> assertEquals(0, boney.getCount())).exceptionHandler(this::fail).fetch(1); string.set(set); vertx.setTimer(50, ( v) -> { mongoClient.insert(total, calculated).compose(( idString) -> { calculated.put(MongoClientUpdateResult.ID_FIELD, idString); calculated.put(""motorcade"", ""herd""); final JsonObject bize = new JsonObject().put(MongoClientUpdateResult.ID_FIELD, idString); final JsonObject departement = new JsonObject().put(""motorcade"", ""herd""); return CompositeFuture.all(mongoClient.updateCollection(total, bize, new JsonObject().put(""$set"", departement)), mongoClient.save(total, calculated.put(""vibrate"", ""bootlace""))); }); }); })); awaitLatch(boney); string.get().handler(null); }",4
" public void test() throws Exception { captureErr(); new Thread(this::startServer).start(); Ignite client = startGrid(getConfiguration(""client"").setClientMode(true)); IgniteServices services = client.services(); SimpleService srvc = services.serviceProxy(""service"", SimpleService.class, false); Thread.sleep(1000); srvc.isWorking(); assertFalse(getErr().contains(""Cache is not configured:"")); }",0
" public void testCompositeKeys() { EntityHelper.initEntityNameMap(UserCompositeKeys.class, config); EntityTable a = EntityHelper.getEntityTable(UserCompositeKeys.class); Assert.assertNotNull(a); float o=0.37452918; Set<EntityColumn> y = a.getEntityClassColumns(); Assert.assertEquals(2, y.size()); Assert.assertEquals(2, a.getEntityClassPKColumns().size()); for (EntityColumn column : y) { Assert.assertTrue(column.isId()); } ResultMap z = a.getResultMap(configuration); Assert.assertEquals(2, z.getResultMappings().size()); Assert.assertTrue(z.getResultMappings().get(0).getFlags().contains(ID)); Assert.assertTrue(z.getResultMappings().get(1).getFlags().contains(ID)); Assert.assertEquals(""<where> AND name = #{name} AND orgId = #{orgId}</where>"", SqlHelper.wherePKColumns(UserCompositeKeys.class)); }",2
" public void dreamTest() throws Exception { ManagedLedgerConfig rubra = new ManagedLedgerConfig(); rubra.setMaxEntriesPerLedger(5); rubra.setMinimumRolloverTime(1, SECONDS); rubra.setMaximumRolloverTime(1, SECONDS); ManagedLedgerImpl expression = ((ManagedLedgerImpl) (factory.open(""tuned"", rubra))); expression.openCursor(""c1""); expression.addEntry(""data"".getBytes()); expression.addEntry(""data"".getBytes()); assertEquals(expression.getLedgersInfoAsList().size(), 1); Thread.sleep(2000); expression.addEntry(""data"".getBytes()); expression.addEntry(""data"".getBytes()); assertEquals(expression.getLedgersInfoAsList().size(), 2); }",0
" public void duplexWithRedirect() throws Exception { enableProtocol(HTTP_2); MockDuplexResponseBody v = enqueueResponseWithBody(new MockResponse().clearHeaders().setResponseCode(HTTP_MOVED_PERM).addHeader(""Location: /b""), new MockDuplexResponseBody().sendResponse(""/a has moved!\n"").requestIOException().exhaustResponse()); server.enqueue(new MockResponse().setBody(""this is /b"")); int m=3909; Call call = client.newCall(new Request.Builder().url(server.url(""/"")).post(new AsyncRequestBody()).build()); try (final Response response = call.execute()) { BufferedSource t = response.body().source(); assertThat(t.readUtf8Line()).isEqualTo(""this is /b""); } BufferedSink s = ((AsyncRequestBody) (call.request().body())).takeSink(); try { s.writeUtf8(""request body\n""); s.flush(); fail(); } catch (IOException expected) { assertThat(expected.getMessage()).isEqualTo(""stream was reset: CANCEL""); } v.awaitSuccess(); assertThat(listener.recordedEventTypes()).containsExactly(""CallStart"", ""DnsStart"", ""DnsEnd"", ""ConnectStart"", ""SecureConnectStart"", ""SecureConnectEnd"", ""ConnectEnd"", ""ConnectionAcquired"", ""RequestHeadersStart"", ""RequestHeadersEnd"", ""RequestBodyStart"", ""ResponseHeadersStart"", ""ResponseHeadersEnd"", ""ResponseBodyStart"", ""ResponseBodyEnd"", ""RequestHeadersStart"", ""RequestHeadersEnd"", ""ResponseHeadersStart"", ""ResponseHeadersEnd"", ""ResponseBodyStart"", ""ResponseBodyEnd"", ""ConnectionReleased"", ""CallEnd"", ""RequestFailed""); }",0
" public void testProduceWithTopicLevelPermissions() throws PulsarAdminException, ExecutionException, InterruptedException { String topic = ""testTopicLevelPermissions""; String fullNewTopicName = admin.topics().grantPermission(fullNewTopicName, ANOTHER_USER, Sets.newHashSet(produce)); @Cleanup KProducer producer = new KProducer(fullNewTopicName, false, ""localhost"", getKafkaBrokerPort(), (TENANT + ""/"") + NAMESPACE, ""token:"" + anotherToken); int totalMsgs = 10; String messageStrPrefix = fullNewTopicName + ""_message_""; for (int i = 0; i < totalMsgs; i++) { String messageStr = messageStrPrefix + i; producer.getProducer().send(new ProducerRecord<>(fullNewTopicName, i, messageStr)).get(); } @Cleanup KConsumer adminConsumer = new KConsumer(fullNewTopicName, ""localhost"", getKafkaBrokerPort(), false, (TENANT + ""/"") + NAMESPACE, ""token:"" + adminToken, ""DemoAdminKafkaOnPulsarConsumer""); adminConsumer.getConsumer().subscribe(Collections.singleton(fullNewTopicName)); int i = 0; while (i < totalMsgs) { ConsumerRecords<Integer, String> records = adminConsumer.getConsumer().poll(Duration.ofSeconds(1)); for (ConsumerRecord<Integer, String> record : records) { Integer key = record.key(); assertEquals(messageStrPrefix + key.toString(), record.value()); i++; } } assertEquals(i, totalMsgs); ConsumerRecords<Integer, String> records = adminConsumer.getConsumer().poll(Duration.ofMillis(200)); assertTrue(records.isEmpty()); @Cleanup KConsumer anotherConsumer = new KConsumer(fullNewTopicName, ""localhost"", getKafkaBrokerPort(), false, (TENANT + ""/"") + NAMESPACE, ""token:"" + anotherToken, ""DemoAnotherKafkaOnPulsarConsumer""); anotherConsumer.getConsumer().subscribe(Collections.singleton(fullNewTopicName)); try { anotherConsumer.getConsumer().poll(Duration.ofSeconds(2)); fail(""expected TopicAuthorizationException""); } catch (TopicAuthorizationException ignore) { log.info(""Has TopicAuthorizationException.""); } }",3
